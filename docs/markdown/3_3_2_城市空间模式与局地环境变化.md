> Created on Wed Feb  2 20:18:06 2022 @author: Richie Bao-caDesign设计(cadesign.cn)

# 3.3.2 城市空间模式与局地环境变化

## A. 建立研究代码项目

1. 建立本地仓库与GitHub仓库

建立本地仓库（项目文件夹），命名为`PAPER_Urban_Spatial_Pattern_N_Local_Environmental_Changes`，并推送至GitHub端。链接地址：[PAPER_Urban_Spatial_Pattern_N_Local_Environmental_Changes](https://github.com/richieBao/PAPER_Urban_Spatial_Pattern_N_Local_Environmental_Changes)，`https://github.com/richieBao/PAPER_Urban_Spatial_Pattern_N_Local_Environmental_Changes`。


2. 建立数据库

使用[pgAdmin](https://www.pgadmin.org/)创建本地关系数据库`PAPER_Urban_Spatial_Pattern_N_Local_Environmental_Changes`，并在`Query Editor`中执行`CREATE EXTENSION postgis;`，使能够存储具有坐标系统的地理几何对象。随书写研究代码进展读写数据库。

完成项目后，从`pgAdmain`下导出（`Backup`）该数据库，可以发布，并从`pgAdmain`下导入（`Restore`）该项目数据库。也可以单独通过`Import/Export`导入，导出单独的表数据。


3. 建立配置文件

使用[YAML](https://en.wikipedia.org/wiki/YAML)文件格式，书写配置文件。


4. 项目文件结构


5. requirements文件

`requirements_install info.txt`
```txt

```


## B. 专项研究与代码实现

### B.1 背景



### B.2 研究方法与结果



#### B.2.1 研究区域


#### B.2.2 数据

| 序号  | 数据名称  | 数据来源  | 说明  |大小|数据类型|
|---|---|---|---|---|---|
| 1  | AoT_Chicago.complete.2021-12-20  | [Array of Things(AoT) 城市环境传感器](https://arrayofthings.github.io/)  |  主要包括：data, node,sensors及说明文件README  |data:39.5GB |.csv|
| 2  |  行政区域:Chicago Community Areas | [Chicago Data Portal](https://data.cityofchicago.org/)  | 方便定位传感器在城市中的位置 |/ |.shp|
| 3  | 建筑高度数据：Building Footprints (current)   | [Chicago Data Portal](https://data.cityofchicago.org/Buildings/Building-Footprints-current-/hz9b-7nh8)   | 用于建筑围合城市空间（城市峡谷）与城市环境测量值关系分析  |948MB|.geojson|
|  4 |道路中心线: Street Center Lines(current)  |[Chicago Data Portal](https://data.cityofchicago.org/Transportation/Street-Center-Lines/6imu-meau) |  探索道路类型、分布和密度等统计量与传感器测量值的关系 |72.1MB|.geojson|
|5|土地利用:Land Use Inventory for Northeast Illinois, 2015 |[CMAP DATA HUB](https://datahub.cmap.illinois.gov/group/land-use-inventories)|分析土地利用与传感器测量值的关系|553MB|.shp|
|6|芝加哥城边界: Boundaries - City| [Chicago Data Portal](https://data.cityofchicago.org/Facilities-Geographic-Boundaries/Boundaries-City/ewy2-6yfk)|研究边界|/|.shp|
|7|伊利诺伊州激光雷达数据|[伊利诺斯州草原地质调查研究所（Illinois state geological survey - prairie research institute）](https://www.arcgis.com/apps/webappviewer/index.html?id=44eb65c92c944f3e8b231eb1e2814f4d)|提取植被信息，含高中低三个分类|1.4T|.las|


##### B.2.2.1 数据获取及预处理


###### 1) 环境传感器说明

下载的AoT数据包括:

1. `data(data.csv.gz)`: 按时间戳升序排列的传感器测量数据;
2. `nodes.csv`: 节点元数据。主要包括节点的ID，经纬度，时间戳，信息描述等信息；
3. `sensors.csv`： 传感器元数据。 包括传感器测量内容，浓度单位，最小最大值，以及传感器说明文件；
4. `provenance.csv`：项目版本，起止时间和数据下地址等；
5. `README.md`：说明文件。对各文件的解释及数据参数的说明。

根据`sensors.csv`文件，分类测量内容为气体类、颗粒物、热环境、噪音、光、电磁场和惯性测量等内容。在后续分析过程中，将根据分类内容分别分析前5类。

| 序号  | 分类  | 测量内容  | 单位  | 说明  |
|---|---|---|---|---|
| 1  | 气体类  | CO（一氧化碳，carbon monoxide）  | ppm   | CO是一种无色、无味的气体。当大量吸入时，对人体造成伤害。某物燃烧时会释放CO，在户外，空气中的CO主要来源于燃烧化石燃料的各类汽车和机械；在户内未通风条件下，有泄露的煤油、燃气、烟筒、火炉等，影响室内空气质量。 <br>吸入高浓度CO，会减少血液中输送到心脏和大脑等关键器官的氧气量。在室内封闭环境下，会导致头晕、神志不清、昏迷和死亡；在户外，非常高浓度的CO不太可能发生，但是当达到一定水平，会对某些类型的心脏病患者造成特别影响。在健身或压力增大等心脏需要更多氧气条件下，导致进入心脏的氧气减少，并伴有胸痛（胸绞痛）。 |
| 2 |   |  H2S（硫化氢，Hydrogen Sulfide） | ppm  |  H2S是一种剧毒有害气体，透明、散发出臭鸡蛋的气味。这种气体具有高度的爆炸性，长时间暴漏在这种气体中可能会致命。H2S长存在于制造工厂、炼油厂和气体处理设施中。 |
| 3|   | NO<sub>2</sub>(二氧化氮, Nitrogen Dioxide)  | ppm  | NO<sub>2</sub>是一种气态的空气污染物，由氮和氧组成（氮氧化物）。当煤、石油、天然气或柴油等化石燃料在高温下燃烧时产生。 汽车是最大的排放源，其次是放电厂、柴油驱动的重型建筑设备和其它可移动发动机及工业锅炉。室外空气中的二氧化氮和其他氮氧化物会造成颗粒污染和产生臭氧的化学反应。 NO<sub>2</sub>会对肺部造成一系列有害影响，包括：气道炎症、咳嗽、气喘、降低肺功能、增加哮喘发作，对肺癌患者造成更大风险。同时，NO<sub>2</sub>与心血管疾病、新生儿出生体重过轻及过早死亡风险增加有关。<br>室内的煤油或燃气加热器和煤气炉灶也会大量产生NO<sub>2</sub>，如果没有完全排放到室外，室内浓度会升高。|
| 4  |   | O<sub>3</sub> (臭氧, trioxygen)  | ppm  |  O<sub>3</sub>由3个氧原子结合在一起，有一种特殊的刺鼻气味。因为自身不稳定在低层大气中分解为 O<sub>2</sub>。O<sub>3</sub>是由O<sub>2</sub>在地球大气中的紫外线（UV, ultraviolet）和放电作用下形成。它的浓度很低，在平流层的臭氧层（ozone layer）中浓度最高。臭氧层通过过滤大部分紫外线辐射保护地球生物。地面上的O<sub>3</sub>，通常是太阳光和汽车、工业等来源排放物相互作用产生，对人类的健康有害。例如， 对眼鼻喉和下呼吸道刺激和炎症（咳嗽、喉咙痛或胸部不舒服）；肺功能下降（不能像平常一样深呼吸或大力呼吸）；引起哮喘和慢性呼吸系统疾病；呼吸道感染的易感性增加。|
| 5  |   | oxidizing_gases（氧化气体）  | ppm  |  oxidizing_gases包括任何含氧高于大气浓度（23-25%）的气体，如氧化氮（nitrogen oxides）、卤素气体（halogen gases，如如氯（chlorine）和氟（fluorine）。）这些气体能与可燃物质发生迅速而聚类的反应。可燃物质包括含碳的有机物质，例如大多数可燃气体，可燃液体、油、润滑脂（greases），很多塑料和植物；金属粉末；及其它可氧化物质，例如肼（hydrazine）、氢（hydrogen）、 氢化物（hydrides）、硫（sulphur）或硫化合物，硅（silicon）和氨（ammonia）或氨化合物。 |
| 6  |  |   reducing_gases（还原性气体） | ppm  | 指化学反应中经常作为还原剂使用的气体。例如氢气（hydrogen）、一氧化碳(carbon monoxide)等。|
| 7  |   |  SO<sub>2</sub>(二氧化硫, Sulfur Dioxide) |  ppm | SO<sub>2</sub> 可被用作更大种类气态硫氧化物SO<sub>x</sub>（gaseous sulfur oxides）的指示物（ indicator）。 大气中发现其它气态硫，例如SO<sub>3</sub>的浓度应小于SO<sub>2</sub>。减少SO<sub>2</sub>的控制措施通常可以预期减少人们暴漏到所有SO<sub>x</sub>中的机会。对减少颗粒状硫污染物（例如细硫酸盐颗粒，fine sulfate particles）的形成同样重要。<br>SO<sub>2</sub>最主要来源于发电厂和其它工业设施的化石燃料燃烧；较小来源于从矿石中提取金属等工业过程，火山等自然资源，机车、轮船和其它车辆，及重型设备，其燃烧的燃料含硫量较高。<br>短期接触SO<sub>2</sub>会损害人体呼吸系统，是呼吸困难。哮喘患者、尤其儿童对SO<sub>2</sub>的这些影响尤其敏感。导致空气中SO<sub>2</sub>高浓度形成的排放也会导致其它氧化物（SO<sub>x</sub>）的形成。与大气中的其它化合物发生反应，形成小颗粒。这些颗粒导致了微粒物质污染（ particulate matter，PM）。小颗粒可以渗入人的肺部，如果达到一定量则会导致健康问题。自然中，高浓度的气态硫会破坏植被的树叶，降低其生长速度。|
| 8  | 颗粒物，微粒(particulate matter,PM)  | pm<sub>1</sub>,pm<sub>2.5</sub>, pm<sub>5</sub>,pm<sub>10</sub> | μg/m<sup>3</sup>  |  PM代表颗粒物质（也称之为颗粒污染，particle pollution），是空气中存在的固体颗粒和液滴的混合物。有些颗粒，例如灰尘粉末、煤烟等大到肉眼可见；另一些则很小，只能用电子显微镜观察。<br>颗粒污染包括：PM<sub>10</sub>可吸入颗粒物，直径一般在10微米（micrometers）及一下；PM<sub>2.5</sub>可吸入的细小微粒，直径一般在2.5微米一下。这些颗粒有许多大小和形状，可由数百种不同的化学物质组成。<br>颗粒污染有些是直接从源头排放，例如建筑工地、未铺设的道路、田地、烟囱或火灾等。大气中的大多数颗粒由二氧化硫和氧化物等化学物质的复杂反应形成，通常是发电厂、工业和汽车排放的污染物。<br>颗粒物包含微小的固体或液滴，因为非常小，足可以被吸入并导致严重的健康问题。一些小于10微米的颗粒可以进入人的肺部，一些甚至可能进入到人的血液中。直径小于2.5微米的颗粒，也称为细颗粒（ fine particles，或者PM<sub>2.5</sub>），对健康构成最大的风险。PM<sub>2.5</sub>也是雾霾的主要起因。 |
| 9  | 热环境  | 温度（temperature）   |  C | 在强调温度的时空分布时，通常使用热状态（thermal regime）一词。温度在塑造水生态系统的结构和功能时起到基本作用。例如在物理（Physical）层面上， 影响水密度（Water density）、热分层（thermal stratification），氧和其它化学物质的溶解度（solubility ）；在化学（Chemical）层面上，影响养分循环速率、污染物转换速率；在生物（Biological）层面上，影响生物的生存、生长、繁殖、发展、行为、生境偏好和竞争。温度同样影响人们活动的热舒适度，以及某些事物发生的起因，例如在加热的排放物附近聚集的鱼群，不透水表面影响等。|
| 10  |   |  湿度（humidity） | 相对湿度（Relative Humidity, RH）  | RH是空气中湿度的量度，与潜在的饱和水平相比较（potential saturation level）。温暖的空气可以容纳更多的水分，当接近100%的湿度时，空气中的水分会凝结（露点）。RH是热舒适性的决定条件之一。  |
| 11  |   | 大气压（pressure）  |  hPa（Hectopascal Pressure Unit） |  百帕斯卡是帕斯卡的100倍，帕斯卡是国际单位制的压力单位。百帕斯卡是测量大气压力或气压的国际单位。1百帕斯卡等于100帕斯卡。 |
| 12  | 噪音  | octave_n_intensity  | dB（分贝）  | 声压级计算（Sound Pressure Level Calculation），每65秒报告一次周围的噪音水平（1分钟间隔，5秒采样）。从麦克风采样音频5秒，以dBm（毫瓦分贝）计算噪音水平。声压级的估计是基于傅里叶变换。通过傅里叶变换将麦克风采集到的数据转换成频率强度域。在频率强度域中，选取22hz ~ 22khz的频率计算给定倍频带（Octave_band用于控制倍频，默认为1/1倍频。octave_n_intensity，默认10个。）下的平均dBm。 <br> 噪音通常来源于交通工具、工厂机器设备、建筑施工和人们的社会和家庭活动等。噪音对人类的危害主要表现在听力的损伤、睡眠干扰、人体的生理和心理影响。当在100分贝左右噪音环境下工作会感到刺耳、难受、甚至引起暂时性耳聋。超过140分贝的噪音会引起眼球振动，视觉模糊，呼吸、脉搏和血压都会发生波动。甚至会使用、全身血管收缩，供血减少，说话能力了受到影响。|
| 13  | 光  | 光强度（light intensity）/可见光强度（visible light intensity）  | 照度：uW/cm<sup>2</sup>（辐照度（irradiance）单位，落在单位表面上的能量）； lux（光度单位，落在单位表面上的可见光）。  |  人工照明在为人类带来好处的同时，对环境也带来了负面的影响。例如光污染用来描述过度的夜间人工照明，尤其是在大型的城市聚集区。这对自然适应夜间生活的动植物和人类健康产生负面影响。同时，城市区域的高层建筑高度和密度也对城市室外和室内的太阳光照时长带来直接的影响。 |
| 14  |   | 红外光谱强度（ir_intensity）  | uW/cm<sup>2</sup>  |  / |
| 15 |   | 紫外线强度（uv_intensity）  | uW/cm<sup>2</sup>  | 臭氧层的损耗减少了大气吸收紫外线避免生物受到伤害的能力。过度暴露于紫外线下影响人类的健康，这包括皮肤癌等各类皮肤疾病，又如光化性角化病、 皮肤过早老化等；同时会增加某些白内障的可能性及眼睛损伤；也会抑制人体免疫系统的正常功能等。|
| 16  | 电磁场（EMFs ，Electric and magnetic fields）  | magnetic_field_x/y/z  | mG  | 除地球磁场外，电磁场由各类电子设备产生，是人类日常生活的一部分。目前没有证据证明其于任何疾病有关。  |
| 17  | 惯性测量装置（inertial measurement unit，IMU）  | 加速度（acceleration_x/y/z）  | mg  | /  |



> 主要参考 [EPA](https://www.epa.gov/)(U.S. Environmental Protection Agency)

`sensors.csv`文件包含了所有已发布数据（data文件）传感器信息。从给定链接中可以获取传感器详细说明。使用`pd.read_csv()`读取`sensors.csv`文件查看。
```python
AoT_sensors_fp=cfg['AoT']['AoT_sensors_fp']
AoT_nodes_df=pd.read_csv(AoT_sensors_fp,sep=",",header=0)
print(AoT_nodes_df)
```

`sensors.csv`文件包含的数据信息主要有：

* `ontology` - 传感器测量对象.
* `subsystem` - 包含传感器的子系统.
* `sensor` - 传感器名称.
* `parameter` - 传感器参数.
* `hrf_unit` - HRF值（转换传感器测量值后）物理单位.
* `hrf_minval` - 依据传感器说明，HRF最小值，用于过滤数值（异常值）；
* `hrf_maxval` - 依据传感器说明，HRF最大值，用于过滤数值（异常值）；
* `datasheet` - 传感器说明书的下载地址。


|ontology                                        |subsystem |sensor         |parameter              |hrf_unit   |hrf_minval|hrf_maxval|datasheet                                                                                |
|------------------------------------------------|----------|---------------|-----------------------|-----------|----------|----------|-----------------------------------------------------------------------------------------|
|/sensing/air_quality/gases/co                   |chemsense |co             |concentration          |ppm        |0         |1000      |https://github.com/waggle-sensor/sensors/raw/master/sensors/datasheets/co.pdf            |
|/sensing/air_quality/gases/h2s                  |chemsense |h2s            |concentration          |ppm        |0         |50        |https://github.com/waggle-sensor/sensors/raw/master/sensors/datasheets/h2s.pdf           |
|/sensing/air_quality/gases/no2                  |chemsense |no2            |concentration          |ppm        |0         |20        |https://github.com/waggle-sensor/sensors/raw/master/sensors/datasheets/no2.pdf           |
|/sensing/air_quality/gases/o3                   |chemsense |o3             |concentration          |ppm        |0         |20        |https://github.com/waggle-sensor/sensors/raw/master/sensors/datasheets/o3.pdf            |
|/sensing/air_quality/gases/oxidizing_gases      |chemsense |oxidizing_gases|concentration          |ppm        |0         |100       |https://github.com/waggle-sensor/sensors/blob/master/sensors/chemsense                   |
|/sensing/air_quality/gases/reducing_gases       |chemsense |reducing_gases |concentration          |ppm        |0         |20        |https://github.com/waggle-sensor/sensors/blob/master/sensors/chemsense                   |
|/sensing/air_quality/gases/so2                  |chemsense |so2            |concentration          |ppm        |0         |20        |https://github.com/waggle-sensor/sensors/raw/master/sensors/datasheets/so2.pdf           |
|/sensing/air_quality/particulates/particle_count|alphasense|opc_n2         |bins                   |counts     |0         |          |https://github.com/waggle-sensor/sensors/raw/master/sensors/datasheets/opcn2.pdf         |
|/sensing/air_quality/particulates/pm_10         |alphasense|opc_n2         |pm10                   |μg/m^3     |0         |          |https://github.com/waggle-sensor/sensors/raw/master/sensors/datasheets/opcn2.pdf         |
|/sensing/air_quality/particulates/pm_2_5        |alphasense|opc_n2         |pm2_5                  |μg/m^3     |0         |          |https://github.com/waggle-sensor/sensors/raw/master/sensors/datasheets/opcn2.pdf         |
|/sensing/air_quality/particulates/pm_1          |alphasense|opc_n2         |pm1                    |μg/m^3     |0         |          |https://github.com/waggle-sensor/sensors/raw/master/sensors/datasheets/opcn2.pdf         |
|/sensing/air_quality/particulates/particle_count|plantower |pms7003        |point_3um_particle     |μg/m^3     |0         |          |https://github.com/waggle-sensor/sensors/raw/master/sensors/datasheets/pms7003.pdf       |
|/sensing/air_quality/particulates/particle_count|plantower |pms7003        |point_5um_particle     |μg/m^3     |0         |          |https://github.com/waggle-sensor/sensors/raw/master/sensors/datasheets/pms7003.pdf       |
|/sensing/air_quality/particulates/particle_count|plantower |pms7003        |1um_particle           |μg/m^3     |0         |          |https://github.com/waggle-sensor/sensors/raw/master/sensors/datasheets/pms7003.pdf       |
|/sensing/air_quality/particulates/particle_count|plantower |pms7003        |2_5um_particle         |μg/m^3     |0         |          |https://github.com/waggle-sensor/sensors/raw/master/sensors/datasheets/pms7003.pdf       |
|/sensing/air_quality/particulates/particle_count|plantower |pms7003        |5um_particle           |μg/m^3     |0         |          |https://github.com/waggle-sensor/sensors/raw/master/sensors/datasheets/pms7003.pdf       |
|/sensing/air_quality/particulates/particle_count|plantower |pms7003        |10um_particle          |μg/m^3     |0         |          |https://github.com/waggle-sensor/sensors/raw/master/sensors/datasheets/pms7003.pdf       |
|/sensing/air_quality/particulates/pm_1          |plantower |pms7003        |pm1_cf                 |μg/m^3     |0         |          |https://github.com/waggle-sensor/sensors/raw/master/sensors/datasheets/pms7003.pdf       |
|/sensing/air_quality/particulates/pm_1          |plantower |pms7003        |pm1_atm                |μg/m^3     |0         |          |https://github.com/waggle-sensor/sensors/raw/master/sensors/datasheets/pms7003.pdf       |
|/sensing/air_quality/particulates/pm_2_5        |plantower |pms7003        |pm25_cf                |μg/m^3     |0         |          |https://github.com/waggle-sensor/sensors/raw/master/sensors/datasheets/pms7003.pdf       |
|/sensing/air_quality/particulates/pm_2_5        |plantower |pms7003        |pm25_atm               |μg/m^3     |0         |          |https://github.com/waggle-sensor/sensors/raw/master/sensors/datasheets/pms7003.pdf       |
|/sensing/air_quality/particulates/pm_10         |plantower |pms7003        |pm10_cf                |μg/m^3     |0         |          |https://github.com/waggle-sensor/sensors/raw/master/sensors/datasheets/pms7003.pdf       |
|/sensing/air_quality/particulates/pm_10         |plantower |pms7003        |pm10_atm               |μg/m^3     |0         |          |https://github.com/waggle-sensor/sensors/raw/master/sensors/datasheets/pms7003.pdf       |
|/sensing/meteorology/humidity                   |metsense  |hih4030        |humidity               |RH         |0         |100       |https://github.com/waggle-sensor/sensors/raw/master/sensors/datasheets/hih4030.pdf       |
|/sensing/meteorology/humidity                   |metsense  |htu21d         |humidity               |RH         |0         |100       |https://github.com/waggle-sensor/sensors/raw/master/sensors/datasheets/htu21d.pdf        |
|/sensing/meteorology/pressure                   |metsense  |bmp180         |pressure               |hPa        |300       |1100      |https://github.com/waggle-sensor/sensors/raw/master/sensors/datasheets/bmp180.pdf        |
|/sensing/meteorology/temperature                |metsense  |bmp180         |temperature            |C          |-40       |85        |https://github.com/waggle-sensor/sensors/raw/master/sensors/datasheets/bmp180.pdf        |
|/sensing/meteorology/temperature                |metsense  |htu21d         |temperature            |C          |-40       |125       |https://github.com/waggle-sensor/sensors/raw/master/sensors/datasheets/htu21d.pdf        |
|/sensing/meteorology/temperature                |metsense  |pr103j2        |temperature            |C          |-55       |80        |https://github.com/waggle-sensor/sensors/raw/master/sensors/datasheets/pr103j2.pdf       |
|/sensing/meteorology/temperature                |metsense  |tmp112         |temperature            |C          |-40       |125       |https://github.com/waggle-sensor/sensors/raw/master/sensors/datasheets/tmp112.pdf        |
|/sensing/meteorology/temperature                |metsense  |tsys01         |temperature            |C          |-40       |125       |https://github.com/waggle-sensor/sensors/raw/master/sensors/datasheets/tsys01.pdf        |
|/sensing/physical/audio/spl                     |audio     |microphone     |octave_total_intensity |dB         |          |140       |https://github.com/waggle-sensor/plugin_manager/tree/master/plugins/audio_spl            |
|/sensing/physical/audio/spl                     |audio     |microphone     |octave_1_intensity     |dB         |          |140       |https://github.com/waggle-sensor/plugin_manager/tree/master/plugins/audio_spl            |
|/sensing/physical/audio/spl                     |audio     |microphone     |octave_2_intensity     |dB         |          |140       |https://github.com/waggle-sensor/plugin_manager/tree/master/plugins/audio_spl            |
|/sensing/physical/audio/spl                     |audio     |microphone     |octave_3_intensity     |dB         |          |140       |https://github.com/waggle-sensor/plugin_manager/tree/master/plugins/audio_spl            |
|/sensing/physical/audio/spl                     |audio     |microphone     |octave_4_intensity     |dB         |          |140       |https://github.com/waggle-sensor/plugin_manager/tree/master/plugins/audio_spl            |
|/sensing/physical/audio/spl                     |audio     |microphone     |octave_5_intensity     |dB         |          |140       |https://github.com/waggle-sensor/plugin_manager/tree/master/plugins/audio_spl            |
|/sensing/physical/audio/spl                     |audio     |microphone     |octave_6_intensity     |dB         |          |140       |https://github.com/waggle-sensor/plugin_manager/tree/master/plugins/audio_spl            |
|/sensing/physical/audio/spl                     |audio     |microphone     |octave_7_intensity     |dB         |          |140       |https://github.com/waggle-sensor/plugin_manager/tree/master/plugins/audio_spl            |
|/sensing/physical/audio/spl                     |audio     |microphone     |octave_8_intensity     |dB         |          |140       |https://github.com/waggle-sensor/plugin_manager/tree/master/plugins/audio_spl            |
|/sensing/physical/audio/spl                     |audio     |microphone     |octave_9_intensity     |dB         |          |140       |https://github.com/waggle-sensor/plugin_manager/tree/master/plugins/audio_spl            |
|/sensing/physical/audio/spl                     |audio     |microphone     |octave_10_intensity    |dB         |          |140       |https://github.com/waggle-sensor/plugin_manager/tree/master/plugins/audio_spl            |
|/sensing/physical/ir                            |lightsense|tsl260rd       |intensity              |uW/cm^2    |0         |132       |https://github.com/waggle-sensor/sensors/raw/master/sensors/datasheets/tsl260rd.pdf      |
|/sensing/physical/light                         |lightsense|apds_9006_020  |intensity              |lux        |0         |1000      |https://github.com/waggle-sensor/sensors/raw/master/sensors/datasheets/apd9006020.pdf    |
|/sensing/physical/light                         |lightsense|mlx75305       |intensity              |uW/cm^2    |0         |160       |https://github.com/waggle-sensor/sensors/raw/master/sensors/datasheets/mlx75305c.pdf     |
|/sensing/physical/light                         |lightsense|tsl250rd       |intensity              |uW/cm^2    |0         |124       |https://github.com/waggle-sensor/sensors/raw/master/sensors/datasheets/tsl250rd.pdf      |
|/sensing/physical/magnetic_field                |lightsense|hmc5883l       |magnetic_field_x       |mG         |-8000     |8000      |https://github.com/waggle-sensor/sensors/raw/master/sensors/datasheets/hmc5883l.pdf      |
|/sensing/physical/magnetic_field                |lightsense|hmc5883l       |magnetic_field_y       |mG         |-8000     |8000      |https://github.com/waggle-sensor/sensors/raw/master/sensors/datasheets/hmc5883l.pdf      |
|/sensing/physical/magnetic_field                |lightsense|hmc5883l       |magnetic_field_z       |mG         |-8000     |8000      |https://github.com/waggle-sensor/sensors/raw/master/sensors/datasheets/hmc5883l.pdf      |
|/sensing/physical/sound_level                   |metsense  |spv1840lr5h_b  |intensity              |dB         |0         |121       |https://github.com/waggle-sensor/sensors/raw/master/sensors/datasheets/spv1840lr5h-b.pdf |
|/sensing/physical/uv                            |lightsense|ml8511         |intensity              |uW/cm^2    |0         |15        |https://github.com/waggle-sensor/sensors/raw/master/sensors/datasheets/ml8511.pdf        |
|/sensing/physical/vibration                     |metsense  |mma8452q       |acceleration_x         |mg         |-8000     |8000      |https://github.com/waggle-sensor/sensors/raw/master/sensors/datasheets/mma8452q.pdf      |
|/sensing/physical/vibration                     |metsense  |mma8452q       |acceleration_y         |mg         |-8000     |8000      |https://github.com/waggle-sensor/sensors/raw/master/sensors/datasheets/mma8452q.pdf      |
|/sensing/physical/vibration                     |metsense  |mma8452q       |acceleration_z         |mg         |-8000     |8000      |https://github.com/waggle-sensor/sensors/raw/master/sensors/datasheets/mma8452q.pdf      |
|/system/environment/humidity                    |lightsense|hih6130        |humidity               |RH         |0         |100       |https://github.com/waggle-sensor/sensors/raw/master/sensors/datasheets/hih6130.pdf       |
|/system/environment/ir                          |chemsense |si1145         |ir_intensity           |uW/cm^2    |0         |          |https://github.com/waggle-sensor/sensors/raw/master/sensors/datasheets/si1145uv.pdf      |
|/system/environment/light                       |chemsense |si1145         |visible_light_intensity|uW/cm^2    |0         |          |https://github.com/waggle-sensor/sensors/raw/master/sensors/datasheets/si1145uv.pdf      |
|/system/environment/temperature                 |lightsense|hih6130        |temperature            |C          |-25       |85        |https://github.com/waggle-sensor/sensors/raw/master/sensors/datasheets/hih6130.pdf       |
|/system/environment/humidity                    |wagman    |htu21d         |humidity               |RH         |0         |100       |https://github.com/waggle-sensor/sensors/raw/master/sensors/datasheets/htu21d.pdf        |
|/system/environment/temperature                 |wagman    |htu21d         |temperature            |C          |-40       |125       |https://github.com/waggle-sensor/sensors/raw/master/sensors/datasheets/htu21d.pdf        |
|/system/environment/temperature                 |wagman    |temperatures   |battery                |C          |-55       |125       |https://github.com/waggle-sensor/core/blob/master/scripts/status-service                 |
|/system/environment/temperature                 |wagman    |temperatures   |brainplate             |C          |-55       |125       |https://github.com/waggle-sensor/core/blob/master/scripts/status-service                 |
|/system/environment/temperature                 |wagman    |temperatures   |ep_heatsink            |C          |-55       |125       |https://github.com/waggle-sensor/core/blob/master/scripts/status-service                 |
|/system/environment/temperature                 |wagman    |temperatures   |nc_heatsink            |C          |-55       |125       |https://github.com/waggle-sensor/core/blob/master/scripts/status-service                 |
|/system/environment/temperature                 |wagman    |temperatures   |powersupply            |C          |-55       |125       |https://github.com/waggle-sensor/core/blob/master/scripts/status-service                 |
|/system/environment/temperature                 |lightsense|tmp421         |temperature            |C          |-55       |127       |https://github.com/waggle-sensor/sensors/raw/master/sensors/datasheets/tmp421.pdf        |
|/system/environment/uv                          |chemsense |si1145         |uv_intensity           |uW/cm^2    |          |          |https://github.com/waggle-sensor/sensors/raw/master/sensors/datasheets/si1145uv.pdf      |
|/system/other/flow_rate                         |alphasense|opc_n2         |sample_flow_rate       |           |          |          |https://github.com/waggle-sensor/sensors/raw/master/sensors/datasheets/opcn2.pdf         |
|/system/other/pressure                          |chemsense |lps25h         |pressure               |hPa        |260       |1260      |https://github.com/waggle-sensor/sensors/raw/master/sensors/datasheets/lps25h.pdf        |
|/system/other/humidity                          |chemsense |sht25          |humidity               |RH         |0         |100       |https://github.com/waggle-sensor/sensors/raw/master/sensors/datasheets/sht25.pdf         |
|/system/other/id                                |chemsense |chemsense      |id                     |id         |          |          |https://github.com/waggle-sensor/sensors                                                 |
|/system/other/id                                |metsense  |metsense       |id                     |id         |          |          |https://github.com/waggle-sensor/sensors                                                 |
|/system/other/id                                |alphasense|opc_n2         |fw                     |           |          |          |https://github.com/waggle-sensor/sensors/raw/master/sensors/datasheets/opcn2.pdf         |
|/system/other/light                             |metsense  |tsl250rd       |intensity              |uW/cm^2    |0         |124       |https://github.com/waggle-sensor/sensors/raw/master/sensors/datasheets/tsl250rd.pdf      |
|/system/other/temperature                       |chemsense |lps25h         |temperature            |C          |-30       |105       |https://github.com/waggle-sensor/sensors/raw/master/sensors/datasheets/lps25h.pdf        |
|/system/other/sampling_period                   |alphasense|opc_n2         |sampling_period        |           |          |          |https://github.com/waggle-sensor/sensors/raw/master/sensors/datasheets/opcn2.pdf         |
|/system/other/temperature                       |chemsense |at0            |temperature            |C          |-40       |125       |https://github.com/waggle-sensor/sensors                                                 |
|/system/other/temperature                       |chemsense |at1            |temperature            |C          |-40       |125       |https://github.com/waggle-sensor/sensors                                                 |
|/system/other/temperature                       |chemsense |at2            |temperature            |C          |-40       |125       |https://github.com/waggle-sensor/sensors                                                 |
|/system/other/temperature                       |chemsense |at3            |temperature            |C          |-40       |125       |https://github.com/waggle-sensor/sensors                                                 |
|/system/other/temperature                       |chemsense |sht25          |temperature            |C          |-40       |125       |https://github.com/waggle-sensor/sensors/raw/master/sensors/datasheets/sht25.pdf         |
|/system/loadavg                                 |nc        |loadavg        |loadavg1               |loadavg    |0         |          |https://github.com/waggle-sensor/plugin_manager/tree/master/plugins/status.plugin        |
|    ...                        |        |      |             |   |       |          |      |

###### 2) 环境传感器布局

为读取AoT数据，并写入到本地数据库中，首先建立`database.py`文件，将读写PostgreSQL数据库。同时，包括读取.yml格式的配置文件。

`database.py`
```python
# -*- coding: utf-8 -*-
"""
Created on Thu Feb  3 20:10:26 2022

@author: Richie Bao-caDesign设计(cadesign.cn)
"""

def gpd2postSQL(gdf,table_name,**kwargs):  
    '''
    function - 将GeoDataFrame格式数据写入PostgreSQL数据库
    
    Paras:
        gdf - GeoDataFrame格式数据，含geometry字段（几何对象，点、线和面，数据值对应定义的坐标系统）
        table_name - 写入数据库中的表名
        **kwargs - 连接数据库相关信息，包括myusername（数据库的用户名），mypassword（用户密钥），mydatabase（数据库名）
    '''    
    from sqlalchemy import create_engine
    #The URI should start with postgresql:// instead of postgres://. SQLAlchemy used to accept both, but has removed support for the postgres name.
    engine=create_engine("postgresql://{myusername}:{mypassword}@localhost:5432/{mydatabase}".format(myusername=kwargs['myusername'],mypassword=kwargs['mypassword'],mydatabase=kwargs['mydatabase']))  
    gdf.to_postgis(table_name, con=engine, if_exists='replace', index=False,)  
    print("_"*50)
    print('The GeoDataFrame has been written to the PostgreSQL database.The table name is {}.'.format(table_name))

def postSQL2gpd(table_name,geom_col='geometry',**kwargs):    
    '''
    function - 读取PostgreSQL数据库中的表为GeoDataFrame格式数据
    
    Paras:
        table_name - 待读取数据库中的表名
        geom_col='geometry' - 几何对象，常规默认字段为'geometry'
        **kwargs - 连接数据库相关信息，包括myusername（数据库的用户名），mypassword（用户密钥），mydatabase（数据库名）
    '''
    from sqlalchemy import create_engine
    import geopandas as gpd   
    
    engine=create_engine("postgresql://{myusername}:{mypassword}@localhost:5432/{mydatabase}".format(myusername=kwargs['myusername'],mypassword=kwargs['mypassword'],mydatabase=kwargs['mydatabase']))  
    gdf=gpd.read_postgis(table_name, con=engine,geom_col=geom_col)
    print("_"*50)
    print('The data has been read from PostgreSQL database. The table name is {}.'.format(table_name))    
    return gdf 

def cfg_load_yaml(ymlf_fp):
    '''
    读取 yaml 格式的配置文件

    Parameters
    ----------
    ymlf_fp : string
        配置文件路径.

    Returns
    -------
    cfg : yaml-dict
        读取到python中的配置信息.
    '''
    import yaml
    with open (ymlf_fp,'r') as ymlfile:
        cfg=yaml.safe_load(ymlfile)   
    return cfg
```

对AoT数据预处理的代码均写在`AoTData_preprocessing.py`下。读取`nodes.csv`数据，并将其写入到数据库。`nodes`数据给出了传感器的布置位置，在读取`data`数据并根据需求处理后（例如提取不同测量内容，并进一步分析后），需要根据各自给出的`node_id`字段，合并数据定位分析结果的空间分布，用于空间分析。

为定位传感器的空间位置，读取叠加行政区域。

`AoTData_preprocessing.py`
```python
# -*- coding: utf-8 -*-
"""
Created on Fri Feb  4 11:00:11 2022

@author: Richie Bao-caDesign设计(cadesign.cn)
"""

def AoT_nodes2gdf(nodes_fn,epsg=4326):
    '''
    读取AoT_nodes数据，并写入数据库

    Parameters
    ----------
    nodes_fn : string
        AoT_nodes文件路径.
    epsg : int, optional
        坐标投影系统，epsg编号. The default is 4326.

    Returns
    -------
    AoT_nodes_gdf : GeoDataFrame
        AoT_nodes的GeoDataFrame格式.

    '''
    import pandas as pd
    import geopandas as gpd
    from shapely.geometry import Point
    
    AoT_nodes_df=pd.read_csv(AoT_nodes_fp,sep=",",header=0)
    AoT_nodes_df["geometry"]=AoT_nodes_df.apply(lambda row:Point(row.lon,row.lat),axis=1) #使用shapely库建立几何点数据
    AoT_nodes_gdf=gpd.GeoDataFrame(AoT_nodes_df,crs=4326)
    if epsg!=4326:
        AoT_nodes_gdf.to_crs(epsg,inplace=True)
        
    print("nodes columns:{}".format(AoT_nodes_gdf.columns))
    return AoT_nodes_gdf

if __name__=="__main__":
    import sys,os
    sys.path.append('..')  
    
    from database import postSQL2gpd,gpd2postSQL,cfg_load_yaml   
    import pickle
    parent_path=os.path.dirname(os.getcwd())

    cfg=cfg_load_yaml('./config.yml')  
    UN=cfg["postgreSQL"]["myusername"]
    PW=cfg["postgreSQL"]["mypassword"]
    DB=cfg["postgreSQL"]["mydatabase"] 
    GC='geometry'     

    AoT_nodes_fp=cfg['AoT']['AoT_nodes_fp']
    Chicago_epsg=cfg['Chicago_epsg']

    #A. AoT-nodes信息读取并写入数据库
    AoT_nodes_gdf=AoT_nodes2gdf(AoT_nodes_fp,Chicago_epsg)
    AoT_nodes_TN=cfg['table_name']['AoT_nodes_TN']    
    gpd2postSQL(AoT_nodes_gdf,table_name=AoT_nodes_TN,myusername=UN,mypassword=PW,mydatabase=DB) 
    AoT_nodes_gdf=postSQL2gpd(table_name=AoT_nodes_TN,geom_col=GC,myusername=UN,mypassword=PW,mydatabase=DB)
    
    #B.读取行政区划数据，并写入数据库，用于定位AoT分布
    import geopandas as gpd
    Chicago_Community_Areas_fn=cfg['raw_data']['Chicago_Community_Areas_fn']
    Chicago_community_areas=gpd.read_file(Chicago_Community_Areas_fn)
    Chicago_community_areas_TN=cfg['table_name']['Chicago_community_areas_TN']
    gpd2postSQL(Chicago_community_areas.to_crs(Chicago_epsg),table_name=Chicago_community_areas_TN,myusername=UN,mypassword=PW,mydatabase=DB)
    Chicago_community_areas=postSQL2gpd(table_name=Chicago_community_areas_TN,geom_col=GC,myusername=UN,mypassword=PW,mydatabase=DB)  
```

<a href=""><img src="./imgs/3_3_2_01.png" height="auto" width="auto" title="caDesign"></a>

AoT在芝加哥布局了126个测量点位，位于道路街口，临湖道路、芝加哥大学校园内、或者邻近较大公园的附近道路、及中心城区、高速等不同环境，基本涵盖了芝加哥城全城区域。（为详细查看AoT在地图上的分布，可以转换`nodes`数据为.kml数据后，在[Google Earth](https://earth.google.com/web/)下读入）

`nodes.csv`读取的节点元数据个字段解释如下（来源于`README.md`文件）：

* `node_id` - 节点ID；
* `project_id` - 节点管理项目ID；
* `vsn` - 节点的公共名称，并标识在传感器设备上；
* `address` - 节点安装的街道地址；
* `lat` - 维度；
* `lon` - 精度；
* `description` - 对节点传感器构建和配置更详细的描述；
* `start_timestamp` - 节点安装的开始时间戳；
* `end_timestamp` - 节点安装结束的时间戳。

根据`lat`和`lon`建立GeoDataFrame的`geometry`几何对象。`node_id`用于数据合并关联字段。

###### 3) 分类数据

气体类、颗粒物、热环境、噪音、光等传感器测量的数据均混合写在`data`文件下。需要将数据测量内容分离出来单独保存，具体测量内容包含于`data`数据的`parameter`字段。编写`total_sample_length_csv()`方法，计算样本长度，并提取`parameter`字段pickle写入到单独文件下，方便后续数据分类提取时调用。

`AoTData_preprocessing.py`
```python
def total_sample_length_csv(csv_fp,chunksize,category=None,save_fp=None):
    '''
    读取.csv样本数据，计算样本总长度（行数）;并给定分类字段，提取分类名并保存

    Parameters
    ----------
    csv_fp : string
        .csv文件路径.
    chunksize : int
        数据块大小（单独一次读取的行数）.
    category : string(column name), optional
        分类字段. The default is None.
    save_fp : string, optional
        分类名保存路径. The default is None.

    Returns
    -------
    category_set : set
        分类名集合.

    '''
    from tqdm.auto import tqdm
    import pandas as pd
    import pickle
    
    count=0
    set_list=[]
    for chunk in tqdm(pd.read_csv(csv_fp,chunksize=chunksize)):
        count+= 1 #样本分组数
        last_len=len(chunk)  #最后一组的样本数量
        if category:
            set_list.append(set(chunk[category]))
        # if count==3:break
            
    data_length=(count*chunksize+last_len-chunksize) #数据行（样本）总长度
    print("数据行（样本）总长度={}".format(data_length)) 
    if category:
        category_set=set().union(*set_list)
        if save_fp:
            with open(save_fp,'wb') as f:
                pickle.dump(category_set,f)            
        return category_set

if __name__=="__main__":
    #C.AoT-data数据样本长度计算，并提取data:parameter传感器测量分类字段   
    AoT_data_fp=cfg['AoT']['AoT_data_fp']
    category_set_fp=cfg['processed_data']['category_set_fp']
    category_set=total_sample_length_csv(AoT_data_fp,chunksize=10**6,category='parameter',save_fp=category_set_fp) #数据行（样本）总长度=573074785
    with open(category_set_fp,'rb') as f:
        category_set=pickle.load(f)             
```

`data:parameter`计算结果具体如下：

    {'10um_particle',
    '1um_particle',
    '2_5um_particle',
    '5um_particle',
    'acceleration_x',
    'acceleration_y',
    'acceleration_z',
    'alphasense',
    'b',
    'bins',
    'commit',
    'concentration',
    'coresense',
    'cs',
    'current',
    'device',
    'ep',
    'free',
    'fw',
    'g',
    'humidity',
    'id',
    'idletime',
    'intensity',
    'ir_intensity',
    'load_1',
    'load_10',
    'load_5',
    'magnetic_field_x',
    'magnetic_field_y',
    'magnetic_field_z',
    'major',
    'minor',
    'modem',
    'nc',
    'octave_10_intensity',
    'octave_1_intensity',
    'octave_2_intensity',
    'octave_3_intensity',
    'octave_4_intensity',
    'octave_5_intensity',
    'octave_6_intensity',
    'octave_7_intensity',
    'octave_8_intensity',
    'octave_9_intensity',
    'octave_total_intensity',
    'other',
    'patch',
    'pm1',
    'pm10',
    'pm10_atm',
    'pm10_cf1',
    'pm1_atm',
    'pm1_cf1',
    'pm25_atm',
    'pm25_cf1',
    'pm2_5',
    'point_3um_particle',
    'point_5um_particle',
    'pressure',
    'r',
    'rx',
    'sample_flow_rate',
    'sampling_period',
    'state',
    'substate',
    'temperature',
    'total',
    'tx',
    'uptime',
    'used',
    'uv_intensity',
    'visible_light_intensity',
    'wagman'}

因为`data`数据量有39.5GB，样本总长度为573,074,785条。根据`data:parameter`字段分类提取数据时，可能造成内存溢出，因此分批读取与写入。另外，在处理`data`数据时，为提高计算效率，缩短计算时长，有如下考虑：

1. 可以根据后续分析内容提前规划所要提取的数据字段，舍弃不需要的字段；
2. 提取的分类数据保存格式可以是pickle方式保存的DataFrame数据格式，也可以用geopandas保存为GPKG数据格式。需要注意，geopandas因为要处理几何空间对象，因此pickle读写效率要远远高于geopandas读写效率，具体选择哪种存储方式，可以根据具体情况调整。同时，因为单个文件较大的数据量，写入数据库时可能会出现错误，及较长的读写时间，因此并没有将数据写入数据库；(实验中，两种格式均有保存)
3. 使用多线程处理，加快计算速度。多线程计算时，有个别分类字段可能会超出内存大小中断程序，对这些分类字段可单独进行计算。单独计算时，将数据按照配置的`chunksize`参数大小分批保存为多个文件；
4. pd.read_csv(data_fn,chunksize=chunksize)读取`data`时，使用`chunksize`参数分批读取数据，避免内存溢出。

`data(data.csv.gz)`数据文件包含的字段信息包括：

* `timestamp` - 测量了完成时的UTC（Coordinated Universal Time）时间戳；
* `node_id` - 用于测量的节点ID；
* `subsystem` - 包含传感器节点的子系统；
* `sensor` - 用于测量的传感器；
* `parameter` - 测量的传感器参数；
* `value_raw` - 来自传感器的原始测量值；
* `value_hrf` - 从传感器转换的“可读”值，即标准测量单位。

`AoTData_preprocessing_pool.py`
```python
# -*- coding: utf-8 -*-
"""
Created on Fri Feb  4 19:00:35 2022

@author: Richie Bao-caDesign设计(cadesign.cn)
"""

def AoT_data_category_pool(category,args):
    '''
    读取AoT-data数据，并存储为.gpkg或者.pkl

    Parameters
    ----------
    category : string
        分类名.
    args : list
        变量列表.

    Returns
    -------
    category : string
        分类名。可以不定义返回值，该返回值即为输入值.

    '''
    import pandas as pd
    import geopandas as gpd
    import os
    import pickle
    
    data_fn,chunksize,category_column,save_path,AoT_nodes=args    
    category_fn_dict={}
    count=0
    temp=[]
    for chunk in pd.read_csv(data_fn,chunksize=chunksize):
        temp.append(chunk[chunk[category_column]==category])            
        count+= 1
        # if count==3:break
    category_df=pd.concat(temp)    
    # print("+"*50)
    # print(category_df)
    if category_df.empty is False:
        if AoT_nodes is not None:
            category_df=pd.merge(category_df,AoT_nodes,on="node_id")
            category_gdf=gpd.GeoDataFrame(category_df,crs=AoT_nodes.crs)
            category_fn=os.path.join(save_path,"{}.gpkg".format(category))
            category_gdf.to_file(category_fn,driver="GPKG")    
        else:
            category_fn=os.path.join(save_path,"{}.pkl".format(category))
            category_df.to_pickle(category_fn)
    else:
        return category

if __name__=="__main__":
    #下述代码测试多线程调用的子程序
    import sys,os
    sys.path.append('..')  
    
    from database import postSQL2gpd,gpd2postSQL,cfg_load_yaml   
    import pickle
    parent_path=os.path.dirname(os.getcwd())

    cfg=cfg_load_yaml('./config.yml')  
    UN=cfg["postgreSQL"]["myusername"]
    PW=cfg["postgreSQL"]["mypassword"]
    DB=cfg["postgreSQL"]["mydatabase"] 
    GC='geometry'     
    
    AoT_data_fp=cfg['AoT']['AoT_data_fp']
    category_set_fp=cfg['processed_data']['category_set_fp']
    with open(category_set_fp,'rb') as f:
         category_set=pickle.load(f) 
        
    AoT_data_category_save_fp=cfg['processed_data']['AoT_data_category_save_fp']  
    AoT_nodes_TN=cfg['table_name']['AoT_nodes_TN']     
    AoT_nodes_gdf=postSQL2gpd(table_name=AoT_nodes_TN,geom_col=GC,myusername=UN,mypassword=PW,mydatabase=DB)
    for category in list(category_set)[:3]:
         _=AoT_data_category_pool(category,[AoT_data_fp,10**6,'parameter',AoT_data_category_save_fp,AoT_nodes_gdf])
```

`AoTData_preprocessing.py`
```python
def AoT_data_sort(data_fn,category_set,category_column,save_path,chunksize,AoT_nodes=None):
    '''
    多线程。读取AoT-data数据，并存储为.gpkg或者.pkl

    Parameters
    ----------
    data_fn : string
        AoT_data数据，传感器测量数据.
    category_set : list(string)
        data:parameter传感器测量分类字段列表.
    category_column : string
        判断分类的列表，即AoT-data的parameter字段.
    save_path : string
        文件保存的根目录.
    chunksize : int.
        分批读取数据一次读取的文件量（样本行）.
    AoT_nodes : GeoDataFrame, optional
        AoT-nodes节点信息数据，包含节点分布几何点（geometry）。如果给定该参数则保存为GPKG，否则保存为.pkl(pickle保存). The default is None.

    Returns
    -------
    category_none : list(string)
        已经保存的分类数据名列表.
    '''
    from tqdm.auto import tqdm
    from multiprocessing import Pool
    from AoTData_preprocessing_pool import AoT_data_category_pool
    from functools import partial
    
    args=partial(AoT_data_category_pool, args=[data_fn,chunksize,category_column,save_path,AoT_nodes])
    with Pool(8) as p:
        category_none=p.map(args, tqdm(list(category_set))) #[:3]
        
    category_fn_dict={category:os.path.join(save_path,"{}.pkl".format(category)) for category in category_set}
    category_fn_dict_fn= os.path.join(save_path,"category_fn_dict.pkl")  
    with open(category_fn_dict_fn,'wb') as f:
        pickle.dump(category_fn_dict,f)
    return category_none    

def AoT_data_category_single(data_fn,category,category_column,save_path,AoT_nodes=None,chunksize=10**6):
    '''
    读取AoT-data数据，提取单个分类，并存储为.gpkg或者.pkl

    Parameters
    ----------
    data_fn : string
        AoT_data数据，传感器测量数据.
    category : string
        提取单个分类数据的分类名.
    category_column : string
        判断分类的列表，即AoT-data的parameter字段.
    save_path : string
        文件保存的根目录.
    AoT_nodes : GeoDataFrame,optional
        AoT-nodes节点信息数据，包含节点分布几何点（geometry）。如果给定该参数则保存为GPKG，否则保存为.pkl(pickle保存). The default is None.
    chunksize : int, optional
        分批读取数据一次读取的文件量（样本行）. The default is 10**6.

    Returns
    -------
    category : string
        分类名。可以不定义返回值，该返回值即为输入值.

    '''
    import pandas as pd
    import geopandas as gpd
    import os
    import pickle    
    
    count=0
    for chunk in pd.read_csv(data_fn,chunksize=chunksize):
        category_chunk_df=chunk[chunk[category_column]==category]          
        count+= 1  
        
        if category_chunk_df.empty is False:
            if AoT_nodes is not None:
                category_chunk_df=pd.merge(category_chunk_df,AoT_nodes,on="node_id")
                category_chunky_gdf=gpd.GeoDataFrame(category_chunk_df,crs=AoT_nodes.crs)
                category_chunk_fn=os.path.join(save_path,"{}_{}.gpkg".format(category,count))
                category_chunky_gdf.to_file(category_chunk_fn,driver="GPKG")    
            else:
                category_chunk_fn=os.path.join(save_path,"{}_{}.pkl".format(category,count))
                category_chunk_df.to_pickle(category_chunk_fn)
        else:
            return category 

if __name__=="__main__":
    #D.按data:parameter传感器测量分类字段，分类提取数据用pickle保存，或者用geopandas保存为GPKG格式地理数据。根据电脑算力确定
    AoT_data_category_save_fp=cfg['processed_data']['AoT_data_category_save_fp'] 
    category_none=AoT_data_sort(AoT_data_fp,category_set,'parameter',AoT_data_category_save_fp,chunksize=10**6,AoT_nodes=AoT_nodes_gdf) 
    #如果内存溢出，部分传感器分类数据不能写入（如temperature，shape (6, 169342609)），可以单独读取写入。为避免重新计算已计算分类，由下行代码提取未写入分类进行单独计算，或者手工配置
    from glob import glob
    from pathlib import Path    
    category_hold=category_set-set([Path(fn).stem for fn in glob(os.path.join(AoT_data_category_save_fp,"*.gpkg"))])
    print(category_hold) #结果为{'temperature'}    
    _=AoT_data_category_single(AoT_data_fp,'temperature','parameter',AoT_data_category_save_fp,AoT_nodes_gdf,chunksize=10**8) #手工配置为'temperature'
```

###### 4) 分析用潜在城市空间数据准备

AoT数据分析涉及到自身时空数据分析，包括单独节点的时间变化值和多个节点的时空变化值；及传感器测量值与城市空间环境相关因素的关系分析，例如建筑高度、道路、交通、城市用地，植被等。在实验过程中，无法预测相关因素关系情况下，会尝试多种可能性，这可能包括OSM提供的点标签（实际计算后发现提取的用地类型信息很少，及标签分类繁复，不易提取针对此次实验的相关信息）；或者节点位置的全景图语义分割对象百分比的关系等。

* 建筑高度数据

`Chicago data Portal`提供的`BUilding Footprints(current)`数据可以导出为多种格式类型，包括KML、KMX、Shapefile、GeoJSON等地理格式数据，以及CSV、CSV for Excel、JSON、RDF、RSS、TSV for Excel及XML等非地理格式数据。这里下载的数据格式为GeoJSON地理格式数据，可以用geopandas直接读取为GeoDataFrame数据格式。为方便调用，并配置投影和转换字段为字符串的列为数值类型（float, int等）定义函数`json2gdf()`。

`database.py`
```python
def json2gdf(json_fn,numeric_columns=None,epsg=None):
    '''
    读取.geojson(json)文件为GeoDataFrame格式文件，选择配置投影

    Parameters
    ----------
    json_fn : string
        文件路径.
    epsg : int, optional
        坐标投影系统，epsg编号. The default is None.

    Returns
    -------
    gdf : GeoDataFrmae
        转换后的GeoDataFrame格式文件.

    '''
    import geopandas as gpd
    
    gdf=gpd.read_file(json_fn)
    if epsg:
        gdf.to_crs(epsg,inplace=True)   
    print("fields_{}".format(gdf.columns))    
    if numeric_columns:
        gdf=gdf.astype(numeric_columns)

    return gdf

if __name__=="__main__":   
    #A.建筑轮廓（含层高）写入数据库
    Building_Footprints_fn=cfg['raw_data']['Building_Footprints_fn']    
    Building_Footprints=json2gdf(Building_Footprints_fn,numeric_columns={'no_stories':'int','stories':'int'},epsg=Chicago_epsg)
    
    Building_Footprints_TN=cfg['table_name']['Building_Footprints_TN']    
    BF_columns_selection=['no_stories','stories','geometry']
    gpd2postSQL(Building_Footprints[BF_columns_selection].dropna(),table_name=Building_Footprints_TN,myusername=UN,mypassword=PW,mydatabase=DB) 
    Building_Footprints=postSQL2gpd(table_name=Building_Footprints_TN,geom_col=GC,myusername=UN,mypassword=PW,mydatabase=DB)   
```

<a href=""><img src="./imgs/3_3_2_02_s.jpg" height="auto" width="auto" title="caDesign"></a>

较高的建筑基本分布于临湖的中心城区。其余建筑多为住宅，混合低矮建筑的商业区。

* 道路中心线

下载的道路中心线数据格式为GeoJSON，可以直接用上述定义的`json2gdf()`函数读取数据并写入数据库。

`database.py`
```python
if __name__=="__main__":    
    #B.道路中心线 
    street_center_lines_fn=cfg['raw_data']['Street_Center_Lines_fn']
    street_center_lines=json2gdf(street_center_lines_fn,epsg=Chicago_epsg)
    street_center_lines_TN=cfg['table_name']['street_center_lines_TN']
    gpd2postSQL(street_center_lines,table_name=street_center_lines_TN,myusername=UN,mypassword=PW,mydatabase=DB) 
    street_center_lines=postSQL2gpd(table_name=street_center_lines_TN,geom_col=GC,myusername=UN,mypassword=PW,mydatabase=DB)        
```

<a href=""><img src="./imgs/3_3_2_03_s.jpg" height="auto" width="auto" title="caDesign"></a>

下载的[Street Centerline Attributes and Lookup Tables](https://data.cityofchicago.org/Transportation/Street-Center-Lines/6imu-meau)文件描述了道路中心线字段，其中`STREET_TYPE`字段为道路分类，摘录如下：

| CODE| DESCRIPTION     |
|-----------|-----------|
| AVE| AVENUE           |
| BLVD| BOULEVARD       |
| CRES| CRESCENT COURT  |
| CT |COURT             |
| DR |DRIVE             |
| ER| ENTRANCE RAMP     |
| EXPY| EXPRESSWAY      |
| HWY| HIGHWAY          |
| LN |LANE              |
| PKWY| PARK WAY        |
| PL |PLACE             |
| ROW |ROW              |
| SQ| SQUARE            |
| SR |SERVICE ROAD      |
| ST| STREET            |
| TER |TERRACE          |
| TOLL| TOLL WAY        |
| VIA |WAY              |
| WAY| EXIT RAMP        |

* 土地利用

土地利用（Land Use Inventory）从[CMAP(Chicago Metropolitan Agency for Planning) Data Hub](https://datahub.cmap.illinois.gov/group/land-use-inventories) 下载，数据文件时间为2015年（通常每5年一更新）。下载地址也提供了'Land Use Inventory Metadata (2015)'PDF说明文件，可以对照`LANDUSE`字段提供的代码查看土地利用。该部分的映射也写在`config.yml`配置文件中。

读取研究区域（芝加哥城边界数据）用前文定义的`shp2gdf()`函数。对于土地利用数据的读取和裁切，重新定义`shp2gdf_updated()`函数，使用`gpd.clip()`方法裁切。

`database.py`
```python
def shp2gdf(fn,epsg=None,boundary=None,encoding='utf-8'):    
    '''
    function - 转换.shp地理信息数据为GeoDataFrame(geopandas)数据格式，可以配置投影
    
    Paras:
        fn - .shp文件路径
        epsg - 配置投影，默认为None
        boundary - 配置裁切边界，默认为None
        encoding - 配置编码，默认为'utf-8'
    '''
    import geopandas as gpd
    
    shp_gdf=gpd.read_file(fn,encoding=encoding)
    print('original data info:{}'.format(shp_gdf.shape))
    shp_gdf.dropna(how='all',axis=1,inplace=True)
    print('dropna-how=all,result:{}'.format(shp_gdf.shape))
    shp_gdf.dropna(inplace=True)
    print('dropna-several rows,result:{}'.format(shp_gdf.shape))
    if epsg is not None:
        shp_gdf_proj=shp_gdf.to_crs(epsg=epsg)
        print(shp_gdf_proj.crs)
    if boundary:
        shp_gdf_proj['mask']=shp_gdf_proj.geometry.apply(lambda row:row.within(boundary))
        shp_gdf_proj.query('mask',inplace=True)        
    
    return shp_gdf_proj

def shp2gdf_updated(fn,boundary=None,encoding='utf-8'):    
    '''
    function - 转换.shp地理信息数据为GeoDataFrame(geopandas)数据格式，配置投影为给定边界的crs，并应用gpd.clip()方法裁切
    
    Paras:
        fn - .shp文件路径
        boundary - 配置裁切边界，默认为None
        encoding - 配置编码，默认为'utf-8'
    '''
    import geopandas as gpd
    from tqdm import tqdm
    tqdm.pandas()  
    
    shp_gdf=gpd.read_file(fn,encoding=encoding)    
    if boundary is not None:        
        shp_gdf['mask']=shp_gdf.geometry.progress_apply(lambda row:row.is_valid)
        shp_gdf=shp_gdf[shp_gdf['mask']==True]
        shp_clip_gdf=gpd.clip(shp_gdf.to_crs(boundary.crs),boundary)    
        return shp_clip_gdf
    else:
        return shp_gdf

if __name__=="__main__":
    #C.土地利用
    #研究边界
    Chicago_boundary_fp=cfg['raw_data']['Chicago_boundary']
    Chicago_boundary_gdf=shp2gdf(Chicago_boundary_fp,epsg=Chicago_epsg)
    Chicago_boundary_TN=cfg['table_name']['Chicago_boundary_TN']
    gpd2postSQL(Chicago_boundary_gdf,table_name=Chicago_boundary_TN,myusername=UN,mypassword=PW,mydatabase=DB)    
    Chicago_boundary=postSQL2gpd(table_name=Chicago_boundary_TN,geom_col=GC,myusername=UN,mypassword=PW,mydatabase=DB)
    
    #读取土地利用数据并裁切到研究区域
    landuse_fn=cfg['raw_data']['landuse_fn']
    landuse_gdf=shp2gdf_updated(landuse_fn,boundary=Chicago_boundary)
    landuse_mapping=cfg['landuse']['landuse_mapping']
    landuse_gdf['landuse_name']=landuse_gdf['LANDUSE'].map(landuse_mapping)

    landuse_TN=cfg['table_name']['landuse_TN']
    gpd2postSQL(landuse_gdf,table_name=landuse_TN,myusername=UN,mypassword=PW,mydatabase=DB)
    landuse_gdf=postSQL2gpd(table_name=landuse_TN,geom_col=GC,myusername=UN,mypassword=PW,mydatabase=DB)
```

<a href=""><img src="./imgs/3_3_2_04_s.jpg" height="auto" width="auto" title="caDesign"></a>

* 植被（高，中，低）

该部分数据是直接使用'点云数据处理'一章中使用[.las格式的激光雷达数据](https://www.arcgis.com/apps/webappviewer/index.html?id=44eb65c92c944f3e8b231eb1e2814f4d)提取的植被信息，包括高的树木（high vegetation），中等树木（medium vegetation）和低矮树木（low vegetation）。栅格的投影为`EPSG:6455 - NAD83(2011) / Illinois East (ftUS)`，需要统一为本次实验的投影`EPSG:32616 - WGS 84 / UTM zone 16N`。定义栅格数据重投影的函数`raster_reprojection()`转换投影坐标。

`database.py`
```python
def raster_reprojection(raster_fp,save_path,dst_crs):
    from rasterio.warp import calculate_default_transform, reproject, Resampling
    import rasterio as rio
    '''
    function - 转换栅格投影
    
    Paras:
        raster_fp - 待转换投影的栅格
        dst_crs - 目标投影
        save_path - 保存路径
    '''
    with rio.open(raster_fp) as src:
        transform, width, height = calculate_default_transform(src.crs, dst_crs, src.width, src.height, *src.bounds)
        kwargs = src.meta.copy()
        kwargs.update({
            'crs': dst_crs,
            'transform': transform,
            'width': width,
            'height': height,
            "compress":'lzw',
        })
        with rio.open(save_path, 'w', **kwargs) as dst:
            for i in range(1, src.count + 1):
                reproject(
                    source=rio.band(src, i),
                    destination=rio.band(dst, i),
                    src_transform=src.transform,
                    src_crs=src.crs,
                    dst_transform=transform,
                    dst_crs=dst_crs,
                    resampling=Resampling.nearest)      

def raster_reprojection_batch(srcs,dsts,epsg):
    '''
    批量转换栅格投影

    Parameters
    ----------
    srcs : string
        待转换投影的栅格路径名.
    dsts : string
        转换后存储栅格路径名.
    epsg : int
        坐标投影系统，epsg编号.

    Returns
    -------
    None.

    '''
    from tqdm import tqdm
    for i in tqdm(range(len(srcs))):
        raster_reprojection(srcs[i],dsts[i],epsg)  

if __name__=="__main__":
    #D. 树木（高，中，低）栅格数据重投影
    HighVegetation_fn=cfg['raw_data']['HighVegetation_fn']
    MediumVegetation_fn=cfg['raw_data']['MediumVegetation_fn']
    LowVegetation_fn=cfg['raw_data']['LowVegetation_fn']
    HighVegetation_reprojection_fn=cfg['processed_data']['HighVegetation_reprojection_fn']
    MediumVegetation_reprojection_fn=cfg['processed_data']['MediumVegetation_reprojection_fn']
    LowVegetation_reprojection_fn=cfg['processed_data']['LowVegetation_reprojection_fn']
    raster_reprojection_batch(srcs=[HighVegetation_fn,MediumVegetation_fn,LowVegetation_fn],dsts=[HighVegetation_reprojection_fn,MediumVegetation_reprojection_fn,LowVegetation_reprojection_fn],epsg=Chicago_epsg)   
```

<a href=""><img src="./imgs/3_3_2_05_s.jpg" height="auto" width="auto" title="caDesign"></a>

###### 5) 节点处全景图

在开始探索因素之间关系时，由全景图提取的语义分割信息是否与传感器测量的几类数据具有相关性并不确定，但是全景图可以帮助观察节点所在的场地环境。芝加哥区域街道全景图（Street View panorama）可以从[Google Developers Console_Street View Static API ](https://accounts.google.com/ServiceLogin/signinchooser?service=cloudconsole&passive=1209600&osid=1&continue=https%3A%2F%2Fconsole.cloud.google.com%2Fapis%2Fdashboard&followup=https%3A%2F%2Fconsole.cloud.google.com%2Fapis%2Fdashboard&flowName=GlifWebSignIn&flowEntry=ServiceLogin)支付下载。或者从[istreetview](https://istreetview.com/)通过节点坐标获取全景图索引（PanoID），然后用[Street View Download 360](https://svd360.istreetview.com/)辅助下载。

对全景图包括语义分割的数据处理方法可以参考‘城市街道视域景观指数与邻里尺度特征效应’一章。

| 001e06113d20-原图  | 语义分割  |
|---|---|
| <a href=""><img src="./imgs/3_3_2_06_s.gif" height="auto" width="auto" title="caDesign"></a>  |  <a href=""><img src="./imgs/3_3_2_07_s.gif" height="auto" width="auto" title="caDesign"></a> |


##### B.2.2.2 QGIS建立地图

地图的建立可以辅助查看数据及出图。使用[QGIS](https://www.qgis.org/en/site/)建立名为'PAPER_Urban_Spatial_Pattern_N_Local_Environmental_Changes'的地图文件，上述数据地图均在QGIS中读取写入到数据的文件后，建立布局（Layout）出图。所有的图纸（Pages）均放置于一个布局之下，为了便于不断调整的需要，在`Layers`图层管理下，对每一单张图纸（Page）涉及的所有图层均放置于一个组之下（用Add Group增加组）。注意，每个组（图纸）中的图层可能来源于同一个数据库文件。

#### B.2.3 分析与结果

分析过程按照传感器测量分类分5组进行，包括
1. 气体类，涉及CO、H<sub>2</sub>S、NO<sub>2</sub>、O<sub>3</sub>、oxidizing_gases、reducing_gases和SO<sub>2</sub>;
2. 颗粒物，微粒，涉及pm<sub>1</sub>,pm</sub>2.5</sub>, pm<sub>5</sub>,pm<sub>10</sub>;
3. 热环境，涉及温度，湿度和大气压；
4. 噪音；
5. 光环境，涉及光强度，红外光谱强度和紫外线强度。

##### B.2.3.1 气体类

###### 1) 分类气体

在数据预处理时，使用`data:parameter`字段分类数据时，所有的气体类测量数据均位于'concentration_x.gpkg(pkl)'下。需要按照不同的气体类型（`sensor`字段）进一步提取并保存为单独的文件。

`air_sensor_category.py`
```python
# -*- coding: utf-8 -*-
"""
Created on Tue Feb 15 09:58:38 2022

@author: Richie Bao-caDesign设计(cadesign.cn)
"""

def air_sensor_category_extraction(air_sensor_list,field,concentration_fps,air_sensor_category_save_fp):
    '''
    将混合了不同气体类型的一个分类数据进一步根据气体类型切分与保存为单独的文件

    Parameters
    ----------
    air_sensor_list : list(string)
        气体类型，包括['co', 'h2s', 'no2', 'o3', 'oxidizing_gases', 'reducing_gases', 'so2'].
    field : string
        含有气体类型名的列名.
    concentration_fps : list(string)
        初始处理的分类数据，包含不同气体类型.
    air_sensor_category_save_fp : string
        保存路径.

    Returns
    -------
    None.

    '''    
    import pandas as pd
    from tqdm import tqdm
    
    for sensor in tqdm(air_sensor_list):
        p_list=[]
        for concentration_fp in concentration_fps:
            concentration=gpd.read_file(concentration_fp)
            p_sensor=concentration[concentration[field]==sensor]
            p_list.append(p_sensor)
            
        p_concat=pd.concat(p_list)  
        sensor_save_fn=os.path.join(air_sensor_category_save_fp,"air_{}.gpkg".format(sensor))
        p_concat.to_file(sensor_save_fn,driver="GPKG")
        
if __name__=="__main__":
    import sys
    sys.path.append('..')
    import util    
    import geopandas as gpd
    import pandas as pd
    import os
    import pickle
    from database import postSQL2gpd,gpd2postSQL,cfg_load_yaml   
    parent_path=os.path.dirname(os.getcwd())
    
    cfg=cfg_load_yaml('../config.yml')  
    UN=cfg["postgreSQL"]["myusername"]
    PW=cfg["postgreSQL"]["mypassword"]
    DB=cfg["postgreSQL"]["mydatabase"] 
    GC='geometry'      
    
    Chicago_epsg=cfg['Chicago_epsg']
    AoT_data_category_save_fp=cfg['processed_data']['AoT_data_category_save_fp'] 
    
    #A.按sensor列，提取气体类型列表。使用.pkl格式分类数据（不包含'geometry'（GeoDataFrame）的DataFrame数据），提高读取速度
    AoT_data_category_pkl_save_fp=cfg['processed_data']['AoT_data_category_pkl_save_fp'] 
    concentration_pkl_save_fp=os.path.join(parent_path,AoT_data_category_pkl_save_fp,"concentration.pkl")   
    s_t=util.start_time()
    with open(concentration_pkl_save_fp,'rb') as f:
        concentration_df=pickle.load(f) #6.06GB, total time spend:1.15 minutes
    util.duration(s_t)
    sensor_list=concentration_df.sensor.unique()
    print(sensor_list)        
        
    #B.分别提取气体类型（字段sensor）并保存至硬盘，用于后续分析
    air_sensor_list=cfg['analysis_air']['air_sensor_list']
    print("air_sensors:",air_sensor_list)
    air_sensor_category_save_fp=cfg['analysis_air']['air_sensor_category_save_fp']
    concentration_fps=[os.path.join(parent_path,AoT_data_category_save_fp,"concentration_{}.gpkg".format(i)) for i in range(1,7)]
    print("concentration_fps:",concentration_fps) 
    s_t=util.start_time()
    air_sensor_category_extraction(air_sensor_list,'sensor',concentration_fps,air_sensor_category_save_fp)  #直接处理GeoPandas的.gpkg格式文件非常耗时，应先处理Pandas保存为.pkg的DataFrame格式文件，而后再增加几何对象，转换为GeoDataFrame格式
    util.duration(s_t)    
```

###### 2) 传感器值域，数据预处理与按时间周期重采样

'sensors.csv'文件包含有对不同传感器值域信息，为最小值列`hrf_minval`和最大值列`hrf_maxval`，气体类浓度单位为ppm，提取各个气体对应值域为：

```python
{'co': [0.0, 1000.0],
 'h2s': [0.0, 50.0],
 'no2': [0.0, 20.0],
 'o3': [0.0, 20.0],
 'oxidizing_gases': [0.0, 100.0],
 'reducing_gases': [0.0, 20.0],
 'so2': [0.0, 20.0]}
 ```


因此数据的预处理阶段通常包括：

1. 剔除不在给定值域内的值；
2. 常规剔除异常值；
3. 移除空值、无效值等。（是否必须移除空值，需要根据具体情况确定）

当预处理数据后，对于时间序列的数据可以指定时间周期来重采样数据，这里按均值重采样了日、星期、月和年，对应输入参数为['D','W','M','Y']。按时间周期重采样的数据写入到数据库。

`time_series_analysis.py`
```python
# -*- coding: utf-8 -*-
"""
Created on Sun Mar 13 08:26:52 2022

@author: Richie Bao-caDesign设计(cadesign.cn)
"""
def df_value_within_range(df,val_column,specified_range,dropnone=False,value_type=None):
    '''
    给定DataFrame格式数据列，移除空值，保留给定区间的值，配置数据类型。

    Parameters
    ----------
    df : DataFrame
        待处理的数据.
    val_column : string
        处理列的列名.
    specified_range : list(float)
        值域区间.
    dropnone : bool, optional
        是否移除空值. The default is False.
    value_type : string, optional
        转换为的数据类型. The default is None.

    Returns
    -------
    df_filter : DataFrame
        处理后的数据.

    '''
    if dropnone:        
        df.dropna(subset=[val_column],inplace=True)
    if value_type:
        df[val_column]=df[val_column].astype(value_type) 
    df_filter=df.loc[(df[val_column]<specified_range[1]) & (df[val_column]>specified_range[0])] 
    
    return df_filter

def df_drop_outliers(df,val_column,z_thresh=3):
    '''
    由stats.zscore方法移除DataFrame中给定列的异常值

    Parameters
    ----------
    df : DataFrame
        包含待处理数据列.
    val_column : string
        待处理异常值列.
    z_thresh : float, optional
        剔除异常值的阈值. The default is 3.

    Returns
    -------
    df : DataFrame
        剔除异常值后的DataFrame格式数据.

    '''
    from scipy import stats
    import numpy as np
    constrains=np.abs(stats.zscore(df[val_column])) < z_thresh
    df.drop(df.index[~constrains],inplace=True)
    
    return df

def df_resample(gdf,val_column,time_column,rule,group=None,specified_range=None):
    '''
    给定数值列和时间列，按照规则（按日，月，年等）计算均值（采样）

    Parameters
    ----------
    gdf : GeoDataFrame
        待处理的数据，因为处理后写入地理信息数据库PostgreSQL，因此采用gdf格式数据.
    val_column : string
        计算列.
    time_column : sring
        时间列.
    rule : list(string)
        例如：['D','W','M','Y'].
    group : string, optional
        分组列名. The default is None.

    Returns
    -------
    TYPE : GeoDataFrame
        按时间周期采用后数据.
        
    '''
    import geopandas as gpd
    import pandas as pd
    from shapely import wkt
    from tqdm import tqdm
    
    gdf_notnull=gdf[gdf[val_column].notnull()]
    gdf_notnull['ts']=pd.to_datetime(gdf_notnull[time_column])
    gdf_notnull_sort=gdf_notnull.sort_values(time_column)
    gdf_notnull_sort[val_column]=gdf_notnull_sort[val_column].astype('float')  
    crs=gdf.crs
    print("crs={}".format(crs))
    
    if specified_range:
        gdf_notnull_sort=df_value_within_range(gdf_notnull_sort,val_column,specified_range)
    
    g_dic={}
    if group:
        gdf_notnull_sort_group=gdf_notnull_sort.groupby([group])
        # i=0
        for g in tqdm(gdf_notnull_sort_group):
            g_name=g[0]
            g_val=g[1]                    
            g_geometry=g_val.iloc[[0]].geometry.values[0]
            g_val.set_index('ts',inplace=True)
            g_resample_dict={}
            for r in rule:
                g_resample_series=g_val[val_column].resample(r).mean()
                g_resample_df=pd.DataFrame(g_resample_series).T
                g_resample_df.rename(index={val_column:g_name},inplace=True)
                if "H" in rule:
                    g_resample_df.rename({i:"{}_{}".format(r,pd.to_datetime(i).strftime('%Y-%m-%d %H:%M:%S')) for i in g_resample_df.columns},axis=1,inplace=True)  
                else:
                    g_resample_df.rename({i:"{}_{}".format(r,pd.to_datetime(i).strftime('%Y-%m-%d')) for i in g_resample_df.columns},axis=1,inplace=True)                
                g_resample_dict[r]=g_resample_df
            g_resample_concat=pd.concat(g_resample_dict.values(),axis=1)
            g_resample_concat['geometry']=g_geometry
            g_resample_concat[group]=g_name            
            g_dic[g_name]=g_resample_concat 
            
            # if i==1:break
            # i+=1
        resample_concat=pd.concat(g_dic.values(),axis=1)
        def sjoin(x): return ';'.join(x[x.notnull()].astype(str))  
        resample_concat_m=resample_concat.groupby(level=0, axis=1).apply(lambda x: x.apply(sjoin, axis=1))
        resample_concat_m['geometry']=resample_concat_m['geometry'].apply(wkt.loads) 
        timestamp_columns=list(set(resample_concat_m.columns.to_list())-set(['geometry',group]))
        resample_concat_m[timestamp_columns]=resample_concat_m[timestamp_columns].apply(pd.to_numeric)
        resample_gdf=gpd.GeoDataFrame(resample_concat_m,geometry='geometry',crs=crs)    
        return resample_gdf 
    else:
        resample_dict={}
        for r in rule:
            gdf_notnull_sort.set_index('ts',inplace=True)
            resample_series=gdf_notnull_sort[val_column].resample(r).mean()
            resample_dict[r]=resample_series
        return resample_dict

def df_resample_bundle(sensor_fns,sensor_list,val_columns,time_column,rule,cfg,group=None,specified_range_dict=None,prefix=None):
    '''
    批量读取与计算多个GeoDataFrame格式数据，并写入数据库。给定数值列和时间列，按照规则（按日，月，年等）计算均值（采样）

    Parameters
    ----------
    sensor_fns : string
        多个待处理数据路径列表，为geopandas可以读取的地理信息格式，例如.gpkg.
    sensor_list : string
        与多个待处理数据对应的名称列表，例如测量内容名称.
    val_columns : list(string)
        处理数据列名.
    time_column : string
        时间列名.
    rule : list(string)
        按时间周期采样，例如['D','W','M','Y'].
    cfg : dict
        包含数据库信息的配置文件.
    group : string, optional
        用于分组的列名. The default is None.
    prefix : string, optional
        标识表名的前缀. The default is None.

    Returns
    -------
    tn_list : list(string)
        表名列表.

    '''
    from tqdm import tqdm
    from database import gpd2postSQL 
    import geopandas as gpd
      
    UN=cfg["postgreSQL"]["myusername"]
    PW=cfg["postgreSQL"]["mypassword"]
    DB=cfg["postgreSQL"]["mydatabase"] 
    GC='geometry'    
    
    tn_list=[]
    for idx in tqdm(range(len(sensor_fns))):
        air_gdf=gpd.read_file(sensor_fns[idx])
        specified_range=specified_range_dict[sensor_list[idx]]
        for val in val_columns:            
            air_resample_gdf=df_resample(air_gdf,val,time_column,rule,group,specified_range) 
            if prefix:
                table_name='{}_{}_resample_{}'.format(prefix,sensor_list[idx],val)     
            else:
                table_name='{}_resample_{}'.format(sensor_list[idx],val) 
            gpd2postSQL(air_resample_gdf,table_name,myusername=UN,mypassword=PW,mydatabase=DB)
            tn_list.append(table_name)
    return tn_list
```

`air_time_series_analysis.py`
```python
if __name__=="__main__":
    import sys
    sys.path.append('..')
    import util    
    import geopandas as gpd
    import pandas as pd
    import os
    import pickle
    from database import postSQL2gpd,gpd2postSQL,cfg_load_yaml  
    from glob import glob
    import time_series_analysis as tsa
    from datetime import datetime
    parent_path=os.path.dirname(os.getcwd())
    
    cfg=cfg_load_yaml('../config.yml')  
    UN=cfg["postgreSQL"]["myusername"]
    PW=cfg["postgreSQL"]["mypassword"]
    DB=cfg["postgreSQL"]["mydatabase"] 
    GC='geometry' 
    
    air_sensor_category_save_fp=cfg['analysis_air']['air_sensor_category_save_fp']
    air_sensor_category_fns=glob(os.path.join(air_sensor_category_save_fp,"*.gpkg"))
    air_sensor_list=cfg['analysis_air']['air_sensor_list']
    print(air_sensor_list)  #['co', 'h2s', 'no2', 'o3', 'oxidizing_gases', 'reducing_gases', 'so2']  
    
    AoT_nodes_TN=cfg['table_name']['AoT_nodes_TN']  
    AoT_nodes_gdf=postSQL2gpd(table_name=AoT_nodes_TN,geom_col=GC,myusername=UN,mypassword=PW,mydatabase=DB)
    
    #A.传感器值域
    AoT_sensors_fp=os.path.join(parent_path,cfg['AoT']['AoT_sensors_fp'])
    AoT_nodes_df=pd.read_csv(AoT_sensors_fp,sep=",",header=0)
    AoT_sensors_range=AoT_nodes_df.set_index('sensor')[['hrf_minval', 'hrf_maxval']].to_dict()
    co_value_range=[AoT_sensors_range['hrf_minval']['co'],AoT_sensors_range['hrf_maxval']['co']]
    specified_range_dict={sensor_name:[AoT_sensors_range['hrf_minval'][sensor_name],AoT_sensors_range['hrf_maxval'][sensor_name]] for sensor_name in air_sensor_list}
    
    #B.测量数据按照时间周期重采样，包括移除空值和超出给定值域的行，并写入数据    
    air_tn_list=tsa.df_resample_bundle(air_sensor_category_fns,air_sensor_list,['value_hrf'],'timestamp',['D','W','M','Y'],cfg,'node_id',specified_range_dict,'air')    
```

###### 3) 时间序列

时间序列分析内容包括打印查看数据，及白噪声检验（纯随机性检验）、平稳性和周期性等内容。

* 白噪声检验

获取的气体传感器时间序列数据，通过图表打印查看各节点数值变化，部分数据很难确定是否具有规律性，因此通过[`statsmodels.stats.diagnostic.acorr_ljungbox`](https://www.statsmodels.org/dev/generated/statsmodels.stats.diagnostic.acorr_ljungbox.html)方法计算确定。配置`corr_ljungbox`输入参数`boxpierce=True`，除计算`Ljung-Box test`外，也计算`Box-Pierce test `，判断返回的`lb_pvalue`和`bp_pvalue`是否大于给定的显著性水平（默认配置为0.05），如果均大于无法拒绝原假设，则认为该数据为白噪声，即纯粹的随机数据。


* 平稳性检验

如果要对时间序列建立预测模型，例如ARMA（autoregressive–moving-average）、ARIMA（autoregressive integrated moving average），需要时间序列数据具有平稳性(意味均值和方差保持不变)。通过检验气体传感器时间序列数据的平稳性，也可以确定气体污染浓度变化趋势，是否数值稳定在一个固定区间内，还是会有剧烈的随机波动。计算使用[`statsmodels.tsa.stattools.adfuller`](https://www.statsmodels.org/devel/generated/statsmodels.tsa.stattools.adfuller.html)方法，如`adfuller（ADF）`返回的`pvalue`值小于给定的显著性水平（默认配置为0.05），则数据平稳；否则无法拒绝原假设，数据不平稳。

* 周期性模式判断

使用自相关系数（autocorrelation function，ACF）和偏自相关系数（Partial autocorrelation function, PACF）来检验时间序列数据与给定延迟数（lag）错位自身的时间序列数据之间是否具有相关性，寻找时间序列数据重复模式，例如是否具有周期性。通过图表打印平滑后的气体时间序列数据，能够在噪声掩盖下发现气体浓度具有一定的周期性，通过ACF和PACF进一步验证和确定这一特点。

时间序列的数据分析不仅可以应用于气体类，同样适用于颗粒类、热环境、噪音和光环境类，因此在代码编写过程中，将代码分为两个文件，一个为核心基础的计算函数文件`time_series_analysis.py`，包括给定值域提取数据的`df_value_within_range()`函数；给定阈值，剔除异常值的`df_drop_outliers()`函数；给定采样时间周期，按均值重采样时间序列的`df_resample()`函数和批量处理的`df_resample_bundle()`函数；ACF的`autocorrelation_time_series()`函数和PACF的`partial_autocorrelation_time_series()`函数；平稳性检验的`stationary_adfuller()`函数；白噪声检验的`white_noise_testing()`函数；以及时间序列打印的`time_series_plot_MultiColumns()`函数。这个文件可以被其它传感器数据类调用进行同样的分析。另一个文件`air_time_series_analysis.py`为气体类调用`time_series_analysis.py`中的函数实现批量计算所有节点的代码。气体类包括多个子类，有'co', 'h2s', 'no2', 'o3', 'oxidizing_gases', 'reducing_gases', 'so2'等，因此定义`time_series_analysis_batch`类方便分别调用计算。

`time_series_analysis.py`
```python
# -*- coding: utf-8 -*-
"""
Created on Sun Mar 13 08:26:52 2022

@author: Richie Bao-caDesign设计(cadesign.cn)
"""
def df_value_within_range(df,val_column,specified_range,dropnone=False,value_type=None):
    '''
    给定DataFrame格式数据列，移除空值，保留给定区间的值，配置数据类型。

    Parameters
    ----------
    df : DataFrame
        待处理的数据.
    val_column : string
        处理列的列名.
    specified_range : list(float)
        值域区间.
    dropnone : bool, optional
        是否移除空值. The default is False.
    value_type : string, optional
        转换为的数据类型. The default is None.

    Returns
    -------
    df_filter : DataFrame
        处理后的数据.

    '''
    if dropnone:        
        df.dropna(subset=[val_column],inplace=True)
    if value_type:
        df[val_column]=df[val_column].astype(value_type) 
    df_filter=df.loc[(df[val_column]<specified_range[1]) & (df[val_column]>specified_range[0])] 
    
    return df_filter

def df_drop_outliers(df,val_column,z_thresh=3):
    '''
    由stats.zscore方法移除DataFrame中给定列的异常值

    Parameters
    ----------
    df : DataFrame
        包含待处理数据列.
    val_column : string
        待处理异常值列.
    z_thresh : float, optional
        剔除异常值的阈值. The default is 3.

    Returns
    -------
    df : DataFrame
        剔除异常值后的DataFrame格式数据.

    '''
    from scipy import stats
    import numpy as np
    constrains=np.abs(stats.zscore(df[val_column])) < z_thresh
    df.drop(df.index[~constrains],inplace=True)
    
    return df

def df_resample(gdf,val_column,time_column,rule,group=None,specified_range=None):
    '''
    给定数值列和时间列，按照规则（按日，月，年等）计算均值（采样）

    Parameters
    ----------
    gdf : GeoDataFrame
        待处理的数据，因为处理后写入地理信息数据库PostgreSQL，因此采用gdf格式数据.
    val_column : string
        计算列.
    time_column : sring
        时间列.
    rule : list(string)
        例如：['D','W','M','Y'].
    group : string, optional
        分组列名. The default is None.

    Returns
    -------
    TYPE : GeoDataFrame
        按时间周期采用后数据.
        
    '''
    import geopandas as gpd
    import pandas as pd
    from shapely import wkt
    from tqdm import tqdm
    
    gdf_notnull=gdf[gdf[val_column].notnull()]
    gdf_notnull['ts']=pd.to_datetime(gdf_notnull[time_column])
    gdf_notnull_sort=gdf_notnull.sort_values(time_column)
    gdf_notnull_sort[val_column]=gdf_notnull_sort[val_column].astype('float')  
    crs=gdf.crs
    print("crs={}".format(crs))
    
    if specified_range:
        gdf_notnull_sort=df_value_within_range(gdf_notnull_sort,val_column,specified_range)
    
    g_dic={}
    if group:
        gdf_notnull_sort_group=gdf_notnull_sort.groupby([group])
        # i=0
        for g in tqdm(gdf_notnull_sort_group):
            g_name=g[0]
            g_val=g[1]                    
            g_geometry=g_val.iloc[[0]].geometry.values[0]
            g_val.set_index('ts',inplace=True)
            g_resample_dict={}
            for r in rule:
                g_resample_series=g_val[val_column].resample(r).mean()
                g_resample_df=pd.DataFrame(g_resample_series).T
                g_resample_df.rename(index={val_column:g_name},inplace=True)
                if "H" in rule:
                    g_resample_df.rename({i:"{}_{}".format(r,pd.to_datetime(i).strftime('%Y-%m-%d %H:%M:%S')) for i in g_resample_df.columns},axis=1,inplace=True)  
                else:
                    g_resample_df.rename({i:"{}_{}".format(r,pd.to_datetime(i).strftime('%Y-%m-%d')) for i in g_resample_df.columns},axis=1,inplace=True)                
                g_resample_dict[r]=g_resample_df
            g_resample_concat=pd.concat(g_resample_dict.values(),axis=1)
            g_resample_concat['geometry']=g_geometry
            g_resample_concat[group]=g_name            
            g_dic[g_name]=g_resample_concat 
            
            # if i==1:break
            # i+=1
        resample_concat=pd.concat(g_dic.values(),axis=1)
        def sjoin(x): return ';'.join(x[x.notnull()].astype(str))  
        resample_concat_m=resample_concat.groupby(level=0, axis=1).apply(lambda x: x.apply(sjoin, axis=1))
        resample_concat_m['geometry']=resample_concat_m['geometry'].apply(wkt.loads) 
        timestamp_columns=list(set(resample_concat_m.columns.to_list())-set(['geometry',group]))
        resample_concat_m[timestamp_columns]=resample_concat_m[timestamp_columns].apply(pd.to_numeric)
        resample_gdf=gpd.GeoDataFrame(resample_concat_m,geometry='geometry',crs=crs)    
        return resample_gdf 
    else:
        resample_dict={}
        for r in rule:
            gdf_notnull_sort.set_index('ts',inplace=True)
            resample_series=gdf_notnull_sort[val_column].resample(r).mean()
            resample_dict[r]=resample_series
        return resample_dict

def df_resample_bundle(sensor_fns,sensor_list,val_columns,time_column,rule,cfg,group=None,specified_range_dict=None,prefix=None):
    '''
    批量读取与计算多个GeoDataFrame格式数据，并写入数据库。给定数值列和时间列，按照规则（按日，月，年等）计算均值（采样）

    Parameters
    ----------
    sensor_fns : string
        多个待处理数据路径列表，为geopandas可以读取的地理信息格式，例如.gpkg.
    sensor_list : string
        与多个待处理数据对应的名称列表，例如测量内容名称.
    val_columns : list(string)
        处理数据列名.
    time_column : string
        时间列名.
    rule : list(string)
        按时间周期采样，例如['D','W','M','Y'].
    cfg : dict
        包含数据库信息的配置文件.
    group : string, optional
        用于分组的列名. The default is None.
    prefix : string, optional
        标识表名的前缀. The default is None.

    Returns
    -------
    tn_list : list(string)
        表名列表.

    '''
    from tqdm import tqdm
    from database import gpd2postSQL 
    import geopandas as gpd
      
    UN=cfg["postgreSQL"]["myusername"]
    PW=cfg["postgreSQL"]["mypassword"]
    DB=cfg["postgreSQL"]["mydatabase"] 
    GC='geometry'    
    
    tn_list=[]
    for idx in tqdm(range(len(sensor_fns))):
        air_gdf=gpd.read_file(sensor_fns[idx])
        specified_range=specified_range_dict[sensor_list[idx]]
        for val in val_columns:            
            air_resample_gdf=df_resample(air_gdf,val,time_column,rule,group,specified_range) 
            if prefix:
                table_name='{}_{}_resample_{}'.format(prefix,sensor_list[idx],val)     
            else:
                table_name='{}_resample_{}'.format(sensor_list[idx],val) 
            gpd2postSQL(air_resample_gdf,table_name,myusername=UN,mypassword=PW,mydatabase=DB)
            tn_list.append(table_name)
    return tn_list


def autocorrelation_time_series(df, value_column,nlags=None,plot=False,bins_list=[-1,-0.75,-0.5,-0.25,0,0.25,0.5,0.75,1],title="ACF",xticks_step=6,save_path=None): 
    '''
    计算DataFrame给定列的自相关系数和打印图标，及统计区间频数

    Parameters
    ----------
    df : DataFrame
        含计算列的DataFrame格式数据.
    value_column : string
        待计算列名.
    nlags : int, optional
        滞后（延迟）数. The default is None.
    plot : bool, optional
        是否打印图表. The default is False.
    bins_list : list(float), optional
        分类区间. The default is [-1,-0.75,-0.5,-0.25,0,0.25,0.5,0.75,1].

    Returns
    -------
    acf : list(float)
        各个延迟数下的自相关系数.
    categories_counts : pandas.core.series.Series (int)
        自相关系数区间频数统计.

    '''
    import matplotlib.pyplot as plt
    from statsmodels import api as sm
    import pandas as pd
    import os
    
    value_series=df[value_column]
    value_series.dropna(inplace=True)
    # get the autocorrelation coefficient
    if nlags is not None:
        acf=sm.tsa.acf(value_series, nlags=nlags)
    else:
        acf=sm.tsa.acf(value_series, nlags=len(value_series))   
        
    bins_tuples=[(bins_list[i],bins_list[i+1]) for i in range(len(bins_list)-1)]  
    bins=pd.IntervalIndex.from_tuples(bins_tuples)
    categories_counts=pd.cut(acf, bins).value_counts()   
        
    if plot:        
        fig=plt.figure(figsize=(12,8))
        ax=fig.add_subplot(111)
        plt.rc('axes', unicode_minus=False)
        if nlags is not None:
            fig=sm.graphics.tsa.plot_acf(value_series, lags=nlags,ax=ax,title=title)
        else:
            fig=sm.graphics.tsa.plot_acf(value_series, lags=len(value_series)-1,ax=ax,title=title)
        ax.xaxis.set_ticks_position('bottom') 
        fig.tight_layout()
        
        old_xticks=ax.get_xticks()
        xticks_step=xticks_step
        new_xticks=list(range(0,int(old_xticks[-1]),xticks_step))
        ax.set_xticks(new_xticks)
        if save_path:
            plt.savefig(os.path.join(save_path,"{}.jpg".format(title)))
        
        plt.show()
        
    return acf,categories_counts

def partial_autocorrelation_time_series(df, value_column,nlags=None,plot=False,bins_list=[-1,-0.75,-0.5,-0.25,0,0.25,0.5,0.75,1],title="PACF",xticks_step=6,save_path=None): 
    '''
    计算DataFrame给定列的偏自相关系数和打印图标，及统计区间频数

    Parameters
    ----------
    df : DataFrame
       含计算列的DataFrame格式数据.
    value_column : string
        待计算列名.
    nlags : int, optional
        滞后（延迟）数. The default is None.
    plot : bool, optional
        是否打印图表. The default is False.
    bins_list : list(float), optional
        分类区间. The default is [-1,-0.75,-0.5,-0.25,0,0.25,0.5,0.75,1].

    Returns
    -------
    pacf : list(float)
        各个延迟数下的偏自相关系数.
    categories_counts : pandas.core.series.Series (int)
        偏自相关系数区间频数统计.

    '''
    import matplotlib.pyplot as plt
    from statsmodels import api as sm
    import pandas as pd
    import os
    
    value_series=df[value_column]
    value_series.dropna(inplace=True)
    # get the autocorrelation coefficient
    if nlags is not None:
        pacf=sm.tsa.pacf(value_series, nlags=nlags)
    else:
        pacf=sm.tsa.pacf(value_series, nlags=len(value_series))   
        
    bins_tuples=[(bins_list[i],bins_list[i+1]) for i in range(len(bins_list)-1)]  
    bins=pd.IntervalIndex.from_tuples(bins_tuples)
    categories_counts=pd.cut(pacf, bins).value_counts()          
        
    if plot:
        fig=plt.figure(figsize=(12,8))
        ax=fig.add_subplot(111)
        plt.rc('axes', unicode_minus=False)
        if nlags is not None:
            fig=sm.graphics.tsa.plot_pacf(value_series, lags=nlags,ax=ax,title=title)
        else:
            fig=sm.graphics.tsa.plot_pacf(value_series, lags=len(value_series)-1,ax=ax,title=title)
        ax.xaxis.set_ticks_position('bottom') 
        fig.tight_layout()
        
        old_xticks=ax.get_xticks()
        xticks_step=xticks_step
        new_xticks=list(range(0,int(old_xticks[-1]),xticks_step))
        ax.set_xticks(new_xticks)   
        if save_path:
            plt.savefig(os.path.join(save_path,"{}.jpg".format(title)))        
        
        plt.show()
        
    return pacf,categories_counts


def dropFirstNonnullRows_day(df,value_column): 
    '''
    移除第一天数据

    Parameters
    ----------
    df : DataFrame
        含待处理列的DataFrame格式数据.
    value_column : string
        待处理数据列名.

    Returns
    -------
    df_masked : DataFrame
        移除第一天后的数据.

    '''
    import numpy as np
    
    value_series=df[value_column]
    idx_first=value_series.loc[~value_series.isnull()].index[0]
    first_day=idx_first.date()
    mask=np.array([dt.date()==first_day for dt in value_series.index]) 
    df_masked=df[~mask]

    return df_masked

def stationary_adfuller(df,value_column,autolag=None,alpha=0.05,print_detail=False):    
    '''
    计算时间序列的平稳性（statsmodels的adfuller方法）

    Parameters
    ----------
    df : DataFrame
        包含计算列的DataFrame格式数据.
    value_column : string
        待计算的列名.
    autolag : string, optional
        {“AIC”, “BIC”, “t-stat”, None}，具体参考 https://www.statsmodels.org/devel/generated/statsmodels.tsa.stattools.adfuller.html. The default is None.
    alpha : float, optional
        显著性水平(p-value). The default is 0.05.
    print_detail : bool, optional
        是否打印统计细节信息. The default is False.

    Returns
    -------
    is_stationary : dict
        节点名：是否平稳布尔值.

    '''
    from statsmodels.tsa.stattools import adfuller 
    
    df_drop=df[value_column].dropna()
    adfuller_test=adfuller(df_drop,autolag=autolag) #https://www.statsmodels.org/devel/generated/statsmodels.tsa.stattools.adfuller.html
    is_stationary=True if adfuller_test[1]<=alpha else False
    if print_detail:
        print('ADF statistic: %f' % adfuller_test[0])
        print('p-value: %f' % adfuller_test[1])
        print('critical values:')
        for key, value in adfuller_test[4].items():
            print('\t%s: %.3f' % (key, value))        
    return is_stationary

def white_noise_testing(df,value_column,lags=[6,12]):
    '''
    白噪声检验(纯随机性检验)，statsmodels.stats.diagnostic.acorr_ljungbox方法计算，包括Ljung-Box test和Box-Pierce test

    Parameters
    ----------
    df : DataFrame
        包含检测列的DataFrame格式数据.
    value_column : string
        待检测列名.
    lags : int, optional
        延迟数. The default is [6,12].

    Returns
    -------
    stat_pvalue : dict
        返回Ljung-Box test和Box-Pierce统计值，及p_value值.

    '''
    import statsmodels.stats.diagnostic as diag
    df_drop=df[value_column].dropna()
    stat_pvalue=diag.acorr_ljungbox(df_drop, lags=lags, boxpierce=True, model_df=0, period=None, return_df=None)
    return stat_pvalue   

def time_series_plot_MultiColumns(df,span=None,rolling_window=None,figsize=(10,10),font_size=10,legend=True,**setting):
    '''
    打印所有列的时间序列数据。

    Parameters
    ----------
    df : DataFrame
        计算数据.
    span : list(string), optional
        打印时间区间，（表述时间的字符串）. The default is None.
    rolling_window : int, optional
        数据平滑. The default is None.
    figsize : tuple(int,float), optional
        图表大小. The default is (10,10).
    font_size : int or float, optional
        字体大小. The default is 10.
    legend : bool, optional
        是否打印图例. The default is True.
    **setting : kw-argument(string)
        包括xlabel，ylabel，title.

    Returns
    -------
    df_span : DataFrame
        提取时间区间内的数据行.

    '''
    import matplotlib.pyplot as plt
    from pylab import mpl
    import matplotlib.dates as md
    from matplotlib.dates import DayLocator, HourLocator, DateFormatter, drange
    
    mpl.rcParams['font.sans-serif']=['SimHei'] #解决中文字符乱码问题
    plt.figure()
    plt.rcParams.update({'font.size':font_size}) # must set in top
    
    setting_dict={"xlabel":"X","ylabel":"Y","title":None,"xticklabels_strftime":"%Y-%m-%d","xticks_rotation":0}
    setting_dict.update(setting)     
    df_span=df[span[0]:span[1]]    
    
    if rolling_window:
        df_span_rolling=df_span.rolling(rolling_window).mean()        
        ax=df_span_rolling.plot(legend=legend,figsize=figsize) 
    else:
        ax=df_span.plot(legend=legend,figsize=figsize) 
    #https://matplotlib.org/stable/api/_as_gen/matplotlib.axes.Axes.set.html    
    ax.set(xlabel=setting_dict["xlabel"],
           ylabel=setting_dict["ylabel"],
           title=setting_dict["title"],
           )  
    
    return df_span
```

`air_time_series_analysis.py`
```python
# -*- coding: utf-8 -*-
"""
Created on Sun Mar 13 08:27:50 2022

@author: Richie Bao-caDesign设计(cadesign.cn)
"""
#%%
class time_series_analysis_batch:
    '''
    class - 与时间序列相关的计算，包括数据预处理，图表打印，自相关和偏自相关系数，及平稳性计算等
    '''
    
    def __init__(self,df,sensor_name,value_column,time_column,group_column,rule=["H"],dropnone=True,value_type='float',z_thresh=3):
        '''
        类初始化值

        Parameters
        ----------
        df : DataFrame
            待处理的数据.
        sensor_name : string
            传感器名称.
        value_column : string
            待处理的列名.
        time_column : string
            含有时间的列名.
        group_column : string
            分组列名.
        rule : string, optional
            时间序列重采样规则，例如['H','D','M','Y']等. The default is ["H"].
        dropnone : bool, optional
            是否移除空值. The default is True.
        value_type : string, optional
            因为处理列可能为object类型（string），需要重定义数据类型进行后续计算. The default is 'float'.
        z_thresh : float, optional
            异常值处理阈值. The default is 3.

        Returns
        -------
        None.

        '''
        self.df=df
        self.sensor_name=sensor_name
        self.value_column=value_column
        self.dropnone=dropnone
        self.value_type=value_type
        self.z_thresh=z_thresh
        self.time_column=time_column
        self.group_column=group_column
        self.rule=rule
     
    def sensors_range(self,AoT_sensors_fp,sensor_column,min_column,max_column):
        '''
        提取传感器取值区间

        Parameters
        ----------
        AoT_sensors_fp : string
            AoT的sensors.csv文件.
        sensor_column : string
            包含传感器名称的列名.
        min_column : string
            包含传感器最小取值的列名.
        max_column : string
            包含传感器最大取值的列名.

        Returns
        -------
        dict
            各个传感器的取值区间字典.

        '''
        import pandas as pd
        
        AoT_nodes_df=pd.read_csv(AoT_sensors_fp,sep=",",header=0)
        AoT_sensors_range=AoT_nodes_df.set_index(sensor_column)[[min_column,max_column]].to_dict()
        self.specified_range_dict={sensor_name:[AoT_sensors_range[min_column][sensor_name],AoT_sensors_range[max_column][sensor_name]] for sensor_name in air_sensor_list}
        
        return self.specified_range_dict
    
    def df_preprocessing(self):
        '''
        数据预处理，包括根据传感器取值区间提取行；移除空值行；剔除异常值；根据时间戳重采样等

        Returns
        -------
        DataFrame
            数据预处理结果.

        '''
        import time_series_analysis as tsa
        
        value_range=self.specified_range_dict[self.sensor_name]
        value_within_range=tsa.df_value_within_range(self.df,self.value_column,value_range,dropnone=self.dropnone,value_type=self.value_type)        
        value_drop_outliers=tsa.df_drop_outliers(value_within_range,self.value_column,z_thresh=self.z_thresh)   
        value_resample=tsa.df_resample(value_drop_outliers,self.value_column,self.time_column,self.rule,group=self.group_column)
        mask=[i.split("_")[0] in self.rule for i in value_resample.columns]
        self.value_resample_mask=value_resample.loc[:,mask].T #value_resample_mask=value_resample.drop(columns=['geometry','node_id']).T
        self.value_resample_mask.rename(index={i:datetime.strptime(i.split("_")[1],'%Y-%m-%d %H:%M:%S') for i in self.value_resample_mask.index.to_list()},inplace=True)    
        
        return self.value_resample_mask
    
    def time_series_plot(self,span,columns=None,rolling_window=10,xlabel="X",ylabel="Y",figsize=(20,10),font_size=10,legend=False):  
        '''
        打印所有列的时间序列数据。

        Parameters
        ----------
        span : list(string)
            打印时间区间，（表述时间的字符串）.
        columns : string, optional
            打印列（nodes），如果默认，则打印全部节点. The default is None.
        rolling_window : int, optional
            数据平滑. The default is 10.
        xlabel : string, optional
            横轴名. The default is "X".
        ylabel : string, optional
            纵轴名. The default is "Y".
        figsize : tuple(float or int), optional
            图表大小. The default is (20,10).
        font_size : int or float, optional
            字体大小. The default is 10.
        legend : bool, optional
            是否打印图例. The default is False.

        Returns
        -------
        df_span : DataFrame
            提取时间区间内的数据行.

        '''
        import time_series_analysis as tsa     
        
        if columns:
            df_span=tsa.time_series_plot_MultiColumns(self.value_resample_mask[columns],span=span,rolling_window=rolling_window,figsize=figsize,font_size=font_size,legend=legend,xlabel=xlabel,ylabel=ylabel)
        else:
            df_span=tsa.time_series_plot_MultiColumns(self.value_resample_mask,span=span,rolling_window=rolling_window,figsize=figsize,font_size=font_size,legend=legend,xlabel=xlabel,ylabel=ylabel)
        
        return df_span    
    
    def acf_pacf_counter(self,nlags=7,plot=False,save_path_acf=None,save_path_pacf=None,diff_periods=None):
        '''
        所有节点（nodes）自相关autocorrelation和偏自相关partial autocorrelation计算及频数统计

        Parameters
        ----------
        nlags : int, optional
            延迟数. The default is 7.
        plot : bool, optional
            是否打印图表,True为打印. The default is False.

        Returns
        -------
        acf_counter_dict : dict
            返回自相关系数字典（node:acf）.
        pacf_counter_dict : dict
            返回偏自相关字典（node:pacf）.

        '''
        import time_series_analysis as tsa
        from tqdm import tqdm
        
        value_resample_mask=self.value_resample_mask.copy(deep=True)
        sensor_nodes=value_resample_mask.columns
        acf_counter_dict={}
        pacf_counter_dict={}
        acf_insufficient_num=0
        pacf_insufficient_num=0  
        if diff_periods:
            value_resample_mask=value_resample_mask.diff(diff_periods)
        for node in tqdm(sensor_nodes):
            try:
                acf,acf_categories_counts=tsa.autocorrelation_time_series(value_resample_mask,node,plot=plot,nlags=nlags,title="acf_{}".format(node),save_path=save_path_acf)
                acf_counter_dict[node]=acf_categories_counts  
            except:
                acf_insufficient_num+=1
                print("acf_{}-Insufficient sample size!".format(node))               
                
            try:   
               pacf,pacf_categories_counts=tsa.partial_autocorrelation_time_series(value_resample_mask,node,plot=plot,nlags=nlags,title="pacf_{}".format(node),save_path=save_path_pacf) 
               pacf_counter_dict[node]=pacf_categories_counts
            except:
                pacf_insufficient_num+=1
                print("pacf_{}-Insufficient sample size!".format(node)) 
                
        acf_counter_sum=pd.DataFrame(acf_counter_dict.values()).sum(axis=0)  
        pacf_counter_sum=pd.DataFrame(pacf_counter_dict.values()).sum(axis=0)
        print("_"*50)
        print("acf_valid node number={};pacf_valid node number={}".format(len(sensor_nodes)-acf_insufficient_num,len(sensor_nodes)-pacf_insufficient_num))
        print("_"*50)
        print("acf_counter_sum={},\n,pacf_counter_sum={};".format(acf_counter_sum,pacf_counter_sum))
        return acf_counter_dict,pacf_counter_dict
    
    def stationary_stat(self,autolag=None,alpha=0.05,print_detail=False,diff_periods=None):
        '''
        批量计算所有节点的平稳性

        Parameters
        ----------
        autolag : string, optional
            {“AIC”, “BIC”, “t-stat”, None}. The default is None.
        alpha : float, optional
            显著性水平(p-value). The default is 0.05.
        print_detail : bool, optional
            是否打印统计细节信息. The default is False.

        Returns
        -------
        is_stationary_dict : dict(node:bool)
            返回各个节点是否平稳的布尔值，为True则平稳.

        '''
        import time_series_analysis as tsa
        from tqdm import tqdm
        
        value_resample_mask=self.value_resample_mask.copy(deep=True)
        is_stationary_dict={}
        sensor_nodes=value_resample_mask.columns
        valid_nodes=[]
        
        if diff_periods:
            value_resample_mask=value_resample_mask.diff(diff_periods)
        
        for node in tqdm(sensor_nodes):
            try:
                is_stationary=tsa.stationary_adfuller(value_resample_mask,node,autolag=autolag,alpha=alpha,print_detail=print_detail)
                is_stationary_dict[node]=is_stationary
                valid_nodes.append(node)
            except:
                print("sample size is too short to calculate.")
        
        print("is_stationary number={} in {} of valid nodes.".format(list(is_stationary_dict.values()).count(True),len(valid_nodes)))
        return is_stationary_dict
    
    def white_noise_Ljung_box_pierce(self,lags=[6,12],alpha=0.05):
        '''
        白噪声批量检验(纯随机性检验)，statsmodels.stats.diagnostic.acorr_ljungbox方法计算，包括Ljung-Box test和Box-Pierce test。并根据计算p-value值是否大于显著性水平（0.05或0.01），判断是否为白噪声

        Parameters
        ----------
        lags : int, optional
            延迟数. The default is [6,12].
        alpha : float, optional
            显著性水平. The default is 0.05.

        Returns
        -------
        stat_pvalue_dict : dict
            包括Ljung-Box test和Box-Pierce test的统计值和p-value.
        is_white_nose : dict
            各个节点（node）是否为白噪音.

        '''
        import time_series_analysis as tsa
        from tqdm import tqdm
        
        sensor_nodes=self.value_resample_mask.columns
        stat_pvalue_dict={}
        is_white_nose={}
        for node in tqdm(sensor_nodes):            
            try:
                stat_pvalue=tsa.white_noise_testing(self.value_resample_mask,node,lags=lags)
                lb_pvalue=stat_pvalue[1]
                bp_pvalue=stat_pvalue[3]
                stat_pvalue_dict[node]={"stat":{"lb_stat":stat_pvalue[0],"bp_stat":stat_pvalue[2]},"pvalue":{"lb_pvalue":lb_pvalue,"bp_pvalue":bp_pvalue}}
                is_white_nose[node]=dict(zip(["lag_{}".format(i) for i in lags],[True if i>alpha and j>alpha else False for i,j in zip(lb_pvalue,bp_pvalue)]))
            except:
                print("{}-error!".format(node))           
        return stat_pvalue_dict,is_white_nose
    
    def gantt_chart_H(self):
        '''
        打印节点传感器含有测量值的连续时间（小时）区间

        Returns
        -------
        None.

        '''
        import plotly.figure_factory as ff
        from tqdm import tqdm
        import pandas as pd
        from random import randint
        import numpy as np
        import plotly.io as pio
        pio.renderers.default='browser'
        
        sensor_nodes=self.value_resample_mask.columns        
        Start_Finish_Task=[]
        for node in tqdm(sensor_nodes):
            ts_node=self.value_resample_mask[node]
            ts_node.dropna(inplace=True)
            ts_node=ts_node.reset_index()
            ts_node['group']=(ts_node['ts'].shift(1)!=ts_node['ts']-pd.Timedelta(hours=1)).cumsum()
            ts_node=ts_node.groupby('group')['ts'].agg(['first', 'last', 'count'])
            ts_node['count']=ts_node['count']-1            
            ts_node.columns=['Start', 'Finish', 'Duration_Hours']
            ts_node['Task']=node
            
            Start_Finish_Task.append(ts_node)
        
        SFT=pd.concat(Start_Finish_Task,ignore_index=True,axis=0)        
        # print(SFT)        
        colors=["rgb({},{},{})".format(randint(0,255),randint(0,255),randint(0,255) ) for i in range(len(np.unique(SFT.Task)))]
        fig=ff.create_gantt(SFT,group_tasks=True,index_col='Task',colors=colors)
        fig.update_layout(autosize=False,width=2100,height=1200,)
        fig.show()
        
        return SFT
  
#%%    

if __name__=="__main__":
    import sys
    sys.path.append('..')
    import util    
    import geopandas as gpd
    import pandas as pd
    import os
    import pickle
    from database import postSQL2gpd,gpd2postSQL,cfg_load_yaml  
    from glob import glob
    import time_series_analysis as tsa
    from datetime import datetime
    parent_path=os.path.dirname(os.getcwd())
    
    cfg=cfg_load_yaml('../config.yml')  
    UN=cfg["postgreSQL"]["myusername"]
    PW=cfg["postgreSQL"]["mypassword"]
    DB=cfg["postgreSQL"]["mydatabase"] 
    GC='geometry' 
    
    air_sensor_category_save_fp=cfg['analysis_air']['air_sensor_category_save_fp']
    air_sensor_category_fns=glob(os.path.join(air_sensor_category_save_fp,"*.gpkg"))
    air_sensor_list=cfg['analysis_air']['air_sensor_list']
    print(air_sensor_list)  #['co', 'h2s', 'no2', 'o3', 'oxidizing_gases', 'reducing_gases', 'so2']  
    
    AoT_nodes_TN=cfg['table_name']['AoT_nodes_TN']  
    AoT_nodes_gdf=postSQL2gpd(table_name=AoT_nodes_TN,geom_col=GC,myusername=UN,mypassword=PW,mydatabase=DB)
    
    #A.传感器值域
    AoT_sensors_fp=os.path.join(parent_path,cfg['AoT']['AoT_sensors_fp'])
    AoT_nodes_df=pd.read_csv(AoT_sensors_fp,sep=",",header=0)
    AoT_sensors_range=AoT_nodes_df.set_index('sensor')[['hrf_minval', 'hrf_maxval']].to_dict()
    co_value_range=[AoT_sensors_range['hrf_minval']['co'],AoT_sensors_range['hrf_maxval']['co']]
    specified_range_dict={sensor_name:[AoT_sensors_range['hrf_minval'][sensor_name],AoT_sensors_range['hrf_maxval'][sensor_name]] for sensor_name in air_sensor_list}
    
    #B.测量数据按照时间周期重采样，包括移除空值和超出给定值域的行，并写入数据    
    air_tn_list=tsa.df_resample_bundle(air_sensor_category_fns,air_sensor_list,['value_hrf'],'timestamp',['D','W','M','Y'],cfg,'node_id',specified_range_dict,'air')
    
```

__1-CO-污染气体时间序列（时序）分析__

* 测量值时间轴

各个节点测量值时间上并不是完全连续，按照1小时连续性来切分时间段，即如果时间之间相差1小时以上则进行划分。从打印结果来看，CO传感器浓度值时间上虽然断续，但是连续较长的测量值也存在。同时需要注意，各个节点获取的测量值时间段上很难完全吻合。

<a href=""><img src="./imgs/3_3_2_13.png" height="auto" width="auto" title="caDesign"></a>

* 时序打印

为了方便观察时序数据，分别打印全部节点全部时间，可以纵观所有数据情况；打印部分节点全部时间，避免节点间互相干扰，较为清晰的观察数值变化关系；打印全部节点部分时间，可以详细观察细微时间变化下的数值变化情况，以及不同节点之间的数值关系。

从图表初步判断，CO气体时序数据具有一定的平稳性和周期性，不是白噪声随机数据。同时各个节点之间的时序数值起伏变化趋势趋同。

__Fig. CO时序数据__  

全部节点和全部时间：

<a href=""><img src="./imgs/3_3_2_08.png" height="auto" width="auto" title="caDesign"></a>

随机抽取几个节点打印全部时间：

<a href=""><img src="./imgs/3_3_2_09.png" height="auto" width="auto" title="caDesign"></a>

打印全部节点部分时间：

<a href=""><img src="./imgs/3_3_2_11.png" height="auto" width="auto" title="caDesign"></a>

* 白噪音检测

包含有CO传感器浓度值的节点总共有52个，在白噪音计算时，因为数据量不足的节点有6个，因此最终白噪音检测的节点数为46。延迟数配置上包括3个量，为12（小时）,24（小时）和168（小时），对应半天、一天和7周时间。从计算结果来看，除了延迟数7天中有两个节点可能为白噪音外，其余均不是白噪音。

```python
              co_lag_12  co_lag_24  co_lag_168
001e0610890f      False      False       False
001e06109416      False      False       False
001e0610ba13      False      False       False
001e0610ba15      False      False       False
001e0610ba46      False      False       False
001e0610bbe5      False      False       False
001e0610bc10      False      False       False
001e0610bc12      False      False       False
001e0610e537      False      False       False
001e0610e538      False      False       False
001e0610e539      False      False       False
001e0610e835      False      False       False
001e0610e8cb      False      False        True
001e0610eef2      False      False       False
001e0610ef27      False      False       False
001e0610f05c      False      False       False
001e0610f513      False      False        True
001e0610f6db      False      False       False
001e0610f6dd      False      False       False
001e0610f703      False      False       False
001e0610f732      False      False       False
001e0610f8f4      False      False       False
001e06112e77      False      False       False
001e061130f4      False      False       False
001e06113107      False      False       False
001e06113acb      False      False       False
001e06113ace      False      False       False
001e06113ad6      False      False       False
001e06113ad8      False      False       False
001e06113cf1      False      False       False
001e06113cff      False      False       False
001e06113d32      False      False       False
001e06113d83      False      False       False
001e06113dbc      False      False       False
001e06113f54      False      False       False
001e0611441e      False      False       False
001e061144be      False      False       False
001e061144c0      False      False       False
001e06114500      False      False       False
001e06114503      False      False       False
001e061146bc      False      False       False
001e061146cb      False      False       False
001e061146d6      False      False       False
001e06114fd4      False      False       False
001e06115365      False      False       False
001e06115369      False      False       False
```

* 平稳性检测

计算结果显示51个有效计算节点下有35个节点为平稳，占有效总数的68.63%；有31.37%个节点CO测量值变化幅度较大。如果对一阶差分后的时序进行平稳性检验，则50个有效计算节点下有47个节点为平稳，占有效总数94%。

__Fig. CO平稳性检验（未差分）__  

<a href=""><img src="./imgs/3_3_2_12_s.jpg" height="auto" width="auto" title="caDesign"></a>

* 周期性模式判断

CO的平稳性检验中有部分数据数值变化较大，因此通过自相关系数计算和图表打印，不是很容易发现周期性的模式。因此同时对一阶差分后的时序进行自相关系数计算，结果图表较之未差分前，交易判断具有周期性模式，周期约为24小时（天）。


__Fig. CO自相关系数 (ACF) 未差分 lag=24×7__ 

<a href=""><img src="./imgs/3_3_2_14_s.jpg" height="auto" width="auto" title="caDesign"></a>

__Fig. CO偏自相关系数(PACF) 未差分 lag=24×7__ 

<a href=""><img src="./imgs/3_3_2_15_s.jpg" height="auto" width="auto" title="caDesign"></a>

__Fig. CO自相关系数 (ACF) 一阶差分 lag=24×7__ 

<a href=""><img src="./imgs/3_3_2_16_s.jpg" height="auto" width="auto" title="caDesign"></a>

__Fig. CO偏自相关系数(PACF) 一阶差分 lag=24×7__ 

<a href=""><img src="./imgs/3_3_2_17_s.jpg" height="auto" width="auto" title="caDesign"></a>


`air_time_series_analysis.py`
```python
if __name__=="__main__":
    #C.时间序列相关分析
    #C_1. co
    air_co_fn=os.path.join(parent_path,air_sensor_category_save_fp,"air_co.gpkg")     
    s_t=util.start_time()
    air_co=gpd.read_file(air_co_fn) #2.50GB， Total time spend:10.77 minutes（外置固态硬盘）    
    util.duration(s_t)     
        
    tsab_co=time_series_analysis_batch(air_co,"co",'value_hrf','timestamp','node_id')
    sensor_value_range=tsab_co.sensors_range(AoT_sensors_fp,'sensor','hrf_minval', 'hrf_maxval')  
    co_value_resample_mask=tsab_co.df_preprocessing()  
    
    co_SFT=tsab_co.gantt_chart_H()  
    
    _=tsab_co.time_series_plot(['2018-01-17 0:0:0','2018-05-16 0:0:0'],rolling_window=10,xlabel="时间",ylabel="CO-浓度(ppm)",figsize=(20,10),font_size=15)
    _=tsab_co.time_series_plot(['2018-01-17 0:0:0','2018-06-16 0:0:0'],['001e061146d6','001e06115365', '001e06113cff', '001e06113d22', '001e0610e537'],rolling_window=6,xlabel="时间",ylabel="浓度(ppm)",figsize=(20,10),font_size=15,legend=True)
    _=tsab_co.time_series_plot(['2018-04-25 0:0:0','2018-05-01 0:0:0'],rolling_window=6,xlabel="时间",ylabel="浓度(ppm)",figsize=(20,10),font_size=15,legend=False)
    
    co_stat_pvalue_dict,co_is_white_noise=tsab_co.white_noise_Ljung_box_pierce(lags=[12,24,24*7])
    co_is_white_noise_df=pd.DataFrame.from_dict(co_is_white_noise,orient='index')
    co_is_white_noise_columns_new={i:"co_{}".format(i) for i in co_is_white_noise_df.columns}
    co_is_white_noise_df=co_is_white_noise_df.rename(columns=co_is_white_noise_columns_new)
    air_is_white_noise_gdf=pd.merge(AoT_nodes_gdf,co_is_white_noise_df,left_on='node_id',right_index=True,how='outer')
    gpd2postSQL(air_is_white_noise_gdf,table_name='air_is_white_noise',myusername=UN,mypassword=PW,mydatabase=DB)
    
    co_is_stationary_dict=tsab_co.stationary_stat(print_detail=False) #,autolag="AIC"
    co_is_stationary_dict=tsab_co.stationary_stat(print_detail=False,diff_periods=1) #,autolag="AIC"
    
    co_is_stationary_df=pd.DataFrame.from_dict(co_is_stationary_dict,orient='index',columns=["co_is_stationary"])
    air_is_stationary_gdf=pd.merge(AoT_nodes_gdf,co_is_stationary_df,left_on='node_id',right_index=True,how='outer')
    gpd2postSQL(air_is_stationary_gdf,table_name='air_is_stationary',myusername=UN,mypassword=PW,mydatabase=DB)    
    
    save_path_acf=os.path.join(parent_path,'./charts/co_acf')
    save_path_pacf=os.path.join(parent_path,'./charts/co_pacf')
    co_acf_counter_dict,pacf_counter_dict=tsab_co.acf_pacf_counter(nlags=24*7,plot=True,save_path_acf=save_path_acf,save_path_pacf=save_path_pacf,diff_periods=1)    
```


__2-H2S-污染气体时间序列分析__

* 测量值时间轴

H2S测量时间轴与CO大部分趋同，但是也存在多处不同。

<a href=""><img src="./imgs/3_3_2_18.png" height="auto" width="auto" title="caDesign"></a>

* 时序打印

__Fig. H2S时序数据__  

全部节点和全部时间：

<a href=""><img src="./imgs/3_3_2_19.png" height="auto" width="auto" title="caDesign"></a>

随机抽取几个节点打印全部时间：

<a href=""><img src="./imgs/3_3_2_20.png" height="auto" width="auto" title="caDesign"></a>

打印全部节点部分时间：

<a href=""><img src="./imgs/3_3_2_21.png" height="auto" width="auto" title="caDesign"></a>

* 白噪音检测

有个别节点为True，即为白噪音，大部分均无白噪音。

```python
              h2s_lag_12  h2s_lag_24  h2s_lag_168
001e0610890f        True        True         True
001e06109416       False       False        False
001e0610ba15       False       False        False
001e0610ba46       False       False        False
001e0610bbe5       False       False        False
001e0610bc10       False       False        False
001e0610bc12        True        True         True
001e0610e537       False       False        False
001e0610e538       False       False        False
001e0610e539       False       False        False
001e0610e835       False       False        False
001e0610e8cb        True        True         True
001e0610eef2       False       False        False
001e0610ef27        True        True         True
001e0610f05c       False       False         True
001e0610f513       False       False         True
001e0610f6db       False       False        False
001e0610f6dd       False       False        False
001e0610f703       False       False        False
001e0610f732       False       False        False
001e0610f8f4       False       False        False
001e06112e77       False       False        False
001e061130f4       False       False        False
001e06113107       False       False        False
001e06113acb       False       False        False
001e06113ace       False       False        False
001e06113ad6       False       False        False
001e06113ad8       False       False        False
001e06113cf1       False       False        False
001e06113cff       False       False        False
001e06113d32       False       False        False
001e06113d83       False       False        False
001e06113dbc       False       False        False
001e06113f54       False       False        False
001e0611441e       False       False        False
001e061144be       False       False        False
001e061144c0       False       False        False
001e06114500       False       False        False
001e06114503       False       False        False
001e061146bc       False       False        False
001e061146cb       False       False        False
001e061146d6       False       False        False
001e06114fd4       False       False        False
001e06115365       False       False        False
001e06115369       False       False        False
```

* 平稳性检测

计算结果显示51个有效计算节点下有38个节点为平稳，占有效总数的74.51%；有25.49%个节点H2S测量值变化幅度较大。如果对一阶差分后的时序进行平稳性检验，则50个有效计算节点下有48个节点为平稳，占有效总数96%。

对比未差分的H2S和CO平稳性检测结果，均平稳的节点有33个；均不平稳的节点有10个；其中一项测量值平稳，而另一项不平稳的有7个。一致性结果占86%，可以判断H2S和CO平稳性基本保持一致。

* 周期性模式判断

从计算结果图表可以初步判断，H2S时序测量值具有周期性模式，周期约为24小时（天）。

__Fig. H2S自相关系数 (ACF) 未差分 lag=24×7__ 

<a href=""><img src="./imgs/3_3_2_22_s.jpg" height="auto" width="auto" title="caDesign"></a>

__Fig. H2S偏自相关系数(PACF) 未差分 lag=24×7__ 

<a href=""><img src="./imgs/3_3_2_23_s.jpg" height="auto" width="auto" title="caDesign"></a>

__Fig. H2S自相关系数 (ACF) 一阶差分 lag=24×7__ 

<a href=""><img src="./imgs/3_3_2_24_s.jpg" height="auto" width="auto" title="caDesign"></a>

__Fig. H2S偏自相关系数(PACF) 一阶差分 lag=24×7__ 

<a href=""><img src="./imgs/3_3_2_25_s.jpg" height="auto" width="auto" title="caDesign"></a>

'time_series_analysis.py'
```python
#%%
def compare_TFN(df,col_a,col_b):
    import numpy as np
    from collections import Counter
    
    df_copy=df.copy(deep=True)
    original_rowsNum=len(df_copy)
    df_copy.dropna(subset=[col_a,col_b],inplace=True)
    dropped_rowsNum=len(df_copy)
    print("orginal rows num={},dropped rows num={}".format(original_rowsNum,dropped_rowsNum))
    conditions=[(df_copy[col_a]==True) & (df_copy[col_b]==True),(df_copy[col_a]==False) & (df_copy[col_b]==False), df_copy[col_a]!=df_copy[col_b]]
    choices=['T','F','D']
    df_copy['compare']=np.select(conditions,choices, ) #default=np.nan
    choices_counter=Counter(df_copy['compare'])
    print(choices_counter)
    
    return df_copy
```


`air_time_series_analysis.py`
```python
if __name__=="__main__":
    #C_2. h2s
    air_h2s_fn=os.path.join(parent_path,air_sensor_category_save_fp,"air_h2s.gpkg")     
    s_t=util.start_time()
    air_h2s=gpd.read_file(air_h2s_fn)  
    util.duration(s_t)     
        
    tsab_h2s=time_series_analysis_batch(air_h2s,"h2s",'value_hrf','timestamp','node_id')
    sensor_value_range=tsab_h2s.sensors_range(AoT_sensors_fp,'sensor','hrf_minval', 'hrf_maxval')  
    h2s_value_resample_mask=tsab_h2s.df_preprocessing()  
    
    h2s_SFT=tsab_h2s.gantt_chart_H()  
    
    _=tsab_h2s.time_series_plot(['2018-01-17 0:0:0','2018-05-16 0:0:0'],rolling_window=10,xlabel="时间",ylabel="H2S-浓度(ppm)",figsize=(20,10),font_size=15)
    _=tsab_h2s.time_series_plot(['2018-01-17 0:0:0','2018-06-16 0:0:0'],['001e061146d6','001e06115365', '001e06113cff', '001e06113d22', '001e0610e537'],rolling_window=6,xlabel="时间",ylabel="H2S-浓度(ppm)",figsize=(20,10),font_size=15,legend=True)
    _=tsab_h2s.time_series_plot(['2018-04-25 0:0:0','2018-05-01 0:0:0'],rolling_window=6,xlabel="时间",ylabel="H2S-浓度(ppm)",figsize=(20,10),font_size=15,legend=False)
    
    h2s_stat_pvalue_dict,h2s_is_white_noise=tsab_h2s.white_noise_Ljung_box_pierce(lags=[12,24,24*7])
    h2s_is_white_noise_df=pd.DataFrame.from_dict(h2s_is_white_noise,orient='index')
    h2s_is_white_noise_columns_new={i:"h2s_{}".format(i) for i in h2s_is_white_noise_df.columns}
    h2s_is_white_noise_df=h2s_is_white_noise_df.rename(columns=h2s_is_white_noise_columns_new)    
    air_is_white_noise_gdf=postSQL2gpd(table_name="air_is_white_noise",geom_col=GC,myusername=UN,mypassword=PW,mydatabase=DB) 
    air_is_white_noise_gdf=pd.merge(air_is_white_noise_gdf,h2s_is_white_noise_df,left_on='node_id',right_index=True,how='outer')
    gpd2postSQL(air_is_white_noise_gdf,table_name='air_is_white_noise',myusername=UN,mypassword=PW,mydatabase=DB)
    
    h2s_is_stationary_dict_d=tsab_h2s.stationary_stat(print_detail=False,diff_periods=1) #,autolag="AIC" 
    h2s_is_stationary_dict=tsab_h2s.stationary_stat(print_detail=False) #,autolag="AIC"       
    h2s_is_stationary_df=pd.DataFrame.from_dict(h2s_is_stationary_dict,orient='index',columns=["h2s_is_stationary"])
    air_is_stationary_gdf=postSQL2gpd(table_name="air_is_stationary",geom_col=GC,myusername=UN,mypassword=PW,mydatabase=DB)     
    air_is_stationary_gdf=pd.merge(air_is_stationary_gdf,h2s_is_stationary_df,left_on='node_id',right_index=True,how='outer')
    gpd2postSQL(air_is_stationary_gdf,table_name='air_is_stationary',myusername=UN,mypassword=PW,mydatabase=DB)    
    
    _=tsa.compare_TFN(air_is_stationary_gdf,'co_is_stationary','h2s_is_stationary')
        
    save_path_acf=os.path.join(parent_path,'./charts/h2s_acf')
    save_path_pacf=os.path.join(parent_path,'./charts/h2s_pacf')
    h2s_acf_counter_dict,pacf_counter_dict=tsab_co.acf_pacf_counter(nlags=24*7,plot=True,save_path_acf=save_path_acf,save_path_pacf=save_path_pacf,diff_periods=1) #diff_periods=1
```

__3-NO2-污染气体时间序列分析__

* 测量值时间轴

<a href=""><img src="./imgs/3_3_2_26.png" height="auto" width="auto" title="caDesign"></a>

* 时序打印

__Fig. NO2时序数据__  

全部节点和全部时间：

<a href=""><img src="./imgs/3_3_2_27.png" height="auto" width="auto" title="caDesign"></a>

随机抽取几个节点打印全部时间：

<a href=""><img src="./imgs/3_3_2_28.png" height="auto" width="auto" title="caDesign"></a>

打印全部节点部分时间：

<a href=""><img src="./imgs/3_3_2_29.png" height="auto" width="auto" title="caDesign"></a>

* 白噪音检测

```python
              no2_lag_12  no2_lag_24  no2_lag_168
001e0610890f       False       False        False
001e06109416       False       False        False
001e0610ba15       False       False        False
001e0610ba46       False       False        False
001e0610bbe5       False       False        False
001e0610bc10       False       False        False
001e0610bc12       False       False        False
001e0610e537       False       False        False
001e0610e538       False       False        False
001e0610e539       False       False        False
001e0610e835       False       False        False
001e0610e8cb       False       False        False
001e0610eef2       False       False        False
001e0610ef27       False       False        False
001e0610f05c       False       False        False
001e0610f513       False       False        False
001e0610f6db       False       False        False
001e0610f6dd       False       False        False
001e0610f703       False       False        False
001e0610f732       False       False        False
001e0610f8f4       False       False        False
001e06112e77       False       False        False
001e061130f4       False       False        False
001e06113107       False       False        False
001e06113acb       False       False        False
001e06113ace       False       False        False
001e06113ad6       False       False        False
001e06113ad8       False       False        False
001e06113cf1       False       False        False
001e06113cff       False       False        False
001e06113d32       False        True         True
001e06113d83       False       False        False
001e06113dbc       False       False        False
001e06113f54       False       False        False
001e0611441e       False       False        False
001e061144be       False       False        False
001e061144c0       False       False        False
001e06114500       False       False        False
001e06114503       False       False        False
001e061146bc       False       False        False
001e061146cb       False       False        False
001e061146d6       False       False        False
001e06114fd4       False       False        False
001e06115365       False       False        False
001e06115369       False       False        False
```

* 平稳性检测

计算结果显示51个有效计算节点下有35个节点为平稳，占有效总数的68.63%；有31.37%个节点NO2测量值变化幅度较大。如果对一阶差分后的时序进行平稳性检验，则50个有效计算节点下有48个节点为平稳，占有效总数96%。

对比未差分的CO和NO2平稳性检测结果，均平稳的节点有32个；均不平稳的节点有12个；其中一项测量值平稳，而另一项不平稳的有6个。一致性结果占88%，可以判断H2S和CO平稳性基本保持一致。

* 周期性模式判断


__Fig. NO2自相关系数 (ACF) 未差分 lag=24×7__ 

<a href=""><img src="./imgs/3_3_2_30_s.jpg" height="auto" width="auto" title="caDesign"></a>

__Fig. NO2偏自相关系数(PACF) 未差分 lag=24×7__ 

<a href=""><img src="./imgs/3_3_2_31_s.jpg" height="auto" width="auto" title="caDesign"></a>

__Fig. NO2自相关系数 (ACF) 一阶差分 lag=24×7__ 

<a href=""><img src="./imgs/3_3_2_32_s.jpg" height="auto" width="auto" title="caDesign"></a>

__Fig. NO2偏自相关系数(PACF) 一阶差分 lag=24×7__ 

<a href=""><img src="./imgs/3_3_2_33_s.jpg" height="auto" width="auto" title="caDesign"></a>

`air_time_series_analysis.py`
```python
if __name__=="__main__":
    #C_3. no2
    air_no2_fn=os.path.join(parent_path,air_sensor_category_save_fp,"air_no2.gpkg")     
    s_t=util.start_time()
    air_no2=gpd.read_file(air_no2_fn)  
    util.duration(s_t)     
        
    tsab_no2=time_series_analysis_batch(air_no2,"no2",'value_hrf','timestamp','node_id')
    sensor_value_range=tsab_no2.sensors_range(AoT_sensors_fp,'sensor','hrf_minval', 'hrf_maxval')  
    no2_value_resample_mask=tsab_no2.df_preprocessing()  
    
    no2_SFT=tsab_no2.gantt_chart_H()  
    
    _=tsab_no2.time_series_plot(['2018-01-17 0:0:0','2018-05-16 0:0:0'],rolling_window=10,xlabel="时间",ylabel="no2-浓度(ppm)",figsize=(20,10),font_size=15)
    _=tsab_no2.time_series_plot(['2018-01-17 0:0:0','2018-06-16 0:0:0'],['001e061146d6','001e06115365', '001e06113cff', '001e06113d22', '001e0610e537'],rolling_window=6,xlabel="时间",ylabel="no2-浓度(ppm)",figsize=(20,10),font_size=15,legend=True)
    _=tsab_no2.time_series_plot(['2018-04-25 0:0:0','2018-05-01 0:0:0'],rolling_window=6,xlabel="时间",ylabel="no2-浓度(ppm)",figsize=(20,10),font_size=15,legend=False)
    
    no2_stat_pvalue_dict,no2_is_white_noise=tsab_no2.white_noise_Ljung_box_pierce(lags=[12,24,24*7])
    no2_is_white_noise_df=pd.DataFrame.from_dict(no2_is_white_noise,orient='index')
    no2_is_white_noise_columns_new={i:"no2_{}".format(i) for i in no2_is_white_noise_df.columns}
    no2_is_white_noise_df=no2_is_white_noise_df.rename(columns=no2_is_white_noise_columns_new)    
    air_is_white_noise_gdf=postSQL2gpd(table_name="air_is_white_noise",geom_col=GC,myusername=UN,mypassword=PW,mydatabase=DB) 
    air_is_white_noise_gdf=pd.merge(air_is_white_noise_gdf,no2_is_white_noise_df,left_on='node_id',right_index=True,how='outer')
    gpd2postSQL(air_is_white_noise_gdf,table_name='air_is_white_noise',myusername=UN,mypassword=PW,mydatabase=DB)
    
    no2_is_stationary_dict_d=tsab_no2.stationary_stat(print_detail=False,diff_periods=1) #,autolag="AIC" 
    no2_is_stationary_dict=tsab_no2.stationary_stat(print_detail=False) #,autolag="AIC"       
    no2_is_stationary_df=pd.DataFrame.from_dict(no2_is_stationary_dict,orient='index',columns=["no2_is_stationary"])
    air_is_stationary_gdf=postSQL2gpd(table_name="air_is_stationary",geom_col=GC,myusername=UN,mypassword=PW,mydatabase=DB)     
    air_is_stationary_gdf=pd.merge(air_is_stationary_gdf,no2_is_stationary_df,left_on='node_id',right_index=True,how='outer')
    gpd2postSQL(air_is_stationary_gdf,table_name='air_is_stationary',myusername=UN,mypassword=PW,mydatabase=DB)    
    
    _=tsa.compare_TFN(air_is_stationary_gdf,'co_is_stationary','no2_is_stationary')
        
    save_path_acf=os.path.join(parent_path,'./charts/no2_acf')
    save_path_pacf=os.path.join(parent_path,'./charts/no2_pacf')
    no2_acf_counter_dict,pacf_counter_dict=tsab_co.acf_pacf_counter(nlags=24*7,plot=True,save_path_acf=save_path_acf,save_path_pacf=save_path_pacf,diff_periods=1) #diff_periods=1
    
```

__4-O3-污染气体时间序列分析__

* 测量值时间轴

<a href=""><img src="./imgs/3_3_2_34.png" height="auto" width="auto" title="caDesign"></a>

* 时序打印

__Fig. O3时序数据__  

全部节点和全部时间：

<a href=""><img src="./imgs/3_3_2_35.png" height="auto" width="auto" title="caDesign"></a>

随机抽取几个节点打印全部时间：

<a href=""><img src="./imgs/3_3_2_36.png" height="auto" width="auto" title="caDesign"></a>

打印全部节点部分时间：

<a href=""><img src="./imgs/3_3_2_37.png" height="auto" width="auto" title="caDesign"></a>

* 白噪音检测

```python
              o3_lag_12  o3_lag_24  o3_lag_168
001e0610890f      False      False       False
001e06109416      False      False       False
001e0610ba15      False      False       False
001e0610ba46      False      False       False
001e0610bbe5      False      False       False
001e0610bc10      False      False       False
001e0610bc12      False      False       False
001e0610e537      False      False       False
001e0610e538      False      False       False
001e0610e539      False      False       False
001e0610e835      False      False       False
001e0610e8cb      False      False       False
001e0610eef2      False      False       False
001e0610ef27      False      False       False
001e0610f05c      False      False       False
001e0610f513      False      False       False
001e0610f6db      False      False       False
001e0610f6dd      False      False       False
001e0610f703      False      False       False
001e0610f732      False      False       False
001e0610f8f4      False      False       False
001e06112e77      False      False       False
001e061130f4      False      False       False
001e06113107      False      False       False
001e06113acb      False      False       False
001e06113ace      False      False       False
001e06113ad6      False      False       False
001e06113ad8      False      False       False
001e06113cf1      False      False       False
001e06113cff      False      False       False
001e06113d32       True       True        True
001e06113d83      False      False       False
001e06113dbc      False      False       False
001e06113f54      False      False       False
001e0611441e      False      False       False
001e061144be      False      False       False
001e061144c0      False      False       False
001e06114500      False      False       False
001e06114503      False      False       False
001e061146bc      False      False       False
001e061146cb      False      False       False
001e061146d6      False      False       False
001e06114fd4      False      False       False
001e06115365      False      False       False
001e06115369      False      False       False
```

* 平稳性检测

计算结果显示51个有效计算节点下有33个节点为平稳，占有效总数的64.71%；有35.29%个节点O3测量值变化幅度较大。如果对一阶差分后的时序进行平稳性检验，则50个有效计算节点下有49个节点为平稳，占有效总数98%。

对比未差分的CO和O3平稳性检测结果，均平稳的节点有26个；均不平稳的节点有15个；其中一项测量值平稳，而另一项不平稳的有9个。一致性结果占82%，可以判断CO和O3平稳性基本保持一致。

* 周期性模式判断


__Fig. O3自相关系数 (ACF) 未差分 lag=24×7__ 

<a href=""><img src="./imgs/3_3_2_38_s.jpg" height="auto" width="auto" title="caDesign"></a>

__Fig. O3偏自相关系数(PACF) 未差分 lag=24×7__ 

<a href=""><img src="./imgs/3_3_2_39_s.jpg" height="auto" width="auto" title="caDesign"></a>

__Fig. O3自相关系数 (ACF) 一阶差分 lag=24×7__ 

<a href=""><img src="./imgs/3_3_2_40_s.jpg" height="auto" width="auto" title="caDesign"></a>

__Fig. O3偏自相关系数(PACF) 一阶差分 lag=24×7__ 

<a href=""><img src="./imgs/3_3_2_41_s.jpg" height="auto" width="auto" title="caDesign"></a>

`air_time_series_analysis.py`
```python
if __name__=="__main__":
    #C_4. O3
    air_o3_fn=os.path.join(parent_path,air_sensor_category_save_fp,"air_o3.gpkg")     
    s_t=util.start_time()
    air_o3=gpd.read_file(air_o3_fn)  
    util.duration(s_t)     
        
    tsab_o3=time_series_analysis_batch(air_o3,"o3",'value_hrf','timestamp','node_id')
    sensor_value_range=tsab_o3.sensors_range(AoT_sensors_fp,'sensor','hrf_minval', 'hrf_maxval')  
    o3_value_resample_mask=tsab_o3.df_preprocessing()  
    
    o3_SFT=tsab_o3.gantt_chart_H()  
    
    _=tsab_o3.time_series_plot(['2018-01-17 0:0:0','2018-05-16 0:0:0'],rolling_window=10,xlabel="时间",ylabel="o3-浓度(ppm)",figsize=(20,10),font_size=15)
    _=tsab_o3.time_series_plot(['2018-01-17 0:0:0','2018-06-16 0:0:0'],['001e061146d6','001e06115365', '001e06113cff', '001e06113d22', '001e0610e537'],rolling_window=6,xlabel="时间",ylabel="o3-浓度(ppm)",figsize=(20,10),font_size=15,legend=True)
    _=tsab_o3.time_series_plot(['2018-04-25 0:0:0','2018-05-01 0:0:0'],rolling_window=6,xlabel="时间",ylabel="o3-浓度(ppm)",figsize=(20,10),font_size=15,legend=False)
    
    o3_stat_pvalue_dict,o3_is_white_noise=tsab_o3.white_noise_Ljung_box_pierce(lags=[12,24,24*7])
    o3_is_white_noise_df=pd.DataFrame.from_dict(o3_is_white_noise,orient='index')
    o3_is_white_noise_columns_new={i:"o3_{}".format(i) for i in o3_is_white_noise_df.columns}
    o3_is_white_noise_df=o3_is_white_noise_df.rename(columns=o3_is_white_noise_columns_new)    
    air_is_white_noise_gdf=postSQL2gpd(table_name="air_is_white_noise",geom_col=GC,myusername=UN,mypassword=PW,mydatabase=DB) 
    air_is_white_noise_gdf=pd.merge(air_is_white_noise_gdf,o3_is_white_noise_df,left_on='node_id',right_index=True,how='outer')
    gpd2postSQL(air_is_white_noise_gdf,table_name='air_is_white_noise',myusername=UN,mypassword=PW,mydatabase=DB)
    
    o3_is_stationary_dict_d=tsab_o3.stationary_stat(print_detail=False,diff_periods=1) #,autolag="AIC" 
    o3_is_stationary_dict=tsab_o3.stationary_stat(print_detail=False) #,autolag="AIC"       
    o3_is_stationary_df=pd.DataFrame.from_dict(o3_is_stationary_dict,orient='index',columns=["o3_is_stationary"])
    air_is_stationary_gdf=postSQL2gpd(table_name="air_is_stationary",geom_col=GC,myusername=UN,mypassword=PW,mydatabase=DB)     
    air_is_stationary_gdf=pd.merge(air_is_stationary_gdf,o3_is_stationary_df,left_on='node_id',right_index=True,how='outer')
    gpd2postSQL(air_is_stationary_gdf,table_name='air_is_stationary',myusername=UN,mypassword=PW,mydatabase=DB)    
    
    _=tsa.compare_TFN(air_is_stationary_gdf,'co_is_stationary','o3_is_stationary')
        
    save_path_acf=os.path.join(parent_path,'./charts/o3_acf')
    save_path_pacf=os.path.join(parent_path,'./charts/o3_pacf')
    o3_acf_counter_dict,pacf_counter_dict=tsab_co.acf_pacf_counter(nlags=24*7,plot=True,save_path_acf=save_path_acf,save_path_pacf=save_path_pacf,diff_periods=1) #diff_periods=1
    
```


__5-SO2-污染气体时间序列分析__

* 测量值时间轴

<a href=""><img src="./imgs/3_3_2_42.png" height="auto" width="auto" title="caDesign"></a>

* 时序打印

__Fig. SO2时序数据__  

全部节点和全部时间：

<a href=""><img src="./imgs/3_3_2_43.png" height="auto" width="auto" title="caDesign"></a>

随机抽取几个节点打印全部时间：

<a href=""><img src="./imgs/3_3_2_44.png" height="auto" width="auto" title="caDesign"></a>

打印全部节点部分时间：

<a href=""><img src="./imgs/3_3_2_45.png" height="auto" width="auto" title="caDesign"></a>

* 白噪音检测

```python
              so2_lag_12  so2_lag_24  so2_lag_168
001e0610890f       False        True         True
001e06109416       False       False        False
001e0610ba13        True        True         True
001e0610ba15       False       False        False
001e0610ba46       False       False        False
001e0610bbe5       False       False        False
001e0610bc10       False       False        False
001e0610bc12       False       False        False
001e0610e537       False       False        False
001e0610e538       False       False        False
001e0610e539       False       False        False
001e0610e835       False       False        False
001e0610e8cb       False       False        False
001e0610eef2       False       False        False
001e0610ef27       False       False         True
001e0610f05c       False       False        False
001e0610f513       False       False        False
001e0610f6db       False       False        False
001e0610f6dd       False       False        False
001e0610f703       False       False        False
001e0610f732       False       False        False
001e0610f8f4       False       False        False
001e06112e77       False       False        False
001e061130f4       False       False        False
001e06113107       False       False        False
001e06113acb       False       False        False
001e06113ace       False       False        False
001e06113ad6       False       False        False
001e06113ad8       False        True         True
001e06113cf1       False       False        False
001e06113cff       False       False        False
001e06113d32       False       False        False
001e06113d83       False       False        False
001e06113dbc       False       False        False
001e06113f54       False       False        False
001e0611441e       False       False        False
001e061144be       False       False        False
001e061144c0       False       False        False
001e06114500       False       False        False
001e06114503       False       False        False
001e061146bc       False       False        False
001e061146cb       False       False        False
001e061146d6       False       False        False
001e06114fd4       False       False        False
001e06115365       False       False        False
001e06115369       False       False        False
```

* 平稳性检测

计算结果显示52个有效计算节点下有32个节点为平稳，占有效总数的61.54%；有38.46%个SO2节点测量值变化幅度较大。如果对一阶差分后的时序进行平稳性检验，则51个有效计算节点下有50个节点为平稳，占有效总数98.04%。

对比未差分的CO和SO2平稳性检测结果，均平稳的节点有23个；均不平稳的节点有21个；其中一项测量值平稳，而另一项不平稳的有7个。一致性结果占86.27%，可以判断CO和SO2平稳性基本保持一致。

* 周期性模式判断


__Fig. SO2自相关系数 (ACF) 未差分 lag=24×7__ 

<a href=""><img src="./imgs/3_3_2_46_s.jpg" height="auto" width="auto" title="caDesign"></a>

__Fig. SO2偏自相关系数(PACF) 未差分 lag=24×7__ 

<a href=""><img src="./imgs/3_3_2_47_s.jpg" height="auto" width="auto" title="caDesign"></a>

__Fig. SO2自相关系数 (ACF) 一阶差分 lag=24×7__ 

<a href=""><img src="./imgs/3_3_2_48_s.jpg" height="auto" width="auto" title="caDesign"></a>

__Fig. SO2偏自相关系数(PACF) 一阶差分 lag=24×7__ 

<a href=""><img src="./imgs/3_3_2_49_s.jpg" height="auto" width="auto" title="caDesign"></a>

`air_time_series_analysis.py`
```python
if __name__=="__main__":
    #C_5. so2
    air_so2_fn=os.path.join(parent_path,air_sensor_category_save_fp,"air_so2.gpkg")     
    s_t=util.start_time()
    air_so2=gpd.read_file(air_so2_fn)  
    util.duration(s_t)     
        
    tsab_so2=time_series_analysis_batch(air_so2,"so2",'value_hrf','timestamp','node_id')
    sensor_value_range=tsab_so2.sensors_range(AoT_sensors_fp,'sensor','hrf_minval', 'hrf_maxval')  
    so2_value_resample_mask=tsab_so2.df_preprocessing()  
    
    so2_SFT=tsab_so2.gantt_chart_H()  
    
    _=tsab_so2.time_series_plot(['2018-01-17 0:0:0','2018-05-16 0:0:0'],rolling_window=10,xlabel="时间",ylabel="so2-浓度(ppm)",figsize=(20,10),font_size=15)
    _=tsab_so2.time_series_plot(['2018-01-17 0:0:0','2018-06-16 0:0:0'],['001e061146d6','001e06115365', '001e06113cff', '001e06113d22', '001e0610e537'],rolling_window=6,xlabel="时间",ylabel="so2-浓度(ppm)",figsize=(20,10),font_size=15,legend=True)
    _=tsab_so2.time_series_plot(['2018-04-25 0:0:0','2018-05-01 0:0:0'],rolling_window=6,xlabel="时间",ylabel="so2-浓度(ppm)",figsize=(20,10),font_size=15,legend=False)
    
    so2_stat_pvalue_dict,so2_is_white_noise=tsab_so2.white_noise_Ljung_box_pierce(lags=[12,24,24*7])
    so2_is_white_noise_df=pd.DataFrame.from_dict(so2_is_white_noise,orient='index')
    so2_is_white_noise_columns_new={i:"so2_{}".format(i) for i in so2_is_white_noise_df.columns}
    so2_is_white_noise_df=so2_is_white_noise_df.rename(columns=so2_is_white_noise_columns_new)    
    air_is_white_noise_gdf=postSQL2gpd(table_name="air_is_white_noise",geom_col=GC,myusername=UN,mypassword=PW,mydatabase=DB) 
    air_is_white_noise_gdf=pd.merge(air_is_white_noise_gdf,so2_is_white_noise_df,left_on='node_id',right_index=True,how='outer')
    gpd2postSQL(air_is_white_noise_gdf,table_name='air_is_white_noise',myusername=UN,mypassword=PW,mydatabase=DB)
    
    so2_is_stationary_dict_d=tsab_so2.stationary_stat(print_detail=False,diff_periods=1) #,autolag="AIC" 
    so2_is_stationary_dict=tsab_so2.stationary_stat(print_detail=False) #,autolag="AIC"       
    so2_is_stationary_df=pd.DataFrame.from_dict(so2_is_stationary_dict,orient='index',columns=["so2_is_stationary"])
    air_is_stationary_gdf=postSQL2gpd(table_name="air_is_stationary",geom_col=GC,myusername=UN,mypassword=PW,mydatabase=DB)     
    air_is_stationary_gdf=pd.merge(air_is_stationary_gdf,so2_is_stationary_df,left_on='node_id',right_index=True,how='outer')
    gpd2postSQL(air_is_stationary_gdf,table_name='air_is_stationary',myusername=UN,mypassword=PW,mydatabase=DB)    
    
    _=tsa.compare_TFN(air_is_stationary_gdf,'co_is_stationary','so2_is_stationary')
        
    save_path_acf=os.path.join(parent_path,'./charts/so2_acf')
    save_path_pacf=os.path.join(parent_path,'./charts/so2_pacf')
    so2_acf_counter_dict,pacf_counter_dict=tsab_co.acf_pacf_counter(nlags=24*7,plot=True,save_path_acf=save_path_acf,save_path_pacf=save_path_pacf,diff_periods=1) #diff_periods=1  
```

__6-oxidizing gases-污染气体时间序列分析__

* 测量值时间轴

<a href=""><img src="./imgs/3_3_2_50.png" height="auto" width="auto" title="caDesign"></a>

* 时序打印

__Fig. oxidizing_gases时序数据__  

全部节点和全部时间：

<a href=""><img src="./imgs/3_3_2_51.png" height="auto" width="auto" title="caDesign"></a>

随机抽取几个节点打印全部时间：

<a href=""><img src="./imgs/3_3_2_52.png" height="auto" width="auto" title="caDesign"></a>

打印全部节点部分时间：

<a href=""><img src="./imgs/3_3_2_53.png" height="auto" width="auto" title="caDesign"></a>

* 白噪音检测

```python
              oxidizing_lag_12  oxidizing_lag_24  oxidizing_lag_168
001e06109416             False             False              False
001e0610ba13             False             False              False
001e0610ba15             False             False               True
001e0610ba46             False             False              False
001e0610bbe5              True              True               True
001e0610bc10              True              True               True
001e0610bc12             False             False              False
001e0610e537             False             False              False
001e0610e538             False             False              False
001e0610e539             False             False               True
001e0610e835             False             False              False
001e0610eef2             False             False              False
001e0610ef27             False             False              False
001e0610f05c              True              True               True
001e0610f513             False             False              False
001e0610f6db             False             False              False
001e0610f6dd             False             False              False
001e0610f703             False             False              False
001e0610f732             False             False              False
001e0610f8f4             False             False              False
001e06112e77             False             False              False
001e061130f4             False             False              False
001e06113107             False             False              False
001e06113acb              True              True               True
001e06113ace             False             False              False
001e06113ad6              True              True               True
001e06113cf1             False             False              False
001e06113cff             False             False              False
001e06113d32             False             False              False
001e06113d83             False             False              False
001e06113dbc             False             False               True
001e0611441e             False             False              False
001e061144be              True              True               True
001e061144c0             False             False              False
001e06114500             False             False              False
001e06114503             False             False              False
001e061146cb             False             False              False
001e061146d6             False             False               True
001e06114fd4             False             False              False
```

* 平稳性检测

计算结果显示48个有效计算节点下有35个节点为平稳，占有效总数的72.92%；有27.08%oxidizing_gases节点测量值变化幅度较大。如果对一阶差分后的时序进行平稳性检验，则48个有效计算节点下有42个节点为平稳，占有效总数87.5%。

对比未差分的CO和oxidizing_gases平稳性检测结果，均平稳的节点有29个；均不平稳的节点有11个；其中一项测量值平稳，而另一项不平稳的有8个。一致性结果占83.33%，可以判断CO和oxidizing_gases平稳性基本保持一致。

* 周期性模式判断


__Fig. H2S自相关系数 (ACF) 未差分 lag=24×7__ 

<a href=""><img src="./imgs/3_3_2_54_s.jpg" height="auto" width="auto" title="caDesign"></a>

__Fig. H2S偏自相关系数(PACF) 未差分 lag=24×7__ 

<a href=""><img src="./imgs/3_3_2_55_s.jpg" height="auto" width="auto" title="caDesign"></a>

__Fig. H2S自相关系数 (ACF) 一阶差分 lag=24×7__ 

<a href=""><img src="./imgs/3_3_2_56_s.jpg" height="auto" width="auto" title="caDesign"></a>

__Fig. H2S偏自相关系数(PACF) 一阶差分 lag=24×7__ 

<a href=""><img src="./imgs/3_3_2_57_s.jpg" height="auto" width="auto" title="caDesign"></a>

```python
if __name__=="__main__":
    #C_6. oxidizing_gases
    air_oxidizing_fn=os.path.join(parent_path,air_sensor_category_save_fp,"air_oxidizing_gases.gpkg")     
    s_t=util.start_time()
    air_oxidizing=gpd.read_file(air_oxidizing_fn)  
    util.duration(s_t)     
        
    tsab_oxidizing=time_series_analysis_batch(air_oxidizing,"oxidizing_gases",'value_hrf','timestamp','node_id')
    sensor_value_range=tsab_oxidizing.sensors_range(AoT_sensors_fp,'sensor','hrf_minval', 'hrf_maxval')  
    oxidizing_value_resample_mask=tsab_oxidizing.df_preprocessing()  
    
    oxidizing_SFT=tsab_oxidizing.gantt_chart_H()  
    
    _=tsab_oxidizing.time_series_plot(['2018-01-17 0:0:0','2018-05-16 0:0:0'],rolling_window=10,xlabel="时间",ylabel="oxidizing-浓度(ppm)",figsize=(20,10),font_size=15)
    _=tsab_oxidizing.time_series_plot(['2018-01-17 0:0:0','2018-06-16 0:0:0'],['001e061146d6','001e06115365', '001e06113cff', '001e06113d22', '001e0610e537'],rolling_window=6,xlabel="时间",ylabel="oxidizing-浓度(ppm)",figsize=(20,10),font_size=15,legend=True)
    _=tsab_oxidizing.time_series_plot(['2018-04-25 0:0:0','2018-05-01 0:0:0'],rolling_window=6,xlabel="时间",ylabel="oxidizing-浓度(ppm)",figsize=(20,10),font_size=15,legend=False)
    
    oxidizing_stat_pvalue_dict,oxidizing_is_white_noise=tsab_oxidizing.white_noise_Ljung_box_pierce(lags=[12,24,24*7])
    oxidizing_is_white_noise_df=pd.DataFrame.from_dict(oxidizing_is_white_noise,orient='index')
    oxidizing_is_white_noise_columns_new={i:"oxidizing_{}".format(i) for i in oxidizing_is_white_noise_df.columns}
    oxidizing_is_white_noise_df=oxidizing_is_white_noise_df.rename(columns=oxidizing_is_white_noise_columns_new)    
    air_is_white_noise_gdf=postSQL2gpd(table_name="air_is_white_noise",geom_col=GC,myusername=UN,mypassword=PW,mydatabase=DB) 
    air_is_white_noise_gdf=pd.merge(air_is_white_noise_gdf,oxidizing_is_white_noise_df,left_on='node_id',right_index=True,how='outer')
    gpd2postSQL(air_is_white_noise_gdf,table_name='air_is_white_noise',myusername=UN,mypassword=PW,mydatabase=DB)
    
    oxidizing_is_stationary_dict_d=tsab_oxidizing.stationary_stat(print_detail=False,diff_periods=1) #,autolag="AIC" 
    oxidizing_is_stationary_dict=tsab_oxidizing.stationary_stat(print_detail=False) #,autolag="AIC"       
    oxidizing_is_stationary_df=pd.DataFrame.from_dict(oxidizing_is_stationary_dict,orient='index',columns=["oxidizing_is_stationary"])
    air_is_stationary_gdf=postSQL2gpd(table_name="air_is_stationary",geom_col=GC,myusername=UN,mypassword=PW,mydatabase=DB)     
    air_is_stationary_gdf=pd.merge(air_is_stationary_gdf,oxidizing_is_stationary_df,left_on='node_id',right_index=True,how='outer')
    gpd2postSQL(air_is_stationary_gdf,table_name='air_is_stationary',myusername=UN,mypassword=PW,mydatabase=DB)    
    
    _=tsa.compare_TFN(air_is_stationary_gdf,'co_is_stationary','oxidizing_is_stationary')
        
    save_path_acf=os.path.join(parent_path,'./charts/oxidizing_acf')
    save_path_pacf=os.path.join(parent_path,'./charts/oxidizing_pacf')
    oxidizing_acf_counter_dict,pacf_counter_dict=tsab_co.acf_pacf_counter(nlags=24*7,plot=True,save_path_acf=save_path_acf,save_path_pacf=save_path_pacf,diff_periods=1 ) #diff_periods=1    
 
```

__7-reducing gases-污染气体时间序列分析__

* 测量值时间轴

<a href=""><img src="./imgs/3_3_2_58.png" height="auto" width="auto" title="caDesign"></a>

* 时序打印

__Fig. reducing_gases时序数据__  

全部节点和全部时间：

<a href=""><img src="./imgs/3_3_2_59.png" height="auto" width="auto" title="caDesign"></a>

随机抽取几个节点打印全部时间：

<a href=""><img src="./imgs/3_3_2_60.png" height="auto" width="auto" title="caDesign"></a>

打印全部节点部分时间：

<a href=""><img src="./imgs/3_3_2_61.png" height="auto" width="auto" title="caDesign"></a>

* 白噪音检测

```python
              reducing_lag_12  reducing_lag_24  reducing_lag_168
001e0610890f            False            False             False
001e06109416            False            False             False
001e0610ba13            False            False             False
001e0610ba15            False            False             False
001e0610ba46            False            False             False
001e0610bbe5            False            False             False
001e0610bc10            False            False             False
001e0610bc12            False            False             False
001e0610e537            False            False             False
001e0610e538            False            False             False
001e0610e539            False            False             False
001e0610e835            False            False             False
001e0610e8cb            False            False             False
001e0610eef2            False            False             False
001e0610ef27            False            False              True
001e0610f05c            False            False             False
001e0610f513            False            False             False
001e0610f6db            False            False             False
001e0610f6dd            False            False             False
001e0610f703            False            False             False
001e0610f732            False            False             False
001e0610f8f4            False            False             False
001e06112e77            False            False             False
001e061130f4            False            False             False
001e06113107            False            False             False
001e06113acb            False            False             False
001e06113ace            False            False              True
001e06113ad6            False            False             False
001e06113ad8            False            False             False
001e06113cf1            False            False             False
001e06113cff            False            False             False
001e06113d32            False            False             False
001e06113d83            False            False             False
001e06113dbc            False            False             False
001e06113f54            False            False             False
001e0611441e            False            False             False
001e061144be            False            False             False
001e061144c0            False            False             False
001e06114500            False            False             False
001e06114503            False            False             False
001e061146cb            False            False             False
001e061146d6            False            False             False
001e06114fd4            False            False             False
001e06115365            False            False             False
001e06115369            False            False             False
```

* 平稳性检测

计算结果显示50个有效计算节点下有27个节点为平稳，占有效总数的54%；有46%reducing_gases节点测量值变化幅度较大。如果对一阶差分后的时序进行平稳性检验，则50个有效计算节点下有49个节点为平稳，占有效总数98%。

对比未差分的CO和reducing_gases平稳性检测结果，均平稳的节点有24个；均不平稳的节点有14个；其中一项测量值平稳，而另一项不平稳的有12个。一致性结果占76%，可以判断CO和reducing_gases平稳性基本保持一致。

* 周期性模式判断


__Fig. reducing_gases自相关系数 (ACF) 未差分 lag=24×7__ 

<a href=""><img src="./imgs/3_3_2_62_s.jpg" height="auto" width="auto" title="caDesign"></a>

__Fig. reducing_gases偏自相关系数(PACF) 未差分 lag=24×7__ 

<a href=""><img src="./imgs/3_3_2_63_s.jpg" height="auto" width="auto" title="caDesign"></a>

__Fig. reducing_gases自相关系数 (ACF) 一阶差分 lag=24×7__ 

<a href=""><img src="./imgs/3_3_2_64_s.jpg" height="auto" width="auto" title="caDesign"></a>

__Fig. reducing_gases偏自相关系数(PACF) 一阶差分 lag=24×7__ 

<a href=""><img src="./imgs/3_3_2_65_s.jpg" height="auto" width="auto" title="caDesign"></a>

```python
if __name__=="__main__":
    #C_7. reducing_gases
    air_reducing_fn=os.path.join(parent_path,air_sensor_category_save_fp,"air_reducing_gases.gpkg")     
    s_t=util.start_time()
    air_reducing=gpd.read_file(air_reducing_fn)  
    util.duration(s_t)     
        
    tsab_reducing=time_series_analysis_batch(air_reducing,"reducing_gases",'value_hrf','timestamp','node_id')
    sensor_value_range=tsab_reducing.sensors_range(AoT_sensors_fp,'sensor','hrf_minval', 'hrf_maxval')  
    reducing_value_resample_mask=tsab_reducing.df_preprocessing()  
    
    reducing_SFT=tsab_reducing.gantt_chart_H()  
    
    _=tsab_reducing.time_series_plot(['2018-01-17 0:0:0','2018-05-16 0:0:0'],rolling_window=10,xlabel="时间",ylabel="reducing-浓度(ppm)",figsize=(20,10),font_size=15)
    _=tsab_reducing.time_series_plot(['2018-01-17 0:0:0','2018-06-16 0:0:0'],['001e061146d6','001e06115365', '001e06113cff', '001e06113d22', '001e0610e537'],rolling_window=6,xlabel="时间",ylabel="reducing-浓度(ppm)",figsize=(20,10),font_size=15,legend=True)
    _=tsab_reducing.time_series_plot(['2018-04-25 0:0:0','2018-05-01 0:0:0'],rolling_window=6,xlabel="时间",ylabel="reducing-浓度(ppm)",figsize=(20,10),font_size=15,legend=False)
    
    reducing_stat_pvalue_dict,reducing_is_white_noise=tsab_reducing.white_noise_Ljung_box_pierce(lags=[12,24,24*7])
    reducing_is_white_noise_df=pd.DataFrame.from_dict(reducing_is_white_noise,orient='index')
    reducing_is_white_noise_columns_new={i:"reducing_{}".format(i) for i in reducing_is_white_noise_df.columns}
    reducing_is_white_noise_df=reducing_is_white_noise_df.rename(columns=reducing_is_white_noise_columns_new)    
    air_is_white_noise_gdf=postSQL2gpd(table_name="air_is_white_noise",geom_col=GC,myusername=UN,mypassword=PW,mydatabase=DB) 
    air_is_white_noise_gdf=pd.merge(air_is_white_noise_gdf,reducing_is_white_noise_df,left_on='node_id',right_index=True,how='outer')
    gpd2postSQL(air_is_white_noise_gdf,table_name='air_is_white_noise',myusername=UN,mypassword=PW,mydatabase=DB)
    
    reducing_is_stationary_dict_d=tsab_reducing.stationary_stat(print_detail=False,diff_periods=1) #,autolag="AIC" 
    reducing_is_stationary_dict=tsab_reducing.stationary_stat(print_detail=False) #,autolag="AIC"       
    reducing_is_stationary_df=pd.DataFrame.from_dict(reducing_is_stationary_dict,orient='index',columns=["reducing_is_stationary"])
    air_is_stationary_gdf=postSQL2gpd(table_name="air_is_stationary",geom_col=GC,myusername=UN,mypassword=PW,mydatabase=DB)     
    air_is_stationary_gdf=pd.merge(air_is_stationary_gdf,reducing_is_stationary_df,left_on='node_id',right_index=True,how='outer')
    gpd2postSQL(air_is_stationary_gdf,table_name='air_is_stationary',myusername=UN,mypassword=PW,mydatabase=DB)    
    
    _=tsa.compare_TFN(air_is_stationary_gdf,'co_is_stationary','reducing_is_stationary')
        
    save_path_acf=os.path.join(parent_path,'./charts/reducing_acf')
    save_path_pacf=os.path.join(parent_path,'./charts/reducing_pacf')
    reducing_acf_counter_dict,pacf_counter_dict=tsab_co.acf_pacf_counter(nlags=24*7,plot=True,save_path_acf=save_path_acf,save_path_pacf=save_path_pacf, diff_periods=1) #diff_periods=1    
 
```

###### 4) 时空分析



##### B.2.3.2 颗粒类

##### B.2.3.3 热环境


##### B.2.3.4 噪音


##### B.2.3.5 光环境


### B.3 讨论与结论


#### B.参考文献


## C. 研究代码更新、发布与安装