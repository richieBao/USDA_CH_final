> Created on Wed Feb  2 20:18:06 2022 @author: Richie Bao-caDesign设计(cadesign.cn)

# 3.3.2 城市空间模式与局地环境变化

## A. 建立研究代码项目

1. 建立本地仓库与GitHub仓库

建立本地仓库（项目文件夹），命名为`PAPER_Urban_Spatial_Pattern_N_Local_Environmental_Changes`，并推送至GitHub端。链接地址：[PAPER_Urban_Spatial_Pattern_N_Local_Environmental_Changes](https://github.com/richieBao/PAPER_Urban_Spatial_Pattern_N_Local_Environmental_Changes)，`https://github.com/richieBao/PAPER_Urban_Spatial_Pattern_N_Local_Environmental_Changes`。


2. 建立数据库

使用[pgAdmin](https://www.pgadmin.org/)创建本地关系数据库`PAPER_Urban_Spatial_Pattern_N_Local_Environmental_Changes`，并在`Query Editor`中执行`CREATE EXTENSION postgis;`，使能够存储具有坐标系统的地理几何对象。随书写研究代码进展读写数据库。

完成项目后，从`pgAdmain`下导出（`Backup`）该数据库，可以发布，并从`pgAdmain`下导入（`Restore`）该项目数据库。也可以单独通过`Import/Export`导入，导出单独的表数据。


3. 建立配置文件

使用[YAML](https://en.wikipedia.org/wiki/YAML)文件格式，书写配置文件。


4. 项目文件结构


5. requirements文件

`requirements_install info.txt`
```txt

```


## B. 专项研究与代码实现

### B.1 背景



### B.2 研究方法与结果



#### B.2.1 研究区域


#### B.2.2 数据

| 序号  | 数据名称  | 数据来源  | 说明  |大小|数据类型|
|---|---|---|---|---|---|
| 1  | AoT_Chicago.complete.2021-12-20  | [Array of Things(AoT) 城市环境传感器](https://arrayofthings.github.io/)  |  主要包括：data, node,sensors及说明文件README  |data:39.5GB |.csv|
| 2  |  行政区域:Chicago Community Areas | [Chicago Data Portal](https://data.cityofchicago.org/)  | 方便定位传感器在城市中的位置 |/ |.shp|
| 3  | 建筑高度数据：Building Footprints (current)   | [Chicago Data Portal](https://data.cityofchicago.org/Buildings/Building-Footprints-current-/hz9b-7nh8)   | 用于建筑围合城市空间（城市峡谷）与城市环境测量值关系分析  |948MB|.geojson|
|  4 |道路中心线: Street Center Lines(current)  |[Chicago Data Portal](https://data.cityofchicago.org/Transportation/Street-Center-Lines/6imu-meau) |  探索道路类型、分布和密度等统计量与传感器测量值的关系 |72.1MB|.geojson|
|5|土地利用:Land Use Inventory for Northeast Illinois, 2015 |[CMAP DATA HUB](https://datahub.cmap.illinois.gov/group/land-use-inventories)|分析土地利用与传感器测量值的关系|553MB|.shp|
|6|芝加哥城边界: Boundaries - City| [Chicago Data Portal](https://data.cityofchicago.org/Facilities-Geographic-Boundaries/Boundaries-City/ewy2-6yfk)|研究边界|/|.shp|
|7|伊利诺伊州激光雷达数据|[伊利诺斯州草原地质调查研究所（Illinois state geological survey - prairie research institute）](https://www.arcgis.com/apps/webappviewer/index.html?id=44eb65c92c944f3e8b231eb1e2814f4d)|提取植被信息，含高中低三个分类|1.4T|.las|


##### B.2.2.1 数据获取及预处理


###### 1) 环境传感器说明

下载的AoT数据包括:

1. `data(data.csv.gz)`: 按时间戳升序排列的传感器测量数据;
2. `nodes.csv`: 节点元数据。主要包括节点的ID，经纬度，时间戳，信息描述等信息；
3. `sensors.csv`： 传感器元数据。 包括传感器测量内容，浓度单位，最小最大值，以及传感器说明文件；
4. `provenance.csv`：项目版本，起止时间和数据下地址等；
5. `README.md`：说明文件。对各文件的解释及数据参数的说明。

根据`sensors.csv`文件，分类测量内容为气体类、颗粒物、热环境、噪音、光、电磁场和惯性测量等内容。在后续分析过程中，将根据分类内容分别分析前5类。

| 序号  | 分类  | 测量内容  | 单位  | 说明  |
|---|---|---|---|---|
| 1  | 气体类  | CO（一氧化碳，carbon monoxide）  | ppm   | CO是一种无色、无味的气体。当大量吸入时，对人体造成伤害。某物燃烧时会释放CO，在户外，空气中的CO主要来源于燃烧化石燃料的各类汽车和机械；在户内未通风条件下，有泄露的煤油、燃气、烟筒、火炉等，影响室内空气质量。 <br>吸入高浓度CO，会减少血液中输送到心脏和大脑等关键器官的氧气量。在室内封闭环境下，会导致头晕、神志不清、昏迷和死亡；在户外，非常高浓度的CO不太可能发生，但是当达到一定水平，会对某些类型的心脏病患者造成特别影响。在健身或压力增大等心脏需要更多氧气条件下，导致进入心脏的氧气减少，并伴有胸痛（胸绞痛）。 |
| 2 |   |  H2S（硫化氢，Hydrogen Sulfide） | ppm  |  H2S是一种剧毒有害气体，透明、散发出臭鸡蛋的气味。这种气体具有高度的爆炸性，长时间暴漏在这种气体中可能会致命。H2S长存在于制造工厂、炼油厂和气体处理设施中。 |
| 3|   | NO<sub>2</sub>(二氧化氮, Nitrogen Dioxide)  | ppm  | NO<sub>2</sub>是一种气态的空气污染物，由氮和氧组成（氮氧化物）。当煤、石油、天然气或柴油等化石燃料在高温下燃烧时产生。 汽车是最大的排放源，其次是放电厂、柴油驱动的重型建筑设备和其它可移动发动机及工业锅炉。室外空气中的二氧化氮和其他氮氧化物会造成颗粒污染和产生臭氧的化学反应。 NO<sub>2</sub>会对肺部造成一系列有害影响，包括：气道炎症、咳嗽、气喘、降低肺功能、增加哮喘发作，对肺癌患者造成更大风险。同时，NO<sub>2</sub>与心血管疾病、新生儿出生体重过轻及过早死亡风险增加有关。<br>室内的煤油或燃气加热器和煤气炉灶也会大量产生NO<sub>2</sub>，如果没有完全排放到室外，室内浓度会升高。|
| 4  |   | O<sub>3</sub> (臭氧, trioxygen)  | ppm  |  O<sub>3</sub>由3个氧原子结合在一起，有一种特殊的刺鼻气味。因为自身不稳定在低层大气中分解为 O<sub>2</sub>。O<sub>3</sub>是由O<sub>2</sub>在地球大气中的紫外线（UV, ultraviolet）和放电作用下形成。它的浓度很低，在平流层的臭氧层（ozone layer）中浓度最高。臭氧层通过过滤大部分紫外线辐射保护地球生物。地面上的O<sub>3</sub>，通常是太阳光和汽车、工业等来源排放物相互作用产生，对人类的健康有害。例如， 对眼鼻喉和下呼吸道刺激和炎症（咳嗽、喉咙痛或胸部不舒服）；肺功能下降（不能像平常一样深呼吸或大力呼吸）；引起哮喘和慢性呼吸系统疾病；呼吸道感染的易感性增加。|
| 5  |   | oxidizing_gases（氧化气体）  | ppm  |  oxidizing_gases包括任何含氧高于大气浓度（23-25%）的气体，如氧化氮（nitrogen oxides）、卤素气体（halogen gases，如如氯（chlorine）和氟（fluorine）。）这些气体能与可燃物质发生迅速而聚类的反应。可燃物质包括含碳的有机物质，例如大多数可燃气体，可燃液体、油、润滑脂（greases），很多塑料和植物；金属粉末；及其它可氧化物质，例如肼（hydrazine）、氢（hydrogen）、 氢化物（hydrides）、硫（sulphur）或硫化合物，硅（silicon）和氨（ammonia）或氨化合物。 |
| 6  |  |   reducing_gases（还原性气体） | ppm  | 指化学反应中经常作为还原剂使用的气体。例如氢气（hydrogen）、一氧化碳(carbon monoxide)等。|
| 7  |   |  SO<sub>2</sub>(二氧化硫, Sulfur Dioxide) |  ppm | SO<sub>2</sub> 可被用作更大种类气态硫氧化物SO<sub>x</sub>（gaseous sulfur oxides）的指示物（ indicator）。 大气中发现其它气态硫，例如SO<sub>3</sub>的浓度应小于SO<sub>2</sub>。减少SO<sub>2</sub>的控制措施通常可以预期减少人们暴漏到所有SO<sub>x</sub>中的机会。对减少颗粒状硫污染物（例如细硫酸盐颗粒，fine sulfate particles）的形成同样重要。<br>SO<sub>2</sub>最主要来源于发电厂和其它工业设施的化石燃料燃烧；较小来源于从矿石中提取金属等工业过程，火山等自然资源，机车、轮船和其它车辆，及重型设备，其燃烧的燃料含硫量较高。<br>短期接触SO<sub>2</sub>会损害人体呼吸系统，是呼吸困难。哮喘患者、尤其儿童对SO<sub>2</sub>的这些影响尤其敏感。导致空气中SO<sub>2</sub>高浓度形成的排放也会导致其它氧化物（SO<sub>x</sub>）的形成。与大气中的其它化合物发生反应，形成小颗粒。这些颗粒导致了微粒物质污染（ particulate matter，PM）。小颗粒可以渗入人的肺部，如果达到一定量则会导致健康问题。自然中，高浓度的气态硫会破坏植被的树叶，降低其生长速度。|
| 8  | 颗粒物，微粒(particulate matter,PM)  | pm<sub>1</sub>,pm<sub>2.5</sub>, pm<sub>5</sub>,pm<sub>10</sub> | μg/m<sup>3</sup>  |  PM代表颗粒物质（也称之为颗粒污染，particle pollution），是空气中存在的固体颗粒和液滴的混合物。有些颗粒，例如灰尘粉末、煤烟等大到肉眼可见；另一些则很小，只能用电子显微镜观察。<br>颗粒污染包括：PM<sub>10</sub>可吸入颗粒物，直径一般在10微米（micrometers）及一下；PM<sub>2.5</sub>可吸入的细小微粒，直径一般在2.5微米一下。这些颗粒有许多大小和形状，可由数百种不同的化学物质组成。<br>颗粒污染有些是直接从源头排放，例如建筑工地、未铺设的道路、田地、烟囱或火灾等。大气中的大多数颗粒由二氧化硫和氧化物等化学物质的复杂反应形成，通常是发电厂、工业和汽车排放的污染物。<br>颗粒物包含微小的固体或液滴，因为非常小，足可以被吸入并导致严重的健康问题。一些小于10微米的颗粒可以进入人的肺部，一些甚至可能进入到人的血液中。直径小于2.5微米的颗粒，也称为细颗粒（ fine particles，或者PM<sub>2.5</sub>），对健康构成最大的风险。PM<sub>2.5</sub>也是雾霾的主要起因。 |
| 9  | 热环境  | 温度（temperature）   |  C | 在强调温度的时空分布时，通常使用热状态（thermal regime）一词。温度在塑造水生态系统的结构和功能时起到基本作用。例如在物理（Physical）层面上， 影响水密度（Water density）、热分层（thermal stratification），氧和其它化学物质的溶解度（solubility ）；在化学（Chemical）层面上，影响养分循环速率、污染物转换速率；在生物（Biological）层面上，影响生物的生存、生长、繁殖、发展、行为、生境偏好和竞争。温度同样影响人们活动的热舒适度，以及某些事物发生的起因，例如在加热的排放物附近聚集的鱼群，不透水表面影响等。|
| 10  |   |  湿度（humidity） | 相对湿度（Relative Humidity, RH）  | RH是空气中湿度的量度，与潜在的饱和水平相比较（potential saturation level）。温暖的空气可以容纳更多的水分，当接近100%的湿度时，空气中的水分会凝结（露点）。RH是热舒适性的决定条件之一。  |
| 11  |   | 大气压（pressure）  |  hPa（Hectopascal Pressure Unit） |  百帕斯卡是帕斯卡的100倍，帕斯卡是国际单位制的压力单位。百帕斯卡是测量大气压力或气压的国际单位。1百帕斯卡等于100帕斯卡。 |
| 12  | 噪音  | octave_n_intensity  | dB（分贝）  | 声压级计算（Sound Pressure Level Calculation），每65秒报告一次周围的噪音水平（1分钟间隔，5秒采样）。从麦克风采样音频5秒，以dBm（毫瓦分贝）计算噪音水平。声压级的估计是基于傅里叶变换。通过傅里叶变换将麦克风采集到的数据转换成频率强度域。在频率强度域中，选取22hz ~ 22khz的频率计算给定倍频带（Octave_band用于控制倍频，默认为1/1倍频。octave_n_intensity，默认10个。）下的平均dBm。 <br> 噪音通常来源于交通工具、工厂机器设备、建筑施工和人们的社会和家庭活动等。噪音对人类的危害主要表现在听力的损伤、睡眠干扰、人体的生理和心理影响。当在100分贝左右噪音环境下工作会感到刺耳、难受、甚至引起暂时性耳聋。超过140分贝的噪音会引起眼球振动，视觉模糊，呼吸、脉搏和血压都会发生波动。甚至会使用、全身血管收缩，供血减少，说话能力了受到影响。|
| 13  | 光  | 光强度（light intensity）/可见光强度（visible light intensity）  | 照度：uW/cm<sup>2</sup>（辐照度（irradiance）单位，落在单位表面上的能量）； lux（光度单位，落在单位表面上的可见光）。  |  人工照明在为人类带来好处的同时，对环境也带来了负面的影响。例如光污染用来描述过度的夜间人工照明，尤其是在大型的城市聚集区。这对自然适应夜间生活的动植物和人类健康产生负面影响。同时，城市区域的高层建筑高度和密度也对城市室外和室内的太阳光照时长带来直接的影响。 |
| 14  |   | 红外光谱强度（ir_intensity）  | uW/cm<sup>2</sup>  |  / |
| 15 |   | 紫外线强度（uv_intensity）  | uW/cm<sup>2</sup>  | 臭氧层的损耗减少了大气吸收紫外线避免生物受到伤害的能力。过度暴露于紫外线下影响人类的健康，这包括皮肤癌等各类皮肤疾病，又如光化性角化病、 皮肤过早老化等；同时会增加某些白内障的可能性及眼睛损伤；也会抑制人体免疫系统的正常功能等。|
| 16  | 电磁场（EMFs ，Electric and magnetic fields）  | magnetic_field_x/y/z  | mG  | 除地球磁场外，电磁场由各类电子设备产生，是人类日常生活的一部分。目前没有证据证明其于任何疾病有关。  |
| 17  | 惯性测量装置（inertial measurement unit，IMU）  | 加速度（acceleration_x/y/z）  | mg  | /  |



> 主要参考 [EPA](https://www.epa.gov/)(U.S. Environmental Protection Agency)

`sensors.csv`文件包含了所有已发布数据（data文件）传感器信息。从给定链接中可以获取传感器详细说明。使用`pd.read_csv()`读取`sensors.csv`文件查看。
```python
AoT_sensors_fp=cfg['AoT']['AoT_sensors_fp']
AoT_nodes_df=pd.read_csv(AoT_sensors_fp,sep=",",header=0)
print(AoT_nodes_df)
```

`sensors.csv`文件包含的数据信息主要有：

* `ontology` - 传感器测量对象.
* `subsystem` - 包含传感器的子系统.
* `sensor` - 传感器名称.
* `parameter` - 传感器参数.
* `hrf_unit` - HRF值（转换传感器测量值后）物理单位.
* `hrf_minval` - 依据传感器说明，HRF最小值，用于过滤数值（异常值）；
* `hrf_maxval` - 依据传感器说明，HRF最大值，用于过滤数值（异常值）；
* `datasheet` - 传感器说明书的下载地址。


|ontology                                        |subsystem |sensor         |parameter              |hrf_unit   |hrf_minval|hrf_maxval|datasheet                                                                                |
|------------------------------------------------|----------|---------------|-----------------------|-----------|----------|----------|-----------------------------------------------------------------------------------------|
|/sensing/air_quality/gases/co                   |chemsense |co             |concentration          |ppm        |0         |1000      |https://github.com/waggle-sensor/sensors/raw/master/sensors/datasheets/co.pdf            |
|/sensing/air_quality/gases/h2s                  |chemsense |h2s            |concentration          |ppm        |0         |50        |https://github.com/waggle-sensor/sensors/raw/master/sensors/datasheets/h2s.pdf           |
|/sensing/air_quality/gases/no2                  |chemsense |no2            |concentration          |ppm        |0         |20        |https://github.com/waggle-sensor/sensors/raw/master/sensors/datasheets/no2.pdf           |
|/sensing/air_quality/gases/o3                   |chemsense |o3             |concentration          |ppm        |0         |20        |https://github.com/waggle-sensor/sensors/raw/master/sensors/datasheets/o3.pdf            |
|/sensing/air_quality/gases/oxidizing_gases      |chemsense |oxidizing_gases|concentration          |ppm        |0         |100       |https://github.com/waggle-sensor/sensors/blob/master/sensors/chemsense                   |
|/sensing/air_quality/gases/reducing_gases       |chemsense |reducing_gases |concentration          |ppm        |0         |20        |https://github.com/waggle-sensor/sensors/blob/master/sensors/chemsense                   |
|/sensing/air_quality/gases/so2                  |chemsense |so2            |concentration          |ppm        |0         |20        |https://github.com/waggle-sensor/sensors/raw/master/sensors/datasheets/so2.pdf           |
|/sensing/air_quality/particulates/particle_count|alphasense|opc_n2         |bins                   |counts     |0         |          |https://github.com/waggle-sensor/sensors/raw/master/sensors/datasheets/opcn2.pdf         |
|/sensing/air_quality/particulates/pm_10         |alphasense|opc_n2         |pm10                   |μg/m^3     |0         |          |https://github.com/waggle-sensor/sensors/raw/master/sensors/datasheets/opcn2.pdf         |
|/sensing/air_quality/particulates/pm_2_5        |alphasense|opc_n2         |pm2_5                  |μg/m^3     |0         |          |https://github.com/waggle-sensor/sensors/raw/master/sensors/datasheets/opcn2.pdf         |
|/sensing/air_quality/particulates/pm_1          |alphasense|opc_n2         |pm1                    |μg/m^3     |0         |          |https://github.com/waggle-sensor/sensors/raw/master/sensors/datasheets/opcn2.pdf         |
|/sensing/air_quality/particulates/particle_count|plantower |pms7003        |point_3um_particle     |μg/m^3     |0         |          |https://github.com/waggle-sensor/sensors/raw/master/sensors/datasheets/pms7003.pdf       |
|/sensing/air_quality/particulates/particle_count|plantower |pms7003        |point_5um_particle     |μg/m^3     |0         |          |https://github.com/waggle-sensor/sensors/raw/master/sensors/datasheets/pms7003.pdf       |
|/sensing/air_quality/particulates/particle_count|plantower |pms7003        |1um_particle           |μg/m^3     |0         |          |https://github.com/waggle-sensor/sensors/raw/master/sensors/datasheets/pms7003.pdf       |
|/sensing/air_quality/particulates/particle_count|plantower |pms7003        |2_5um_particle         |μg/m^3     |0         |          |https://github.com/waggle-sensor/sensors/raw/master/sensors/datasheets/pms7003.pdf       |
|/sensing/air_quality/particulates/particle_count|plantower |pms7003        |5um_particle           |μg/m^3     |0         |          |https://github.com/waggle-sensor/sensors/raw/master/sensors/datasheets/pms7003.pdf       |
|/sensing/air_quality/particulates/particle_count|plantower |pms7003        |10um_particle          |μg/m^3     |0         |          |https://github.com/waggle-sensor/sensors/raw/master/sensors/datasheets/pms7003.pdf       |
|/sensing/air_quality/particulates/pm_1          |plantower |pms7003        |pm1_cf                 |μg/m^3     |0         |          |https://github.com/waggle-sensor/sensors/raw/master/sensors/datasheets/pms7003.pdf       |
|/sensing/air_quality/particulates/pm_1          |plantower |pms7003        |pm1_atm                |μg/m^3     |0         |          |https://github.com/waggle-sensor/sensors/raw/master/sensors/datasheets/pms7003.pdf       |
|/sensing/air_quality/particulates/pm_2_5        |plantower |pms7003        |pm25_cf                |μg/m^3     |0         |          |https://github.com/waggle-sensor/sensors/raw/master/sensors/datasheets/pms7003.pdf       |
|/sensing/air_quality/particulates/pm_2_5        |plantower |pms7003        |pm25_atm               |μg/m^3     |0         |          |https://github.com/waggle-sensor/sensors/raw/master/sensors/datasheets/pms7003.pdf       |
|/sensing/air_quality/particulates/pm_10         |plantower |pms7003        |pm10_cf                |μg/m^3     |0         |          |https://github.com/waggle-sensor/sensors/raw/master/sensors/datasheets/pms7003.pdf       |
|/sensing/air_quality/particulates/pm_10         |plantower |pms7003        |pm10_atm               |μg/m^3     |0         |          |https://github.com/waggle-sensor/sensors/raw/master/sensors/datasheets/pms7003.pdf       |
|/sensing/meteorology/humidity                   |metsense  |hih4030        |humidity               |RH         |0         |100       |https://github.com/waggle-sensor/sensors/raw/master/sensors/datasheets/hih4030.pdf       |
|/sensing/meteorology/humidity                   |metsense  |htu21d         |humidity               |RH         |0         |100       |https://github.com/waggle-sensor/sensors/raw/master/sensors/datasheets/htu21d.pdf        |
|/sensing/meteorology/pressure                   |metsense  |bmp180         |pressure               |hPa        |300       |1100      |https://github.com/waggle-sensor/sensors/raw/master/sensors/datasheets/bmp180.pdf        |
|/sensing/meteorology/temperature                |metsense  |bmp180         |temperature            |C          |-40       |85        |https://github.com/waggle-sensor/sensors/raw/master/sensors/datasheets/bmp180.pdf        |
|/sensing/meteorology/temperature                |metsense  |htu21d         |temperature            |C          |-40       |125       |https://github.com/waggle-sensor/sensors/raw/master/sensors/datasheets/htu21d.pdf        |
|/sensing/meteorology/temperature                |metsense  |pr103j2        |temperature            |C          |-55       |80        |https://github.com/waggle-sensor/sensors/raw/master/sensors/datasheets/pr103j2.pdf       |
|/sensing/meteorology/temperature                |metsense  |tmp112         |temperature            |C          |-40       |125       |https://github.com/waggle-sensor/sensors/raw/master/sensors/datasheets/tmp112.pdf        |
|/sensing/meteorology/temperature                |metsense  |tsys01         |temperature            |C          |-40       |125       |https://github.com/waggle-sensor/sensors/raw/master/sensors/datasheets/tsys01.pdf        |
|/sensing/physical/audio/spl                     |audio     |microphone     |octave_total_intensity |dB         |          |140       |https://github.com/waggle-sensor/plugin_manager/tree/master/plugins/audio_spl            |
|/sensing/physical/audio/spl                     |audio     |microphone     |octave_1_intensity     |dB         |          |140       |https://github.com/waggle-sensor/plugin_manager/tree/master/plugins/audio_spl            |
|/sensing/physical/audio/spl                     |audio     |microphone     |octave_2_intensity     |dB         |          |140       |https://github.com/waggle-sensor/plugin_manager/tree/master/plugins/audio_spl            |
|/sensing/physical/audio/spl                     |audio     |microphone     |octave_3_intensity     |dB         |          |140       |https://github.com/waggle-sensor/plugin_manager/tree/master/plugins/audio_spl            |
|/sensing/physical/audio/spl                     |audio     |microphone     |octave_4_intensity     |dB         |          |140       |https://github.com/waggle-sensor/plugin_manager/tree/master/plugins/audio_spl            |
|/sensing/physical/audio/spl                     |audio     |microphone     |octave_5_intensity     |dB         |          |140       |https://github.com/waggle-sensor/plugin_manager/tree/master/plugins/audio_spl            |
|/sensing/physical/audio/spl                     |audio     |microphone     |octave_6_intensity     |dB         |          |140       |https://github.com/waggle-sensor/plugin_manager/tree/master/plugins/audio_spl            |
|/sensing/physical/audio/spl                     |audio     |microphone     |octave_7_intensity     |dB         |          |140       |https://github.com/waggle-sensor/plugin_manager/tree/master/plugins/audio_spl            |
|/sensing/physical/audio/spl                     |audio     |microphone     |octave_8_intensity     |dB         |          |140       |https://github.com/waggle-sensor/plugin_manager/tree/master/plugins/audio_spl            |
|/sensing/physical/audio/spl                     |audio     |microphone     |octave_9_intensity     |dB         |          |140       |https://github.com/waggle-sensor/plugin_manager/tree/master/plugins/audio_spl            |
|/sensing/physical/audio/spl                     |audio     |microphone     |octave_10_intensity    |dB         |          |140       |https://github.com/waggle-sensor/plugin_manager/tree/master/plugins/audio_spl            |
|/sensing/physical/ir                            |lightsense|tsl260rd       |intensity              |uW/cm^2    |0         |132       |https://github.com/waggle-sensor/sensors/raw/master/sensors/datasheets/tsl260rd.pdf      |
|/sensing/physical/light                         |lightsense|apds_9006_020  |intensity              |lux        |0         |1000      |https://github.com/waggle-sensor/sensors/raw/master/sensors/datasheets/apd9006020.pdf    |
|/sensing/physical/light                         |lightsense|mlx75305       |intensity              |uW/cm^2    |0         |160       |https://github.com/waggle-sensor/sensors/raw/master/sensors/datasheets/mlx75305c.pdf     |
|/sensing/physical/light                         |lightsense|tsl250rd       |intensity              |uW/cm^2    |0         |124       |https://github.com/waggle-sensor/sensors/raw/master/sensors/datasheets/tsl250rd.pdf      |
|/sensing/physical/magnetic_field                |lightsense|hmc5883l       |magnetic_field_x       |mG         |-8000     |8000      |https://github.com/waggle-sensor/sensors/raw/master/sensors/datasheets/hmc5883l.pdf      |
|/sensing/physical/magnetic_field                |lightsense|hmc5883l       |magnetic_field_y       |mG         |-8000     |8000      |https://github.com/waggle-sensor/sensors/raw/master/sensors/datasheets/hmc5883l.pdf      |
|/sensing/physical/magnetic_field                |lightsense|hmc5883l       |magnetic_field_z       |mG         |-8000     |8000      |https://github.com/waggle-sensor/sensors/raw/master/sensors/datasheets/hmc5883l.pdf      |
|/sensing/physical/sound_level                   |metsense  |spv1840lr5h_b  |intensity              |dB         |0         |121       |https://github.com/waggle-sensor/sensors/raw/master/sensors/datasheets/spv1840lr5h-b.pdf |
|/sensing/physical/uv                            |lightsense|ml8511         |intensity              |uW/cm^2    |0         |15        |https://github.com/waggle-sensor/sensors/raw/master/sensors/datasheets/ml8511.pdf        |
|/sensing/physical/vibration                     |metsense  |mma8452q       |acceleration_x         |mg         |-8000     |8000      |https://github.com/waggle-sensor/sensors/raw/master/sensors/datasheets/mma8452q.pdf      |
|/sensing/physical/vibration                     |metsense  |mma8452q       |acceleration_y         |mg         |-8000     |8000      |https://github.com/waggle-sensor/sensors/raw/master/sensors/datasheets/mma8452q.pdf      |
|/sensing/physical/vibration                     |metsense  |mma8452q       |acceleration_z         |mg         |-8000     |8000      |https://github.com/waggle-sensor/sensors/raw/master/sensors/datasheets/mma8452q.pdf      |
|/system/environment/humidity                    |lightsense|hih6130        |humidity               |RH         |0         |100       |https://github.com/waggle-sensor/sensors/raw/master/sensors/datasheets/hih6130.pdf       |
|/system/environment/ir                          |chemsense |si1145         |ir_intensity           |uW/cm^2    |0         |          |https://github.com/waggle-sensor/sensors/raw/master/sensors/datasheets/si1145uv.pdf      |
|/system/environment/light                       |chemsense |si1145         |visible_light_intensity|uW/cm^2    |0         |          |https://github.com/waggle-sensor/sensors/raw/master/sensors/datasheets/si1145uv.pdf      |
|/system/environment/temperature                 |lightsense|hih6130        |temperature            |C          |-25       |85        |https://github.com/waggle-sensor/sensors/raw/master/sensors/datasheets/hih6130.pdf       |
|/system/environment/humidity                    |wagman    |htu21d         |humidity               |RH         |0         |100       |https://github.com/waggle-sensor/sensors/raw/master/sensors/datasheets/htu21d.pdf        |
|/system/environment/temperature                 |wagman    |htu21d         |temperature            |C          |-40       |125       |https://github.com/waggle-sensor/sensors/raw/master/sensors/datasheets/htu21d.pdf        |
|/system/environment/temperature                 |wagman    |temperatures   |battery                |C          |-55       |125       |https://github.com/waggle-sensor/core/blob/master/scripts/status-service                 |
|/system/environment/temperature                 |wagman    |temperatures   |brainplate             |C          |-55       |125       |https://github.com/waggle-sensor/core/blob/master/scripts/status-service                 |
|/system/environment/temperature                 |wagman    |temperatures   |ep_heatsink            |C          |-55       |125       |https://github.com/waggle-sensor/core/blob/master/scripts/status-service                 |
|/system/environment/temperature                 |wagman    |temperatures   |nc_heatsink            |C          |-55       |125       |https://github.com/waggle-sensor/core/blob/master/scripts/status-service                 |
|/system/environment/temperature                 |wagman    |temperatures   |powersupply            |C          |-55       |125       |https://github.com/waggle-sensor/core/blob/master/scripts/status-service                 |
|/system/environment/temperature                 |lightsense|tmp421         |temperature            |C          |-55       |127       |https://github.com/waggle-sensor/sensors/raw/master/sensors/datasheets/tmp421.pdf        |
|/system/environment/uv                          |chemsense |si1145         |uv_intensity           |uW/cm^2    |          |          |https://github.com/waggle-sensor/sensors/raw/master/sensors/datasheets/si1145uv.pdf      |
|/system/other/flow_rate                         |alphasense|opc_n2         |sample_flow_rate       |           |          |          |https://github.com/waggle-sensor/sensors/raw/master/sensors/datasheets/opcn2.pdf         |
|/system/other/pressure                          |chemsense |lps25h         |pressure               |hPa        |260       |1260      |https://github.com/waggle-sensor/sensors/raw/master/sensors/datasheets/lps25h.pdf        |
|/system/other/humidity                          |chemsense |sht25          |humidity               |RH         |0         |100       |https://github.com/waggle-sensor/sensors/raw/master/sensors/datasheets/sht25.pdf         |
|/system/other/id                                |chemsense |chemsense      |id                     |id         |          |          |https://github.com/waggle-sensor/sensors                                                 |
|/system/other/id                                |metsense  |metsense       |id                     |id         |          |          |https://github.com/waggle-sensor/sensors                                                 |
|/system/other/id                                |alphasense|opc_n2         |fw                     |           |          |          |https://github.com/waggle-sensor/sensors/raw/master/sensors/datasheets/opcn2.pdf         |
|/system/other/light                             |metsense  |tsl250rd       |intensity              |uW/cm^2    |0         |124       |https://github.com/waggle-sensor/sensors/raw/master/sensors/datasheets/tsl250rd.pdf      |
|/system/other/temperature                       |chemsense |lps25h         |temperature            |C          |-30       |105       |https://github.com/waggle-sensor/sensors/raw/master/sensors/datasheets/lps25h.pdf        |
|/system/other/sampling_period                   |alphasense|opc_n2         |sampling_period        |           |          |          |https://github.com/waggle-sensor/sensors/raw/master/sensors/datasheets/opcn2.pdf         |
|/system/other/temperature                       |chemsense |at0            |temperature            |C          |-40       |125       |https://github.com/waggle-sensor/sensors                                                 |
|/system/other/temperature                       |chemsense |at1            |temperature            |C          |-40       |125       |https://github.com/waggle-sensor/sensors                                                 |
|/system/other/temperature                       |chemsense |at2            |temperature            |C          |-40       |125       |https://github.com/waggle-sensor/sensors                                                 |
|/system/other/temperature                       |chemsense |at3            |temperature            |C          |-40       |125       |https://github.com/waggle-sensor/sensors                                                 |
|/system/other/temperature                       |chemsense |sht25          |temperature            |C          |-40       |125       |https://github.com/waggle-sensor/sensors/raw/master/sensors/datasheets/sht25.pdf         |
|/system/loadavg                                 |nc        |loadavg        |loadavg1               |loadavg    |0         |          |https://github.com/waggle-sensor/plugin_manager/tree/master/plugins/status.plugin        |
|    ...                        |        |      |             |   |       |          |      |

###### 2) 环境传感器布局

为读取AoT数据，并写入到本地数据库中，首先建立`database.py`文件，将读写PostgreSQL数据库。同时，包括读取.yml格式的配置文件。

`database.py`
```python
# -*- coding: utf-8 -*-
"""
Created on Thu Feb  3 20:10:26 2022

@author: Richie Bao-caDesign设计(cadesign.cn)
"""

def gpd2postSQL(gdf,table_name,**kwargs):  
    '''
    function - 将GeoDataFrame格式数据写入PostgreSQL数据库
    
    Paras:
        gdf - GeoDataFrame格式数据，含geometry字段（几何对象，点、线和面，数据值对应定义的坐标系统）
        table_name - 写入数据库中的表名
        **kwargs - 连接数据库相关信息，包括myusername（数据库的用户名），mypassword（用户密钥），mydatabase（数据库名）
    '''    
    from sqlalchemy import create_engine
    #The URI should start with postgresql:// instead of postgres://. SQLAlchemy used to accept both, but has removed support for the postgres name.
    engine=create_engine("postgresql://{myusername}:{mypassword}@localhost:5432/{mydatabase}".format(myusername=kwargs['myusername'],mypassword=kwargs['mypassword'],mydatabase=kwargs['mydatabase']))  
    gdf.to_postgis(table_name, con=engine, if_exists='replace', index=False,)  
    print("_"*50)
    print('The GeoDataFrame has been written to the PostgreSQL database.The table name is {}.'.format(table_name))

def postSQL2gpd(table_name,geom_col='geometry',**kwargs):    
    '''
    function - 读取PostgreSQL数据库中的表为GeoDataFrame格式数据
    
    Paras:
        table_name - 待读取数据库中的表名
        geom_col='geometry' - 几何对象，常规默认字段为'geometry'
        **kwargs - 连接数据库相关信息，包括myusername（数据库的用户名），mypassword（用户密钥），mydatabase（数据库名）
    '''
    from sqlalchemy import create_engine
    import geopandas as gpd   
    
    engine=create_engine("postgresql://{myusername}:{mypassword}@localhost:5432/{mydatabase}".format(myusername=kwargs['myusername'],mypassword=kwargs['mypassword'],mydatabase=kwargs['mydatabase']))  
    gdf=gpd.read_postgis(table_name, con=engine,geom_col=geom_col)
    print("_"*50)
    print('The data has been read from PostgreSQL database. The table name is {}.'.format(table_name))    
    return gdf 

def cfg_load_yaml(ymlf_fp):
    '''
    读取 yaml 格式的配置文件

    Parameters
    ----------
    ymlf_fp : string
        配置文件路径.

    Returns
    -------
    cfg : yaml-dict
        读取到python中的配置信息.
    '''
    import yaml
    with open (ymlf_fp,'r') as ymlfile:
        cfg=yaml.safe_load(ymlfile)   
    return cfg
```

对AoT数据预处理的代码均写在`AoTData_preprocessing.py`下。读取`nodes.csv`数据，并将其写入到数据库。`nodes`数据给出了传感器的布置位置，在读取`data`数据并根据需求处理后（例如提取不同测量内容，并进一步分析后），需要根据各自给出的`node_id`字段，合并数据定位分析结果的空间分布，用于空间分析。

为定位传感器的空间位置，读取叠加行政区域。

`AoTData_preprocessing.py`
```python
# -*- coding: utf-8 -*-
"""
Created on Fri Feb  4 11:00:11 2022

@author: Richie Bao-caDesign设计(cadesign.cn)
"""

def AoT_nodes2gdf(nodes_fn,epsg=4326):
    '''
    读取AoT_nodes数据，并写入数据库

    Parameters
    ----------
    nodes_fn : string
        AoT_nodes文件路径.
    epsg : int, optional
        坐标投影系统，epsg编号. The default is 4326.

    Returns
    -------
    AoT_nodes_gdf : GeoDataFrame
        AoT_nodes的GeoDataFrame格式.

    '''
    import pandas as pd
    import geopandas as gpd
    from shapely.geometry import Point
    
    AoT_nodes_df=pd.read_csv(AoT_nodes_fp,sep=",",header=0)
    AoT_nodes_df["geometry"]=AoT_nodes_df.apply(lambda row:Point(row.lon,row.lat),axis=1) #使用shapely库建立几何点数据
    AoT_nodes_gdf=gpd.GeoDataFrame(AoT_nodes_df,crs=4326)
    if epsg!=4326:
        AoT_nodes_gdf.to_crs(epsg,inplace=True)
        
    print("nodes columns:{}".format(AoT_nodes_gdf.columns))
    return AoT_nodes_gdf

if __name__=="__main__":
    import sys,os
    sys.path.append('..')  
    
    from database import postSQL2gpd,gpd2postSQL,cfg_load_yaml   
    import pickle
    parent_path=os.path.dirname(os.getcwd())

    cfg=cfg_load_yaml('./config.yml')  
    UN=cfg["postgreSQL"]["myusername"]
    PW=cfg["postgreSQL"]["mypassword"]
    DB=cfg["postgreSQL"]["mydatabase"] 
    GC='geometry'     

    AoT_nodes_fp=cfg['AoT']['AoT_nodes_fp']
    Chicago_epsg=cfg['Chicago_epsg']

    #A. AoT-nodes信息读取并写入数据库
    AoT_nodes_gdf=AoT_nodes2gdf(AoT_nodes_fp,Chicago_epsg)
    AoT_nodes_TN=cfg['table_name']['AoT_nodes_TN']    
    gpd2postSQL(AoT_nodes_gdf,table_name=AoT_nodes_TN,myusername=UN,mypassword=PW,mydatabase=DB) 
    AoT_nodes_gdf=postSQL2gpd(table_name=AoT_nodes_TN,geom_col=GC,myusername=UN,mypassword=PW,mydatabase=DB)
    
    #B.读取行政区划数据，并写入数据库，用于定位AoT分布
    import geopandas as gpd
    Chicago_Community_Areas_fn=cfg['raw_data']['Chicago_Community_Areas_fn']
    Chicago_community_areas=gpd.read_file(Chicago_Community_Areas_fn)
    Chicago_community_areas_TN=cfg['table_name']['Chicago_community_areas_TN']
    gpd2postSQL(Chicago_community_areas.to_crs(Chicago_epsg),table_name=Chicago_community_areas_TN,myusername=UN,mypassword=PW,mydatabase=DB)
    Chicago_community_areas=postSQL2gpd(table_name=Chicago_community_areas_TN,geom_col=GC,myusername=UN,mypassword=PW,mydatabase=DB)  
```

<a href=""><img src="./imgs/3_3_2_01.png" height="auto" width="auto" title="caDesign"></a>

AoT在芝加哥布局了126个测量点位，位于道路街口，临湖道路、芝加哥大学校园内、或者邻近较大公园的附近道路、及中心城区、高速等不同环境，基本涵盖了芝加哥城全城区域。（为详细查看AoT在地图上的分布，可以转换`nodes`数据为.kml数据后，在[Google Earth](https://earth.google.com/web/)下读入）

`nodes.csv`读取的节点元数据个字段解释如下（来源于`README.md`文件）：

* `node_id` - 节点ID；
* `project_id` - 节点管理项目ID；
* `vsn` - 节点的公共名称，并标识在传感器设备上；
* `address` - 节点安装的街道地址；
* `lat` - 维度；
* `lon` - 精度；
* `description` - 对节点传感器构建和配置更详细的描述；
* `start_timestamp` - 节点安装的开始时间戳；
* `end_timestamp` - 节点安装结束的时间戳。

根据`lat`和`lon`建立GeoDataFrame的`geometry`几何对象。`node_id`用于数据合并关联字段。

###### 3) 分类数据

气体类、颗粒物、热环境、噪音、光等传感器测量的数据均混合写在`data`文件下。需要将数据测量内容分离出来单独保存，具体测量内容包含于`data`数据的`parameter`字段。编写`total_sample_length_csv()`方法，计算样本长度，并提取`parameter`字段pickle写入到单独文件下，方便后续数据分类提取时调用。

`AoTData_preprocessing.py`
```python
def total_sample_length_csv(csv_fp,chunksize,category=None,save_fp=None):
    '''
    读取.csv样本数据，计算样本总长度（行数）;并给定分类字段，提取分类名并保存

    Parameters
    ----------
    csv_fp : string
        .csv文件路径.
    chunksize : int
        数据块大小（单独一次读取的行数）.
    category : string(column name), optional
        分类字段. The default is None.
    save_fp : string, optional
        分类名保存路径. The default is None.

    Returns
    -------
    category_set : set
        分类名集合.

    '''
    from tqdm.auto import tqdm
    import pandas as pd
    import pickle
    
    count=0
    set_list=[]
    for chunk in tqdm(pd.read_csv(csv_fp,chunksize=chunksize)):
        count+= 1 #样本分组数
        last_len=len(chunk)  #最后一组的样本数量
        if category:
            set_list.append(set(chunk[category]))
        # if count==3:break
            
    data_length=(count*chunksize+last_len-chunksize) #数据行（样本）总长度
    print("数据行（样本）总长度={}".format(data_length)) 
    if category:
        category_set=set().union(*set_list)
        if save_fp:
            with open(save_fp,'wb') as f:
                pickle.dump(category_set,f)            
        return category_set

if __name__=="__main__":
    #C.AoT-data数据样本长度计算，并提取data:parameter传感器测量分类字段   
    AoT_data_fp=cfg['AoT']['AoT_data_fp']
    category_set_fp=cfg['processed_data']['category_set_fp']
    category_set=total_sample_length_csv(AoT_data_fp,chunksize=10**6,category='parameter',save_fp=category_set_fp) #数据行（样本）总长度=573074785
    with open(category_set_fp,'rb') as f:
        category_set=pickle.load(f)             
```

`data:parameter`计算结果具体如下：

    {'10um_particle',
    '1um_particle',
    '2_5um_particle',
    '5um_particle',
    'acceleration_x',
    'acceleration_y',
    'acceleration_z',
    'alphasense',
    'b',
    'bins',
    'commit',
    'concentration',
    'coresense',
    'cs',
    'current',
    'device',
    'ep',
    'free',
    'fw',
    'g',
    'humidity',
    'id',
    'idletime',
    'intensity',
    'ir_intensity',
    'load_1',
    'load_10',
    'load_5',
    'magnetic_field_x',
    'magnetic_field_y',
    'magnetic_field_z',
    'major',
    'minor',
    'modem',
    'nc',
    'octave_10_intensity',
    'octave_1_intensity',
    'octave_2_intensity',
    'octave_3_intensity',
    'octave_4_intensity',
    'octave_5_intensity',
    'octave_6_intensity',
    'octave_7_intensity',
    'octave_8_intensity',
    'octave_9_intensity',
    'octave_total_intensity',
    'other',
    'patch',
    'pm1',
    'pm10',
    'pm10_atm',
    'pm10_cf1',
    'pm1_atm',
    'pm1_cf1',
    'pm25_atm',
    'pm25_cf1',
    'pm2_5',
    'point_3um_particle',
    'point_5um_particle',
    'pressure',
    'r',
    'rx',
    'sample_flow_rate',
    'sampling_period',
    'state',
    'substate',
    'temperature',
    'total',
    'tx',
    'uptime',
    'used',
    'uv_intensity',
    'visible_light_intensity',
    'wagman'}

因为`data`数据量有39.5GB，样本总长度为573,074,785条。根据`data:parameter`字段分类提取数据时，可能造成内存溢出，因此分批读取与写入。另外，在处理`data`数据时，为提高计算效率，缩短计算时长，有如下考虑：

1. 可以根据后续分析内容提前规划所要提取的数据字段，舍弃不需要的字段；
2. 提取的分类数据保存格式可以是pickle方式保存的DataFrame数据格式，也可以用geopandas保存为GPKG数据格式。需要注意，geopandas因为要处理几何空间对象，因此pickle读写效率要远远高于geopandas读写效率，具体选择哪种存储方式，可以根据具体情况调整。同时，因为单个文件较大的数据量，写入数据库时可能会出现错误，及较长的读写时间，因此并没有将数据写入数据库；(实验中，两种格式均有保存)
3. 使用多线程处理，加快计算速度。多线程计算时，有个别分类字段可能会超出内存大小中断程序，对这些分类字段可单独进行计算。单独计算时，将数据按照配置的`chunksize`参数大小分批保存为多个文件；
4. pd.read_csv(data_fn,chunksize=chunksize)读取`data`时，使用`chunksize`参数分批读取数据，避免内存溢出。

`data(data.csv.gz)`数据文件包含的字段信息包括：

* `timestamp` - 测量了完成时的UTC（Coordinated Universal Time）时间戳；
* `node_id` - 用于测量的节点ID；
* `subsystem` - 包含传感器节点的子系统；
* `sensor` - 用于测量的传感器；
* `parameter` - 测量的传感器参数；
* `value_raw` - 来自传感器的原始测量值；
* `value_hrf` - 从传感器转换的“可读”值，即标准测量单位。

`AoTData_preprocessing_pool.py`
```python
# -*- coding: utf-8 -*-
"""
Created on Fri Feb  4 19:00:35 2022

@author: Richie Bao-caDesign设计(cadesign.cn)
"""

def AoT_data_category_pool(category,args):
    '''
    读取AoT-data数据，并存储为.gpkg或者.pkl

    Parameters
    ----------
    category : string
        分类名.
    args : list
        变量列表.

    Returns
    -------
    category : string
        分类名。可以不定义返回值，该返回值即为输入值.

    '''
    import pandas as pd
    import geopandas as gpd
    import os
    import pickle
    
    data_fn,chunksize,category_column,save_path,AoT_nodes=args    
    category_fn_dict={}
    count=0
    temp=[]
    for chunk in pd.read_csv(data_fn,chunksize=chunksize):
        temp.append(chunk[chunk[category_column]==category])            
        count+= 1
        # if count==3:break
    category_df=pd.concat(temp)    
    # print("+"*50)
    # print(category_df)
    if category_df.empty is False:
        if AoT_nodes is not None:
            category_df=pd.merge(category_df,AoT_nodes,on="node_id")
            category_gdf=gpd.GeoDataFrame(category_df,crs=AoT_nodes.crs)
            category_fn=os.path.join(save_path,"{}.gpkg".format(category))
            category_gdf.to_file(category_fn,driver="GPKG")    
        else:
            category_fn=os.path.join(save_path,"{}.pkl".format(category))
            category_df.to_pickle(category_fn)
    else:
        return category

if __name__=="__main__":
    #下述代码测试多线程调用的子程序
    import sys,os
    sys.path.append('..')  
    
    from database import postSQL2gpd,gpd2postSQL,cfg_load_yaml   
    import pickle
    parent_path=os.path.dirname(os.getcwd())

    cfg=cfg_load_yaml('./config.yml')  
    UN=cfg["postgreSQL"]["myusername"]
    PW=cfg["postgreSQL"]["mypassword"]
    DB=cfg["postgreSQL"]["mydatabase"] 
    GC='geometry'     
    
    AoT_data_fp=cfg['AoT']['AoT_data_fp']
    category_set_fp=cfg['processed_data']['category_set_fp']
    with open(category_set_fp,'rb') as f:
         category_set=pickle.load(f) 
        
    AoT_data_category_save_fp=cfg['processed_data']['AoT_data_category_save_fp']  
    AoT_nodes_TN=cfg['table_name']['AoT_nodes_TN']     
    AoT_nodes_gdf=postSQL2gpd(table_name=AoT_nodes_TN,geom_col=GC,myusername=UN,mypassword=PW,mydatabase=DB)
    for category in list(category_set)[:3]:
         _=AoT_data_category_pool(category,[AoT_data_fp,10**6,'parameter',AoT_data_category_save_fp,AoT_nodes_gdf])
```

`AoTData_preprocessing.py`
```python
def AoT_data_sort(data_fn,category_set,category_column,save_path,chunksize,AoT_nodes=None):
    '''
    多线程。读取AoT-data数据，并存储为.gpkg或者.pkl

    Parameters
    ----------
    data_fn : string
        AoT_data数据，传感器测量数据.
    category_set : list(string)
        data:parameter传感器测量分类字段列表.
    category_column : string
        判断分类的列表，即AoT-data的parameter字段.
    save_path : string
        文件保存的根目录.
    chunksize : int.
        分批读取数据一次读取的文件量（样本行）.
    AoT_nodes : GeoDataFrame, optional
        AoT-nodes节点信息数据，包含节点分布几何点（geometry）。如果给定该参数则保存为GPKG，否则保存为.pkl(pickle保存). The default is None.

    Returns
    -------
    category_none : list(string)
        已经保存的分类数据名列表.
    '''
    from tqdm.auto import tqdm
    from multiprocessing import Pool
    from AoTData_preprocessing_pool import AoT_data_category_pool
    from functools import partial
    
    args=partial(AoT_data_category_pool, args=[data_fn,chunksize,category_column,save_path,AoT_nodes])
    with Pool(8) as p:
        category_none=p.map(args, tqdm(list(category_set))) #[:3]
        
    category_fn_dict={category:os.path.join(save_path,"{}.pkl".format(category)) for category in category_set}
    category_fn_dict_fn= os.path.join(save_path,"category_fn_dict.pkl")  
    with open(category_fn_dict_fn,'wb') as f:
        pickle.dump(category_fn_dict,f)
    return category_none    

def AoT_data_category_single(data_fn,category,category_column,save_path,AoT_nodes=None,chunksize=10**6):
    '''
    读取AoT-data数据，提取单个分类，并存储为.gpkg或者.pkl

    Parameters
    ----------
    data_fn : string
        AoT_data数据，传感器测量数据.
    category : string
        提取单个分类数据的分类名.
    category_column : string
        判断分类的列表，即AoT-data的parameter字段.
    save_path : string
        文件保存的根目录.
    AoT_nodes : GeoDataFrame,optional
        AoT-nodes节点信息数据，包含节点分布几何点（geometry）。如果给定该参数则保存为GPKG，否则保存为.pkl(pickle保存). The default is None.
    chunksize : int, optional
        分批读取数据一次读取的文件量（样本行）. The default is 10**6.

    Returns
    -------
    category : string
        分类名。可以不定义返回值，该返回值即为输入值.

    '''
    import pandas as pd
    import geopandas as gpd
    import os
    import pickle    
    
    count=0
    for chunk in pd.read_csv(data_fn,chunksize=chunksize):
        category_chunk_df=chunk[chunk[category_column]==category]          
        count+= 1  
        
        if category_chunk_df.empty is False:
            if AoT_nodes is not None:
                category_chunk_df=pd.merge(category_chunk_df,AoT_nodes,on="node_id")
                category_chunky_gdf=gpd.GeoDataFrame(category_chunk_df,crs=AoT_nodes.crs)
                category_chunk_fn=os.path.join(save_path,"{}_{}.gpkg".format(category,count))
                category_chunky_gdf.to_file(category_chunk_fn,driver="GPKG")    
            else:
                category_chunk_fn=os.path.join(save_path,"{}_{}.pkl".format(category,count))
                category_chunk_df.to_pickle(category_chunk_fn)
        else:
            return category 

if __name__=="__main__":
    #D.按data:parameter传感器测量分类字段，分类提取数据用pickle保存，或者用geopandas保存为GPKG格式地理数据。根据电脑算力确定
    AoT_data_category_save_fp=cfg['processed_data']['AoT_data_category_save_fp'] 
    category_none=AoT_data_sort(AoT_data_fp,category_set,'parameter',AoT_data_category_save_fp,chunksize=10**6,AoT_nodes=AoT_nodes_gdf) 
    #如果内存溢出，部分传感器分类数据不能写入（如temperature，shape (6, 169342609)），可以单独读取写入。为避免重新计算已计算分类，由下行代码提取未写入分类进行单独计算，或者手工配置
    from glob import glob
    from pathlib import Path    
    category_hold=category_set-set([Path(fn).stem for fn in glob(os.path.join(AoT_data_category_save_fp,"*.gpkg"))])
    print(category_hold) #结果为{'temperature'}    
    _=AoT_data_category_single(AoT_data_fp,'temperature','parameter',AoT_data_category_save_fp,AoT_nodes_gdf,chunksize=10**8) #手工配置为'temperature'
```

###### 4) 分析用潜在城市空间数据准备

AoT数据分析涉及到自身时空数据分析，包括单独节点的时间变化值和多个节点的时空变化值；及传感器测量值与城市空间环境相关因素的关系分析，例如建筑高度、道路、交通、城市用地，植被等。在实验过程中，无法预测相关因素关系情况下，会尝试多种可能性，这可能包括OSM提供的点标签（实际计算后发现提取的用地类型信息很少，及标签分类繁复，不易提取针对此次实验的相关信息）；或者节点位置的全景图语义分割对象百分比的关系等。

* 建筑高度数据

`Chicago data Portal`提供的`BUilding Footprints(current)`数据可以导出为多种格式类型，包括KML、KMX、Shapefile、GeoJSON等地理格式数据，以及CSV、CSV for Excel、JSON、RDF、RSS、TSV for Excel及XML等非地理格式数据。这里下载的数据格式为GeoJSON地理格式数据，可以用geopandas直接读取为GeoDataFrame数据格式。为方便调用，并配置投影和转换字段为字符串的列为数值类型（float, int等）定义函数`json2gdf()`。

`database.py`
```python
def json2gdf(json_fn,numeric_columns=None,epsg=None):
    '''
    读取.geojson(json)文件为GeoDataFrame格式文件，选择配置投影

    Parameters
    ----------
    json_fn : string
        文件路径.
    epsg : int, optional
        坐标投影系统，epsg编号. The default is None.

    Returns
    -------
    gdf : GeoDataFrmae
        转换后的GeoDataFrame格式文件.

    '''
    import geopandas as gpd
    
    gdf=gpd.read_file(json_fn)
    if epsg:
        gdf.to_crs(epsg,inplace=True)   
    print("fields_{}".format(gdf.columns))    
    if numeric_columns:
        gdf=gdf.astype(numeric_columns)

    return gdf

if __name__=="__main__":   
    #A.建筑轮廓（含层高）写入数据库
    Building_Footprints_fn=cfg['raw_data']['Building_Footprints_fn']    
    Building_Footprints=json2gdf(Building_Footprints_fn,numeric_columns={'no_stories':'int','stories':'int'},epsg=Chicago_epsg)
    
    Building_Footprints_TN=cfg['table_name']['Building_Footprints_TN']    
    BF_columns_selection=['no_stories','stories','geometry']
    gpd2postSQL(Building_Footprints[BF_columns_selection].dropna(),table_name=Building_Footprints_TN,myusername=UN,mypassword=PW,mydatabase=DB) 
    Building_Footprints=postSQL2gpd(table_name=Building_Footprints_TN,geom_col=GC,myusername=UN,mypassword=PW,mydatabase=DB)   
```

<a href=""><img src="./imgs/3_3_2_02_s.jpg" height="auto" width="auto" title="caDesign"></a>

较高的建筑基本分布于临湖的中心城区。其余建筑多为住宅，混合低矮建筑的商业区。

* 道路中心线

下载的道路中心线数据格式为GeoJSON，可以直接用上述定义的`json2gdf()`函数读取数据并写入数据库。

`database.py`
```python
if __name__=="__main__":    
    #B.道路中心线 
    street_center_lines_fn=cfg['raw_data']['Street_Center_Lines_fn']
    street_center_lines=json2gdf(street_center_lines_fn,epsg=Chicago_epsg)
    street_center_lines_TN=cfg['table_name']['street_center_lines_TN']
    gpd2postSQL(street_center_lines,table_name=street_center_lines_TN,myusername=UN,mypassword=PW,mydatabase=DB) 
    street_center_lines=postSQL2gpd(table_name=street_center_lines_TN,geom_col=GC,myusername=UN,mypassword=PW,mydatabase=DB)        
```

<a href=""><img src="./imgs/3_3_2_03_s.jpg" height="auto" width="auto" title="caDesign"></a>

下载的[Street Centerline Attributes and Lookup Tables](https://data.cityofchicago.org/Transportation/Street-Center-Lines/6imu-meau)文件描述了道路中心线字段，其中`STREET_TYPE`字段为道路分类，摘录如下：

| CODE| DESCRIPTION     |
|-----------|-----------|
| AVE| AVENUE           |
| BLVD| BOULEVARD       |
| CRES| CRESCENT COURT  |
| CT |COURT             |
| DR |DRIVE             |
| ER| ENTRANCE RAMP     |
| EXPY| EXPRESSWAY      |
| HWY| HIGHWAY          |
| LN |LANE              |
| PKWY| PARK WAY        |
| PL |PLACE             |
| ROW |ROW              |
| SQ| SQUARE            |
| SR |SERVICE ROAD      |
| ST| STREET            |
| TER |TERRACE          |
| TOLL| TOLL WAY        |
| VIA |WAY              |
| WAY| EXIT RAMP        |

* 土地利用

土地利用（Land Use Inventory）从[CMAP(Chicago Metropolitan Agency for Planning) Data Hub](https://datahub.cmap.illinois.gov/group/land-use-inventories) 下载，数据文件时间为2015年（通常每5年一更新）。下载地址也提供了'Land Use Inventory Metadata (2015)'PDF说明文件，可以对照`LANDUSE`字段提供的代码查看土地利用。该部分的映射也写在`config.yml`配置文件中。

读取研究区域（芝加哥城边界数据）用前文定义的`shp2gdf()`函数。对于土地利用数据的读取和裁切，重新定义`shp2gdf_updated()`函数，使用`gpd.clip()`方法裁切。

`database.py`
```python
def shp2gdf(fn,epsg=None,boundary=None,encoding='utf-8'):    
    '''
    function - 转换.shp地理信息数据为GeoDataFrame(geopandas)数据格式，可以配置投影
    
    Paras:
        fn - .shp文件路径
        epsg - 配置投影，默认为None
        boundary - 配置裁切边界，默认为None
        encoding - 配置编码，默认为'utf-8'
    '''
    import geopandas as gpd
    
    shp_gdf=gpd.read_file(fn,encoding=encoding)
    print('original data info:{}'.format(shp_gdf.shape))
    shp_gdf.dropna(how='all',axis=1,inplace=True)
    print('dropna-how=all,result:{}'.format(shp_gdf.shape))
    shp_gdf.dropna(inplace=True)
    print('dropna-several rows,result:{}'.format(shp_gdf.shape))
    if epsg is not None:
        shp_gdf_proj=shp_gdf.to_crs(epsg=epsg)
        print(shp_gdf_proj.crs)
    if boundary:
        shp_gdf_proj['mask']=shp_gdf_proj.geometry.apply(lambda row:row.within(boundary))
        shp_gdf_proj.query('mask',inplace=True)        
    
    return shp_gdf_proj

def shp2gdf_updated(fn,boundary=None,encoding='utf-8'):    
    '''
    function - 转换.shp地理信息数据为GeoDataFrame(geopandas)数据格式，配置投影为给定边界的crs，并应用gpd.clip()方法裁切
    
    Paras:
        fn - .shp文件路径
        boundary - 配置裁切边界，默认为None
        encoding - 配置编码，默认为'utf-8'
    '''
    import geopandas as gpd
    from tqdm import tqdm
    tqdm.pandas()  
    
    shp_gdf=gpd.read_file(fn,encoding=encoding)    
    if boundary is not None:        
        shp_gdf['mask']=shp_gdf.geometry.progress_apply(lambda row:row.is_valid)
        shp_gdf=shp_gdf[shp_gdf['mask']==True]
        shp_clip_gdf=gpd.clip(shp_gdf.to_crs(boundary.crs),boundary)    
        return shp_clip_gdf
    else:
        return shp_gdf

if __name__=="__main__":
    #C.土地利用
    #研究边界
    Chicago_boundary_fp=cfg['raw_data']['Chicago_boundary']
    Chicago_boundary_gdf=shp2gdf(Chicago_boundary_fp,epsg=Chicago_epsg)
    Chicago_boundary_TN=cfg['table_name']['Chicago_boundary_TN']
    gpd2postSQL(Chicago_boundary_gdf,table_name=Chicago_boundary_TN,myusername=UN,mypassword=PW,mydatabase=DB)    
    Chicago_boundary=postSQL2gpd(table_name=Chicago_boundary_TN,geom_col=GC,myusername=UN,mypassword=PW,mydatabase=DB)
    
    #读取土地利用数据并裁切到研究区域
    landuse_fn=cfg['raw_data']['landuse_fn']
    landuse_gdf=shp2gdf_updated(landuse_fn,boundary=Chicago_boundary)
    landuse_mapping=cfg['landuse']['landuse_mapping']
    landuse_gdf['landuse_name']=landuse_gdf['LANDUSE'].map(landuse_mapping)

    landuse_TN=cfg['table_name']['landuse_TN']
    gpd2postSQL(landuse_gdf,table_name=landuse_TN,myusername=UN,mypassword=PW,mydatabase=DB)
    landuse_gdf=postSQL2gpd(table_name=landuse_TN,geom_col=GC,myusername=UN,mypassword=PW,mydatabase=DB)
```

<a href=""><img src="./imgs/3_3_2_04_s.jpg" height="auto" width="auto" title="caDesign"></a>

* 植被（高，中，低）

该部分数据是直接使用'点云数据处理'一章中使用[.las格式的激光雷达数据](https://www.arcgis.com/apps/webappviewer/index.html?id=44eb65c92c944f3e8b231eb1e2814f4d)提取的植被信息，包括高的树木（high vegetation），中等树木（medium vegetation）和低矮树木（low vegetation）。栅格的投影为`EPSG:6455 - NAD83(2011) / Illinois East (ftUS)`，需要统一为本次实验的投影`EPSG:32616 - WGS 84 / UTM zone 16N`。定义栅格数据重投影的函数`raster_reprojection()`转换投影坐标。

`database.py`
```python
def raster_reprojection(raster_fp,save_path,dst_crs):
    from rasterio.warp import calculate_default_transform, reproject, Resampling
    import rasterio as rio
    '''
    function - 转换栅格投影
    
    Paras:
        raster_fp - 待转换投影的栅格
        dst_crs - 目标投影
        save_path - 保存路径
    '''
    with rio.open(raster_fp) as src:
        transform, width, height = calculate_default_transform(src.crs, dst_crs, src.width, src.height, *src.bounds)
        kwargs = src.meta.copy()
        kwargs.update({
            'crs': dst_crs,
            'transform': transform,
            'width': width,
            'height': height,
            "compress":'lzw',
        })
        with rio.open(save_path, 'w', **kwargs) as dst:
            for i in range(1, src.count + 1):
                reproject(
                    source=rio.band(src, i),
                    destination=rio.band(dst, i),
                    src_transform=src.transform,
                    src_crs=src.crs,
                    dst_transform=transform,
                    dst_crs=dst_crs,
                    resampling=Resampling.nearest)      

def raster_reprojection_batch(srcs,dsts,epsg):
    '''
    批量转换栅格投影

    Parameters
    ----------
    srcs : string
        待转换投影的栅格路径名.
    dsts : string
        转换后存储栅格路径名.
    epsg : int
        坐标投影系统，epsg编号.

    Returns
    -------
    None.

    '''
    from tqdm import tqdm
    for i in tqdm(range(len(srcs))):
        raster_reprojection(srcs[i],dsts[i],epsg)  

if __name__=="__main__":
    #D. 树木（高，中，低）栅格数据重投影
    HighVegetation_fn=cfg['raw_data']['HighVegetation_fn']
    MediumVegetation_fn=cfg['raw_data']['MediumVegetation_fn']
    LowVegetation_fn=cfg['raw_data']['LowVegetation_fn']
    HighVegetation_reprojection_fn=cfg['processed_data']['HighVegetation_reprojection_fn']
    MediumVegetation_reprojection_fn=cfg['processed_data']['MediumVegetation_reprojection_fn']
    LowVegetation_reprojection_fn=cfg['processed_data']['LowVegetation_reprojection_fn']
    raster_reprojection_batch(srcs=[HighVegetation_fn,MediumVegetation_fn,LowVegetation_fn],dsts=[HighVegetation_reprojection_fn,MediumVegetation_reprojection_fn,LowVegetation_reprojection_fn],epsg=Chicago_epsg)   
```

<a href=""><img src="./imgs/3_3_2_05_s.jpg" height="auto" width="auto" title="caDesign"></a>

###### 5) 节点处全景图

在开始探索因素之间关系时，由全景图提取的语义分割信息是否与传感器测量的几类数据具有相关性并不确定，但是全景图可以帮助观察节点所在的场地环境。芝加哥区域街道全景图（Street View panorama）可以从[Google Developers Console_Street View Static API ](https://accounts.google.com/ServiceLogin/signinchooser?service=cloudconsole&passive=1209600&osid=1&continue=https%3A%2F%2Fconsole.cloud.google.com%2Fapis%2Fdashboard&followup=https%3A%2F%2Fconsole.cloud.google.com%2Fapis%2Fdashboard&flowName=GlifWebSignIn&flowEntry=ServiceLogin)支付下载。或者从[istreetview](https://istreetview.com/)通过节点坐标获取全景图索引（PanoID），然后用[Street View Download 360](https://svd360.istreetview.com/)辅助下载。

对全景图包括语义分割的数据处理方法可以参考‘城市街道视域景观指数与邻里尺度特征效应’一章。

| 001e06113d20-原图  | 语义分割  |
|---|---|
| <a href=""><img src="./imgs/3_3_2_06_s.gif" height="auto" width="auto" title="caDesign"></a>  |  <a href=""><img src="./imgs/3_3_2_07_s.gif" height="auto" width="auto" title="caDesign"></a> |


##### B.2.2.2 QGIS建立地图

地图的建立可以辅助查看数据及出图。使用[QGIS](https://www.qgis.org/en/site/)建立名为'PAPER_Urban_Spatial_Pattern_N_Local_Environmental_Changes'的地图文件，上述数据地图均在QGIS中读取写入到数据的文件后，建立布局（Layout）出图。所有的图纸（Pages）均放置于一个布局之下，为了便于不断调整的需要，在`Layers`图层管理下，对每一单张图纸（Page）涉及的所有图层均放置于一个组之下（用Add Group增加组）。注意，每个组（图纸）中的图层可能来源于同一个数据库文件。

#### B.2.3 分析与结果

分析过程按照传感器测量分类分5组进行，包括
1. 气体类，涉及CO、H<sub>2</sub>S、NO<sub>2</sub>、O<sub>3</sub>、oxidizing_gases、reducing_gases和SO<sub>2</sub>;
2. 颗粒物，微粒，涉及pm<sub>1</sub>,pm</sub>2.5</sub>, pm<sub>5</sub>,pm<sub>10</sub>;
3. 热环境，涉及温度，湿度和大气压；
4. 噪音；
5. 光环境，涉及光强度，红外光谱强度和紫外线强度。

##### B.2.3.1 气体类

###### 1) 分类气体

在数据预处理时，使用`data:parameter`字段分类数据时，所有的气体类测量数据均位于'concentration_x.gpkg(pkl)'下。需要按照不同的气体类型（`sensor`字段）进一步提取并保存为单独的文件。

`air_sensor_category.py`
```python
# -*- coding: utf-8 -*-
"""
Created on Tue Feb 15 09:58:38 2022

@author: Richie Bao-caDesign设计(cadesign.cn)
"""

def air_sensor_category_extraction(air_sensor_list,field,concentration_fps,air_sensor_category_save_fp):
    '''
    将混合了不同气体类型的一个分类数据进一步根据气体类型切分与保存为单独的文件

    Parameters
    ----------
    air_sensor_list : list(string)
        气体类型，包括['co', 'h2s', 'no2', 'o3', 'oxidizing_gases', 'reducing_gases', 'so2'].
    field : string
        含有气体类型名的列名.
    concentration_fps : list(string)
        初始处理的分类数据，包含不同气体类型.
    air_sensor_category_save_fp : string
        保存路径.

    Returns
    -------
    None.

    '''    
    import pandas as pd
    from tqdm import tqdm
    
    for sensor in tqdm(air_sensor_list):
        p_list=[]
        for concentration_fp in concentration_fps:
            concentration=gpd.read_file(concentration_fp)
            p_sensor=concentration[concentration[field]==sensor]
            p_list.append(p_sensor)
            
        p_concat=pd.concat(p_list)  
        sensor_save_fn=os.path.join(air_sensor_category_save_fp,"air_{}.gpkg".format(sensor))
        p_concat.to_file(sensor_save_fn,driver="GPKG")
        
if __name__=="__main__":
    import sys
    sys.path.append('..')
    import util    
    import geopandas as gpd
    import pandas as pd
    import os
    import pickle
    from database import postSQL2gpd,gpd2postSQL,cfg_load_yaml   
    parent_path=os.path.dirname(os.getcwd())
    
    cfg=cfg_load_yaml('../config.yml')  
    UN=cfg["postgreSQL"]["myusername"]
    PW=cfg["postgreSQL"]["mypassword"]
    DB=cfg["postgreSQL"]["mydatabase"] 
    GC='geometry'      
    
    Chicago_epsg=cfg['Chicago_epsg']
    AoT_data_category_save_fp=cfg['processed_data']['AoT_data_category_save_fp'] 
    
    #A.按sensor列，提取气体类型列表。使用.pkl格式分类数据（不包含'geometry'（GeoDataFrame）的DataFrame数据），提高读取速度
    AoT_data_category_pkl_save_fp=cfg['processed_data']['AoT_data_category_pkl_save_fp'] 
    concentration_pkl_save_fp=os.path.join(parent_path,AoT_data_category_pkl_save_fp,"concentration.pkl")   
    s_t=util.start_time()
    with open(concentration_pkl_save_fp,'rb') as f:
        concentration_df=pickle.load(f) #6.06GB, total time spend:1.15 minutes
    util.duration(s_t)
    sensor_list=concentration_df.sensor.unique()
    print(sensor_list)        
        
    #B.分别提取气体类型（字段sensor）并保存至硬盘，用于后续分析
    air_sensor_list=cfg['analysis_air']['air_sensor_list']
    print("air_sensors:",air_sensor_list)
    air_sensor_category_save_fp=cfg['analysis_air']['air_sensor_category_save_fp']
    concentration_fps=[os.path.join(parent_path,AoT_data_category_save_fp,"concentration_{}.gpkg".format(i)) for i in range(1,7)]
    print("concentration_fps:",concentration_fps) 
    s_t=util.start_time()
    air_sensor_category_extraction(air_sensor_list,'sensor',concentration_fps,air_sensor_category_save_fp)  #直接处理GeoPandas的.gpkg格式文件非常耗时，应先处理Pandas保存为.pkg的DataFrame格式文件，而后再增加几何对象，转换为GeoDataFrame格式
    util.duration(s_t)    
```

###### 2) 传感器值域，数据预处理与按时间周期重采样

'sensors.csv'文件包含有对不同传感器值域信息，为最小值列`hrf_minval`和最大值列`hrf_maxval`，气体类浓度单位为ppm，提取各个气体对应值域为：

```python
{'co': [0.0, 1000.0],
 'h2s': [0.0, 50.0],
 'no2': [0.0, 20.0],
 'o3': [0.0, 20.0],
 'oxidizing_gases': [0.0, 100.0],
 'reducing_gases': [0.0, 20.0],
 'so2': [0.0, 20.0]}
 ```


因此数据的预处理阶段通常包括：

1. 剔除不在给定值域内的值；
2. 常规剔除异常值；
3. 移除空值、无效值等。（是否必须移除空值，需要根据具体情况确定）

当预处理数据后，对于时间序列的数据可以指定时间周期来重采样数据，这里按均值重采样了日、星期、月和年，对应输入参数为['D','W','M','Y']。按时间周期重采样的数据写入到数据库。

`time_series_analysis.py`
```python
# -*- coding: utf-8 -*-
"""
Created on Sun Mar 13 08:26:52 2022

@author: Richie Bao-caDesign设计(cadesign.cn)
"""
def df_value_within_range(df,val_column,specified_range,dropnone=False,value_type=None):
    '''
    给定DataFrame格式数据列，移除空值，保留给定区间的值，配置数据类型。

    Parameters
    ----------
    df : DataFrame
        待处理的数据.
    val_column : string
        处理列的列名.
    specified_range : list(float)
        值域区间.
    dropnone : bool, optional
        是否移除空值. The default is False.
    value_type : string, optional
        转换为的数据类型. The default is None.

    Returns
    -------
    df_filter : DataFrame
        处理后的数据.

    '''
    if dropnone:        
        df.dropna(subset=[val_column],inplace=True)
    if value_type:
        df[val_column]=df[val_column].astype(value_type) 
    df_filter=df.loc[(df[val_column]<specified_range[1]) & (df[val_column]>specified_range[0])] 
    
    return df_filter

def df_drop_outliers(df,val_column,z_thresh=3):
    '''
    由stats.zscore方法移除DataFrame中给定列的异常值

    Parameters
    ----------
    df : DataFrame
        包含待处理数据列.
    val_column : string
        待处理异常值列.
    z_thresh : float, optional
        剔除异常值的阈值. The default is 3.

    Returns
    -------
    df : DataFrame
        剔除异常值后的DataFrame格式数据.

    '''
    from scipy import stats
    import numpy as np
    constrains=np.abs(stats.zscore(df[val_column])) < z_thresh
    df.drop(df.index[~constrains],inplace=True)
    
    return df

def df_resample(gdf,val_column,time_column,rule,group=None,specified_range=None):
    '''
    给定数值列和时间列，按照规则（按日，月，年等）计算均值（采样）

    Parameters
    ----------
    gdf : GeoDataFrame
        待处理的数据，因为处理后写入地理信息数据库PostgreSQL，因此采用gdf格式数据.
    val_column : string
        计算列.
    time_column : sring
        时间列.
    rule : list(string)
        例如：['D','W','M','Y'].
    group : string, optional
        分组列名. The default is None.

    Returns
    -------
    TYPE : GeoDataFrame
        按时间周期采用后数据.
        
    '''
    import geopandas as gpd
    import pandas as pd
    from shapely import wkt
    from tqdm import tqdm
    
    gdf_notnull=gdf[gdf[val_column].notnull()]
    gdf_notnull['ts']=pd.to_datetime(gdf_notnull[time_column])
    gdf_notnull_sort=gdf_notnull.sort_values(time_column)
    gdf_notnull_sort[val_column]=gdf_notnull_sort[val_column].astype('float')  
    crs=gdf.crs
    print("crs={}".format(crs))
    
    if specified_range:
        gdf_notnull_sort=df_value_within_range(gdf_notnull_sort,val_column,specified_range)
    
    g_dic={}
    if group:
        gdf_notnull_sort_group=gdf_notnull_sort.groupby([group])
        # i=0
        for g in tqdm(gdf_notnull_sort_group):
            g_name=g[0]
            g_val=g[1]                    
            g_geometry=g_val.iloc[[0]].geometry.values[0]
            g_val.set_index('ts',inplace=True)
            g_resample_dict={}
            for r in rule:
                g_resample_series=g_val[val_column].resample(r).mean()
                g_resample_df=pd.DataFrame(g_resample_series).T
                g_resample_df.rename(index={val_column:g_name},inplace=True)
                if "H" in rule:
                    g_resample_df.rename({i:"{}_{}".format(r,pd.to_datetime(i).strftime('%Y-%m-%d %H:%M:%S')) for i in g_resample_df.columns},axis=1,inplace=True)  
                else:
                    g_resample_df.rename({i:"{}_{}".format(r,pd.to_datetime(i).strftime('%Y-%m-%d')) for i in g_resample_df.columns},axis=1,inplace=True)                
                g_resample_dict[r]=g_resample_df
            g_resample_concat=pd.concat(g_resample_dict.values(),axis=1)
            g_resample_concat['geometry']=g_geometry
            g_resample_concat[group]=g_name            
            g_dic[g_name]=g_resample_concat 
            
            # if i==1:break
            # i+=1
        resample_concat=pd.concat(g_dic.values(),axis=1)
        def sjoin(x): return ';'.join(x[x.notnull()].astype(str))  
        resample_concat_m=resample_concat.groupby(level=0, axis=1).apply(lambda x: x.apply(sjoin, axis=1))
        resample_concat_m['geometry']=resample_concat_m['geometry'].apply(wkt.loads) 
        timestamp_columns=list(set(resample_concat_m.columns.to_list())-set(['geometry',group]))
        resample_concat_m[timestamp_columns]=resample_concat_m[timestamp_columns].apply(pd.to_numeric)
        resample_gdf=gpd.GeoDataFrame(resample_concat_m,geometry='geometry',crs=crs)    
        return resample_gdf 
    else:
        resample_dict={}
        for r in rule:
            gdf_notnull_sort.set_index('ts',inplace=True)
            resample_series=gdf_notnull_sort[val_column].resample(r).mean()
            resample_dict[r]=resample_series
        return resample_dict

def df_resample_bundle(sensor_fns,sensor_list,val_columns,time_column,rule,cfg,group=None,specified_range_dict=None,prefix=None):
    '''
    批量读取与计算多个GeoDataFrame格式数据，并写入数据库。给定数值列和时间列，按照规则（按日，月，年等）计算均值（采样）

    Parameters
    ----------
    sensor_fns : string
        多个待处理数据路径列表，为geopandas可以读取的地理信息格式，例如.gpkg.
    sensor_list : string
        与多个待处理数据对应的名称列表，例如测量内容名称.
    val_columns : list(string)
        处理数据列名.
    time_column : string
        时间列名.
    rule : list(string)
        按时间周期采样，例如['D','W','M','Y'].
    cfg : dict
        包含数据库信息的配置文件.
    group : string, optional
        用于分组的列名. The default is None.
    prefix : string, optional
        标识表名的前缀. The default is None.

    Returns
    -------
    tn_list : list(string)
        表名列表.

    '''
    from tqdm import tqdm
    from database import gpd2postSQL 
    import geopandas as gpd
      
    UN=cfg["postgreSQL"]["myusername"]
    PW=cfg["postgreSQL"]["mypassword"]
    DB=cfg["postgreSQL"]["mydatabase"] 
    GC='geometry'    
    
    tn_list=[]
    for idx in tqdm(range(len(sensor_fns))):
        air_gdf=gpd.read_file(sensor_fns[idx])
        specified_range=specified_range_dict[sensor_list[idx]]
        for val in val_columns:            
            air_resample_gdf=df_resample(air_gdf,val,time_column,rule,group,specified_range) 
            if prefix:
                table_name='{}_{}_resample_{}'.format(prefix,sensor_list[idx],val)     
            else:
                table_name='{}_resample_{}'.format(sensor_list[idx],val) 
            gpd2postSQL(air_resample_gdf,table_name,myusername=UN,mypassword=PW,mydatabase=DB)
            tn_list.append(table_name)
    return tn_list
```

`air_time_series_analysis.py`
```python
if __name__=="__main__":
    import sys
    sys.path.append('..')
    import util    
    import geopandas as gpd
    import pandas as pd
    import os
    import pickle
    from database import postSQL2gpd,gpd2postSQL,cfg_load_yaml  
    from glob import glob
    import time_series_analysis as tsa
    from datetime import datetime
    parent_path=os.path.dirname(os.getcwd())
    
    cfg=cfg_load_yaml('../config.yml')  
    UN=cfg["postgreSQL"]["myusername"]
    PW=cfg["postgreSQL"]["mypassword"]
    DB=cfg["postgreSQL"]["mydatabase"] 
    GC='geometry' 
    
    air_sensor_category_save_fp=cfg['analysis_air']['air_sensor_category_save_fp']
    air_sensor_category_fns=glob(os.path.join(air_sensor_category_save_fp,"*.gpkg"))
    air_sensor_list=cfg['analysis_air']['air_sensor_list']
    print(air_sensor_list)  #['co', 'h2s', 'no2', 'o3', 'oxidizing_gases', 'reducing_gases', 'so2']  
    
    AoT_nodes_TN=cfg['table_name']['AoT_nodes_TN']  
    AoT_nodes_gdf=postSQL2gpd(table_name=AoT_nodes_TN,geom_col=GC,myusername=UN,mypassword=PW,mydatabase=DB)
    
    #A.传感器值域
    AoT_sensors_fp=os.path.join(parent_path,cfg['AoT']['AoT_sensors_fp'])
    AoT_nodes_df=pd.read_csv(AoT_sensors_fp,sep=",",header=0)
    AoT_sensors_range=AoT_nodes_df.set_index('sensor')[['hrf_minval', 'hrf_maxval']].to_dict()
    co_value_range=[AoT_sensors_range['hrf_minval']['co'],AoT_sensors_range['hrf_maxval']['co']]
    specified_range_dict={sensor_name:[AoT_sensors_range['hrf_minval'][sensor_name],AoT_sensors_range['hrf_maxval'][sensor_name]] for sensor_name in air_sensor_list}
    
    #B.测量数据按照时间周期重采样，包括移除空值和超出给定值域的行，并写入数据    
    air_tn_list=tsa.df_resample_bundle(air_sensor_category_fns,air_sensor_list,['value_hrf'],'timestamp',['D','W','M','Y'],cfg,'node_id',specified_range_dict,'air')    
```

###### 3) 时间序列

时间序列分析内容包括打印查看数据，及白噪声检验（纯随机性检验）、平稳性和周期性等内容。

* 白噪声检验

获取的气体传感器时间序列数据，通过图表打印查看各节点数值变化，部分数据很难确定是否具有规律性，因此通过[`statsmodels.stats.diagnostic.acorr_ljungbox`](https://www.statsmodels.org/dev/generated/statsmodels.stats.diagnostic.acorr_ljungbox.html)方法计算确定。配置`corr_ljungbox`输入参数`boxpierce=True`，除计算`Ljung-Box test`外，也计算`Box-Pierce test `，判断返回的`lb_pvalue`和`bp_pvalue`是否大于给定的显著性水平（默认配置为0.05），如果均大于无法拒绝原假设，则认为该数据为白噪声，即纯粹的随机数据。


* 平稳性检验

如果要对时间序列建立预测模型，例如ARMA（autoregressive–moving-average）、ARIMA（autoregressive integrated moving average），需要时间序列数据具有平稳性(意味均值和方差保持不变)。通过检验气体传感器时间序列数据的平稳性，也可以确定气体污染浓度变化趋势，是否数值稳定在一个固定区间内，还是会有剧烈的随机波动。计算使用[`statsmodels.tsa.stattools.adfuller`](https://www.statsmodels.org/devel/generated/statsmodels.tsa.stattools.adfuller.html)方法，如`adfuller（ADF）`返回的`pvalue`值小于给定的显著性水平（默认配置为0.05），则数据平稳；否则无法拒绝原假设，数据不平稳。

* 周期性模式判断

使用自相关系数（autocorrelation function，ACF）和偏自相关系数（Partial autocorrelation function, PACF）来检验时间序列数据与给定延迟数（lag）错位自身的时间序列数据之间是否具有相关性，寻找时间序列数据重复模式，例如是否具有周期性。通过图表打印平滑后的气体时间序列数据，能够在噪声掩盖下发现气体浓度具有一定的周期性，通过ACF和PACF进一步验证和确定这一特点。

时间序列的数据分析不仅可以应用于气体类，同样适用于颗粒类、热环境、噪音和光环境类，因此在代码编写过程中，将代码分为两个文件，一个为核心基础的计算函数文件`time_series_analysis.py`，包括给定值域提取数据的`df_value_within_range()`函数；给定阈值，剔除异常值的`df_drop_outliers()`函数；给定采样时间周期，按均值重采样时间序列的`df_resample()`函数和批量处理的`df_resample_bundle()`函数；ACF的`autocorrelation_time_series()`函数和PACF的`partial_autocorrelation_time_series()`函数；平稳性检验的`stationary_adfuller()`函数；白噪声检验的`white_noise_testing()`函数；以及时间序列打印的`time_series_plot_MultiColumns()`函数。这个文件可以被其它传感器数据类调用进行同样的分析。另一个文件`air_time_series_analysis.py`为气体类调用`time_series_analysis.py`中的函数实现批量计算所有节点的代码。气体类包括多个子类，有'co', 'h2s', 'no2', 'o3', 'oxidizing_gases', 'reducing_gases', 'so2'等，因此定义`time_series_analysis_batch`类方便分别调用计算。

`time_series_analysis.py`
```python
# -*- coding: utf-8 -*-
"""
Created on Sun Mar 13 08:26:52 2022

@author: Richie Bao-caDesign设计(cadesign.cn)
"""
def df_value_within_range(df,val_column,specified_range,dropnone=False,value_type=None):
    '''
    给定DataFrame格式数据列，移除空值，保留给定区间的值，配置数据类型。

    Parameters
    ----------
    df : DataFrame
        待处理的数据.
    val_column : string
        处理列的列名.
    specified_range : list(float)
        值域区间.
    dropnone : bool, optional
        是否移除空值. The default is False.
    value_type : string, optional
        转换为的数据类型. The default is None.

    Returns
    -------
    df_filter : DataFrame
        处理后的数据.

    '''
    if dropnone:        
        df.dropna(subset=[val_column],inplace=True)
    if value_type:
        df[val_column]=df[val_column].astype(value_type) 
    df_filter=df.loc[(df[val_column]<specified_range[1]) & (df[val_column]>specified_range[0])] 
    
    return df_filter

def df_drop_outliers(df,val_column,z_thresh=3):
    '''
    由stats.zscore方法移除DataFrame中给定列的异常值

    Parameters
    ----------
    df : DataFrame
        包含待处理数据列.
    val_column : string
        待处理异常值列.
    z_thresh : float, optional
        剔除异常值的阈值. The default is 3.

    Returns
    -------
    df : DataFrame
        剔除异常值后的DataFrame格式数据.

    '''
    from scipy import stats
    import numpy as np
    constrains=np.abs(stats.zscore(df[val_column])) < z_thresh
    df.drop(df.index[~constrains],inplace=True)
    
    return df

def df_resample(gdf,val_column,time_column,rule,group=None,specified_range=None):
    '''
    给定数值列和时间列，按照规则（按日，月，年等）计算均值（采样）

    Parameters
    ----------
    gdf : GeoDataFrame
        待处理的数据，因为处理后写入地理信息数据库PostgreSQL，因此采用gdf格式数据.
    val_column : string
        计算列.
    time_column : sring
        时间列.
    rule : list(string)
        例如：['D','W','M','Y'].
    group : string, optional
        分组列名. The default is None.

    Returns
    -------
    TYPE : GeoDataFrame
        按时间周期采用后数据.
        
    '''
    import geopandas as gpd
    import pandas as pd
    from shapely import wkt
    from tqdm import tqdm
    
    gdf_notnull=gdf[gdf[val_column].notnull()]
    gdf_notnull['ts']=pd.to_datetime(gdf_notnull[time_column])
    gdf_notnull_sort=gdf_notnull.sort_values(time_column)
    gdf_notnull_sort[val_column]=gdf_notnull_sort[val_column].astype('float')  
    crs=gdf.crs
    print("crs={}".format(crs))
    
    if specified_range:
        gdf_notnull_sort=df_value_within_range(gdf_notnull_sort,val_column,specified_range)
    
    g_dic={}
    if group:
        gdf_notnull_sort_group=gdf_notnull_sort.groupby([group])
        # i=0
        for g in tqdm(gdf_notnull_sort_group):
            g_name=g[0]
            g_val=g[1]                    
            g_geometry=g_val.iloc[[0]].geometry.values[0]
            g_val.set_index('ts',inplace=True)
            g_resample_dict={}
            for r in rule:
                g_resample_series=g_val[val_column].resample(r).mean()
                g_resample_df=pd.DataFrame(g_resample_series).T
                g_resample_df.rename(index={val_column:g_name},inplace=True)
                if "H" in rule:
                    g_resample_df.rename({i:"{}_{}".format(r,pd.to_datetime(i).strftime('%Y-%m-%d %H:%M:%S')) for i in g_resample_df.columns},axis=1,inplace=True)  
                else:
                    g_resample_df.rename({i:"{}_{}".format(r,pd.to_datetime(i).strftime('%Y-%m-%d')) for i in g_resample_df.columns},axis=1,inplace=True)                
                g_resample_dict[r]=g_resample_df
            g_resample_concat=pd.concat(g_resample_dict.values(),axis=1)
            g_resample_concat['geometry']=g_geometry
            g_resample_concat[group]=g_name            
            g_dic[g_name]=g_resample_concat 
            
            # if i==1:break
            # i+=1
        resample_concat=pd.concat(g_dic.values(),axis=1)
        def sjoin(x): return ';'.join(x[x.notnull()].astype(str))  
        resample_concat_m=resample_concat.groupby(level=0, axis=1).apply(lambda x: x.apply(sjoin, axis=1))
        resample_concat_m['geometry']=resample_concat_m['geometry'].apply(wkt.loads) 
        timestamp_columns=list(set(resample_concat_m.columns.to_list())-set(['geometry',group]))
        resample_concat_m[timestamp_columns]=resample_concat_m[timestamp_columns].apply(pd.to_numeric)
        resample_gdf=gpd.GeoDataFrame(resample_concat_m,geometry='geometry',crs=crs)    
        return resample_gdf 
    else:
        resample_dict={}
        for r in rule:
            gdf_notnull_sort.set_index('ts',inplace=True)
            resample_series=gdf_notnull_sort[val_column].resample(r).mean()
            resample_dict[r]=resample_series
        return resample_dict

def df_resample_bundle(sensor_fns,sensor_list,val_columns,time_column,rule,cfg,group=None,specified_range_dict=None,prefix=None):
    '''
    批量读取与计算多个GeoDataFrame格式数据，并写入数据库。给定数值列和时间列，按照规则（按日，月，年等）计算均值（采样）

    Parameters
    ----------
    sensor_fns : string
        多个待处理数据路径列表，为geopandas可以读取的地理信息格式，例如.gpkg.
    sensor_list : string
        与多个待处理数据对应的名称列表，例如测量内容名称.
    val_columns : list(string)
        处理数据列名.
    time_column : string
        时间列名.
    rule : list(string)
        按时间周期采样，例如['D','W','M','Y'].
    cfg : dict
        包含数据库信息的配置文件.
    group : string, optional
        用于分组的列名. The default is None.
    prefix : string, optional
        标识表名的前缀. The default is None.

    Returns
    -------
    tn_list : list(string)
        表名列表.

    '''
    from tqdm import tqdm
    from database import gpd2postSQL 
    import geopandas as gpd
      
    UN=cfg["postgreSQL"]["myusername"]
    PW=cfg["postgreSQL"]["mypassword"]
    DB=cfg["postgreSQL"]["mydatabase"] 
    GC='geometry'    
    
    tn_list=[]
    for idx in tqdm(range(len(sensor_fns))):
        air_gdf=gpd.read_file(sensor_fns[idx])
        specified_range=specified_range_dict[sensor_list[idx]]
        for val in val_columns:            
            air_resample_gdf=df_resample(air_gdf,val,time_column,rule,group,specified_range) 
            if prefix:
                table_name='{}_{}_resample_{}'.format(prefix,sensor_list[idx],val)     
            else:
                table_name='{}_resample_{}'.format(sensor_list[idx],val) 
            gpd2postSQL(air_resample_gdf,table_name,myusername=UN,mypassword=PW,mydatabase=DB)
            tn_list.append(table_name)
    return tn_list


def autocorrelation_time_series(df, value_column,nlags=None,plot=False,bins_list=[-1,-0.75,-0.5,-0.25,0,0.25,0.5,0.75,1],title="ACF",xticks_step=6,save_path=None): 
    '''
    计算DataFrame给定列的自相关系数和打印图标，及统计区间频数

    Parameters
    ----------
    df : DataFrame
        含计算列的DataFrame格式数据.
    value_column : string
        待计算列名.
    nlags : int, optional
        滞后（延迟）数. The default is None.
    plot : bool, optional
        是否打印图表. The default is False.
    bins_list : list(float), optional
        分类区间. The default is [-1,-0.75,-0.5,-0.25,0,0.25,0.5,0.75,1].

    Returns
    -------
    acf : list(float)
        各个延迟数下的自相关系数.
    categories_counts : pandas.core.series.Series (int)
        自相关系数区间频数统计.

    '''
    import matplotlib.pyplot as plt
    from statsmodels import api as sm
    import pandas as pd
    import os
    
    value_series=df[value_column]
    value_series.dropna(inplace=True)
    # get the autocorrelation coefficient
    if nlags is not None:
        acf=sm.tsa.acf(value_series, nlags=nlags)
    else:
        acf=sm.tsa.acf(value_series, nlags=len(value_series))   
        
    bins_tuples=[(bins_list[i],bins_list[i+1]) for i in range(len(bins_list)-1)]  
    bins=pd.IntervalIndex.from_tuples(bins_tuples)
    categories_counts=pd.cut(acf, bins).value_counts()   
        
    if plot:        
        fig=plt.figure(figsize=(12,8))
        ax=fig.add_subplot(111)
        plt.rc('axes', unicode_minus=False)
        if nlags is not None:
            fig=sm.graphics.tsa.plot_acf(value_series, lags=nlags,ax=ax,title=title)
        else:
            fig=sm.graphics.tsa.plot_acf(value_series, lags=len(value_series)-1,ax=ax,title=title)
        ax.xaxis.set_ticks_position('bottom') 
        fig.tight_layout()
        
        old_xticks=ax.get_xticks()
        xticks_step=xticks_step
        new_xticks=list(range(0,int(old_xticks[-1]),xticks_step))
        ax.set_xticks(new_xticks)
        if save_path:
            plt.savefig(os.path.join(save_path,"{}.jpg".format(title)))
        
        plt.show()
        
    return acf,categories_counts

def partial_autocorrelation_time_series(df, value_column,nlags=None,plot=False,bins_list=[-1,-0.75,-0.5,-0.25,0,0.25,0.5,0.75,1],title="PACF",xticks_step=6,save_path=None): 
    '''
    计算DataFrame给定列的偏自相关系数和打印图标，及统计区间频数

    Parameters
    ----------
    df : DataFrame
       含计算列的DataFrame格式数据.
    value_column : string
        待计算列名.
    nlags : int, optional
        滞后（延迟）数. The default is None.
    plot : bool, optional
        是否打印图表. The default is False.
    bins_list : list(float), optional
        分类区间. The default is [-1,-0.75,-0.5,-0.25,0,0.25,0.5,0.75,1].

    Returns
    -------
    pacf : list(float)
        各个延迟数下的偏自相关系数.
    categories_counts : pandas.core.series.Series (int)
        偏自相关系数区间频数统计.

    '''
    import matplotlib.pyplot as plt
    from statsmodels import api as sm
    import pandas as pd
    import os
    
    value_series=df[value_column]
    value_series.dropna(inplace=True)
    # get the autocorrelation coefficient
    if nlags is not None:
        pacf=sm.tsa.pacf(value_series, nlags=nlags)
    else:
        pacf=sm.tsa.pacf(value_series, nlags=len(value_series))   
        
    bins_tuples=[(bins_list[i],bins_list[i+1]) for i in range(len(bins_list)-1)]  
    bins=pd.IntervalIndex.from_tuples(bins_tuples)
    categories_counts=pd.cut(pacf, bins).value_counts()          
        
    if plot:
        fig=plt.figure(figsize=(12,8))
        ax=fig.add_subplot(111)
        plt.rc('axes', unicode_minus=False)
        if nlags is not None:
            fig=sm.graphics.tsa.plot_pacf(value_series, lags=nlags,ax=ax,title=title)
        else:
            fig=sm.graphics.tsa.plot_pacf(value_series, lags=len(value_series)-1,ax=ax,title=title)
        ax.xaxis.set_ticks_position('bottom') 
        fig.tight_layout()
        
        old_xticks=ax.get_xticks()
        xticks_step=xticks_step
        new_xticks=list(range(0,int(old_xticks[-1]),xticks_step))
        ax.set_xticks(new_xticks)   
        if save_path:
            plt.savefig(os.path.join(save_path,"{}.jpg".format(title)))        
        
        plt.show()
        
    return pacf,categories_counts


def dropFirstNonnullRows_day(df,value_column): 
    '''
    移除第一天数据

    Parameters
    ----------
    df : DataFrame
        含待处理列的DataFrame格式数据.
    value_column : string
        待处理数据列名.

    Returns
    -------
    df_masked : DataFrame
        移除第一天后的数据.

    '''
    import numpy as np
    
    value_series=df[value_column]
    idx_first=value_series.loc[~value_series.isnull()].index[0]
    first_day=idx_first.date()
    mask=np.array([dt.date()==first_day for dt in value_series.index]) 
    df_masked=df[~mask]

    return df_masked

def stationary_adfuller(df,value_column,autolag=None,alpha=0.05,print_detail=False):    
    '''
    计算时间序列的平稳性（statsmodels的adfuller方法）

    Parameters
    ----------
    df : DataFrame
        包含计算列的DataFrame格式数据.
    value_column : string
        待计算的列名.
    autolag : string, optional
        {“AIC”, “BIC”, “t-stat”, None}，具体参考 https://www.statsmodels.org/devel/generated/statsmodels.tsa.stattools.adfuller.html. The default is None.
    alpha : float, optional
        显著性水平(p-value). The default is 0.05.
    print_detail : bool, optional
        是否打印统计细节信息. The default is False.

    Returns
    -------
    is_stationary : dict
        节点名：是否平稳布尔值.

    '''
    from statsmodels.tsa.stattools import adfuller 
    
    df_drop=df[value_column].dropna()
    adfuller_test=adfuller(df_drop,autolag=autolag) #https://www.statsmodels.org/devel/generated/statsmodels.tsa.stattools.adfuller.html
    is_stationary=True if adfuller_test[1]<=alpha else False
    if print_detail:
        print('ADF statistic: %f' % adfuller_test[0])
        print('p-value: %f' % adfuller_test[1])
        print('critical values:')
        for key, value in adfuller_test[4].items():
            print('\t%s: %.3f' % (key, value))        
    return is_stationary

def white_noise_testing(df,value_column,lags=[6,12]):
    '''
    白噪声检验(纯随机性检验)，statsmodels.stats.diagnostic.acorr_ljungbox方法计算，包括Ljung-Box test和Box-Pierce test

    Parameters
    ----------
    df : DataFrame
        包含检测列的DataFrame格式数据.
    value_column : string
        待检测列名.
    lags : int, optional
        延迟数. The default is [6,12].

    Returns
    -------
    stat_pvalue : dict
        返回Ljung-Box test和Box-Pierce统计值，及p_value值.

    '''
    import statsmodels.stats.diagnostic as diag
    df_drop=df[value_column].dropna()
    stat_pvalue=diag.acorr_ljungbox(df_drop, lags=lags, boxpierce=True, model_df=0, period=None, return_df=None)
    return stat_pvalue   

def time_series_plot_MultiColumns(df,span=None,rolling_window=None,figsize=(10,10),font_size=10,legend=True,**setting):
    '''
    打印所有列的时间序列数据。

    Parameters
    ----------
    df : DataFrame
        计算数据.
    span : list(string), optional
        打印时间区间，（表述时间的字符串）. The default is None.
    rolling_window : int, optional
        数据平滑. The default is None.
    figsize : tuple(int,float), optional
        图表大小. The default is (10,10).
    font_size : int or float, optional
        字体大小. The default is 10.
    legend : bool, optional
        是否打印图例. The default is True.
    **setting : kw-argument(string)
        包括xlabel，ylabel，title.

    Returns
    -------
    df_span : DataFrame
        提取时间区间内的数据行.

    '''
    import matplotlib.pyplot as plt
    from pylab import mpl
    import matplotlib.dates as md
    from matplotlib.dates import DayLocator, HourLocator, DateFormatter, drange
    
    mpl.rcParams['font.sans-serif']=['SimHei'] #解决中文字符乱码问题
    plt.figure()
    plt.rcParams.update({'font.size':font_size}) # must set in top
    
    setting_dict={"xlabel":"X","ylabel":"Y","title":None,"xticklabels_strftime":"%Y-%m-%d","xticks_rotation":0}
    setting_dict.update(setting)     
    df_span=df[span[0]:span[1]]    
    
    if rolling_window:
        df_span_rolling=df_span.rolling(rolling_window).mean()        
        ax=df_span_rolling.plot(legend=legend,figsize=figsize) 
    else:
        ax=df_span.plot(legend=legend,figsize=figsize) 
    #https://matplotlib.org/stable/api/_as_gen/matplotlib.axes.Axes.set.html    
    ax.set(xlabel=setting_dict["xlabel"],
           ylabel=setting_dict["ylabel"],
           title=setting_dict["title"],
           )  
    
    return df_span
```

`air_time_series_analysis.py`
```python
# -*- coding: utf-8 -*-
"""
Created on Sun Mar 13 08:27:50 2022

@author: Richie Bao-caDesign设计(cadesign.cn)
"""
#%%
class time_series_analysis_batch:
    '''
    class - 与时间序列相关的计算，包括数据预处理，图表打印，自相关和偏自相关系数，及平稳性计算等
    '''
    
    def __init__(self,df,sensor_name,value_column,time_column,group_column,rule=["H"],dropnone=True,value_type='float',z_thresh=3):
        '''
        类初始化值

        Parameters
        ----------
        df : DataFrame
            待处理的数据.
        sensor_name : string
            传感器名称.
        value_column : string
            待处理的列名.
        time_column : string
            含有时间的列名.
        group_column : string
            分组列名.
        rule : string, optional
            时间序列重采样规则，例如['H','D','M','Y']等. The default is ["H"].
        dropnone : bool, optional
            是否移除空值. The default is True.
        value_type : string, optional
            因为处理列可能为object类型（string），需要重定义数据类型进行后续计算. The default is 'float'.
        z_thresh : float, optional
            异常值处理阈值. The default is 3.

        Returns
        -------
        None.

        '''
        self.df=df
        self.sensor_name=sensor_name
        self.value_column=value_column
        self.dropnone=dropnone
        self.value_type=value_type
        self.z_thresh=z_thresh
        self.time_column=time_column
        self.group_column=group_column
        self.rule=rule
     
    def sensors_range(self,AoT_sensors_fp,sensor_column,min_column,max_column):
        '''
        提取传感器取值区间

        Parameters
        ----------
        AoT_sensors_fp : string
            AoT的sensors.csv文件.
        sensor_column : string
            包含传感器名称的列名.
        min_column : string
            包含传感器最小取值的列名.
        max_column : string
            包含传感器最大取值的列名.

        Returns
        -------
        dict
            各个传感器的取值区间字典.

        '''
        import pandas as pd
        
        AoT_nodes_df=pd.read_csv(AoT_sensors_fp,sep=",",header=0)
        AoT_sensors_range=AoT_nodes_df.set_index(sensor_column)[[min_column,max_column]].to_dict()
        self.specified_range_dict={sensor_name:[AoT_sensors_range[min_column][sensor_name],AoT_sensors_range[max_column][sensor_name]] for sensor_name in air_sensor_list}
        
        return self.specified_range_dict
    
    def df_preprocessing(self):
        '''
        数据预处理，包括根据传感器取值区间提取行；移除空值行；剔除异常值；根据时间戳重采样等

        Returns
        -------
        DataFrame
            数据预处理结果.

        '''
        import time_series_analysis as tsa
        
        value_range=self.specified_range_dict[self.sensor_name]
        value_within_range=tsa.df_value_within_range(self.df,self.value_column,value_range,dropnone=self.dropnone,value_type=self.value_type)        
        value_drop_outliers=tsa.df_drop_outliers(value_within_range,self.value_column,z_thresh=self.z_thresh)   
        value_resample=tsa.df_resample(value_drop_outliers,self.value_column,self.time_column,self.rule,group=self.group_column)
        mask=[i.split("_")[0] in self.rule for i in value_resample.columns]
        self.value_resample_mask=value_resample.loc[:,mask].T #value_resample_mask=value_resample.drop(columns=['geometry','node_id']).T
        self.value_resample_mask.rename(index={i:datetime.strptime(i.split("_")[1],'%Y-%m-%d %H:%M:%S') for i in self.value_resample_mask.index.to_list()},inplace=True)    
        
        return self.value_resample_mask
    
    def time_series_plot(self,span,columns=None,rolling_window=10,xlabel="X",ylabel="Y",figsize=(20,10),font_size=10,legend=False):  
        '''
        打印所有列的时间序列数据。

        Parameters
        ----------
        span : list(string)
            打印时间区间，（表述时间的字符串）.
        columns : string, optional
            打印列（nodes），如果默认，则打印全部节点. The default is None.
        rolling_window : int, optional
            数据平滑. The default is 10.
        xlabel : string, optional
            横轴名. The default is "X".
        ylabel : string, optional
            纵轴名. The default is "Y".
        figsize : tuple(float or int), optional
            图表大小. The default is (20,10).
        font_size : int or float, optional
            字体大小. The default is 10.
        legend : bool, optional
            是否打印图例. The default is False.

        Returns
        -------
        df_span : DataFrame
            提取时间区间内的数据行.

        '''
        import time_series_analysis as tsa     
        
        if columns:
            df_span=tsa.time_series_plot_MultiColumns(self.value_resample_mask[columns],span=span,rolling_window=rolling_window,figsize=figsize,font_size=font_size,legend=legend,xlabel=xlabel,ylabel=ylabel)
        else:
            df_span=tsa.time_series_plot_MultiColumns(self.value_resample_mask,span=span,rolling_window=rolling_window,figsize=figsize,font_size=font_size,legend=legend,xlabel=xlabel,ylabel=ylabel)
        
        return df_span    
    
    def acf_pacf_counter(self,nlags=7,plot=False,save_path_acf=None,save_path_pacf=None,diff_periods=None):
        '''
        所有节点（nodes）自相关autocorrelation和偏自相关partial autocorrelation计算及频数统计

        Parameters
        ----------
        nlags : int, optional
            延迟数. The default is 7.
        plot : bool, optional
            是否打印图表,True为打印. The default is False.

        Returns
        -------
        acf_counter_dict : dict
            返回自相关系数字典（node:acf）.
        pacf_counter_dict : dict
            返回偏自相关字典（node:pacf）.

        '''
        import time_series_analysis as tsa
        from tqdm import tqdm
        
        value_resample_mask=self.value_resample_mask.copy(deep=True)
        sensor_nodes=value_resample_mask.columns
        acf_counter_dict={}
        pacf_counter_dict={}
        acf_insufficient_num=0
        pacf_insufficient_num=0  
        if diff_periods:
            value_resample_mask=value_resample_mask.diff(diff_periods)
        for node in tqdm(sensor_nodes):
            try:
                acf,acf_categories_counts=tsa.autocorrelation_time_series(value_resample_mask,node,plot=plot,nlags=nlags,title="acf_{}".format(node),save_path=save_path_acf)
                acf_counter_dict[node]=acf_categories_counts  
            except:
                acf_insufficient_num+=1
                print("acf_{}-Insufficient sample size!".format(node))               
                
            try:   
               pacf,pacf_categories_counts=tsa.partial_autocorrelation_time_series(value_resample_mask,node,plot=plot,nlags=nlags,title="pacf_{}".format(node),save_path=save_path_pacf) 
               pacf_counter_dict[node]=pacf_categories_counts
            except:
                pacf_insufficient_num+=1
                print("pacf_{}-Insufficient sample size!".format(node)) 
                
        acf_counter_sum=pd.DataFrame(acf_counter_dict.values()).sum(axis=0)  
        pacf_counter_sum=pd.DataFrame(pacf_counter_dict.values()).sum(axis=0)
        print("_"*50)
        print("acf_valid node number={};pacf_valid node number={}".format(len(sensor_nodes)-acf_insufficient_num,len(sensor_nodes)-pacf_insufficient_num))
        print("_"*50)
        print("acf_counter_sum={},\n,pacf_counter_sum={};".format(acf_counter_sum,pacf_counter_sum))
        return acf_counter_dict,pacf_counter_dict
    
    def stationary_stat(self,autolag=None,alpha=0.05,print_detail=False,diff_periods=None):
        '''
        批量计算所有节点的平稳性

        Parameters
        ----------
        autolag : string, optional
            {“AIC”, “BIC”, “t-stat”, None}. The default is None.
        alpha : float, optional
            显著性水平(p-value). The default is 0.05.
        print_detail : bool, optional
            是否打印统计细节信息. The default is False.

        Returns
        -------
        is_stationary_dict : dict(node:bool)
            返回各个节点是否平稳的布尔值，为True则平稳.

        '''
        import time_series_analysis as tsa
        from tqdm import tqdm
        
        value_resample_mask=self.value_resample_mask.copy(deep=True)
        is_stationary_dict={}
        sensor_nodes=value_resample_mask.columns
        valid_nodes=[]
        
        if diff_periods:
            value_resample_mask=value_resample_mask.diff(diff_periods)
        
        for node in tqdm(sensor_nodes):
            try:
                is_stationary=tsa.stationary_adfuller(value_resample_mask,node,autolag=autolag,alpha=alpha,print_detail=print_detail)
                is_stationary_dict[node]=is_stationary
                valid_nodes.append(node)
            except:
                print("sample size is too short to calculate.")
        
        print("is_stationary number={} in {} of valid nodes.".format(list(is_stationary_dict.values()).count(True),len(valid_nodes)))
        return is_stationary_dict
    
    def white_noise_Ljung_box_pierce(self,lags=[6,12],alpha=0.05):
        '''
        白噪声批量检验(纯随机性检验)，statsmodels.stats.diagnostic.acorr_ljungbox方法计算，包括Ljung-Box test和Box-Pierce test。并根据计算p-value值是否大于显著性水平（0.05或0.01），判断是否为白噪声

        Parameters
        ----------
        lags : int, optional
            延迟数. The default is [6,12].
        alpha : float, optional
            显著性水平. The default is 0.05.

        Returns
        -------
        stat_pvalue_dict : dict
            包括Ljung-Box test和Box-Pierce test的统计值和p-value.
        is_white_nose : dict
            各个节点（node）是否为白噪音.

        '''
        import time_series_analysis as tsa
        from tqdm import tqdm
        
        sensor_nodes=self.value_resample_mask.columns
        stat_pvalue_dict={}
        is_white_nose={}
        for node in tqdm(sensor_nodes):            
            try:
                stat_pvalue=tsa.white_noise_testing(self.value_resample_mask,node,lags=lags)
                lb_pvalue=stat_pvalue[1]
                bp_pvalue=stat_pvalue[3]
                stat_pvalue_dict[node]={"stat":{"lb_stat":stat_pvalue[0],"bp_stat":stat_pvalue[2]},"pvalue":{"lb_pvalue":lb_pvalue,"bp_pvalue":bp_pvalue}}
                is_white_nose[node]=dict(zip(["lag_{}".format(i) for i in lags],[True if i>alpha and j>alpha else False for i,j in zip(lb_pvalue,bp_pvalue)]))
            except:
                print("{}-error!".format(node))           
        return stat_pvalue_dict,is_white_nose
    
    def gantt_chart_H(self):
        '''
        打印节点传感器含有测量值的连续时间（小时）区间

        Returns
        -------
        None.

        '''
        import plotly.figure_factory as ff
        from tqdm import tqdm
        import pandas as pd
        from random import randint
        import numpy as np
        import plotly.io as pio
        pio.renderers.default='browser'
        
        sensor_nodes=self.value_resample_mask.columns        
        Start_Finish_Task=[]
        for node in tqdm(sensor_nodes):
            ts_node=self.value_resample_mask[node]
            ts_node.dropna(inplace=True)
            ts_node=ts_node.reset_index()
            ts_node['group']=(ts_node['ts'].shift(1)!=ts_node['ts']-pd.Timedelta(hours=1)).cumsum()
            ts_node=ts_node.groupby('group')['ts'].agg(['first', 'last', 'count'])
            ts_node['count']=ts_node['count']-1            
            ts_node.columns=['Start', 'Finish', 'Duration_Hours']
            ts_node['Task']=node
            
            Start_Finish_Task.append(ts_node)
        
        SFT=pd.concat(Start_Finish_Task,ignore_index=True,axis=0)        
        # print(SFT)        
        colors=["rgb({},{},{})".format(randint(0,255),randint(0,255),randint(0,255) ) for i in range(len(np.unique(SFT.Task)))]
        fig=ff.create_gantt(SFT,group_tasks=True,index_col='Task',colors=colors)
        fig.update_layout(autosize=False,width=2100,height=1200,)
        fig.show()
        
        return SFT
  
#%%    

if __name__=="__main__":
    import sys
    sys.path.append('..')
    import util    
    import geopandas as gpd
    import pandas as pd
    import os
    import pickle
    from database import postSQL2gpd,gpd2postSQL,cfg_load_yaml  
    from glob import glob
    import time_series_analysis as tsa
    from datetime import datetime
    parent_path=os.path.dirname(os.getcwd())
    
    cfg=cfg_load_yaml('../config.yml')  
    UN=cfg["postgreSQL"]["myusername"]
    PW=cfg["postgreSQL"]["mypassword"]
    DB=cfg["postgreSQL"]["mydatabase"] 
    GC='geometry' 
    
    air_sensor_category_save_fp=cfg['analysis_air']['air_sensor_category_save_fp']
    air_sensor_category_fns=glob(os.path.join(air_sensor_category_save_fp,"*.gpkg"))
    air_sensor_list=cfg['analysis_air']['air_sensor_list']
    print(air_sensor_list)  #['co', 'h2s', 'no2', 'o3', 'oxidizing_gases', 'reducing_gases', 'so2']  
    
    AoT_nodes_TN=cfg['table_name']['AoT_nodes_TN']  
    AoT_nodes_gdf=postSQL2gpd(table_name=AoT_nodes_TN,geom_col=GC,myusername=UN,mypassword=PW,mydatabase=DB)
    
    #A.传感器值域
    AoT_sensors_fp=os.path.join(parent_path,cfg['AoT']['AoT_sensors_fp'])
    AoT_nodes_df=pd.read_csv(AoT_sensors_fp,sep=",",header=0)
    AoT_sensors_range=AoT_nodes_df.set_index('sensor')[['hrf_minval', 'hrf_maxval']].to_dict()
    co_value_range=[AoT_sensors_range['hrf_minval']['co'],AoT_sensors_range['hrf_maxval']['co']]
    specified_range_dict={sensor_name:[AoT_sensors_range['hrf_minval'][sensor_name],AoT_sensors_range['hrf_maxval'][sensor_name]] for sensor_name in air_sensor_list}
    
    #B.测量数据按照时间周期重采样，包括移除空值和超出给定值域的行，并写入数据    
    air_tn_list=tsa.df_resample_bundle(air_sensor_category_fns,air_sensor_list,['value_hrf'],'timestamp',['D','W','M','Y'],cfg,'node_id',specified_range_dict,'air')
    
```

__1-CO-污染气体时间序列（时序）分析__

* 测量值时间轴

各个节点测量值时间上并不是完全连续，按照1小时连续性来切分时间段，即如果时间之间相差1小时以上则进行划分。从打印结果来看，CO传感器浓度值时间上虽然断续，但是连续较长的测量值也存在。同时需要注意，各个节点获取的测量值时间段上很难完全吻合。

<a href=""><img src="./imgs/3_3_2_13.png" height="auto" width="auto" title="caDesign"></a>

* 时序打印

为了方便观察时序数据，分别打印全部节点全部时间，可以纵观所有数据情况；打印部分节点全部时间，避免节点间互相干扰，较为清晰的观察数值变化关系；打印全部节点部分时间，可以详细观察细微时间变化下的数值变化情况，以及不同节点之间的数值关系。

从图表初步判断，CO气体时序数据具有一定的平稳性和周期性，不是白噪声随机数据。同时各个节点之间的时序数值起伏变化趋势趋同。

__Fig. CO时序数据__  

全部节点和全部时间：

<a href=""><img src="./imgs/3_3_2_08.png" height="auto" width="auto" title="caDesign"></a>

随机抽取几个节点打印全部时间：

<a href=""><img src="./imgs/3_3_2_09.png" height="auto" width="auto" title="caDesign"></a>

打印全部节点部分时间：

<a href=""><img src="./imgs/3_3_2_11.png" height="auto" width="auto" title="caDesign"></a>

* 白噪音检测

包含有CO传感器浓度值的节点总共有52个，在白噪音计算时，因为数据量不足的节点有6个，因此最终白噪音检测的节点数为46。延迟数配置上包括3个量，为12（小时）,24（小时）和168（小时），对应半天、一天和7周时间。从计算结果来看，除了延迟数7天中有两个节点可能为白噪音外，其余均不是白噪音。

```python
              co_lag_12  co_lag_24  co_lag_168
001e0610890f      False      False       False
001e06109416      False      False       False
001e0610ba13      False      False       False
001e0610ba15      False      False       False
001e0610ba46      False      False       False
001e0610bbe5      False      False       False
001e0610bc10      False      False       False
001e0610bc12      False      False       False
001e0610e537      False      False       False
001e0610e538      False      False       False
001e0610e539      False      False       False
001e0610e835      False      False       False
001e0610e8cb      False      False        True
001e0610eef2      False      False       False
001e0610ef27      False      False       False
001e0610f05c      False      False       False
001e0610f513      False      False        True
001e0610f6db      False      False       False
001e0610f6dd      False      False       False
001e0610f703      False      False       False
001e0610f732      False      False       False
001e0610f8f4      False      False       False
001e06112e77      False      False       False
001e061130f4      False      False       False
001e06113107      False      False       False
001e06113acb      False      False       False
001e06113ace      False      False       False
001e06113ad6      False      False       False
001e06113ad8      False      False       False
001e06113cf1      False      False       False
001e06113cff      False      False       False
001e06113d32      False      False       False
001e06113d83      False      False       False
001e06113dbc      False      False       False
001e06113f54      False      False       False
001e0611441e      False      False       False
001e061144be      False      False       False
001e061144c0      False      False       False
001e06114500      False      False       False
001e06114503      False      False       False
001e061146bc      False      False       False
001e061146cb      False      False       False
001e061146d6      False      False       False
001e06114fd4      False      False       False
001e06115365      False      False       False
001e06115369      False      False       False
```

* 平稳性检测

计算结果显示51个有效计算节点下有35个节点为平稳，占有效总数的68.63%；有31.37%个节点CO测量值变化幅度较大。如果对一阶差分后的时序进行平稳性检验，则50个有效计算节点下有47个节点为平稳，占有效总数94%。

__Fig. CO平稳性检验（未差分）__  

<a href=""><img src="./imgs/3_3_2_12_s.jpg" height="auto" width="auto" title="caDesign"></a>

* 周期性模式判断

CO的平稳性检验中有部分数据数值变化较大，因此通过自相关系数计算和图表打印，不是很容易发现周期性的模式。因此同时对一阶差分后的时序进行自相关系数计算，结果图表较之未差分前，交易判断具有周期性模式，周期约为24小时（天）。


__Fig. CO自相关系数 (ACF) 未差分 lag=24×7__ 

<a href=""><img src="./imgs/3_3_2_14_s.jpg" height="auto" width="auto" title="caDesign"></a>

__Fig. CO偏自相关系数(PACF) 未差分 lag=24×7__ 

<a href=""><img src="./imgs/3_3_2_15_s.jpg" height="auto" width="auto" title="caDesign"></a>

__Fig. CO自相关系数 (ACF) 一阶差分 lag=24×7__ 

<a href=""><img src="./imgs/3_3_2_16_s.jpg" height="auto" width="auto" title="caDesign"></a>

__Fig. CO偏自相关系数(PACF) 一阶差分 lag=24×7__ 

<a href=""><img src="./imgs/3_3_2_17_s.jpg" height="auto" width="auto" title="caDesign"></a>


`air_time_series_analysis.py`
```python
if __name__=="__main__":
    #C.时间序列相关分析
    #C_1. co
    air_co_fn=os.path.join(parent_path,air_sensor_category_save_fp,"air_co.gpkg")     
    s_t=util.start_time()
    air_co=gpd.read_file(air_co_fn) #2.50GB， Total time spend:10.77 minutes（外置固态硬盘）    
    util.duration(s_t)     
        
    tsab_co=time_series_analysis_batch(air_co,"co",'value_hrf','timestamp','node_id')
    sensor_value_range=tsab_co.sensors_range(AoT_sensors_fp,'sensor','hrf_minval', 'hrf_maxval')  
    co_value_resample_mask=tsab_co.df_preprocessing()  
    
    co_SFT=tsab_co.gantt_chart_H()  
    
    _=tsab_co.time_series_plot(['2018-01-17 0:0:0','2018-05-16 0:0:0'],rolling_window=10,xlabel="时间",ylabel="CO-浓度(ppm)",figsize=(20,10),font_size=15)
    _=tsab_co.time_series_plot(['2018-01-17 0:0:0','2018-06-16 0:0:0'],['001e061146d6','001e06115365', '001e06113cff', '001e06113d22', '001e0610e537'],rolling_window=6,xlabel="时间",ylabel="浓度(ppm)",figsize=(20,10),font_size=15,legend=True)
    _=tsab_co.time_series_plot(['2018-04-25 0:0:0','2018-05-01 0:0:0'],rolling_window=6,xlabel="时间",ylabel="浓度(ppm)",figsize=(20,10),font_size=15,legend=False)
    
    co_stat_pvalue_dict,co_is_white_noise=tsab_co.white_noise_Ljung_box_pierce(lags=[12,24,24*7])
    co_is_white_noise_df=pd.DataFrame.from_dict(co_is_white_noise,orient='index')
    co_is_white_noise_columns_new={i:"co_{}".format(i) for i in co_is_white_noise_df.columns}
    co_is_white_noise_df=co_is_white_noise_df.rename(columns=co_is_white_noise_columns_new)
    air_is_white_noise_gdf=pd.merge(AoT_nodes_gdf,co_is_white_noise_df,left_on='node_id',right_index=True,how='outer')
    gpd2postSQL(air_is_white_noise_gdf,table_name='air_is_white_noise',myusername=UN,mypassword=PW,mydatabase=DB)
    
    co_is_stationary_dict=tsab_co.stationary_stat(print_detail=False) #,autolag="AIC"
    co_is_stationary_dict=tsab_co.stationary_stat(print_detail=False,diff_periods=1) #,autolag="AIC"
    
    co_is_stationary_df=pd.DataFrame.from_dict(co_is_stationary_dict,orient='index',columns=["co_is_stationary"])
    air_is_stationary_gdf=pd.merge(AoT_nodes_gdf,co_is_stationary_df,left_on='node_id',right_index=True,how='outer')
    gpd2postSQL(air_is_stationary_gdf,table_name='air_is_stationary',myusername=UN,mypassword=PW,mydatabase=DB)    
    
    save_path_acf=os.path.join(parent_path,'./charts/co_acf')
    save_path_pacf=os.path.join(parent_path,'./charts/co_pacf')
    co_acf_counter_dict,pacf_counter_dict=tsab_co.acf_pacf_counter(nlags=24*7,plot=True,save_path_acf=save_path_acf,save_path_pacf=save_path_pacf,diff_periods=1)    
```


__2-H2S-污染气体时间序列分析__

* 测量值时间轴

H2S测量时间轴与CO大部分趋同，但是也存在多处不同。

<a href=""><img src="./imgs/3_3_2_18.png" height="auto" width="auto" title="caDesign"></a>

* 时序打印

__Fig. H2S时序数据__  

全部节点和全部时间：

<a href=""><img src="./imgs/3_3_2_19.png" height="auto" width="auto" title="caDesign"></a>

随机抽取几个节点打印全部时间：

<a href=""><img src="./imgs/3_3_2_20.png" height="auto" width="auto" title="caDesign"></a>

打印全部节点部分时间：

<a href=""><img src="./imgs/3_3_2_21.png" height="auto" width="auto" title="caDesign"></a>

* 白噪音检测

有个别节点为True，即为白噪音，大部分均无白噪音。

```python
              h2s_lag_12  h2s_lag_24  h2s_lag_168
001e0610890f        True        True         True
001e06109416       False       False        False
001e0610ba15       False       False        False
001e0610ba46       False       False        False
001e0610bbe5       False       False        False
001e0610bc10       False       False        False
001e0610bc12        True        True         True
001e0610e537       False       False        False
001e0610e538       False       False        False
001e0610e539       False       False        False
001e0610e835       False       False        False
001e0610e8cb        True        True         True
001e0610eef2       False       False        False
001e0610ef27        True        True         True
001e0610f05c       False       False         True
001e0610f513       False       False         True
001e0610f6db       False       False        False
001e0610f6dd       False       False        False
001e0610f703       False       False        False
001e0610f732       False       False        False
001e0610f8f4       False       False        False
001e06112e77       False       False        False
001e061130f4       False       False        False
001e06113107       False       False        False
001e06113acb       False       False        False
001e06113ace       False       False        False
001e06113ad6       False       False        False
001e06113ad8       False       False        False
001e06113cf1       False       False        False
001e06113cff       False       False        False
001e06113d32       False       False        False
001e06113d83       False       False        False
001e06113dbc       False       False        False
001e06113f54       False       False        False
001e0611441e       False       False        False
001e061144be       False       False        False
001e061144c0       False       False        False
001e06114500       False       False        False
001e06114503       False       False        False
001e061146bc       False       False        False
001e061146cb       False       False        False
001e061146d6       False       False        False
001e06114fd4       False       False        False
001e06115365       False       False        False
001e06115369       False       False        False
```

* 平稳性检测

计算结果显示51个有效计算节点下有38个节点为平稳，占有效总数的74.51%；有25.49%个节点H2S测量值变化幅度较大。如果对一阶差分后的时序进行平稳性检验，则50个有效计算节点下有48个节点为平稳，占有效总数96%。

对比未差分的H2S和CO平稳性检测结果，均平稳的节点有33个；均不平稳的节点有10个；其中一项测量值平稳，而另一项不平稳的有7个。一致性结果占86%，可以判断H2S和CO平稳性基本保持一致。

* 周期性模式判断

从计算结果图表可以初步判断，H2S时序测量值具有周期性模式，周期约为24小时（天）。

__Fig. H2S自相关系数 (ACF) 未差分 lag=24×7__ 

<a href=""><img src="./imgs/3_3_2_22_s.jpg" height="auto" width="auto" title="caDesign"></a>

__Fig. H2S偏自相关系数(PACF) 未差分 lag=24×7__ 

<a href=""><img src="./imgs/3_3_2_23_s.jpg" height="auto" width="auto" title="caDesign"></a>

__Fig. H2S自相关系数 (ACF) 一阶差分 lag=24×7__ 

<a href=""><img src="./imgs/3_3_2_24_s.jpg" height="auto" width="auto" title="caDesign"></a>

__Fig. H2S偏自相关系数(PACF) 一阶差分 lag=24×7__ 

<a href=""><img src="./imgs/3_3_2_25_s.jpg" height="auto" width="auto" title="caDesign"></a>

'time_series_analysis.py'
```python
#%%
def compare_TFN(df,col_a,col_b):
    import numpy as np
    from collections import Counter
    
    df_copy=df.copy(deep=True)
    original_rowsNum=len(df_copy)
    df_copy.dropna(subset=[col_a,col_b],inplace=True)
    dropped_rowsNum=len(df_copy)
    print("orginal rows num={},dropped rows num={}".format(original_rowsNum,dropped_rowsNum))
    conditions=[(df_copy[col_a]==True) & (df_copy[col_b]==True),(df_copy[col_a]==False) & (df_copy[col_b]==False), df_copy[col_a]!=df_copy[col_b]]
    choices=['T','F','D']
    df_copy['compare']=np.select(conditions,choices, ) #default=np.nan
    choices_counter=Counter(df_copy['compare'])
    print(choices_counter)
    
    return df_copy
```


`air_time_series_analysis.py`
```python
if __name__=="__main__":
    #C_2. h2s
    air_h2s_fn=os.path.join(parent_path,air_sensor_category_save_fp,"air_h2s.gpkg")     
    s_t=util.start_time()
    air_h2s=gpd.read_file(air_h2s_fn)  
    util.duration(s_t)     
        
    tsab_h2s=time_series_analysis_batch(air_h2s,"h2s",'value_hrf','timestamp','node_id')
    sensor_value_range=tsab_h2s.sensors_range(AoT_sensors_fp,'sensor','hrf_minval', 'hrf_maxval')  
    h2s_value_resample_mask=tsab_h2s.df_preprocessing()  
    
    h2s_SFT=tsab_h2s.gantt_chart_H()  
    
    _=tsab_h2s.time_series_plot(['2018-01-17 0:0:0','2018-05-16 0:0:0'],rolling_window=10,xlabel="时间",ylabel="H2S-浓度(ppm)",figsize=(20,10),font_size=15)
    _=tsab_h2s.time_series_plot(['2018-01-17 0:0:0','2018-06-16 0:0:0'],['001e061146d6','001e06115365', '001e06113cff', '001e06113d22', '001e0610e537'],rolling_window=6,xlabel="时间",ylabel="H2S-浓度(ppm)",figsize=(20,10),font_size=15,legend=True)
    _=tsab_h2s.time_series_plot(['2018-04-25 0:0:0','2018-05-01 0:0:0'],rolling_window=6,xlabel="时间",ylabel="H2S-浓度(ppm)",figsize=(20,10),font_size=15,legend=False)
    
    h2s_stat_pvalue_dict,h2s_is_white_noise=tsab_h2s.white_noise_Ljung_box_pierce(lags=[12,24,24*7])
    h2s_is_white_noise_df=pd.DataFrame.from_dict(h2s_is_white_noise,orient='index')
    h2s_is_white_noise_columns_new={i:"h2s_{}".format(i) for i in h2s_is_white_noise_df.columns}
    h2s_is_white_noise_df=h2s_is_white_noise_df.rename(columns=h2s_is_white_noise_columns_new)    
    air_is_white_noise_gdf=postSQL2gpd(table_name="air_is_white_noise",geom_col=GC,myusername=UN,mypassword=PW,mydatabase=DB) 
    air_is_white_noise_gdf=pd.merge(air_is_white_noise_gdf,h2s_is_white_noise_df,left_on='node_id',right_index=True,how='outer')
    gpd2postSQL(air_is_white_noise_gdf,table_name='air_is_white_noise',myusername=UN,mypassword=PW,mydatabase=DB)
    
    h2s_is_stationary_dict_d=tsab_h2s.stationary_stat(print_detail=False,diff_periods=1) #,autolag="AIC" 
    h2s_is_stationary_dict=tsab_h2s.stationary_stat(print_detail=False) #,autolag="AIC"       
    h2s_is_stationary_df=pd.DataFrame.from_dict(h2s_is_stationary_dict,orient='index',columns=["h2s_is_stationary"])
    air_is_stationary_gdf=postSQL2gpd(table_name="air_is_stationary",geom_col=GC,myusername=UN,mypassword=PW,mydatabase=DB)     
    air_is_stationary_gdf=pd.merge(air_is_stationary_gdf,h2s_is_stationary_df,left_on='node_id',right_index=True,how='outer')
    gpd2postSQL(air_is_stationary_gdf,table_name='air_is_stationary',myusername=UN,mypassword=PW,mydatabase=DB)    
    
    _=tsa.compare_TFN(air_is_stationary_gdf,'co_is_stationary','h2s_is_stationary')
        
    save_path_acf=os.path.join(parent_path,'./charts/h2s_acf')
    save_path_pacf=os.path.join(parent_path,'./charts/h2s_pacf')
    h2s_acf_counter_dict,pacf_counter_dict=tsab_co.acf_pacf_counter(nlags=24*7,plot=True,save_path_acf=save_path_acf,save_path_pacf=save_path_pacf,diff_periods=1) #diff_periods=1
```

__3-NO2-污染气体时间序列分析__

* 测量值时间轴

<a href=""><img src="./imgs/3_3_2_26.png" height="auto" width="auto" title="caDesign"></a>

* 时序打印

__Fig. NO2时序数据__  

全部节点和全部时间：

<a href=""><img src="./imgs/3_3_2_27.png" height="auto" width="auto" title="caDesign"></a>

随机抽取几个节点打印全部时间：

<a href=""><img src="./imgs/3_3_2_28.png" height="auto" width="auto" title="caDesign"></a>

打印全部节点部分时间：

<a href=""><img src="./imgs/3_3_2_29.png" height="auto" width="auto" title="caDesign"></a>

* 白噪音检测

```python
              no2_lag_12  no2_lag_24  no2_lag_168
001e0610890f       False       False        False
001e06109416       False       False        False
001e0610ba15       False       False        False
001e0610ba46       False       False        False
001e0610bbe5       False       False        False
001e0610bc10       False       False        False
001e0610bc12       False       False        False
001e0610e537       False       False        False
001e0610e538       False       False        False
001e0610e539       False       False        False
001e0610e835       False       False        False
001e0610e8cb       False       False        False
001e0610eef2       False       False        False
001e0610ef27       False       False        False
001e0610f05c       False       False        False
001e0610f513       False       False        False
001e0610f6db       False       False        False
001e0610f6dd       False       False        False
001e0610f703       False       False        False
001e0610f732       False       False        False
001e0610f8f4       False       False        False
001e06112e77       False       False        False
001e061130f4       False       False        False
001e06113107       False       False        False
001e06113acb       False       False        False
001e06113ace       False       False        False
001e06113ad6       False       False        False
001e06113ad8       False       False        False
001e06113cf1       False       False        False
001e06113cff       False       False        False
001e06113d32       False        True         True
001e06113d83       False       False        False
001e06113dbc       False       False        False
001e06113f54       False       False        False
001e0611441e       False       False        False
001e061144be       False       False        False
001e061144c0       False       False        False
001e06114500       False       False        False
001e06114503       False       False        False
001e061146bc       False       False        False
001e061146cb       False       False        False
001e061146d6       False       False        False
001e06114fd4       False       False        False
001e06115365       False       False        False
001e06115369       False       False        False
```

* 平稳性检测

计算结果显示51个有效计算节点下有35个节点为平稳，占有效总数的68.63%；有31.37%个节点NO2测量值变化幅度较大。如果对一阶差分后的时序进行平稳性检验，则50个有效计算节点下有48个节点为平稳，占有效总数96%。

对比未差分的CO和NO2平稳性检测结果，均平稳的节点有32个；均不平稳的节点有12个；其中一项测量值平稳，而另一项不平稳的有6个。一致性结果占88%，可以判断H2S和CO平稳性基本保持一致。

* 周期性模式判断


__Fig. NO2自相关系数 (ACF) 未差分 lag=24×7__ 

<a href=""><img src="./imgs/3_3_2_30_s.jpg" height="auto" width="auto" title="caDesign"></a>

__Fig. NO2偏自相关系数(PACF) 未差分 lag=24×7__ 

<a href=""><img src="./imgs/3_3_2_31_s.jpg" height="auto" width="auto" title="caDesign"></a>

__Fig. NO2自相关系数 (ACF) 一阶差分 lag=24×7__ 

<a href=""><img src="./imgs/3_3_2_32_s.jpg" height="auto" width="auto" title="caDesign"></a>

__Fig. NO2偏自相关系数(PACF) 一阶差分 lag=24×7__ 

<a href=""><img src="./imgs/3_3_2_33_s.jpg" height="auto" width="auto" title="caDesign"></a>

`air_time_series_analysis.py`
```python
if __name__=="__main__":
    #C_3. no2
    air_no2_fn=os.path.join(parent_path,air_sensor_category_save_fp,"air_no2.gpkg")     
    s_t=util.start_time()
    air_no2=gpd.read_file(air_no2_fn)  
    util.duration(s_t)     
        
    tsab_no2=time_series_analysis_batch(air_no2,"no2",'value_hrf','timestamp','node_id')
    sensor_value_range=tsab_no2.sensors_range(AoT_sensors_fp,'sensor','hrf_minval', 'hrf_maxval')  
    no2_value_resample_mask=tsab_no2.df_preprocessing()  
    
    no2_SFT=tsab_no2.gantt_chart_H()  
    
    _=tsab_no2.time_series_plot(['2018-01-17 0:0:0','2018-05-16 0:0:0'],rolling_window=10,xlabel="时间",ylabel="no2-浓度(ppm)",figsize=(20,10),font_size=15)
    _=tsab_no2.time_series_plot(['2018-01-17 0:0:0','2018-06-16 0:0:0'],['001e061146d6','001e06115365', '001e06113cff', '001e06113d22', '001e0610e537'],rolling_window=6,xlabel="时间",ylabel="no2-浓度(ppm)",figsize=(20,10),font_size=15,legend=True)
    _=tsab_no2.time_series_plot(['2018-04-25 0:0:0','2018-05-01 0:0:0'],rolling_window=6,xlabel="时间",ylabel="no2-浓度(ppm)",figsize=(20,10),font_size=15,legend=False)
    
    no2_stat_pvalue_dict,no2_is_white_noise=tsab_no2.white_noise_Ljung_box_pierce(lags=[12,24,24*7])
    no2_is_white_noise_df=pd.DataFrame.from_dict(no2_is_white_noise,orient='index')
    no2_is_white_noise_columns_new={i:"no2_{}".format(i) for i in no2_is_white_noise_df.columns}
    no2_is_white_noise_df=no2_is_white_noise_df.rename(columns=no2_is_white_noise_columns_new)    
    air_is_white_noise_gdf=postSQL2gpd(table_name="air_is_white_noise",geom_col=GC,myusername=UN,mypassword=PW,mydatabase=DB) 
    air_is_white_noise_gdf=pd.merge(air_is_white_noise_gdf,no2_is_white_noise_df,left_on='node_id',right_index=True,how='outer')
    gpd2postSQL(air_is_white_noise_gdf,table_name='air_is_white_noise',myusername=UN,mypassword=PW,mydatabase=DB)
    
    no2_is_stationary_dict_d=tsab_no2.stationary_stat(print_detail=False,diff_periods=1) #,autolag="AIC" 
    no2_is_stationary_dict=tsab_no2.stationary_stat(print_detail=False) #,autolag="AIC"       
    no2_is_stationary_df=pd.DataFrame.from_dict(no2_is_stationary_dict,orient='index',columns=["no2_is_stationary"])
    air_is_stationary_gdf=postSQL2gpd(table_name="air_is_stationary",geom_col=GC,myusername=UN,mypassword=PW,mydatabase=DB)     
    air_is_stationary_gdf=pd.merge(air_is_stationary_gdf,no2_is_stationary_df,left_on='node_id',right_index=True,how='outer')
    gpd2postSQL(air_is_stationary_gdf,table_name='air_is_stationary',myusername=UN,mypassword=PW,mydatabase=DB)    
    
    _=tsa.compare_TFN(air_is_stationary_gdf,'co_is_stationary','no2_is_stationary')
        
    save_path_acf=os.path.join(parent_path,'./charts/no2_acf')
    save_path_pacf=os.path.join(parent_path,'./charts/no2_pacf')
    no2_acf_counter_dict,pacf_counter_dict=tsab_co.acf_pacf_counter(nlags=24*7,plot=True,save_path_acf=save_path_acf,save_path_pacf=save_path_pacf,diff_periods=1) #diff_periods=1
    
```

__4-O3-污染气体时间序列分析__

* 测量值时间轴

<a href=""><img src="./imgs/3_3_2_34.png" height="auto" width="auto" title="caDesign"></a>

* 时序打印

__Fig. O3时序数据__  

全部节点和全部时间：

<a href=""><img src="./imgs/3_3_2_35.png" height="auto" width="auto" title="caDesign"></a>

随机抽取几个节点打印全部时间：

<a href=""><img src="./imgs/3_3_2_36.png" height="auto" width="auto" title="caDesign"></a>

打印全部节点部分时间：

<a href=""><img src="./imgs/3_3_2_37.png" height="auto" width="auto" title="caDesign"></a>

* 白噪音检测

```python
              o3_lag_12  o3_lag_24  o3_lag_168
001e0610890f      False      False       False
001e06109416      False      False       False
001e0610ba15      False      False       False
001e0610ba46      False      False       False
001e0610bbe5      False      False       False
001e0610bc10      False      False       False
001e0610bc12      False      False       False
001e0610e537      False      False       False
001e0610e538      False      False       False
001e0610e539      False      False       False
001e0610e835      False      False       False
001e0610e8cb      False      False       False
001e0610eef2      False      False       False
001e0610ef27      False      False       False
001e0610f05c      False      False       False
001e0610f513      False      False       False
001e0610f6db      False      False       False
001e0610f6dd      False      False       False
001e0610f703      False      False       False
001e0610f732      False      False       False
001e0610f8f4      False      False       False
001e06112e77      False      False       False
001e061130f4      False      False       False
001e06113107      False      False       False
001e06113acb      False      False       False
001e06113ace      False      False       False
001e06113ad6      False      False       False
001e06113ad8      False      False       False
001e06113cf1      False      False       False
001e06113cff      False      False       False
001e06113d32       True       True        True
001e06113d83      False      False       False
001e06113dbc      False      False       False
001e06113f54      False      False       False
001e0611441e      False      False       False
001e061144be      False      False       False
001e061144c0      False      False       False
001e06114500      False      False       False
001e06114503      False      False       False
001e061146bc      False      False       False
001e061146cb      False      False       False
001e061146d6      False      False       False
001e06114fd4      False      False       False
001e06115365      False      False       False
001e06115369      False      False       False
```

* 平稳性检测

计算结果显示51个有效计算节点下有33个节点为平稳，占有效总数的64.71%；有35.29%个节点O3测量值变化幅度较大。如果对一阶差分后的时序进行平稳性检验，则50个有效计算节点下有49个节点为平稳，占有效总数98%。

对比未差分的CO和O3平稳性检测结果，均平稳的节点有26个；均不平稳的节点有15个；其中一项测量值平稳，而另一项不平稳的有9个。一致性结果占82%，可以判断CO和O3平稳性基本保持一致。

* 周期性模式判断


__Fig. O3自相关系数 (ACF) 未差分 lag=24×7__ 

<a href=""><img src="./imgs/3_3_2_38_s.jpg" height="auto" width="auto" title="caDesign"></a>

__Fig. O3偏自相关系数(PACF) 未差分 lag=24×7__ 

<a href=""><img src="./imgs/3_3_2_39_s.jpg" height="auto" width="auto" title="caDesign"></a>

__Fig. O3自相关系数 (ACF) 一阶差分 lag=24×7__ 

<a href=""><img src="./imgs/3_3_2_40_s.jpg" height="auto" width="auto" title="caDesign"></a>

__Fig. O3偏自相关系数(PACF) 一阶差分 lag=24×7__ 

<a href=""><img src="./imgs/3_3_2_41_s.jpg" height="auto" width="auto" title="caDesign"></a>

`air_time_series_analysis.py`
```python
if __name__=="__main__":
    #C_4. O3
    air_o3_fn=os.path.join(parent_path,air_sensor_category_save_fp,"air_o3.gpkg")     
    s_t=util.start_time()
    air_o3=gpd.read_file(air_o3_fn)  
    util.duration(s_t)     
        
    tsab_o3=time_series_analysis_batch(air_o3,"o3",'value_hrf','timestamp','node_id')
    sensor_value_range=tsab_o3.sensors_range(AoT_sensors_fp,'sensor','hrf_minval', 'hrf_maxval')  
    o3_value_resample_mask=tsab_o3.df_preprocessing()  
    
    o3_SFT=tsab_o3.gantt_chart_H()  
    
    _=tsab_o3.time_series_plot(['2018-01-17 0:0:0','2018-05-16 0:0:0'],rolling_window=10,xlabel="时间",ylabel="o3-浓度(ppm)",figsize=(20,10),font_size=15)
    _=tsab_o3.time_series_plot(['2018-01-17 0:0:0','2018-06-16 0:0:0'],['001e061146d6','001e06115365', '001e06113cff', '001e06113d22', '001e0610e537'],rolling_window=6,xlabel="时间",ylabel="o3-浓度(ppm)",figsize=(20,10),font_size=15,legend=True)
    _=tsab_o3.time_series_plot(['2018-04-25 0:0:0','2018-05-01 0:0:0'],rolling_window=6,xlabel="时间",ylabel="o3-浓度(ppm)",figsize=(20,10),font_size=15,legend=False)
    
    o3_stat_pvalue_dict,o3_is_white_noise=tsab_o3.white_noise_Ljung_box_pierce(lags=[12,24,24*7])
    o3_is_white_noise_df=pd.DataFrame.from_dict(o3_is_white_noise,orient='index')
    o3_is_white_noise_columns_new={i:"o3_{}".format(i) for i in o3_is_white_noise_df.columns}
    o3_is_white_noise_df=o3_is_white_noise_df.rename(columns=o3_is_white_noise_columns_new)    
    air_is_white_noise_gdf=postSQL2gpd(table_name="air_is_white_noise",geom_col=GC,myusername=UN,mypassword=PW,mydatabase=DB) 
    air_is_white_noise_gdf=pd.merge(air_is_white_noise_gdf,o3_is_white_noise_df,left_on='node_id',right_index=True,how='outer')
    gpd2postSQL(air_is_white_noise_gdf,table_name='air_is_white_noise',myusername=UN,mypassword=PW,mydatabase=DB)
    
    o3_is_stationary_dict_d=tsab_o3.stationary_stat(print_detail=False,diff_periods=1) #,autolag="AIC" 
    o3_is_stationary_dict=tsab_o3.stationary_stat(print_detail=False) #,autolag="AIC"       
    o3_is_stationary_df=pd.DataFrame.from_dict(o3_is_stationary_dict,orient='index',columns=["o3_is_stationary"])
    air_is_stationary_gdf=postSQL2gpd(table_name="air_is_stationary",geom_col=GC,myusername=UN,mypassword=PW,mydatabase=DB)     
    air_is_stationary_gdf=pd.merge(air_is_stationary_gdf,o3_is_stationary_df,left_on='node_id',right_index=True,how='outer')
    gpd2postSQL(air_is_stationary_gdf,table_name='air_is_stationary',myusername=UN,mypassword=PW,mydatabase=DB)    
    
    _=tsa.compare_TFN(air_is_stationary_gdf,'co_is_stationary','o3_is_stationary')
        
    save_path_acf=os.path.join(parent_path,'./charts/o3_acf')
    save_path_pacf=os.path.join(parent_path,'./charts/o3_pacf')
    o3_acf_counter_dict,pacf_counter_dict=tsab_co.acf_pacf_counter(nlags=24*7,plot=True,save_path_acf=save_path_acf,save_path_pacf=save_path_pacf,diff_periods=1) #diff_periods=1
    
```


__5-SO2-污染气体时间序列分析__

* 测量值时间轴

<a href=""><img src="./imgs/3_3_2_42.png" height="auto" width="auto" title="caDesign"></a>

* 时序打印

__Fig. SO2时序数据__  

全部节点和全部时间：

<a href=""><img src="./imgs/3_3_2_43.png" height="auto" width="auto" title="caDesign"></a>

随机抽取几个节点打印全部时间：

<a href=""><img src="./imgs/3_3_2_44.png" height="auto" width="auto" title="caDesign"></a>

打印全部节点部分时间：

<a href=""><img src="./imgs/3_3_2_45.png" height="auto" width="auto" title="caDesign"></a>

* 白噪音检测

```python
              so2_lag_12  so2_lag_24  so2_lag_168
001e0610890f       False        True         True
001e06109416       False       False        False
001e0610ba13        True        True         True
001e0610ba15       False       False        False
001e0610ba46       False       False        False
001e0610bbe5       False       False        False
001e0610bc10       False       False        False
001e0610bc12       False       False        False
001e0610e537       False       False        False
001e0610e538       False       False        False
001e0610e539       False       False        False
001e0610e835       False       False        False
001e0610e8cb       False       False        False
001e0610eef2       False       False        False
001e0610ef27       False       False         True
001e0610f05c       False       False        False
001e0610f513       False       False        False
001e0610f6db       False       False        False
001e0610f6dd       False       False        False
001e0610f703       False       False        False
001e0610f732       False       False        False
001e0610f8f4       False       False        False
001e06112e77       False       False        False
001e061130f4       False       False        False
001e06113107       False       False        False
001e06113acb       False       False        False
001e06113ace       False       False        False
001e06113ad6       False       False        False
001e06113ad8       False        True         True
001e06113cf1       False       False        False
001e06113cff       False       False        False
001e06113d32       False       False        False
001e06113d83       False       False        False
001e06113dbc       False       False        False
001e06113f54       False       False        False
001e0611441e       False       False        False
001e061144be       False       False        False
001e061144c0       False       False        False
001e06114500       False       False        False
001e06114503       False       False        False
001e061146bc       False       False        False
001e061146cb       False       False        False
001e061146d6       False       False        False
001e06114fd4       False       False        False
001e06115365       False       False        False
001e06115369       False       False        False
```

* 平稳性检测

计算结果显示52个有效计算节点下有32个节点为平稳，占有效总数的61.54%；有38.46%个SO2节点测量值变化幅度较大。如果对一阶差分后的时序进行平稳性检验，则51个有效计算节点下有50个节点为平稳，占有效总数98.04%。

对比未差分的CO和SO2平稳性检测结果，均平稳的节点有23个；均不平稳的节点有21个；其中一项测量值平稳，而另一项不平稳的有7个。一致性结果占86.27%，可以判断CO和SO2平稳性基本保持一致。

* 周期性模式判断


__Fig. SO2自相关系数 (ACF) 未差分 lag=24×7__ 

<a href=""><img src="./imgs/3_3_2_46_s.jpg" height="auto" width="auto" title="caDesign"></a>

__Fig. SO2偏自相关系数(PACF) 未差分 lag=24×7__ 

<a href=""><img src="./imgs/3_3_2_47_s.jpg" height="auto" width="auto" title="caDesign"></a>

__Fig. SO2自相关系数 (ACF) 一阶差分 lag=24×7__ 

<a href=""><img src="./imgs/3_3_2_48_s.jpg" height="auto" width="auto" title="caDesign"></a>

__Fig. SO2偏自相关系数(PACF) 一阶差分 lag=24×7__ 

<a href=""><img src="./imgs/3_3_2_49_s.jpg" height="auto" width="auto" title="caDesign"></a>

`air_time_series_analysis.py`
```python
if __name__=="__main__":
    #C_5. so2
    air_so2_fn=os.path.join(parent_path,air_sensor_category_save_fp,"air_so2.gpkg")     
    s_t=util.start_time()
    air_so2=gpd.read_file(air_so2_fn)  
    util.duration(s_t)     
        
    tsab_so2=time_series_analysis_batch(air_so2,"so2",'value_hrf','timestamp','node_id')
    sensor_value_range=tsab_so2.sensors_range(AoT_sensors_fp,'sensor','hrf_minval', 'hrf_maxval')  
    so2_value_resample_mask=tsab_so2.df_preprocessing()  
    
    so2_SFT=tsab_so2.gantt_chart_H()  
    
    _=tsab_so2.time_series_plot(['2018-01-17 0:0:0','2018-05-16 0:0:0'],rolling_window=10,xlabel="时间",ylabel="so2-浓度(ppm)",figsize=(20,10),font_size=15)
    _=tsab_so2.time_series_plot(['2018-01-17 0:0:0','2018-06-16 0:0:0'],['001e061146d6','001e06115365', '001e06113cff', '001e06113d22', '001e0610e537'],rolling_window=6,xlabel="时间",ylabel="so2-浓度(ppm)",figsize=(20,10),font_size=15,legend=True)
    _=tsab_so2.time_series_plot(['2018-04-25 0:0:0','2018-05-01 0:0:0'],rolling_window=6,xlabel="时间",ylabel="so2-浓度(ppm)",figsize=(20,10),font_size=15,legend=False)
    
    so2_stat_pvalue_dict,so2_is_white_noise=tsab_so2.white_noise_Ljung_box_pierce(lags=[12,24,24*7])
    so2_is_white_noise_df=pd.DataFrame.from_dict(so2_is_white_noise,orient='index')
    so2_is_white_noise_columns_new={i:"so2_{}".format(i) for i in so2_is_white_noise_df.columns}
    so2_is_white_noise_df=so2_is_white_noise_df.rename(columns=so2_is_white_noise_columns_new)    
    air_is_white_noise_gdf=postSQL2gpd(table_name="air_is_white_noise",geom_col=GC,myusername=UN,mypassword=PW,mydatabase=DB) 
    air_is_white_noise_gdf=pd.merge(air_is_white_noise_gdf,so2_is_white_noise_df,left_on='node_id',right_index=True,how='outer')
    gpd2postSQL(air_is_white_noise_gdf,table_name='air_is_white_noise',myusername=UN,mypassword=PW,mydatabase=DB)
    
    so2_is_stationary_dict_d=tsab_so2.stationary_stat(print_detail=False,diff_periods=1) #,autolag="AIC" 
    so2_is_stationary_dict=tsab_so2.stationary_stat(print_detail=False) #,autolag="AIC"       
    so2_is_stationary_df=pd.DataFrame.from_dict(so2_is_stationary_dict,orient='index',columns=["so2_is_stationary"])
    air_is_stationary_gdf=postSQL2gpd(table_name="air_is_stationary",geom_col=GC,myusername=UN,mypassword=PW,mydatabase=DB)     
    air_is_stationary_gdf=pd.merge(air_is_stationary_gdf,so2_is_stationary_df,left_on='node_id',right_index=True,how='outer')
    gpd2postSQL(air_is_stationary_gdf,table_name='air_is_stationary',myusername=UN,mypassword=PW,mydatabase=DB)    
    
    _=tsa.compare_TFN(air_is_stationary_gdf,'co_is_stationary','so2_is_stationary')
        
    save_path_acf=os.path.join(parent_path,'./charts/so2_acf')
    save_path_pacf=os.path.join(parent_path,'./charts/so2_pacf')
    so2_acf_counter_dict,pacf_counter_dict=tsab_co.acf_pacf_counter(nlags=24*7,plot=True,save_path_acf=save_path_acf,save_path_pacf=save_path_pacf,diff_periods=1) #diff_periods=1  
```

__6-oxidizing gases-污染气体时间序列分析__

* 测量值时间轴

<a href=""><img src="./imgs/3_3_2_50.png" height="auto" width="auto" title="caDesign"></a>

* 时序打印

__Fig. oxidizing_gases时序数据__  

全部节点和全部时间：

<a href=""><img src="./imgs/3_3_2_51.png" height="auto" width="auto" title="caDesign"></a>

随机抽取几个节点打印全部时间：

<a href=""><img src="./imgs/3_3_2_52.png" height="auto" width="auto" title="caDesign"></a>

打印全部节点部分时间：

<a href=""><img src="./imgs/3_3_2_53.png" height="auto" width="auto" title="caDesign"></a>

* 白噪音检测

```python
              oxidizing_lag_12  oxidizing_lag_24  oxidizing_lag_168
001e06109416             False             False              False
001e0610ba13             False             False              False
001e0610ba15             False             False               True
001e0610ba46             False             False              False
001e0610bbe5              True              True               True
001e0610bc10              True              True               True
001e0610bc12             False             False              False
001e0610e537             False             False              False
001e0610e538             False             False              False
001e0610e539             False             False               True
001e0610e835             False             False              False
001e0610eef2             False             False              False
001e0610ef27             False             False              False
001e0610f05c              True              True               True
001e0610f513             False             False              False
001e0610f6db             False             False              False
001e0610f6dd             False             False              False
001e0610f703             False             False              False
001e0610f732             False             False              False
001e0610f8f4             False             False              False
001e06112e77             False             False              False
001e061130f4             False             False              False
001e06113107             False             False              False
001e06113acb              True              True               True
001e06113ace             False             False              False
001e06113ad6              True              True               True
001e06113cf1             False             False              False
001e06113cff             False             False              False
001e06113d32             False             False              False
001e06113d83             False             False              False
001e06113dbc             False             False               True
001e0611441e             False             False              False
001e061144be              True              True               True
001e061144c0             False             False              False
001e06114500             False             False              False
001e06114503             False             False              False
001e061146cb             False             False              False
001e061146d6             False             False               True
001e06114fd4             False             False              False
```

* 平稳性检测

计算结果显示48个有效计算节点下有35个节点为平稳，占有效总数的72.92%；有27.08%oxidizing_gases节点测量值变化幅度较大。如果对一阶差分后的时序进行平稳性检验，则48个有效计算节点下有42个节点为平稳，占有效总数87.5%。

对比未差分的CO和oxidizing_gases平稳性检测结果，均平稳的节点有29个；均不平稳的节点有11个；其中一项测量值平稳，而另一项不平稳的有8个。一致性结果占83.33%，可以判断CO和oxidizing_gases平稳性基本保持一致。

* 周期性模式判断


__Fig. H2S自相关系数 (ACF) 未差分 lag=24×7__ 

<a href=""><img src="./imgs/3_3_2_54_s.jpg" height="auto" width="auto" title="caDesign"></a>

__Fig. H2S偏自相关系数(PACF) 未差分 lag=24×7__ 

<a href=""><img src="./imgs/3_3_2_55_s.jpg" height="auto" width="auto" title="caDesign"></a>

__Fig. H2S自相关系数 (ACF) 一阶差分 lag=24×7__ 

<a href=""><img src="./imgs/3_3_2_56_s.jpg" height="auto" width="auto" title="caDesign"></a>

__Fig. H2S偏自相关系数(PACF) 一阶差分 lag=24×7__ 

<a href=""><img src="./imgs/3_3_2_57_s.jpg" height="auto" width="auto" title="caDesign"></a>

```python
if __name__=="__main__":
    #C_6. oxidizing_gases
    air_oxidizing_fn=os.path.join(parent_path,air_sensor_category_save_fp,"air_oxidizing_gases.gpkg")     
    s_t=util.start_time()
    air_oxidizing=gpd.read_file(air_oxidizing_fn)  
    util.duration(s_t)     
        
    tsab_oxidizing=time_series_analysis_batch(air_oxidizing,"oxidizing_gases",'value_hrf','timestamp','node_id')
    sensor_value_range=tsab_oxidizing.sensors_range(AoT_sensors_fp,'sensor','hrf_minval', 'hrf_maxval')  
    oxidizing_value_resample_mask=tsab_oxidizing.df_preprocessing()  
    
    oxidizing_SFT=tsab_oxidizing.gantt_chart_H()  
    
    _=tsab_oxidizing.time_series_plot(['2018-01-17 0:0:0','2018-05-16 0:0:0'],rolling_window=10,xlabel="时间",ylabel="oxidizing-浓度(ppm)",figsize=(20,10),font_size=15)
    _=tsab_oxidizing.time_series_plot(['2018-01-17 0:0:0','2018-06-16 0:0:0'],['001e061146d6','001e06115365', '001e06113cff', '001e06113d22', '001e0610e537'],rolling_window=6,xlabel="时间",ylabel="oxidizing-浓度(ppm)",figsize=(20,10),font_size=15,legend=True)
    _=tsab_oxidizing.time_series_plot(['2018-04-25 0:0:0','2018-05-01 0:0:0'],rolling_window=6,xlabel="时间",ylabel="oxidizing-浓度(ppm)",figsize=(20,10),font_size=15,legend=False)
    
    oxidizing_stat_pvalue_dict,oxidizing_is_white_noise=tsab_oxidizing.white_noise_Ljung_box_pierce(lags=[12,24,24*7])
    oxidizing_is_white_noise_df=pd.DataFrame.from_dict(oxidizing_is_white_noise,orient='index')
    oxidizing_is_white_noise_columns_new={i:"oxidizing_{}".format(i) for i in oxidizing_is_white_noise_df.columns}
    oxidizing_is_white_noise_df=oxidizing_is_white_noise_df.rename(columns=oxidizing_is_white_noise_columns_new)    
    air_is_white_noise_gdf=postSQL2gpd(table_name="air_is_white_noise",geom_col=GC,myusername=UN,mypassword=PW,mydatabase=DB) 
    air_is_white_noise_gdf=pd.merge(air_is_white_noise_gdf,oxidizing_is_white_noise_df,left_on='node_id',right_index=True,how='outer')
    gpd2postSQL(air_is_white_noise_gdf,table_name='air_is_white_noise',myusername=UN,mypassword=PW,mydatabase=DB)
    
    oxidizing_is_stationary_dict_d=tsab_oxidizing.stationary_stat(print_detail=False,diff_periods=1) #,autolag="AIC" 
    oxidizing_is_stationary_dict=tsab_oxidizing.stationary_stat(print_detail=False) #,autolag="AIC"       
    oxidizing_is_stationary_df=pd.DataFrame.from_dict(oxidizing_is_stationary_dict,orient='index',columns=["oxidizing_is_stationary"])
    air_is_stationary_gdf=postSQL2gpd(table_name="air_is_stationary",geom_col=GC,myusername=UN,mypassword=PW,mydatabase=DB)     
    air_is_stationary_gdf=pd.merge(air_is_stationary_gdf,oxidizing_is_stationary_df,left_on='node_id',right_index=True,how='outer')
    gpd2postSQL(air_is_stationary_gdf,table_name='air_is_stationary',myusername=UN,mypassword=PW,mydatabase=DB)    
    
    _=tsa.compare_TFN(air_is_stationary_gdf,'co_is_stationary','oxidizing_is_stationary')
        
    save_path_acf=os.path.join(parent_path,'./charts/oxidizing_acf')
    save_path_pacf=os.path.join(parent_path,'./charts/oxidizing_pacf')
    oxidizing_acf_counter_dict,pacf_counter_dict=tsab_co.acf_pacf_counter(nlags=24*7,plot=True,save_path_acf=save_path_acf,save_path_pacf=save_path_pacf,diff_periods=1 ) #diff_periods=1    
 
```

__7-reducing gases-污染气体时间序列分析__

* 测量值时间轴

<a href=""><img src="./imgs/3_3_2_58.png" height="auto" width="auto" title="caDesign"></a>

* 时序打印

__Fig. reducing_gases时序数据__  

全部节点和全部时间：

<a href=""><img src="./imgs/3_3_2_59.png" height="auto" width="auto" title="caDesign"></a>

随机抽取几个节点打印全部时间：

<a href=""><img src="./imgs/3_3_2_60.png" height="auto" width="auto" title="caDesign"></a>

打印全部节点部分时间：

<a href=""><img src="./imgs/3_3_2_61.png" height="auto" width="auto" title="caDesign"></a>

* 白噪音检测

```python
              reducing_lag_12  reducing_lag_24  reducing_lag_168
001e0610890f            False            False             False
001e06109416            False            False             False
001e0610ba13            False            False             False
001e0610ba15            False            False             False
001e0610ba46            False            False             False
001e0610bbe5            False            False             False
001e0610bc10            False            False             False
001e0610bc12            False            False             False
001e0610e537            False            False             False
001e0610e538            False            False             False
001e0610e539            False            False             False
001e0610e835            False            False             False
001e0610e8cb            False            False             False
001e0610eef2            False            False             False
001e0610ef27            False            False              True
001e0610f05c            False            False             False
001e0610f513            False            False             False
001e0610f6db            False            False             False
001e0610f6dd            False            False             False
001e0610f703            False            False             False
001e0610f732            False            False             False
001e0610f8f4            False            False             False
001e06112e77            False            False             False
001e061130f4            False            False             False
001e06113107            False            False             False
001e06113acb            False            False             False
001e06113ace            False            False              True
001e06113ad6            False            False             False
001e06113ad8            False            False             False
001e06113cf1            False            False             False
001e06113cff            False            False             False
001e06113d32            False            False             False
001e06113d83            False            False             False
001e06113dbc            False            False             False
001e06113f54            False            False             False
001e0611441e            False            False             False
001e061144be            False            False             False
001e061144c0            False            False             False
001e06114500            False            False             False
001e06114503            False            False             False
001e061146cb            False            False             False
001e061146d6            False            False             False
001e06114fd4            False            False             False
001e06115365            False            False             False
001e06115369            False            False             False
```

* 平稳性检测

计算结果显示50个有效计算节点下有27个节点为平稳，占有效总数的54%；有46%reducing_gases节点测量值变化幅度较大。如果对一阶差分后的时序进行平稳性检验，则50个有效计算节点下有49个节点为平稳，占有效总数98%。

对比未差分的CO和reducing_gases平稳性检测结果，均平稳的节点有24个；均不平稳的节点有14个；其中一项测量值平稳，而另一项不平稳的有12个。一致性结果占76%，可以判断CO和reducing_gases平稳性基本保持一致。

* 周期性模式判断


__Fig. reducing_gases自相关系数 (ACF) 未差分 lag=24×7__ 

<a href=""><img src="./imgs/3_3_2_62_s.jpg" height="auto" width="auto" title="caDesign"></a>

__Fig. reducing_gases偏自相关系数(PACF) 未差分 lag=24×7__ 

<a href=""><img src="./imgs/3_3_2_63_s.jpg" height="auto" width="auto" title="caDesign"></a>

__Fig. reducing_gases自相关系数 (ACF) 一阶差分 lag=24×7__ 

<a href=""><img src="./imgs/3_3_2_64_s.jpg" height="auto" width="auto" title="caDesign"></a>

__Fig. reducing_gases偏自相关系数(PACF) 一阶差分 lag=24×7__ 

<a href=""><img src="./imgs/3_3_2_65_s.jpg" height="auto" width="auto" title="caDesign"></a>

```python
if __name__=="__main__":
    #C_7. reducing_gases
    air_reducing_fn=os.path.join(parent_path,air_sensor_category_save_fp,"air_reducing_gases.gpkg")     
    s_t=util.start_time()
    air_reducing=gpd.read_file(air_reducing_fn)  
    util.duration(s_t)     
        
    tsab_reducing=time_series_analysis_batch(air_reducing,"reducing_gases",'value_hrf','timestamp','node_id')
    sensor_value_range=tsab_reducing.sensors_range(AoT_sensors_fp,'sensor','hrf_minval', 'hrf_maxval')  
    reducing_value_resample_mask=tsab_reducing.df_preprocessing()  
    
    reducing_SFT=tsab_reducing.gantt_chart_H()  
    
    _=tsab_reducing.time_series_plot(['2018-01-17 0:0:0','2018-05-16 0:0:0'],rolling_window=10,xlabel="时间",ylabel="reducing-浓度(ppm)",figsize=(20,10),font_size=15)
    _=tsab_reducing.time_series_plot(['2018-01-17 0:0:0','2018-06-16 0:0:0'],['001e061146d6','001e06115365', '001e06113cff', '001e06113d22', '001e0610e537'],rolling_window=6,xlabel="时间",ylabel="reducing-浓度(ppm)",figsize=(20,10),font_size=15,legend=True)
    _=tsab_reducing.time_series_plot(['2018-04-25 0:0:0','2018-05-01 0:0:0'],rolling_window=6,xlabel="时间",ylabel="reducing-浓度(ppm)",figsize=(20,10),font_size=15,legend=False)
    
    reducing_stat_pvalue_dict,reducing_is_white_noise=tsab_reducing.white_noise_Ljung_box_pierce(lags=[12,24,24*7])
    reducing_is_white_noise_df=pd.DataFrame.from_dict(reducing_is_white_noise,orient='index')
    reducing_is_white_noise_columns_new={i:"reducing_{}".format(i) for i in reducing_is_white_noise_df.columns}
    reducing_is_white_noise_df=reducing_is_white_noise_df.rename(columns=reducing_is_white_noise_columns_new)    
    air_is_white_noise_gdf=postSQL2gpd(table_name="air_is_white_noise",geom_col=GC,myusername=UN,mypassword=PW,mydatabase=DB) 
    air_is_white_noise_gdf=pd.merge(air_is_white_noise_gdf,reducing_is_white_noise_df,left_on='node_id',right_index=True,how='outer')
    gpd2postSQL(air_is_white_noise_gdf,table_name='air_is_white_noise',myusername=UN,mypassword=PW,mydatabase=DB)
    
    reducing_is_stationary_dict_d=tsab_reducing.stationary_stat(print_detail=False,diff_periods=1) #,autolag="AIC" 
    reducing_is_stationary_dict=tsab_reducing.stationary_stat(print_detail=False) #,autolag="AIC"       
    reducing_is_stationary_df=pd.DataFrame.from_dict(reducing_is_stationary_dict,orient='index',columns=["reducing_is_stationary"])
    air_is_stationary_gdf=postSQL2gpd(table_name="air_is_stationary",geom_col=GC,myusername=UN,mypassword=PW,mydatabase=DB)     
    air_is_stationary_gdf=pd.merge(air_is_stationary_gdf,reducing_is_stationary_df,left_on='node_id',right_index=True,how='outer')
    gpd2postSQL(air_is_stationary_gdf,table_name='air_is_stationary',myusername=UN,mypassword=PW,mydatabase=DB)    
    
    _=tsa.compare_TFN(air_is_stationary_gdf,'co_is_stationary','reducing_is_stationary')
        
    save_path_acf=os.path.join(parent_path,'./charts/reducing_acf')
    save_path_pacf=os.path.join(parent_path,'./charts/reducing_pacf')
    reducing_acf_counter_dict,pacf_counter_dict=tsab_co.acf_pacf_counter(nlags=24*7,plot=True,save_path_acf=save_path_acf,save_path_pacf=save_path_pacf, diff_periods=1) #diff_periods=1    
 
```

###### 4) 空间自相关

虽然AoT在芝加哥总共布局了126个测量点位，但是并不是每个点位测量所有内容，对于气体类约有50个左右有效测量点。因为气体受局地环境影响较大，可能测量点之间并不存在空间相关性，即不同测量点之间的气体类测量值之间不存在相互依赖性。为了确定这一想法，通过[PySAL](https://pysal.org/)计算全局空间自相关和局部空间自相关，即全局和局部的莫兰指数（Global, Local [Morans's I](https://en.wikipedia.org/wiki/Moran%27s_I)）。

计算气体类测量点之间的空间自相关需要注意：

1. 需要将点数据转换为voronoi的polygons面对象，使用`libpysal.cg.voronoi.voronoi_frames()`方法。如果其中存在重复的点，这里分析时仅保留一个点（注意，可能虽为同一点，但测量内容可能不同。这里因为只有一个重复点，因此不影响分析结果）；
2. 如果存在空值，是直接将其移除，并不会用测量值的均值替换；
3. 计算年（所有测量值），各月和各周测量值均值的空间自相关；
4. 判断空间相关性计算结果是否是完全随机，如果不是完全随机，则说明测量值存在空间相关性；否则，不存在。通过观测属性值随机空间排列构建一个完全空间随机（complete spatial randomness， CSR）参考分布，评估观测结果的统计显著性。显著性水平配置为0.05（通过95%置信度检验），并计算局部自相关满足要求的样本数；
5. 某一周期（月或周）测量值的数量可能较少，不能满足计算需求，因此给定有效值数量（这配置为25），仅计算大于有效值数量的周期。


计算结果入下：

```python
 {'CO': {'GI': ["Moran's I=-0.06146501823956747,p_sim=0.301"], 'LI': {'Y': ['Y_2018-12-31,P_value<0.05 sum=8 in 51'], 'M': ['M_2018-03-31,P_value<0.05 sum=6 in 36', 'M_2018-04-30,P_value<0.05 sum=9 in 38', 'M_2018-05-31,P_value<0.05 sum=3 in 40'], 'W': ['W_2018-03-18,P_value<0.05 sum=0 in 27', 'W_2018-03-25,P_value<0.05 sum=5 in 31', 'W_2018-04-01,P_value<0.05 sum=4 in 32', 'W_2018-04-08,P_value<0.05 sum=4 in 30', 'W_2018-04-15,P_value<0.05 sum=2 in 34', 'W_2018-04-22,P_value<0.05 sum=2 in 31', 'W_2018-04-29,P_value<0.05 sum=2 in 33', 'W_2018-05-06,P_value<0.05 sum=2 in 35', 'W_2018-05-13,P_value<0.05 sum=1 in 39', 'W_2018-05-20,P_value<0.05 sum=3 in 32']}}, 'H2S': {'GI': ["Moran's I=0.27114331308277406,p_sim=0.005"], 'LI': {'Y': ['Y_2018-12-31,P_value<0.05 sum=7 in 51'], 'M': ['M_2018-03-31,P_value<0.05 sum=5 in 37', 'M_2018-04-30,P_value<0.05 sum=6 in 37', 'M_2018-05-31,P_value<0.05 sum=4 in 34'], 'W': ['W_2018-03-18,P_value<0.05 sum=2 in 27', 'W_2018-03-25,P_value<0.05 sum=4 in 31', 'W_2018-04-01,P_value<0.05 sum=0 in 32', 'W_2018-04-08,P_value<0.05 sum=0 in 29', 'W_2018-04-15,P_value<0.05 sum=5 in 33', 'W_2018-04-22,P_value<0.05 sum=3 in 30', 'W_2018-04-29,P_value<0.05 sum=4 in 31', 'W_2018-05-06,P_value<0.05 sum=2 in 33', 'W_2018-05-13,P_value<0.05 sum=7 in 28']}}, 'NO2': {'GI': ["Moran's I=-0.0525880551220806,p_sim=0.268"], 'LI': {'Y': ['Y_2018-12-31,P_value<0.05 sum=4 in 50'], 'M': ['M_2018-03-31,P_value<0.05 sum=3 in 37', 'M_2018-04-30,P_value<0.05 sum=3 in 38', 'M_2018-05-31,P_value<0.05 sum=3 in 37'], 'W': ['W_2018-03-18,P_value<0.05 sum=2 in 27', 'W_2018-03-25,P_value<0.05 sum=2 in 32', 'W_2018-04-01,P_value<0.05 sum=1 in 32', 'W_2018-04-08,P_value<0.05 sum=0 in 30', 'W_2018-04-15,P_value<0.05 sum=3 in 35', 'W_2018-04-22,P_value<0.05 sum=5 in 31', 'W_2018-04-29,P_value<0.05 sum=3 in 33', 'W_2018-05-06,P_value<0.05 sum=1 in 35', 'W_2018-05-13,P_value<0.05 sum=3 in 36', 'W_2018-05-20,P_value<0.05 sum=3 in 31']}}, 'O3': {'GI': ["Moran's I=-0.052331796935156036,p_sim=0.084"], 'LI': {'Y': ['Y_2018-12-31,P_value<0.05 sum=4 in 53'], 'M': ['M_2018-03-31,P_value<0.05 sum=8 in 37', 'M_2018-04-30,P_value<0.05 sum=2 in 38', 'M_2018-05-31,P_value<0.05 sum=4 in 40'], 'W': ['W_2018-03-18,P_value<0.05 sum=3 in 27', 'W_2018-03-25,P_value<0.05 sum=6 in 32', 'W_2018-04-01,P_value<0.05 sum=2 in 32', 'W_2018-04-08,P_value<0.05 sum=4 in 30', 'W_2018-04-15,P_value<0.05 sum=5 in 35', 'W_2018-04-22,P_value<0.05 sum=1 in 31', 'W_2018-04-29,P_value<0.05 sum=7 in 33', 'W_2018-05-06,P_value<0.05 sum=4 in 35', 'W_2018-05-13,P_value<0.05 sum=6 in 39', 'W_2018-05-20,P_value<0.05 sum=4 in 32']}}, 'SO2': {'GI': ["Moran's I=-0.03465807516289722,p_sim=0.103"], 'LI': {'Y': ['Y_2018-12-31,P_value<0.05 sum=5 in 52'], 'M': ['M_2018-03-31,P_value<0.05 sum=3 in 37', 'M_2018-04-30,P_value<0.05 sum=1 in 38', 'M_2018-05-31,P_value<0.05 sum=3 in 40'], 'W': ['W_2018-03-18,P_value<0.05 sum=3 in 27', 'W_2018-03-25,P_value<0.05 sum=4 in 32', 'W_2018-04-01,P_value<0.05 sum=1 in 31', 'W_2018-04-08,P_value<0.05 sum=2 in 30', 'W_2018-04-15,P_value<0.05 sum=4 in 35', 'W_2018-04-22,P_value<0.05 sum=1 in 31', 'W_2018-04-29,P_value<0.05 sum=0 in 33', 'W_2018-05-06,P_value<0.05 sum=5 in 35', 'W_2018-05-13,P_value<0.05 sum=1 in 39', 'W_2018-05-20,P_value<0.05 sum=6 in 32']}}, 'oxidizing_gases': {'GI': ["Moran's I=-0.030483475347338716,p_sim=0.372"], 'LI': {'Y': ['Y_2018-12-31,P_value<0.05 sum=5 in 52'], 'M': ['M_2018-03-31,P_value<0.05 sum=5 in 37', 'M_2018-04-30,P_value<0.05 sum=1 in 38', 'M_2018-05-31,P_value<0.05 sum=3 in 39'], 'W': ['W_2018-03-18,P_value<0.05 sum=4 in 27', 'W_2018-03-25,P_value<0.05 sum=2 in 32', 'W_2018-04-01,P_value<0.05 sum=1 in 32', 'W_2018-04-08,P_value<0.05 sum=1 in 30', 'W_2018-04-15,P_value<0.05 sum=1 in 34', 'W_2018-04-22,P_value<0.05 sum=2 in 31', 'W_2018-04-29,P_value<0.05 sum=4 in 33', 'W_2018-05-06,P_value<0.05 sum=4 in 35', 'W_2018-05-13,P_value<0.05 sum=4 in 38', 'W_2018-05-20,P_value<0.05 sum=2 in 31']}}, 'reducing_gases': {'GI': ["Moran's I=-0.0442381067399344,p_sim=0.127"], 'LI': {'Y': ['Y_2018-12-31,P_value<0.05 sum=7 in 52'], 'M': ['M_2018-03-31,P_value<0.05 sum=2 in 37', 'M_2018-04-30,P_value<0.05 sum=4 in 38', 'M_2018-05-31,P_value<0.05 sum=2 in 39'], 'W': ['W_2018-03-18,P_value<0.05 sum=2 in 27', 'W_2018-03-25,P_value<0.05 sum=4 in 32', 'W_2018-04-01,P_value<0.05 sum=4 in 32', 'W_2018-04-08,P_value<0.05 sum=2 in 30', 'W_2018-04-15,P_value<0.05 sum=2 in 35', 'W_2018-04-22,P_value<0.05 sum=4 in 31', 'W_2018-04-29,P_value<0.05 sum=3 in 33', 'W_2018-05-06,P_value<0.05 sum=5 in 35', 'W_2018-05-13,P_value<0.05 sum=8 in 38', 'W_2018-05-20,P_value<0.05 sum=4 in 32']}}}
```

 {'CO': {'GI': ["Moran's I=-0.06146501823956747,p_sim=0.301"], 'LI': {'Y': ['Y_2018-12-31,P_value<0.05 sum=8 in 51'], 'M': ['M_2018-03-31,P_value<0.05 sum=6 in 36', 'M_2018-04-30,P_value<0.05 sum=9 in 38', 'M_2018-05-31,P_value<0.05 sum=3 in 40'], 'W': ['W_2018-03-18,P_value<0.05 sum=0 in 27', 'W_2018-03-25,P_value<0.05 sum=5 in 31', 'W_2018-04-01,P_value<0.05 sum=4 in 32', 'W_2018-04-08,P_value<0.05 sum=4 in 30', 'W_2018-04-15,P_value<0.05 sum=2 in 34', 'W_2018-04-22,P_value<0.05 sum=2 in 31', 'W_2018-04-29,P_value<0.05 sum=2 in 33', 'W_2018-05-06,P_value<0.05 sum=2 in 35', 'W_2018-05-13,P_value<0.05 sum=1 in 39', 'W_2018-05-20,P_value<0.05 sum=3 in 32']}}, 

 'H2S': {'GI': ["Moran's I=0.27114331308277406,p_sim=0.005"], 'LI': {'Y': ['Y_2018-12-31,P_value<0.05 sum=7 in 51'], 'M': ['M_2018-03-31,P_value<0.05 sum=5 in 37', 'M_2018-04-30,P_value<0.05 sum=6 in 37', 'M_2018-05-31,P_value<0.05 sum=4 in 34'], 'W': ['W_2018-03-18,P_value<0.05 sum=2 in 27', 'W_2018-03-25,P_value<0.05 sum=4 in 31', 'W_2018-04-01,P_value<0.05 sum=0 in 32', 'W_2018-04-08,P_value<0.05 sum=0 in 29', 'W_2018-04-15,P_value<0.05 sum=5 in 33', 'W_2018-04-22,P_value<0.05 sum=3 in 30', 'W_2018-04-29,P_value<0.05 sum=4 in 31', 'W_2018-05-06,P_value<0.05 sum=2 in 33', 'W_2018-05-13,P_value<0.05 sum=7 in 28']}}, 
 
 'NO2': {'GI': ["Moran's I=-0.0525880551220806,p_sim=0.268"], 'LI': {'Y': ['Y_2018-12-31,P_value<0.05 sum=4 in 50'], 'M': ['M_2018-03-31,P_value<0.05 sum=3 in 37', 'M_2018-04-30,P_value<0.05 sum=3 in 38', 'M_2018-05-31,P_value<0.05 sum=3 in 37'], 'W': ['W_2018-03-18,P_value<0.05 sum=2 in 27', 'W_2018-03-25,P_value<0.05 sum=2 in 32', 'W_2018-04-01,P_value<0.05 sum=1 in 32', 'W_2018-04-08,P_value<0.05 sum=0 in 30', 'W_2018-04-15,P_value<0.05 sum=3 in 35', 'W_2018-04-22,P_value<0.05 sum=5 in 31', 'W_2018-04-29,P_value<0.05 sum=3 in 33', 'W_2018-05-06,P_value<0.05 sum=1 in 35', 'W_2018-05-13,P_value<0.05 sum=3 in 36', 'W_2018-05-20,P_value<0.05 sum=3 in 31']}}, 
 
 'O3': {'GI': ["Moran's I=-0.052331796935156036,p_sim=0.084"], 'LI': {'Y': ['Y_2018-12-31,P_value<0.05 sum=4 in 53'], 'M': ['M_2018-03-31,P_value<0.05 sum=8 in 37', 'M_2018-04-30,P_value<0.05 sum=2 in 38', 'M_2018-05-31,P_value<0.05 sum=4 in 40'], 'W': ['W_2018-03-18,P_value<0.05 sum=3 in 27', 'W_2018-03-25,P_value<0.05 sum=6 in 32', 'W_2018-04-01,P_value<0.05 sum=2 in 32', 'W_2018-04-08,P_value<0.05 sum=4 in 30', 'W_2018-04-15,P_value<0.05 sum=5 in 35', 'W_2018-04-22,P_value<0.05 sum=1 in 31', 'W_2018-04-29,P_value<0.05 sum=7 in 33', 'W_2018-05-06,P_value<0.05 sum=4 in 35', 'W_2018-05-13,P_value<0.05 sum=6 in 39', 'W_2018-05-20,P_value<0.05 sum=4 in 32']}}, 
 
 'SO2': {'GI': ["Moran's I=-0.03465807516289722,p_sim=0.103"], 'LI': {'Y': ['Y_2018-12-31,P_value<0.05 sum=5 in 52'], 'M': ['M_2018-03-31,P_value<0.05 sum=3 in 37', 'M_2018-04-30,P_value<0.05 sum=1 in 38', 'M_2018-05-31,P_value<0.05 sum=3 in 40'], 'W': ['W_2018-03-18,P_value<0.05 sum=3 in 27', 'W_2018-03-25,P_value<0.05 sum=4 in 32', 'W_2018-04-01,P_value<0.05 sum=1 in 31', 'W_2018-04-08,P_value<0.05 sum=2 in 30', 'W_2018-04-15,P_value<0.05 sum=4 in 35', 'W_2018-04-22,P_value<0.05 sum=1 in 31', 'W_2018-04-29,P_value<0.05 sum=0 in 33', 'W_2018-05-06,P_value<0.05 sum=5 in 35', 'W_2018-05-13,P_value<0.05 sum=1 in 39', 'W_2018-05-20,P_value<0.05 sum=6 in 32']}},
 
  'oxidizing_gases': {'GI': ["Moran's I=-0.030483475347338716,p_sim=0.372"], 'LI': {'Y': ['Y_2018-12-31,P_value<0.05 sum=5 in 52'], 'M': ['M_2018-03-31,P_value<0.05 sum=5 in 37', 'M_2018-04-30,P_value<0.05 sum=1 in 38', 'M_2018-05-31,P_value<0.05 sum=3 in 39'], 'W': ['W_2018-03-18,P_value<0.05 sum=4 in 27', 'W_2018-03-25,P_value<0.05 sum=2 in 32', 'W_2018-04-01,P_value<0.05 sum=1 in 32', 'W_2018-04-08,P_value<0.05 sum=1 in 30', 'W_2018-04-15,P_value<0.05 sum=1 in 34', 'W_2018-04-22,P_value<0.05 sum=2 in 31', 'W_2018-04-29,P_value<0.05 sum=4 in 33', 'W_2018-05-06,P_value<0.05 sum=4 in 35', 'W_2018-05-13,P_value<0.05 sum=4 in 38', 'W_2018-05-20,P_value<0.05 sum=2 in 31']}}, 
  
  'reducing_gases': {'GI': ["Moran's I=-0.0442381067399344,p_sim=0.127"], 'LI': {'Y': ['Y_2018-12-31,P_value<0.05 sum=7 in 52'], 'M': ['M_2018-03-31,P_value<0.05 sum=2 in 37', 'M_2018-04-30,P_value<0.05 sum=4 in 38', 'M_2018-05-31,P_value<0.05 sum=2 in 39'], 'W': ['W_2018-03-18,P_value<0.05 sum=2 in 27', 'W_2018-03-25,P_value<0.05 sum=4 in 32', 'W_2018-04-01,P_value<0.05 sum=4 in 32', 'W_2018-04-08,P_value<0.05 sum=2 in 30', 'W_2018-04-15,P_value<0.05 sum=2 in 35', 'W_2018-04-22,P_value<0.05 sum=4 in 31', 'W_2018-04-29,P_value<0.05 sum=3 in 33', 'W_2018-05-06,P_value<0.05 sum=5 in 35', 'W_2018-05-13,P_value<0.05 sum=8 in 38', 'W_2018-05-20,P_value<0.05 sum=4 in 32']}}}

从计算结果来看，对于全局空间自相关，除 `H2S`小于显著性水平，其余各气体均大于显著性水平，统计不显著，不具有全局空间相关性。对于局部空间自相关，所有气体小于显著性水平的样本数站全部样本的比例均很小，因此可以确定各气体测量点位之间不存在局部空间自相关。

__Fig. 示例__  

|CO-观测值与参考分布均值关系（全局）|CO-局部空间自相关散点图（测量值vs给定空间权重的测量值）|
|---|---|
| <img src="./imgs/3_3_2_66.png" height="auto" width="auto" title="caDesign">  |  <img src="./imgs/3_3_2_67.png" height="auto" width="auto" title="caDesign"> |  

从观测值与参考分布均值关系可以看到，观测值落于参考分布之内，不能拒绝原假设，CO测量值测量点位之间不存在全局空间自相关。从散点图不能看到测量值和给定空间权重的测量值之间明显的相关性，因此可以初步判定CO测量值测量点位之间不存在局部空间自相关。其它气体同。

`spatio_temporal_analysis.py`
```python
# -*- coding: utf-8 -*-
"""
Created on Wed Apr 20 10:06:46 2022

@author: Richie Bao-caDesign设计(cadesign.cn)
"""
def pts2voronoi_polygons(gdf,epsg=None,show=False):
    '''
    将DataFrame的点对象转换为voronoi的polygons面对象，用于空间数据分析

    Parameters
    ----------
    gdf : GeoDataFrame
        点数据.
    epsg : int, optional
        投影编号. The default is None.
    show : bool, optional
        是否打印地图结果. The default is False.

    Returns
    -------
    gdf_region : GeoDataFrame
        移除了重复点行，并转换为polygon，包含原始数据信息文件.
    '''
    from libpysal.cg.voronoi import voronoi, voronoi_frames      
    import matplotlib.pyplot as plt
    
    if epsg:
        gdf_crs=gdf.to_crs(epsg)
    else:
        gdf_crs=gdf.copy(deep=True)
    print("crs_{}".format(gdf_crs.crs))
    
    G=gdf_crs["geometry"].apply(lambda geom: geom.wkb)    
    gdf_crs=gdf_crs.loc[G.drop_duplicates().index]
    if len(gdf_crs)<len(gdf):print("dropped duplicates num={}".format(len(gdf)-len(gdf_crs)))
    pts=gdf_crs.geometry.to_list()
    pts_coordi=[(pt.x,pt.y) for pt in pts]
    # print(len(pts_coordi))
    # regions, vertices=voronoi(pts_coordi)
    # print(regions,vertices)
    region_df, point_df=voronoi_frames(pts_coordi)
    # print(region_df, point_df)
    gdf_region=gdf_crs.set_geometry(region_df.geometry.to_list())
    
    if show:        
        fig, ax=plt.subplots()
        region_df.plot(ax=ax, color='blue',edgecolor='black', alpha=0.3)
        point_df.plot(ax=ax, color='red')    
            
    return gdf_region

def isnull_fillna_column(gdf,column_name,k=None):
    '''
    检查给定列是否存在空值，如果存在则用该列均值代替空值；并可以按给定k分位数打印地图

    Parameters
    ----------
    gdf : GeoDataFrame
        待处理的数据.
    column_name : String
        给定待计算的列名.
    k : int, optional
        分位数区间数量. The default is None.

    Returns
    -------
    gdf_fillna : GeoDataFrame
        如果存在空值，返回替换后的数据.

    '''
    import pandas as pd
    import matplotlib.pyplot as plt
    
    nulls_num=pd.isnull(gdf[column_name]).sum()
    print("There are {} nulls in total".format(nulls_num))
    if nulls_num>0:
        gdf_fillna=gdf[column_name].fillna((gdf[column_name].mean()), inplace=True)
        return gdf_fillna
    if k:
        fig, ax=plt.subplots(figsize=(12,10), subplot_kw={'aspect':'equal'})
        gdf.plot(column=column_name, scheme='Quantiles', k=k, cmap='GnBu', legend=True, ax=ax)
    
def spatial_lag(gdf,contiguity_w,column_name,knn_k=4,show=False,quantiles_k=4):
    '''
    查看给定空间权重后值聚集分布情况

    Parameters
    ----------
    gdf : GeoDataFrame
        待查看的数据.
    contiguity_w : String
        空间权重，包括queen, rook或knn.
    column_name : String
        待查看的数据列名.
    knn_k : int, optional
        指定KNN空间权重类型下的邻元数. The default is 4.
    show : bool, optional
        是否打印地图查看原值与给定空间权重后值分布比较. The default is False.
    quantiles_k : int, optional
        分位数区间数. The default is 4.

    Returns
    -------
    gdf : GeoDataFrame
        返回包含给定空间权重后值列的数据.

    '''
    from libpysal.weights import Queen, Rook, KNN
    import libpysal as lps
    import matplotlib.pyplot as plt    
    import numpy as np
    
    if contiguity_w=='queen':
        wq=Queen.from_dataframe(gdf)
    elif contiguity_w=='rook':
        wq=Rook.from_dataframe(gdf)
    elif contiguity_w=='knn':
        wq=KNN.from_dataframe(gdf,knn_k)
    else:
        print("Please specify parameter contiguity, optional: queen, rook, and knn")
    wq.transform='r'
    
    y=gdf[column_name]
    ylag=lps.weights.lag_spatial(wq, y)
    ylag_name='lag_{}'.format(column_name)
    gdf[ylag_name]=ylag
    
    if show:
        f,ax = plt.subplots(1,2,figsize=(2.16*4,4))
        gdf.plot(column=column_name, ax=ax[0], edgecolor='k',scheme="quantiles", k=quantiles_k, cmap='GnBu')
        ax[0].axis(gdf.total_bounds[np.asarray([0,2,1,3])])
        ax[0].set_title(column_name)
        
        gdf.plot(column=ylag_name, ax=ax[1], edgecolor='k',scheme='quantiles', cmap='GnBu', k=quantiles_k)
        ax[1].axis(gdf.total_bounds[np.asarray([0,2,1,3])])
        ax[1].set_title(ylag_name)
        ax[0].axis('off')
        ax[1].axis('off')
        plt.show()    
    
    return gdf

def contiguity_weight(gdf,contiguity_w='queen',transform='r'):
    '''
    使用PySAL配置空间权重

    Parameters
    ----------
    gdf : GeoDataFrame
        包含空间几何的地理数据.
    contiguity_w : String, optional
        配置空间权重类型，包括queen, rook或knn. The default is 'queen'.
    transform : String, optional
        配置权重值变换，包括：
        B – Binary
        R – Row-standardization (global sum )
        D – Double-standardization (global sum )
        V – Variance stabilizing
        O – Restore original transformation (from instantiation)
        The default is 'r'.

    Returns
    -------
    wq : libpysal.weights.weights.W
        返回空间权重.

    '''
    from libpysal.weights import Queen, Rook, KNN
    
    if contiguity_w=='queen':
        wq=Queen.from_dataframe(gdf)
    elif contiguity_w=='rook':
        wq=Rook.from_dataframe(gdf)
    elif contiguity_w=='knn':
        wq=KNN.from_dataframe(gdf,knn_k)
    else:
        print("Please specify parameter contiguity, optional: queen, rook, and knn")
        
    wq.transform=transform #b,r,d,v,o ref:https://pysal.org/libpysal/generated/libpysal.weights.W.html?highlight=transform#libpysal.weights.W.set_transform
    return wq 

def global_spatial_autocorrelation_binary_case(gdf,column_name,contiguity_w='queen',transform='r',show=True):
    '''
    以中位数为界，以二进制表述大于和小于中位数的值，并判断集聚分布是否是随机情形

    Parameters
    ----------
    gdf : GeoDataFrame
        用于分析的数据.
    column_name : String
        用于分析的列名.
    contiguity_w : String, optional
        空间权重选项，包括queen, rook或knn. The default is 'queen'.
    transform : String, optional
        配置权重值变换. The default is 'r'.
    show : bool, optional
        是否打印地图，查看集聚分布. The default is True.

    Returns
    -------
    gdf : GeoDataFrame
        返回包含分析结果，即二值情况的数据.

    '''
    import matplotlib.pyplot as plt  
    import libpysal as lps
    from esda import join_counts
    import numpy as np
    import seaborn as sbn
    
    y=gdf[column_name]
    yb=y>y.median()
    print('There are a total of {} values greater than the median.'.format(sum(yb)))
    labels=["0 Low", "1 High"]
    yb=[labels[i] for i in 1*yb] 
    yb_name='binary_{}'.format(column_name)
    gdf[yb_name]=yb  
    
    if show:
        fig, ax=plt.subplots(figsize=(12,10), subplot_kw={'aspect':'equal'})
        gdf.plot(column=yb_name, cmap='binary', edgecolor='grey', legend=True, ax=ax)    
        plt.show()
        
    yb_=1 * (y > y.median()) # convert back to binary   
    wq=contiguity_weight(gdf,contiguity_w=contiguity_w,transform='b')
    np.random.seed(12345)
    jc=join_counts.Join_Counts(yb_, wq)
    print("bb={},ww={},bw={}; The sum is {}.".format(jc.bb,jc.ww,jc.bw,jc.bb + jc.ww + jc.bw))
    
    fig.clear(True)
    sbn.kdeplot(jc.sim_bb, shade=True)
    plt.vlines(jc.bb, 0, 0.075, color='r')
    plt.vlines(jc.mean_bb, 0,0.075)
    plt.xlabel('BB Counts')    
    plt.show()    
    print("p_sim_bb={}".format(jc.p_sim_bb))
    
    return gdf

def global_spatial_autocorrelation_continuous_case(gdf,column_name,contiguity_w='queen',transform='r'):    
    '''
    计算全局Moran's I （莫兰指数），即全局空间自相关。并判断是否是随机结果。给定的数据为polygon数据

    Parameters
    ----------
    gdf : GeoDataFrame
        待分析的数据.
    column_name : String
        用于分析的列名.
    contiguity_w : String, optional
        空间权重选项，包括queen, rook或knn. The default is 'queen'.
    transform : String, optional
        配置权重值变换. The default is 'r'.

    Returns
    -------
    None.

    '''
    from esda import moran
    import seaborn as sbn
    import numpy as np
    import matplotlib.pyplot as plt 
    
    wq=contiguity_weight(gdf,contiguity_w=contiguity_w,transform=transform)
    y=gdf[column_name]    
    np.random.seed(12345)
    mi=moran.Moran(y, wq)    
    print("Moran's I={}".format(mi.I))
    
    sbn.kdeplot(mi.sim, shade=True)
    plt.vlines(mi.I, 0, 1, color='r')
    plt.vlines(mi.EI, 0,1)
    plt.xlabel("Moran's I")  
    
    print("p_sim={}".format(mi.p_sim))
    
def global_spatial_autocorrelation_continuous_case_pts(gdf,column_name,contiguity_w='queen',transform='r',num=25):    
    '''
    计算全局Moran's I （莫兰指数），即全局空间自相关。并判断是否是随机结果。给定的数据为点数据

    Parameters
    ----------
    gdf : GeoDataFrame
        待分析的数据.
    column_name : String
        用于分析的列名.
    contiguity_w : String, optional
        空间权重选项，包括queen, rook或knn. The default is 'queen'.
    transform : String, optional
        配置权重值变换. The default is 'r'.
    num : int, optional
        满足有效值数量，才进行计算.

    Returns
    -------
    None.

    '''
    from esda import moran
    import seaborn as sbn
    import numpy as np
    import matplotlib.pyplot as plt 
    
    nulls_num=gdf[column_name].isnull().sum()
    valid_num=len(gdf)-nulls_num
    if valid_num>num:
        gdf_valid=gdf.dropna(subset=[column_name],how='all')
        valid_region_gdf=pts2voronoi_polygons(gdf_valid,epsg=4326,show=False)
        wq=contiguity_weight(valid_region_gdf,contiguity_w=contiguity_w,transform=transform)
        y=valid_region_gdf[column_name]    
        np.random.seed(12345)
        mi=moran.Moran(y, wq)    
        print("Moran's I={}".format(mi.I))
        
        sbn.kdeplot(mi.sim, shade=True)
        plt.vlines(mi.I, 0, 1, color='r')
        plt.vlines(mi.EI, 0,1)
        plt.xlabel("Moran's I")  
        
        print("p_sim={}".format(mi.p_sim))     
        return "Moran's I={},p_sim={}".format(mi.I,mi.p_sim)
    else:
        print("The number of valid values is {}, which does not meet the given number-{} requirement.".format(valid_num,num))       
    
def local_spatial_autocorrelation(gdf,column_name,contiguity_w='queen',transform='r'):
    '''
    计算局部Moran's I （莫兰指数），即局部空间自相关。绘制Moran's I散点图。

    Parameters
    ----------
    gdf : GeoDataFrame
        待分析的数据.
    column_name : String
        用于分析的列名.
    contiguity_w : String, optional
        空间权重选项，包括queen, rook或knn. The default is 'queen'.
    transform : String, optional
        配置权重值变换. The default is 'r'.

    Returns
    -------
    gdf : GeoDataFrame.
        包含局部空间自相关系数和p_value值类的数据.
    '''
    import numpy as np
    import libpysal as lps
    import matplotlib.pyplot as plt 
    from esda import moran
    from matplotlib import colors
    
    np.random.seed(12345)
    wq=contiguity_weight(gdf,contiguity_w=contiguity_w,transform=transform)
    y_lag=lps.weights.lag_spatial(wq, gdf[column_name])
    
    y=gdf[column_name]
    b, a=np.polyfit(y, y_lag, 1)
    fig, ax=plt.subplots(1, figsize=(9, 9))
    plt.plot(y, y_lag, '.', color='firebrick')
    # dashed vert at mean of the val(y)
    plt.vlines(y.mean(), y_lag.min(), y_lag.max(), linestyle='--')    
    # dashed horizontal at mean of lagged val(y_lag) 
    plt.hlines(y_lag.mean(), y.min(), y.max(), linestyle='--')    
    # red line of best fit using global I as slope
    plt.plot(y, a + b*y, 'r')
    plt.title('Moran Scatterplot')
    plt.ylabel('Spatial Lag of {}'.format(column_name))
    plt.xlabel(column_name)
    plt.show()       
        
    li=moran.Moran_Local(y, wq)  
    print("P_value<0.05 sum={} in {}".format((li.p_sim < 0.05).sum(),len(gdf)))
    sig = 1 * (li.p_sim < 0.05)
    hotspot = 1 * (sig * li.q==1)
    coldspot = 3 * (sig * li.q==3)
    doughnut = 2 * (sig * li.q==2)
    diamond = 4 * (sig * li.q==4)
    spots = hotspot + coldspot + doughnut + diamond
    
    spot_labels=[ '0 ns', '1 hot spot', '2 doughnut', '3 cold spot', '4 diamond'] 
    labels=[spot_labels[i] for i in spots]
    
    fig.clear(True)
    hmap=colors.ListedColormap([ 'lightgrey', 'red', 'lightblue', 'blue', 'pink'])
    f, ax=plt.subplots(1, figsize=(9, 9))
    gdf.assign(cl=labels).plot(column='cl', categorical=True, \
            k=2, cmap=hmap, linewidth=0.1, ax=ax, \
            edgecolor='white', legend=True)    
    ax.set_axis_off()
    plt.show()         
    
    gdf['p_sim_{}'.format(column_name)]=li.p_sim
    gdf['LMoransI_{}'.format(column_name)]=li.q
    
    info="{},P_value<0.05 sum={} in {}".format(column_name,(li.p_sim < 0.05).sum(),len(gdf))
    return gdf,info

def local_spatial_autocorrelation_batch(gdf,columns,num=25):
    '''
    批量计算多个列的局部空间自相关系数

    Parameters
    ----------
    gdf : GeoDataFrame
        待分析的数据.
    columns : List
        用于分析的列名列表.
    num : int, optional
        满足有效值数量，才进行计算. The default is 25.

    Returns
    -------
    infoList : String
        返回计算信息列表，满足p_value<0.05的数量.

    '''
    infoList=[]
    for co_m in columns:
        nulls_num=gdf[co_m].isnull().sum()
        valid_num=len(gdf)-nulls_num
        if valid_num>num:
            gdf_valid=gdf.dropna(subset=[co_m],how='all')
            valid_region_gdf=pts2voronoi_polygons(gdf_valid,epsg=4326,show=False)
            _,info=local_spatial_autocorrelation(valid_region_gdf,co_m)
            infoList.append(info)
        else:
            print("The number of valid values is {}, which does not meet the given number-{} requirement.".format(valid_num,num))
    return infoList
```

`spatio_temporal_analysis.py`
```python
# -*- coding: utf-8 -*-
"""
Created on Wed Apr 20 10:18:40 2022

@author: Richie Bao-caDesign设计(cadesign.cn)
"""
def G_L_spatial_autocorrelation_batch(TN,contiguity_w='queen',transform='r',num=25):
    '''
    批量计算全局和局部空间自相关系数，返回判断信息。

    Parameters
    ----------
    TN : Dict
        数据字段，包含数据库表名.
    contiguity_w : String , optional
        空间权重，包括queen, rook或knn. The default is 'queen'.
    transform : String, optional
        配置权重值变换. The default is 'r'.
    num : int, optional
        满足有效值数量，才进行计算. The default is 25.

    Returns
    -------
    info_dict : Dict
        计算结果信息.

    '''
    sys.path.append('..')
    from database import postSQL2gpd
    import spatio_temporal_analysis as sta
    
    info_dict={}
    for name,tn in TN.items():
        gdf=postSQL2gpd(table_name=tn,geom_col=GC,myusername=UN,mypassword=PW,mydatabase=DB)
        Y_columns=[col for col in gdf.columns if col.split("_")[0]=='Y']
        #全局空间自相关
        G_infoList=[]
        for YCol in Y_columns:
            G_info=sta.global_spatial_autocorrelation_continuous_case_pts(gdf,YCol,contiguity_w=contiguity_w,transform=transform,num=num)   
            G_infoList.append(G_info)
        #局部空间自相关        
        infoList_Y=sta.local_spatial_autocorrelation_batch(gdf,Y_columns)
            
        M_columns=[col for col in gdf if col.split("_")[0]=='M']
        infoList_M=sta.local_spatial_autocorrelation_batch(gdf,M_columns)
    
        W_columns=[col for col in gdf.columns if col.split("_")[0]=='W']
        infoList_W=sta.local_spatial_autocorrelation_batch(gdf,W_columns)
        info_dict[name]={"GI":G_infoList,"LI":{"Y":infoList_Y,"M":infoList_M,"W":infoList_W}}
    print("_"*50,"\n",info_dict)
    return info_dict

if __name__=="__main__":
    import sys
    sys.path.append('..')
    import util    
    import geopandas as gpd
    import pandas as pd
    import os
    import pickle
    from database import postSQL2gpd,gpd2postSQL,cfg_load_yaml  
    from glob import glob
    import time_series_analysis as tsa
    from datetime import datetime
    import spatio_temporal_analysis as sta
    parent_path=os.path.dirname(os.getcwd())
    
    cfg=cfg_load_yaml('../config.yml')  
    UN=cfg["postgreSQL"]["myusername"]
    PW=cfg["postgreSQL"]["mypassword"]
    DB=cfg["postgreSQL"]["mydatabase"] 
    GC='geometry' 
    
    air_sensor_category_save_fp=cfg['analysis_air']['air_sensor_category_save_fp']    
    
    #A_1. co-读取数据      
    air_co_resample_value_hrf_gdf=postSQL2gpd(table_name='air_co_resample_value_hrf',geom_col=GC,myusername=UN,mypassword=PW,mydatabase=DB)
    
    #A_2 将点数据转换为Voronoi区域（Polygon）数据
    air_co_region_gdf=sta.pts2voronoi_polygons(air_co_resample_value_hrf_gdf,epsg=4326,show=True)
    #A_3 Y(年均值)-处理空值
    sta.isnull_fillna_column(air_co_region_gdf,'Y_2018-12-31',k=5)
    #A_4 Y-配置空间权重（Spatial Similarity）和属性权重（Attribute Similarity）
    air_co_region_Y_lag_gdf=sta.spatial_lag(air_co_region_gdf,'queen','Y_2018-12-31',show=True)
    # #A_5 Y-全局空间自相关-二值模式（Binary Case ）
    sta.global_spatial_autocorrelation_binary_case(air_co_region_gdf,'Y_2018-12-31')
    #A_6 Y-全局空间自相关-连续值模式（Continuous Case ）
    sta.global_spatial_autocorrelation_continuous_case(air_co_region_gdf,'Y_2018-12-31')
    #A_7 Y-局部空间自相关
    co_Y_columns=[col for col in air_co_region_gdf.columns if col.split("_")[0]=='Y']
    infoList_Y=sta.local_spatial_autocorrelation_batch(air_co_resample_value_hrf_gdf,co_Y_columns)
    print("_"*50,'\n',infoList_Y)    
        
    co_M_columns=[col for col in air_co_region_gdf.columns if col.split("_")[0]=='M']
    infoList_M=sta.local_spatial_autocorrelation_batch(air_co_resample_value_hrf_gdf,co_M_columns)
    print("_"*50,'\n',infoList_M)

    co_W_columns=[col for col in air_co_region_gdf.columns if col.split("_")[0]=='W']
    infoList_W=sta.local_spatial_autocorrelation_batch(air_co_resample_value_hrf_gdf,co_W_columns)
    print("_"*50,'\n',infoList_W)
    
    #B. CO,H2S,NO2,O3,SO2,oxidizing gases,reducing gases 批量计算全局空间自相关-连续值模式和局部空间自相关（Y,M,W）
    TN={"CO":"air_co_resample_value_hrf",
        "H2S":'air_h2s_resample_value_hrf',
        'NO2':'air_no2_resample_value_hrf',
        'O3':'air_o3_resample_value_hrf',
        'SO2':'air_so2_resample_value_hrf',
        'oxidizing_gases':'air_oxidizing_gases_resample_value_hrf',
        'reducing_gases':'air_reducing_gases_resample_value_hrf'}
    
    G_L_spatial_autocorrelation_batch(TN)    
```

###### 5) 区域统计与复相关性分析（回归分析）

复相关性分析，使用[statsmodels.formula.api.ols](https://www.statsmodels.org/devel/generated/statsmodels.formula.api.ols.html)，即[Ordinary Least Squares, OLS](https://en.wikipedia.org/wiki/Ordinary_least_squares)普通最小二乘法构建多元线性回归模型。其中，因变量（结果变量）$Y$值配置为气体的ppm年均值，自变量（解释变量）$X$配置为各个测量点位给定缓冲区内土地利用栅格数据分类数据频数统计值（包含56个土地利用分类），建筑高度数据（层数），建筑高度数据，植被（高中低）数据等。

土地利用、建筑高度、道路中线等原始数据为.shp格式文件，定义矢量数据转栅格数据函数，`create_multiband_raster（）`为主程序函数，栅格大小配置为(5,5)。区域统计(Zonal statistics)调用[rasterstats](https://pythonhosted.org/rasterstats/)提供的[zonal_stats](https://pythonhosted.org/rasterstats/rasterstats.html?highlight=zonal_stats#rasterstats.zonal_stats)方法计算。该方法中并未提供频数统计计算功能，通过`add_stats`参数调用自定义`frequency()`函数实现。植被（高中低）数据为点云数据处理部分已经处理后的栅格数据，精度为(0.3,0.3)。

首先，计算土地利用、建筑高度、道路和植被与各类气体（CO、H2S、NO2、O3、SO2、oxidizing_gases和reducing_gases），在缓冲距离为`range(10,1500,20)`即[10, 30, 50, 70, 90, 110, 130, 150, 170, 190, 210, 230, 250, 270, 290, 310, 330, 350, 370, 390, 410, 430, 450, 470, 490, 510, 530, 550, 570, 590, 610, 630, 650, 670, 690, 710, 730, 750, 770, 790, 810, 830, 850, 870, 890, 910, 930, 950, 970, 990, 1010, 1030, 1050, 1070, 1090, 1110, 1130, 1150, 1170, 1190, 1210, 1230, 1250, 1270, 1290, 1310, 1330, 1350, 1370, 1390, 1410, 1430, 1450, 1470, 1490]，75个缓冲距离时与气体年度ppm均值的OLS回归模型。提取ADJ. R-squared (调整）决定系数，打印为箱型图，观察数值结果。从结果判断，城市内污染气体与土地利用频数存在较高的决定系数值，当缓冲距离达到一定程度，值基本稳定在0.9左右。与建筑高度、道路和植被的关系基本为无，决定系数的值基本不超过0.1。

__Fig. 土地利用及建筑高度、道路和植被OLS回归模型的 Adj. R-squared （调整）决定系数值分布__

<img src="./imgs/3_3_2_77.png" height="auto" width="auto" title="caDesign">

然后， 通过Adj. R-squared值分布，确定土地利用与污染气体浓度存在相关性之后，需要确定土地利用不同缓冲区采样结果对各类气体的影响，即空间范围的影响。观察Adj. R-squared 缓冲区变化值，H2S、SO2和oxidizing_gases三类气体有少许波动，但基本呈现逐步上升趋势，并达到稳定的决定系数值。CO、O3、NO2和reducing_gases四类气体线随缓冲距离的增加而下降后波动，并达到稳定。从数据判断，各类气体浓度与土地利用频数建立的回归模型决定系数基本稳定的缓冲距离分别为`{'oxidizing_gases':430,'SO2':530, 'NO2':610, 'CO':830, 'H2S':850, 'reducing_gases':850 'O3':930, }`。较小的缓冲距离一定程度上表明，对该类气体影响的土地类型出现频率相对频繁；而较大的缓冲距离一定程度上表明对该类气体影响的土地类型出现频率相对稀少。

__Fig. Adj. R-squared 缓冲区变化值__

<img src="./imgs/3_3_2_78.png" height="auto" width="auto" title="caDesign">

进一步，需要提取土地利用即解释变量的回归系数，从系数的大小可以粗略判断各类土地利用类型对各类不同气体影响的程度。除了使用热力图的方式查看土地利用系数（标注p_value值域）外 ，同时排序系数大小提取正相关（系数正值）、负相关（系数负值）和基本不相关（取绝对值，趋于0的值）的各5个值查看。例如对于CO，正相关影响一氧化碳主要的土地用地类型包括：Aircraft_Transportation，Open_Space_Primarily_Conservation，Under_Construction_Residential，Stormwater_Management和Government_Administration_and_Services等；负相关的包括：Other_Vacant，Urban_Mix_w_Residential_Component，Medical_Facilities，Office和Single_Large_Site_Retail等；而基本不相干的土地利用类型有：Golf_Course，Under_Construction_Industrial，Other_Institutional，Roadway和General_Industrial等。

__Fig. 基于缓冲距离回归模型稳定状态下，土地利用系数热力图。含p_value（$***$，$**$，$*$）标识，($*$)为小于0.05而大于等于0.01，($**$)为小于0.01而大于等于0.001，($***$)为小于0.001__

<img src="./imgs/3_3_2_80.png" height="auto" width="auto" title="caDesign">

__Table. OLS回归系数大小排序（正相关，负相关，不相关）__

| CO_830                                 |             |                                   |             |                               |                 | H2S_850               |              |                                        |              |                                                        |                  | NO2_610                       |              |                                   |              |                                   |                  | O3_930                  |             |                                   |             |                                        |                 | SO2_530                           |              |                                    |              |                               |                  | oxidizing_gases_430                   |                          |                                                |                          |                                 |                              | reducing_gases_850                     |                         |                                |                         |                                   |                             |
|----------------------------------------|-------------|-----------------------------------|-------------|-------------------------------|-----------------|-----------------------|--------------|----------------------------------------|--------------|--------------------------------------------------------|------------------|-------------------------------|--------------|-----------------------------------|--------------|-----------------------------------|------------------|-------------------------|-------------|-----------------------------------|-------------|----------------------------------------|-----------------|-----------------------------------|--------------|------------------------------------|--------------|-------------------------------|------------------|---------------------------------------|--------------------------|------------------------------------------------|--------------------------|---------------------------------|------------------------------|----------------------------------------|-------------------------|--------------------------------|-------------------------|-----------------------------------|-----------------------------|
| head_CO_830_LU                         | head_CO_830 | tail_CO_830_LU                    | tail_CO_830 | abs_tail_CO_830_LU            | abs_tail_CO_830 | head_H2S_850_LU       | head_H2S_850 | tail_H2S_850_LU                        | tail_H2S_850 | abs_tail_H2S_850_LU                                    | abs_tail_H2S_850 | head_NO2_610_LU               | head_NO2_610 | tail_NO2_610_LU                   | tail_NO2_610 | abs_tail_NO2_610_LU               | abs_tail_NO2_610 | head_O3_930_LU          | head_O3_930 | tail_O3_930_LU                    | tail_O3_930 | abs_tail_O3_930_LU                     | abs_tail_O3_930 | head_SO2_530_LU                   | head_SO2_530 | tail_SO2_530_LU                    | tail_SO2_530 | abs_tail_SO2_530_LU           | abs_tail_SO2_530 | head_oxidizing_gases_430_LU           | head_oxidizing_gases_430 | tail_oxidizing_gases_430_LU                    | tail_oxidizing_gases_430 | abs_tail_oxidizing_gases_430_LU | abs_tail_oxidizing_gases_430 | head_reducing_gases_850_LU             | head_reducing_gases_850 | tail_reducing_gases_850_LU     | tail_reducing_gases_850 | abs_tail_reducing_gases_850_LU    | abs_tail_reducing_gases_850 |
|                                        |             |                                   |             |                               |                 |                       |              |                                        |              |                                                        |                  |                               |              |                                   |              |                                   |                  |                         |             |                                   |             |                                        |                 |                                   |              |                                    |              |                               |                  |                                       |                          |                                                |                          |                                 |                              |                                        |                         |                                |                         |                                   |                             |
| Aircraft_Transportation                | 50.777      | Single_Large_Site_Retail          | -18.591     | General_Industrial            | 1.183           | AGRICULTURE           | 77.449       | Intermodal_Facility                    | -12.682      | Other_Linear_Transportation_with_Associated_Facilities | 1.38             | Other_Vacant                  | 101.499      | Hotel_Motel                       | -57.225      | Water                             | 1.53             | Golf_Course             | 98.982      | Urban_Mix_w_Residential_Component | -23.174     | Under_Construction_Commercial          | 0.894           | Open_Space_Primarily_Conservation | 1.26         | Communication                      | -0.189       | Flex_or_Indeterminate         | 0.009            | Single_Family_Detached                | 7.56                     | Hotel_Motel                                    | -0.491                   | Rail_ROW                        | 0.209                        | Golf_Course                            | 1845.653                | Independent_Automobile_Parking | -275.621                | Single_Family_Attached            | 5.924                       |
| Open_Space_Primarily_Conservation      | 43.739      | Office                            | -24.449     | Roadway                       | 0.956           | Stormwater_Management | 63.791       | Urban_Mix                              | -14.104      | Common_Open_Space_in_a_Residential_Development         | 0.861            | Under_Construction_Commercial | 71.748       | Open_Space_Primarily_Recreation   | -61.294      | Regional_Community_Retail_Centers | 1.243            | Aircraft_Transportation | 57.249      | Not_Classifiable                  | -37.49      | Government_Administration_and_Services | 0.399           | Trail_or_Greenway                 | 0.911        | Utility_Right_of_Way               | -0.212       | Warehousing_Distribution      | 0.008            | Post_Secondary_Educational_Facilities | 7.133                    | Common_Open_Space_in_a_Residential_Development | -0.594                   | Other_Institutional             | 0.194                        | Aircraft_Transportation                | 702.276                 | Hotel_Motel                    | -277.002                | K_12_Educational_Facilities       | 4.974                       |
| Under_Construction_Residential         | 38.241      | Medical_Facilities                | -35.38      | Other_Institutional           | 0.525           | Golf_Course           | 24.116       | Water                                  | -17.571      | Flex_or_Indeterminate                                  | 0.574            | Utility_Right_of_Way          | 28.197       | Cultural_Entertainment            | -75.403      | Roadway                           | 1.031            | Stormwater_Management   | 48.941      | Trail_or_Greenway                 | -45.993     | Single_Family_Detached                 | 0.343           | Storage                           | 0.304        | Prison_and_Correctional_Facilities | -0.227       | Medical_Facilities            | 0.004            | Open_Space_Primarily_Recreation       | 6.562                    | Communication                                  | -0.641                   | Under_Construction_Industrial   | 0                            | Not_Classifiable                       | 531.893                 | Stormwater_Management          | -286.303                | Regional_Community_Retail_Centers | 2.563                       |
| Stormwater_Management                  | 36.021      | Urban_Mix_w_Residential_Component | -56.08      | Under_Construction_Industrial | 0               | Hotel_Motel           | 17.171       | Government_Administration_and_Services | -21.043      | Storage                                                | 0.536            | Trail_or_Greenway             | 22.804       | Aircraft_Transportation           | -104.861     | Under_Construction_Industrial     | 0                | Other_Utility_Waste     | 41.346      | Utility_Right_of_Way              | -55.337     | Post_Secondary_Educational_Facilities  | 0.224           | Single_Family_Detached            | 0.285        | Other_Vacant                       | -0.232       | Golf_Course                   | 0                | Multi_Family                          | 5.038                    | Prison_and_Correctional_Facilities             | -0.785                   | Trail_or_Greenway               | 0                            | Other_Vacant                           | 516.38                  | AGRICULTURE                    | -697.256                | Rail_ROW                          | 1.828                       |
| Government_Administration_and_Services | 33.198      | Other_Vacant                      | -64.439     | Golf_Course                   | 0               | Utility_Right_of_Way  | 14.517       | Not_Classifiable                       | -71.238      | Under_Construction_Industrial                          | 0.041            | Other_Institutional           | 21.298       | Open_Space_Primarily_Conservation | -169.047     | Golf_Course                       | 0                | Water                   | 28.16       | Intermodal_Facility               | -118.604    | Wastewater_Treatment_Facility          | 0               | Vacant_Industrial_Land            | 0.275        | Water                              | -0.606       | Under_Construction_Industrial | 0                | Open_Space_Primarily_Conservation     | 4.727                    | Under_Construction_Commercial                  | -2.474                   | Golf_Course                     | 0                            | Government_Administration_and_Services | 490.92                  | Intermodal_Facility            | -2070.493               | Roadway                           | 1.322                       |

为直观的观察土地利用类型对不同气体的影响幅度及正负相关关系，以分组柱状图的方式表述。因为不同气体浓度的回归系数大小差异不同，为方便图表查看，将数据标准化，同时要保持正负号所指示正负相关关系，因此要保持符号不变，使用$\frac{X}{ arg max(  | X |)  }  \times n$方法计算，其中$n$为缩放倍数。计算时，为所有列统一标准化，保持列间的数值幅度关系。

__Fig. OLS系数值分布柱状图__

<img src="./imgs/3_3_2_83.png" height="auto" width="auto" title="caDesign">

最后，比较计算特征重要性（贡献值）的几种方法，除了直接使用回归系数外，DecisionTreeRegressor（DF）和Random Forest Regression(RF)等模型包括`model.feature_importances_`属性值，可以直接获取特征重要性指标。

> 注: 不同模型的特征重要性指标存在出入（此处未做解释）

__Fig. RF/RF/OLS Regression Feature Importance (DecisionTreeRegressor/Random Forest Regression) 特征重要性方法计算比较__

|  <img src="./imgs/3_3_2_81.png" height="auto" width="auto" title="caDesign"> |  <img src="./imgs/3_3_2_82.png" height="auto" width="auto" title="caDesign"> |   
|---|---|


`rasterNvector_processing.py`
```python
# -*- coding: utf-8 -*-
"""
Created on Wed May 11 16:24:19 2022

@author: Richie Bao-caDesign设计(cadesign.cn)
"""
def gdf_label_encoder(gdf,columns):
    '''
    给定(Geo)DataFrame数据，指定一个或多个列，转换为整数值编码，增加新列标识符为LB_

    Parameters
    ----------
    gdf : (Geo)DataFrame
        待处理的数据.
    columns : List(String)
        列名列表.

    Returns
    -------
    gdf : (Geo)DataFrame
        返回含编码列的数据.
    lb_mapping_dic : Dict
        编码映射字典.

    '''
    from sklearn.preprocessing import LabelEncoder
    lb_mapping_dic={}
    for col in columns:
        lb_make=LabelEncoder()
        gdf['LB_'+col]=lb_make.fit_transform(gdf[col])
        lb_mapping=dict(zip(lb_make.classes_, lb_make.transform(lb_make.classes_)))
        lb_mapping_dic[col]=lb_mapping
    return gdf,lb_mapping_dic

def rasterize(shp, attrib_name,cellSize=500,dtype='int32'):
    '''
    转换单个vector（polygon或points）shp格式数据为栅格数据

    Parameters
    ----------
    shp : String
        shp格式对象文件路径.
    attrib_name : String
        字段（属性）名.
    cellSize : numerical, optional
        栅格单元大小. The default is 500.
    dtype : String, optional
        数据类型，对应dtype_mapping = {'byte': gdal.GDT_Byte, 'uint8': gdal.GDT_Byte, 'uint16': gdal.GDT_UInt16, 'int8': gdal.GDT_Byte, 'int16': gdal.GDT_Int16, 'int32': gdal.GDT_Int32, 'uint32': gdal.GDT_UInt32, 'float32': gdal.GDT_Float32}. The default is 'int32'.

    Returns
    -------
    temp_out : TIFF
        栅格临时文件.

    '''
    import gdal
    import gdalnumeric as gdn
    import ogr
    import numpy as np
    import tempfile 
    
    #定义空值（没有数据）的栅格数值 Define NoData value of new raster
    NoData_value=-9999
    
    #打开.shp点数据，并返回地理区域范围 Open the data source and read in the extent
    source_ds=ogr.Open(shp)
    source_layer=source_ds.GetLayer()
    x_min, x_max, y_min, y_max=source_layer.GetExtent()
    
    #使用GDAL库建立栅格 Create the destination data source
    x_res=int((x_max - x_min) / cellSize)
    y_res=int((y_max - y_min) / cellSize)    
      
    # create empty raster (.tif) as temporary file and set its projection and extent to
    # that of the reference raster
    temp_out = tempfile.NamedTemporaryFile(suffix='.tif').name
    memory_driver = gdal.GetDriverByName('GTiff')
    dtype_mapping = {'byte': gdal.GDT_Byte, 'uint8': gdal.GDT_Byte, 'uint16': gdal.GDT_UInt16, 'int8': gdal.GDT_Byte, 'int16': gdal.GDT_Int16, 'int32': gdal.GDT_Int32, 'uint32': gdal.GDT_UInt32, 'float32': gdal.GDT_Float32}
    out_raster_ds = memory_driver.Create(temp_out, x_res, y_res, 1,dtype_mapping[dtype]) #gdal.GDT_Float64;gdal.GDT_Byte
    out_raster_ds.SetGeoTransform((x_min, cellSize, 0, y_max, 0, -cellSize))
    outband=out_raster_ds.GetRasterBand(1)
    outband.SetNoDataValue(NoData_value)

    # open shapefile vector layer to retrieve and burn attribute into the empty raster
    gdal.RasterizeLayer(out_raster_ds, [1], source_layer, options=["ATTRIBUTE="+attrib_name])
    return temp_out 

def img_to_array(input_file, dim_ordering="channel_last", dtype="float32"):
    '''
    将栅格文件各层栅格值转换为（numpy）数组

    Parameters
    ----------
    input_file : TIFF
        栅格文件.
    dim_ordering : String, optional
        调整波段位置. The default is "channel_last".
    dtype : Strng, optional
        栅格存储数据类型. The default is "float32".

    Returns
    -------
    arr : numpy.ndarray
        各层的栅格单元值.

    '''
    import gdal
    import numpy as np
    import gdalnumeric as gdn
    # open input raster, retrieve bands and convert to image array
    file = gdal.Open(input_file)
    bands = [file.GetRasterBand(i) for i in range(1, file.RasterCount +1)]
    arr = np.array([gdn.BandReadAsArray(band) for band in bands]).astype(dtype)
    
    # reoder dimensions so that channels/bands are last
    if dim_ordering=="channel_last": arr = np.transpose(arr, [1,2,0])
    return arr 

# landuse_fn=cfg['raw_data']['landuse_fn']
# temp_out=rasterize(landuse_fn, "3",cellSize=500)

def array_to_tif(array,inVector, dst_filename,cellSize=500):
    '''
    将数组（含多个波段值）写入栅格文件

    Parameters
    ----------
    array : numpy.ndarray
        数组形式各层的栅格单元值.
    inVector : String
        shp格式对象文件路径.
    dst_filename : String
        待保存的栅格文件路径.
    cellSize : numerical, optional
        栅格单元大小. The default is 500.

    Returns
    -------
    None.

    '''
    import gdal,ogr
    import os

    # if os.path.exists(dst_filename):
    #     os.remove(dst_filename)
    #     print("The file has been deleted successfully")
    # else:
    #     print("The file does not exist!")    
    
    NoData_value=-9999
    source_ds=ogr.Open(inVector)
    source_layer=source_ds.GetLayer()
    x_min, x_max, y_min, y_max=source_layer.GetExtent()
    x_res=int((x_max - x_min) / cellSize)
    y_res=int((y_max - y_min) / cellSize)      
    proj=source_layer.GetSpatialRef().ExportToWkt()
    # print(proj)
    
    # create empty raster (.tif) to which array will be written
    bands = array.shape[2]
    dtype = str(array.dtype)
    dtype_mapping = {'byte': gdal.GDT_Byte, 'uint8': gdal.GDT_Byte, 'uint16': gdal.GDT_UInt16, 'int8': gdal.GDT_Byte, 'int16': gdal.GDT_Int16, 'int32': gdal.GDT_Int32, 'uint32': gdal.GDT_UInt32, 'float32': gdal.GDT_Float32}
    driver = gdal.GetDriverByName('GTiff')
    output = driver.Create(dst_filename, x_res, y_res, bands, dtype_mapping[dtype])
    # print(output)
    # set output image extent and projection
    output.SetGeoTransform((x_min, cellSize, 0, y_max, 0, -cellSize))
    output.SetProjection(proj)
    
    # write image array into empty raster
    for i in range(bands): output.GetRasterBand(i+1).WriteArray(array[:, :, i])
    output.FlushCache() 


def vectorLayer_attributeNames(shp_fn):
    '''
    返回SHP文件的字段（属性）名

    Parameters
    ----------
    shp_fn : String
        shp格式文件路径.

    Returns
    -------
    final_attribs : List(String)
        包含的字段名.

    '''
    # get vector layer attribute names
    import ogr
    
    source_ds=ogr.Open(shp_fn)
    lyr=source_ds.GetLayer()
    all_attribs=[attrib.name for attrib in lyr.schema]
    final_attribs=[attribs for attribs in all_attribs if attribs not in ['list of attributes to exclude']]
    # print("vector layer attribute names:{}".format(final_attribs))
    
    return final_attribs

def create_multiband_raster(attribs,inVector,dst_filename,cellSize=500,dtype='int32'):
    '''
    vector(SHP,.shp)格式文件转栅格，主程序

    Parameters
    ----------
    attribs : List(String)
        待存储的.shp属性值列表.
    inVector : .shp
        .shp格式文件路径.
    dst_filename : Stirng-TIFF(.tiff)
        栅格保存路径名，通常以.tif为后缀名.
    cellSize : numercial, optional
        栅格单元大小. The default is 500.
    dtype : String, optional
        栅格单元存储数据的类型。dtype_mapping = {'byte': gdal.GDT_Byte, 'uint8': gdal.GDT_Byte, 'uint16': gdal.GDT_UInt16, 'int8': gdal.GDT_Byte, 'int16': gdal.GDT_Int16, 'int32': gdal.GDT_Int32, 'uint32': gdal.GDT_UInt32, 'float32': gdal.GDT_Float32}. The default is 'int32'.

    Returns
    -------
    None.

    '''
    import numpy as np
    #Rasterize: How to create multiband raster from vector attributes using python https://tkawuah.github.io/Blog1.html
    img_array_list=[]
    for i in attribs:    
        fx=rasterize(inVector, i,cellSize=cellSize,dtype=dtype)
        fx_array=img_to_array(fx,dtype=dtype) #dtype=str
        img_array_list.append(fx_array)          
        # break
    fx_multi=np.concatenate(img_array_list, axis=-1)
    array_to_tif(fx_multi,inVector,dst_filename,cellSize=cellSize)  #fx_multi.astype(np.float32)
    print('The raster was written successfully!')
```

`metricsNsampling.py`
```python
# -*- coding: utf-8 -*-
"""
Created on Wed May 11 14:34:00 2022

@author: Richie Bao-caDesign设计(cadesign.cn)
"""
def sampling_rasterBYpts(raster_fn,sampling_gdf,prefix='sample'):
    '''
    给定采样点，用点坐标提取栅格位置值

    Parameters
    ----------
    raster_fn : String
        待采样栅格文件路径.
    sampling_gdf : GeoDataFrame
        含有用于采样的点几何.
    prefix : String, optional
        采样值列名称. The default is 'sample'.

    Returns
    -------
    sampling_vals_gdf : GeoDataFrame
        返回含有采样点栅格值的数据.

    '''
    import rasterio as rio
    
    sampling_vals_gdf=sampling_gdf.copy(deep=True)
    sampling_coords=[(p.x,p.y) for p in sampling_vals_gdf.geometry]
    
    sampling_vals=[]
    with rio.open(raster_fn,'r') as src:
        sampling_vals_gdf['{}_val'.format(prefix)]=[x for x in src.sample(sampling_coords)]
    
    return sampling_vals_gdf

def pts_buffers(pts_gdf,buffer_radius=100):
    '''
    通过采样点建立圆形的缓冲polygon数据

    Parameters
    ----------
    pts_gdf : DataFrame
        含有采样点几何的数据.
    buffer_radius : Numerical, optional
        缓冲圆半径. The default is 100.

    Returns
    -------
    buffer_gdf : GeoDataFrame
        返回含有缓冲区域几何的数据.

    '''
    
    buffer_gdf=pts_gdf.copy(deep=True)
    buffer_gdf['buffer']=buffer_gdf.geometry.apply(lambda row:row.buffer(buffer_radius))
    buffer_gdf.set_geometry('buffer',inplace=True)
    # buffer_gdf.drop(columns=['buffer'],inplace=True)
    return buffer_gdf

def zonal_stats_raster(raster_fn,sampling_zone,band=1,stats=['majority'],add_stats=['frequency'],nodata=-9999):#
    '''
    区域统计，包括['count', 'min', 'max', 'mean', 'sum', 'std', 'median', 'majority', 'minority', 'unique', 'range', 'nodata', 'nan']，以及自定义的'frequency'，即频数统计

    Parameters
    ----------
    raster_fn : String
        待区域统计的栅格数据路径名.
    sampling_zone : GeoDataFrame
        用于栅格区域统计的polygon几何对象.
    band : int, optional
        数据波段. The default is 1.
    stats : List(String), optional
        默认统计的统计量名称. The default is ['majority'].
    add_stats :List(String) , optional
        自定义统计量名. The default is ['frequency'].

    Returns
    -------
    GeoDataFrame
        返回统计量值.

    '''
    import rasterio as rio
    import rasterstats as rst
    import pandas as pd
     
    sampling_zone_copy=sampling_zone.copy(deep=True)
    
    def frequency(x):
        data=x.data[~x.mask]
        return pd.value_counts(data)
    
    add_stats_dict={'frequency':frequency}
    with rio.open(raster_fn,'r') as src:
        band=src.read(band)
        sampling_zone_copy=sampling_zone_copy.to_crs(src.crs)
        zs_result=rst.zonal_stats(sampling_zone_copy,band,nodata=nodata,affine=src.transform,stats=stats,add_stats={i:add_stats_dict[i] for i in add_stats})
    
    for stat in stats:
        sampling_zone_copy[stat]=[dic[stat] for dic in zs_result]
    for stat  in add_stats:
        if stat=='frequency':
            fre=pd.concat([dic[stat].to_frame().T for dic in zs_result])
            fre.rename(columns={col:"{}_{}".format(stat,col) for col in fre.columns},inplace=True)
            fre.reset_index(inplace=True)  
    try:        
        zonal_stats_gdf=pd.concat([sampling_zone_copy,fre],axis=1)   
        
    except:
        zonal_stats_gdf=sampling_zone_copy
    return zonal_stats_gdf
```

`air_sampling_zonal_stats.py`
```python
# -*- coding: utf-8 -*-
"""
Created on Sat May 14 16:34:08 2022

@author: Richie Bao-caDesign设计(cadesign.cn)
"""
def air_stats_data_df_merge(gdf,stats_df,stats_columns,data_columns,on='key',x_option='nosplit'):
    '''
    合并采样值（区域统计量）与空气测量值数据，用于后续相关性分析等

    Parameters
    ----------
    tn : String
        空气测量值数据数据库表名，用于读取数据.
    stats_df : (Geo)DataFrame
        采样值（区域统计量）数据.
    stats_columns : List(String)
        提取用于后续分析的采样值列名.
    data_columns : List(String)
        提取用于后续分析的空气测量值数据列名.
    on : String, optional
        DataFrame数据合并的公共键（列名）. The default is 'key'.

    Returns
    -------
    correlation_gdf : (Geo)DataFrame
        合并后的数据.

    '''
    # sys.path.append('..')
    # from database import postSQL2gpd
    # gdf=postSQL2gpd(table_name=tn,geom_col=GC,myusername=UN,mypassword=PW,mydatabase=DB)
    concat_gdf=pd.merge(gdf,stats_df,on=on)
    if x_option=='split':
        stats_columns_=[col for col in stats_df.columns if col.split("_")[0] in stats_columns]        
    elif x_option=='nosplit':
        stats_columns_=[col for col in stats_df.columns if col in stats_columns]
    data_columns_=[col for col in gdf.columns if col.split("_")[0] in data_columns]
    correlation_gdf=concat_gdf[stats_columns_+data_columns_]     
    
    return correlation_gdf

def air_stats_correlation(TN,stats_df,stats_columns,data_columns,on='key',null_replacement_value=None,method='pearson'): 
    '''
    相关性分析，包括‘pearson’和 ‘spearman’两种方法，返回相关系数及p_value值

    Parameters
    ----------
    TN : dict(String)
        空气测量值数据库表名.
    stats_df : (Geo)DataFrame
        采样值（区域统计量）数据.
    stats_columns : List(String)
        提取用于后续分析的采样值列名.
    data_columns : List(String)
        提取用于后续分析的空气测量值数据列名.
    on : String, optional
        DataFrame数据合并的公共键（列名）.. The default is 'key'.
    null_replacement_value : numerical, string etc., optional
        空值替换值. The default is None.
    method : String, optional
        ‘pearson’和 ‘spearman’两种方法. The default is 'pearson'.

    Returns
    -------
    info_dict : dict
        返回相关系数和p_value值.

    '''
    import seaborn as sns
    from matplotlib import pyplot as plt
    from scipy.stats import pearsonr
    import numpy as np
    from scipy import stats

    sys.path.append('..')
    from database import postSQL2gpd

    info_dict={}
    for name,tn in TN.items():
        correlation_gdf_=air_stats_data_df_merge(tn,stats_df,stats_columns,data_columns,on=on)
        p_corr_dict={}
        if null_replacement_value is None:
            i=0
            for x in correlation_gdf_.columns:
                for y in correlation_gdf_.columns:
                    df_2=correlation_gdf_[[x,y]]
                    df_2.dropna(inplace=True)
                    if len(df_2)>10:
                        if method=='pearson':
                            corr=stats.pearsonr(df_2.iloc[:,[0]].squeeze(),df_2.iloc[:,[1]].squeeze())
                        elif method=='spearman':
                            corr=stats.spearmanr(df_2.iloc[:,[0]].squeeze(),df_2.iloc[:,[1]].squeeze())
                        p_corr_dict[x+':'+y]=[corr[0],corr[1]]
                i+=1
                if i==1:break
            info_dict[name]=p_corr_dict

        elif null_replacement_value is not None:
            correlation_gdf_.fillna(null_replacement_value,inplace=True)
            df_corr=pd.DataFrame() # Correlation matrix
            df_p=pd.DataFrame()  # Matrix of p-values
            for x in correlation_gdf_.columns:
                for y in correlation_gdf_.columns:
                    if method=='pearson':
                        corr=stats.pearsonr(correlation_gdf_[x], correlation_gdf_[y])
                    elif method=='spearman':
                        corr=stats.spearmanr(correlation_gdf_[x], correlation_gdf_[y])
                    df_corr.loc[x,y]=corr[0]
                    df_p.loc[x,y]=corr[1]  
            info_dict[name]={"p_value":df_p,'correlation':df_corr}

    return info_dict

def df_normalize(df,feature_range=(-1, 1)):
    '''
    对DataFrame格式数据，逐列执行标准化

    Parameters
    ----------
    df : DataFrame
        待执行标准化的数据.
    feature_range : tuple, optional
        标准化后的数值范围. The default is (-1, 1).

    Returns
    -------
    result : DataFrame
        逐列标准化后的数据.
    '''
    from sklearn.preprocessing import MinMaxScaler
    scaler=MinMaxScaler(feature_range=feature_range)
    
    result = df.copy()
    for feature_name in df.columns:
        # max_value=df[feature_name].max()
        # min_value=df[feature_name].min()
        # result[feature_name]=(df[feature_name] - min_value) / (max_value - min_value)
        result[feature_name]=scaler.fit_transform(df[[feature_name]])
    return result

def air_OLS_regresssion_df(TN,tn_dict,stats_df,stats_columns,data_columns,y_column_name,x_column_names,on='key',null_replacement_value=None,PCA_bool=False,std_bool=False,feature_range=(-1, 1),x_option='nosplit'):
    '''
    偏相关|复相关分析（复相关系数）-OLS Regression分析

    Parameters
    ----------
    TN :dict(String)
        空气测量值数据库表名.
    stats_df :  (Geo)DataFrame
        采样值（区域统计量）数据.
    stats_columns : List(String)
        提取用于后续分析的采样值列名.
    data_columns : List(String)
        提取用于后续分析的空气测量值数据列名.
    y_column_name : String
        因变量/结果变量/Y值.
    x_column_names : List(String)
        自变量/解释变量/X值.
    on : String, optional
        DataFrame数据合并的公共键（列名）. The default is 'key'.
    null_replacement_value : numerical, string etc., optional
        空值替换值. The default is None.
    PCA_bool : bool, optional
        是否执行PCA主成分分析降维. The default is False.
    std_bool : bool, optional
        是否数据标准化. The default is True.

    Returns
    -------
    info_dict : dict
        返回相关系数模型.

    '''
    from statsmodels.formula.api import ols   
    import statsmodels.api as sm
    from sklearn.linear_model import LinearRegression
    from statsmodels.multivariate.pca import PCA
    from sklearn.preprocessing import StandardScaler

    info_dict={}
    correlation_gdf_dict={}
    for name,tn in TN.items():
        gdf=tn_dict[name]
        correlation_gdf=air_stats_data_df_merge(gdf,stats_df,stats_columns,data_columns,on=on,x_option=x_option)  
        
        # print(correlation_gdf.dtypes)
        if null_replacement_value is not None:
            correlation_gdf.fillna(null_replacement_value,inplace=True)
        # print(correlation_gdf)    
        # print(correlation_gdf.columns)
        if x_option=='split':
            x_nList=[col for col in correlation_gdf.columns if col.split("_")[0] in x_column_names]      
        elif x_option=='nosplit':
            x_nList=[col for col in correlation_gdf.columns if col in x_column_names]   
        # x_nList=[col for col in correlation_gdf.columns if col.split("_")[0] in x_column_names]
        # print("_"*50)
        # print(x_nList)
        if PCA_bool:
            x_pca=PCA(correlation_gdf[x_nList].to_numpy(),standardize=False)#ncomp=5,
            model=sm.OLS(correlation_gdf[y_column_name],x_pca.factors).fit()
            info_dict[name]=model
            correlation_gdf_dict[name]=x_pca
        else:
            x_n_string=" + ".join(x_nList)
            if std_bool=='all':
                scaler=StandardScaler()
                correlation_gdf_=correlation_gdf.copy(deep=True)
                correlation_std_gdf=pd.DataFrame(scaler.fit_transform(correlation_gdf_),columns=correlation_gdf_.columns)                
                model=ols('Q("{}") ~ {}'.format(y_column_name,x_n_string), data=correlation_std_gdf).fit()
                correlation_gdf_dict[name]=correlation_std_gdf
            elif std_bool=='column':
                correlation_std_gdf=df_normalize(correlation_gdf,feature_range)                
                model=ols('Q("{}") ~ {}'.format(y_column_name,x_n_string), data=correlation_std_gdf).fit()    
                correlation_gdf_dict[name]=correlation_std_gdf
            else:
                model=ols('Q("{}") ~ {}'.format(y_column_name,x_n_string), data=correlation_gdf).fit()
                correlation_gdf_dict[name]=correlation_gdf
            # print(model.params)
            # print(model.summary())
            info_dict[name]=model          
        
    return info_dict,correlation_gdf_dict

def air_buffer_changes_correlation_OLS(pts_gdf,buffer_radius_range,raster_fn,TN,stats_columns,data_columns,y_column_name,x_column_names,on,null_replacement_value=0,band=1,stats=['majority'],add_stats=['frequency']):
    '''
    连续变化缓冲区下的OLS复相关分析

    Parameters
    ----------
    pts_gdf : GeoDataFrame
        含有采样点几何的数据.
    buffer_radius_range : Numerical
        连续变化缓冲区区间[start,stop,step].
    raster_fn : String
        待区域统计的栅格数据路径名.
    TN : dict(String)
        空气测量值数据库表名.
    stats_columns : List(String)
        提取用于后续分析的采样值列名.
    data_columns : List(String)
        提取用于后续分析的空气测量值数据列名.
    y_column_name : String
        因变量/结果变量/Y值.
    x_column_names : List(String)
        自变量/解释变量/X值.
    on : String
        DataFrame数据合并的公共键（列名）.
    null_replacement_value : numerical, string etc., optional
        空值替换值. The default is 0.
    band : nt, optional
        数据波段.. The default is 1.
    stats : List(String), optional
        默认统计的统计量名称. The default is ['majority'].
    add_stats : List(String), optional
        自定义统计量名. The default is ['frequency'].

    Returns
    -------
    info_dict : dict
        返回各个缓冲区提取栅格的区域统计值与空气测量值的回归分析结果，包括参数值和（修正）决定系数.

    '''
    from tqdm import tqdm
    import metricsNsampling as mNs
    
    buffer_radius_list=list(range(buffer_radius_range[0],buffer_radius_range[1],buffer_radius_range[2]))
    print(buffer_radius_list)
    TN_name=list(TN.keys())
    info_dict={}
    landuse_ols_model_dict={}
    for buffer_radius in tqdm(buffer_radius_list):
        sampling_buffer=mNs.pts_buffers(pts_gdf,buffer_radius)
        zonal_stats_landuse_gdf=mNs.zonal_stats_raster(raster_fn,sampling_buffer,band,stats,add_stats)
        landuse_ols_model=air_OLS_regresssion_df(TN,zonal_stats_landuse_gdf,stats_columns,data_columns,y_column_name,x_column_names,on,null_replacement_value)
        landuse_ols_model_dict[buffer_radius]=landuse_ols_model
        
        for t in TN_name:
            model=landuse_ols_model[t]
            params=model.params
            rsquared=model.rsquared
            rsquared_adj=model.rsquared_adj
            
            info_dict["{}_{}".format(buffer_radius,t)]={"params":params,"rsquared":rsquared,"rsquared_adj":rsquared_adj}
            # break
        # print()
        # break
    return info_dict,landuse_ols_model_dict

def air_buffer_changes_correlation_OLS_stats(air_buffer_changes_OLS_dict,landuse_LB_mapping_name):
    '''
    连续变化缓冲区下的复相关分析结果数据整理，把同一类型气体归于同一DataFrame数据下，及对应的（修正）决定系数值，方法观察值变化

    Parameters
    ----------
    air_buffer_changes_OLS_dict : dict
        各个缓冲区提取栅格的区域统计值与空气测量值的回归分析结果.
    landuse_LB_mapping_name : dict
        用地类型名称与标签映射值.

    Returns
    -------
    info_dict : dict
        归类梳理后的数据.

    '''
    import numpy as np
    import pandas as pd
    # print(air_buffer_changes_OLS_dict)
    Name_Label_mapping={v:k for k,v in landuse_LB_mapping_name.items()}
    # print(Name_Lable_mapping)
    
    d_type=list(air_buffer_changes_OLS_dict.keys())
    distanceList=np.unique([int(i.split("_")[0]) for i in d_type])
    gas_typeList=np.unique([i.split("_")[-1] for i in d_type])
    # print(gas_typeList)
    key_df=pd.Series(air_buffer_changes_OLS_dict.keys()).to_frame(name='keys')
    # print(key_df.keys)
    key_df['type']=key_df['keys'].apply(lambda row:"_".join(row.split("_")[1:]))
    key_df['distance']=key_df['keys'].apply(lambda row:int(row.split("_")[0]))
    type_group=key_df.groupby("type")['keys'].agg(list)
    # print(type_group)     
    info_dict={}
    for idx,val in type_group.items():
        # print(idx)
        valList=[air_buffer_changes_OLS_dict[key]['params'].to_frame(name=key) for key in val]        
        val_df=pd.concat(valList,axis=1)
        val_df.drop(['Intercept'],axis=0,inplace=True)
        index_Label_mapping={idx:Name_Label_mapping[int(idx.split("_")[-1])] for idx in val_df.index}
        # print(index_Label_mapping)
        val_df.rename(index=index_Label_mapping,inplace=True)
        rsquared_dict={key:{'rsquared':air_buffer_changes_OLS_dict[key]['rsquared'],'rsquared_adj':air_buffer_changes_OLS_dict[key]['rsquared_adj']} for key in val}
        rsquared_df=pd.DataFrame.from_dict(rsquared_dict,orient='index')
        # print(rsquared_df.head(50))
        info_dict[idx]={'params':val_df,'rsquared':rsquared_df}
    
    return info_dict

def raster_zonal_stats(pts_gdf,buffer_radius_range,rasterFNS_params_dict):
    '''
    多个栅格，多个缓冲距离采样栅格数据，并区域统计

    Parameters
    ----------
    pts_gdf : DataFrame
        含有采样点几何的数据..
    buffer_radius_range : list(int)
        缓冲圆半径列表.
    rasterFNS_params_dict : dict
        采样参数字典，{索引：[栅格路径名,采样波段,空值,统计方法,自定义统计方法]}.

    Returns
    -------
    zonal_stats_dict : dict(df)
        多个栅格多个缓冲距离，给定统计方法返回统计结果字典.

    '''
    from tqdm import tqdm
    import metricsNsampling as mNs
    
    buffer_radius_list=list(range(buffer_radius_range[0],buffer_radius_range[1],buffer_radius_range[2]))
    print(buffer_radius_list)

    zonal_stats_dict={}
    for buffer_radius in tqdm(buffer_radius_list):
        sampling_buffer=mNs.pts_buffers(pts_gdf,buffer_radius)
        buffer_result_dict={}
        for k,v in rasterFNS_params_dict.items():
            zonal_stats_landuse_gdf=mNs.zonal_stats_raster(v[0],sampling_buffer,v[1],stats=v[3],add_stats=v[4],nodata=v[2])    
            buffer_result_dict[k]=zonal_stats_landuse_gdf
            # if k==2:break         
        zonal_stats_dict[buffer_radius]=buffer_result_dict
        # if buffer_radius==100:break
    return zonal_stats_dict

def zonal_stats_dict_concat(zonal_stats_dict):
    '''
    处理函数raster_zonal_stats()的返回结果，合并同一缓冲距离下的统计数据为一个DataFrame文件

    Parameters
    ----------
    zonal_stats_dict : dict(DataFrame)
        raster_zonal_stats()的返回结果.

    Returns
    -------
    zonal_stats_concat_dict : dict(DataFrame)
        按距离合并后的区域统计数据.

    '''
    import pandas as pd
    from functools import reduce
    
    zonal_stats_concat_dict={}
    for k,v in zonal_stats_dict.items():
        v_sub_lst=[]
        for k_p,v_p in rasterFNS_params_dict.items():
            v_sub=v[k_p]
            columns_rename_dict={i:i+"_{}".format(k_p) for i in v_sub.columns if i.split("_")[0] in v_p[-1]+v_p[-2]}
            # print(columns_rename_dict)
            v_sub_=v_sub.rename(columns=columns_rename_dict)
            
            # print(v_sub_)            
            v_sub_lst.append(v_sub_[list(columns_rename_dict.values())+['node_id']])
        # print(v_sub_lst)
        v_sub_concat=reduce(lambda left,right: pd.merge(left,right,on=['node_id'],how='outer'), v_sub_lst)
        # print(v_sub_concat.columns)
        zonal_stats_concat_dict[k]=v_sub_concat
        
        # break
    return zonal_stats_concat_dict

def air_buffer_changes_correlation_OLS_factors(TN_air,zonal_stats_concat_dict,factors_dict,buffer_radius,feature_range=(0,1)):
    '''
    类似air_buffer_changes_correlation_OLS，该函数包括多个影响影子统一计算

    Parameters
    ----------
    TN_air :dict(String)
        空气测量值数据库表名.
    zonal_stats_concat_dict : dict
        包含多个影响因子的采样-区域统计结果.
    factors_dict : dict
        各个影响因子对应的统计值及提取DataFrame列的方法选择（split or nosplit）.
    buffer_radius : list(int)
        缓冲半径列表.
    feature_range : tuple(numerical), optional
        标准化区间. The default is (0,1).

    Returns
    -------
    model_dict : dict(model)
        OLS模型列表.
    data_dict : dict(DataFrame)
        用于回归计算的解释变量及结果变量.
    rsquaredADJ_dict : dict(float)
        决定系数(adj).

    '''
    from tqdm import tqdm
    import numpy as np    
    sys.path.append('..')
    from database import postSQL2gpd
    
    tn_dict={}
    for name,tn in TN_air.items():
        tn_dict[name]=postSQL2gpd(table_name=tn,geom_col=GC,myusername=UN,mypassword=PW,mydatabase=DB)
    
    model_dict={}
    data_dict={}
    rsquaredADJ_dict={}
    for k_name,k_factors in tqdm(factors_dict.items()):
        factors=k_factors[0]
        x_option=k_factors[1]
        model_temp={}
        data_temp={}
        rsquared_results={}
        for br in buffer_radius:
            zonal_stats_br=zonal_stats_concat_dict[br]
            model_dict_,data_dict_=air_OLS_regresssion_df(TN_air,tn_dict,zonal_stats_br,stats_columns=factors,data_columns=['Y'],
                                       y_column_name='Y_2018-12-31',x_column_names=factors,on='node_id',null_replacement_value=0,std_bool='column',x_option=x_option,feature_range=feature_range)
            rsquaredADJ_lst={}
            for k,v in model_dict_.items():
                # print("_"*50)
                # print(k,v.summary())
                # print(v.rsquared_adj)
                rsquaredADJ_lst[k]=v.rsquared_adj
            rsquared_results[br]=rsquaredADJ_lst  
            model_temp[br]=model_dict_
            data_temp[br]=data_dict_

        rsquaredADJ_dict[k_name]=rsquared_results
        model_dict[k_name]=model_temp
        data_dict[k_name]=data_temp

    return model_dict,data_dict,rsquaredADJ_dict

def rsquaredADJ_boxplot(rsquaredADJ_dict):
    '''
    打印每类影响因子['landuse', 'BuildingHeight', 'street', 'HighVegetation', 'MediumVegetation', 'LowVegetation']所有ADJ. R-squared([调整]决定系数)分布
    '''
    import pandas as pd
    import matplotlib.pyplot as plt
    import numpy as np
    boxprops=dict(linestyle='--', linewidth=3, color='darkgoldenrod')
    
    flatten_lst=lambda lst: [m for n_lst in lst for m in flatten_lst(n_lst)] if type(lst) is list else [lst]
    rsquaredADJ_dict4df={k:flatten_lst([list(v.values()) for v in i.values()]) for k,i in rsquaredADJ_dict.items()}
    rsquaredADJ_df=pd.DataFrame.from_dict(rsquaredADJ_dict4df)
    # print(rsquaredADJ_df)        
    rsquaredADJ_df_1=rsquaredADJ_df[['landuse']]
    rsquaredADJ_df_2=rsquaredADJ_df.drop(['landuse'],axis=1)
    
    fig,(ax1,ax2)=plt.subplots(nrows=1, ncols=2,figsize=(15,10),gridspec_kw={'width_ratios': [1, 2]}) 
    rsquaredADJ_df_1.boxplot(grid=False, rot=90, fontsize=15,ax=ax1, boxprops=boxprops)
    rsquaredADJ_df_2.boxplot(grid=False, rot=90, fontsize=15,ax=ax2,boxprops=boxprops)
    ax1.set_yticks(np.arange(-10,2,0.5))
    ax2.set_yticks(np.arange(0,0.2,0.1))
    plt.show()
    
def rsquaredADJ_pvalue_linePlot(rsquaredADJ_dict,model_dict,**kwargs):  
    '''
    观察ADJ. R-squared随缓冲距离的变化
    '''
    import matplotlib.pyplot as plt 
    import numpy as np
    
    plot_params={'figsize':(10,10),'markersize':2,'marker':'o','cmap':'rainbow'}
    plot_params.update(kwargs)
    
    rsquaredADJ_landuse=rsquaredADJ_dict['landuse']
    model_landuse=model_dict['landuse']

    rsquaredADJ_landuse_df=pd.DataFrame.from_dict(rsquaredADJ_landuse).T      
    rsquaredADJ_landuse_df.plot(column=list(rsquaredADJ_landuse_df.columns),
        figsize=plot_params['figsize'],
        markersize=plot_params['markersize'],
        marker=plot_params['marker'],
        cmap=plot_params['cmap'],
        # xticks=rsquared_df.index.values.astype('int')
        ) 
    plt.xticks(np.arange(0, 1500, 40), rotation=90)
    plt.yticks(np.arange(-20, 1, 1), rotation=0)
    plt.legend(loc='lower right')
    plt.show()
    plt.close() 
    
    return rsquaredADJ_landuse_df,model_landuse   

def coefficient_heatmap(model_dict,air_best_bufferRadius,factor,landuse_LB_mapping_name):
    '''
    给定气体类型稳定缓冲距离，打印系数热力图（heatmap）含p_value（***，**，*）标识
    '''
    import pandas as pd
    import seaborn as sns
    import matplotlib.pyplot as plt
    import numpy as np
    
    model_factor=model_dict[factor]
    # print(model_landuse)
    model_best={}
    pvalue_best={}
    for k,v in air_best_bufferRadius.items():
        model_best[k]=model_factor[v][k].params
        pvalue_best[k]=model_factor[v][k].pvalues
    # print(model_best)
    model_best_df=pd.DataFrame.from_dict(model_best)
    pvalue_best_df=pd.DataFrame.from_dict(pvalue_best)
    pvalue_best_df.fillna(0,inplace=True)
    
    Name_Label_mapping={v:k for k,v in landuse_LB_mapping_name.items()}
    # print(model_best_df.index)
    index_Label_mapping={idx:Name_Label_mapping[int(idx.split("_")[-2])] if idx!='Intercept' else idx for idx in model_best_df.index}
    # print(index_Label_mapping)
    model_best_df.rename(index=index_Label_mapping,inplace=True)   
    
    conds=[(pvalue_best_df.values<0.05) & (pvalue_best_df.values>=0.01),(pvalue_best_df.values<0.01) & (pvalue_best_df.values>=0.001),pvalue_best_df.values<0.001]
    choices=['*', '**','***']
    pvalue_best_reclassify_df=pd.DataFrame(np.select(conds,choices,default=''),index=pvalue_best_df.index,columns=pvalue_best_df.columns)
    pvalue_best_reclassify_df.rename(index=index_Label_mapping,inplace=True)          
    
    flatten_lst=lambda lst: [m for n_lst in lst for m in flatten_lst(n_lst)] if type(lst) is list else [lst]
    pvalue_best_reclassify_lst=flatten_lst(pvalue_best_reclassify_df.values.tolist())
    # print(pvalue_best_reclassify_lst)
    # print(pvalue_best_reclassify_df,model_best_df)
    
    plt.rcParams["figure.figsize"] = [10, 30]
    ax=sns.heatmap(model_best_df,annot=True)
    for i,t in enumerate(ax.texts): 
        # print(t.get_text())
        t.set_text(t.get_text() + pvalue_best_reclassify_lst[i])        
    
    return model_best_df,pvalue_best_reclassify_df

def Feature_Importance_CART(data_factor_dict,X_mark,y_column,mapping_dict,model_option='CART'):
    '''
    用DecisionTreeRegressor或Random Forest Regression模型，检测各个特征（解释变量）的重要程度

    Parameters
    ----------
    data_factor_dict : dict
        包含解释变量和结果变量的数据.
    X_mark : list(str)
        解释变量的列名标识.
    y_column : string
        结果变量列名.
    mapping_dict : dict
        用地类型映射字典.
    model_option : string, optional
        模型选择. The default is 'CART'.

    Returns
    -------
    importance_dict : dict
        返回特征重要度指标.

    '''
    from sklearn.datasets import make_regression
    from sklearn.tree import DecisionTreeRegressor
    from sklearn.ensemble import RandomForestRegressor
    from tqdm import tqdm        
    
    Name_Label_mapping={v:k for k,v in mapping_dict.items()}
    # print(Name_Label_mapping)
    if model_option=='CART':
        model=DecisionTreeRegressor()
    elif model_option=='RF':
        model=RandomForestRegressor()
    importance_dict={}
    for br,v_m in tqdm(data_factor_dict.items()):
        importance_dict_temp={}
        for f,v in v_m.items():
            # print(f,v)                
            X_df=v[[i for i in v.columns if i.split('_')[0] in X_mark]]
            factors_=X_df.columns.to_list()
            factors=[Name_Label_mapping[int(i.split("_")[1])] for i in factors_]
            # print(factors)
            X=X_df.values
            # print(X.shape)
            y=v[y_column].values
            # print(y)
            model.fit(X, y)
            importance=model.feature_importances_
            f_importance=dict(zip(factors,importance))
            # print(f_importance)
            importance_dict_temp[f]=f_importance
        importance_dict[br]=importance_dict_temp
    return importance_dict   

def importance_plot(importance_dict,model_factor,air_best_bufferRadius,mapping_dict):
    '''
    CART/RF与OLS方法结果比较
    '''
    import pandas as pd
    import matplotlib.pyplot as plt
    import seaborn as sns
    from tqdm import tqdm
    
    Name_Label_mapping={v:k for k,v in mapping_dict.items()}
    importance_df_dict={}
    importance_norm_df_dict={}
    fig, axs=plt.subplots(2, 4, figsize=(20, 20), constrained_layout=True)
    axs_flatten=axs.flat
    i=0
    for k,v in tqdm(air_best_bufferRadius.items()):
        importance=importance_dict[v][k]
        coefficient=model_factor[v][k].params
        coefficient.drop(labels='Intercept',inplace=True)
        pvalue=model_factor[v][k].pvalues 
        pvalue.drop(labels='Intercept',inplace=True)
        coefficient_dict={Name_Label_mapping[int(idx.split("_")[1])]:value for idx,value in coefficient.items()}
        pvalue_dict={Name_Label_mapping[int(idx.split("_")[1])]:value for idx,value in pvalue.items()}
        # print(pvalue_dict)
        importance_df=pd.DataFrame.from_dict({"RF":importance,"OLS":coefficient_dict})    
        
        importance_norm_df=df_normalize(abs(importance_df),feature_range=(0, 1))
        importance_df_dict['{}_{}'.format(k,v)]=importance_df
        importance_norm_df_dict['{}_{}'.format(k,v)]=importance_norm_df            
        
        ax=axs_flatten[i]
        importance_norm_df.reset_index(inplace=True)
        importance_norm_df.plot(x='index',y=['RF','OLS'],kind="bar",ax=ax)
        ax.set_title('{}_{}'.format(k,v))       
        ax.set(xlabel=None)
        # break        
        i+=1
    plt.show()    
    return importance_df_dict,importance_norm_df_dict   

def OLS_coefficient_differentGases_plot(importance_df_dict):
    '''
    OLS系数比较(稳定状态下模型的解释变量（不同用地类型）系数)
    '''
    import pandas as pd
    import matplotlib.pyplot as plt
    from sklearn.preprocessing import RobustScaler
    
    importance_df_dict4concat={k:v['OLS'] for k,v in importance_df_dict.items()}
    importance_concat=pd.DataFrame.from_dict(importance_df_dict4concat)
    columns=list(importance_concat.columns)
    # print(importance_concat)
    # create a scaler object
    scaler=RobustScaler()
    importance_concat_norm_df=importance_concat/abs(importance_concat).max()*5 #保持正负号不变
    importance_concat_norm_df.reset_index(inplace=True)
    importance_concat_norm_df.plot(x='index',y=columns,kind="bar",figsize=(30,10))
    plt.show()
    return importance_concat,importance_concat_norm_df   

def sortValuesNselection(df_,columns,n=5,decimals=3):
    '''
    排序值，并提取给定个数，正相关、负相关和基本不相关的值及对应的特征名

    Parameters
    ----------
    df_ : DataFrame
        待提取的数据.
    columns : list(string)
        需要处理的列.
    n : int, optional
        提取的个数. The default is 5.
    decimals : int, optional
        保留小数位数. The default is 3.

    Returns
    -------
    sorted_concat_df : DataFrame(multiple index)
        正相关、负相关和基本不相关的提取值.

    '''
    import pandas as pd
    
    df=df_.round(decimals)
    sorted_dict={}
    for i in columns:
        sorted_data=df[i].sort_values(ascending=False)
        sorted_data.dropna(inplace=True)
        sorted_abs_data=abs(sorted_data).sort_values(ascending=False)
        sorted_df=pd.concat([sorted_data.head(n).reset_index().rename(columns={'index':"head_{}_{}".format(i,'LU'),i:"head_{}".format(i)}),
        sorted_data.tail(n).reset_index().rename(columns={'index':"tail_{}_{}".format(i,'LU'),i:"tail_{}".format(i)}),
        sorted_abs_data.tail(n).reset_index().rename(columns={'index':"abs_tail_{}_{}".format(i,'LU'),i:"abs_tail_{}".format(i)})],axis=1)
        
        sorted_dict[i]=sorted_df      
    sorted_concat_df=pd.concat(sorted_dict,axis=1)
    return sorted_concat_df    

if __name__=="__main__":
    import sys
    sys.path.append('..')
    import util    
    import geopandas as gpd
    import pandas as pd
    import os
    import pickle
    from database import postSQL2gpd,gpd2postSQL,cfg_load_yaml  
    from glob import glob
    import time_series_analysis as tsa
    from datetime import datetime
    import spatio_temporal_analysis as sta
    import rasterNvector_processing as rNvp
    import metricsNsampling as mNs
    parent_path=os.path.dirname(os.getcwd())
    
    cfg=cfg_load_yaml('../config.yml')  
    UN=cfg["postgreSQL"]["myusername"]
    PW=cfg["postgreSQL"]["mypassword"]
    DB=cfg["postgreSQL"]["mydatabase"] 
    GC='geometry' 
    
    # air_sensor_category_save_fp=cfg['analysis_air']['air_sensor_category_save_fp']  
    AoT_nodes_TN=cfg['table_name']['AoT_nodes_TN']   
    AoT_nodes_gdf=postSQL2gpd(table_name=AoT_nodes_TN,geom_col=GC,myusername=UN,mypassword=PW,mydatabase=DB)
    TN_air={"CO":"air_co_resample_value_hrf",
        "H2S":'air_h2s_resample_value_hrf',
        'NO2':'air_no2_resample_value_hrf',
        'O3':'air_o3_resample_value_hrf',
        'SO2':'air_so2_resample_value_hrf',
        'oxidizing_gases':'air_oxidizing_gases_resample_value_hrf',
        'reducing_gases':'air_reducing_gases_resample_value_hrf'}
    
    #A:数据准备-.shp转栅格
    #A-1_土地利用转栅格
    # landuse_TN=cfg['table_name']['landuse_TN']
    # landuse_gdf=postSQL2gpd(table_name=landuse_TN,geom_col=GC,myusername=UN,mypassword=PW,mydatabase=DB)
    # landuse_LB_gdf,landuse_LB_mapping=rNvp.gdf_label_encoder(landuse_gdf,columns=['LANDUSE','landuse_name'])
    landuse_LB_mapping_fn='../data/processed_data/landuse_LB_mapping.pickle'
    # with open(landuse_LB_mapping_fn,'wb') as f:
    #     pickle.dump(landuse_LB_mapping,f)
    with open(landuse_LB_mapping_fn,'rb') as f:
        landuse_LB_mapping=pickle.load(f)    
    # landuse_LB_shp_fn=r'G:\data\PAPER_Urban_Spatial_Pattern_N_Local_Environmental_Changes\data\processed_data\landuse_LB_shp\landuse_LB.shp'
    # landuse_LB_gdf.to_file(landuse_LB_shp_fn)
    
    #将polygon数据转换为栅格数据（可包含多个波段，即多个属性值）
    # landuse_attribs=rNvp.vectorLayer_attributeNames(landuse_LB_shp_fn)
    # landuse_attribs_selection=['lB_LANDUSE','lB_landu_1'] #limited the length of field name to 10
    landuse_filename=r'G:\data\PAPER_Urban_Spatial_Pattern_N_Local_Environmental_Changes\data\processed_data/landuse.tif'
    # rNvp.create_multiband_raster(landuse_attribs_selection,landuse_LB_shp_fn,landuse_filename,cellSize=5)
    
    #A-2_建筑高度数据转栅格
    # Building_Footprints_TN=cfg['table_name']['Building_Footprints_TN']
    # Building_Footprints=postSQL2gpd(table_name=Building_Footprints_TN,geom_col=GC,myusername=UN,mypassword=PW,mydatabase=DB)   
    # Building_Footprints_shp_fn=r'G:\data\PAPER_Urban_Spatial_Pattern_N_Local_Environmental_Changes\data\processed_data\landuse_LB_shp\Building_Footprints.shp'
    # Building_Footprints.to_file(Building_Footprints_shp_fn)    
    
    # Building_Footprints_attribs=rNvp.vectorLayer_attributeNames(Building_Footprints_shp_fn) #['no_stories', 'stories']
    # Building_Footprints_attribs_selection=['stories','no_stories']
    Building_Footprints_filename=r'G:\data\PAPER_Urban_Spatial_Pattern_N_Local_Environmental_Changes\data\processed_data/Building_Footprints.tif'
    # rNvp.create_multiband_raster(Building_Footprints_attribs_selection,Building_Footprints_shp_fn,Building_Footprints_filename,cellSize=5)
    
    #A-3_道路中心线转栅格
    # street_center_lines_TN=cfg['table_name']['street_center_lines_TN']
    # street_center_lines=postSQL2gpd(table_name=street_center_lines_TN,geom_col=GC,myusername=UN,mypassword=PW,mydatabase=DB)        
    # street_center_lines['exist']=1
    # street_center_lines_shp_fn=r'G:\data\PAPER_Urban_Spatial_Pattern_N_Local_Environmental_Changes\data\processed_data\landuse_LB_shp\street_center_lines.shp'
    # street_center_lines.to_file(street_center_lines_shp_fn)  
    
    # street_center_lines_attribs_selection=['exist']
    street_center_lines_filename=r'G:\data\PAPER_Urban_Spatial_Pattern_N_Local_Environmental_Changes\data\processed_data/street_center_lines.tif'
    # rNvp.create_multiband_raster(street_center_lines_attribs_selection,street_center_lines_shp_fn,street_center_lines_filename,cellSize=5)

    #A-4_植被（高，中，低）(前期已处理为栅格) #初始空值为 65535
    HighVegetation_reprojection_fn=cfg['processed_data']['HighVegetation_reprojection_fn']
    MediumVegetation_reprojection_fn=cfg['processed_data']['MediumVegetation_reprojection_fn']
    LowVegetation_reprojection_fn=cfg['processed_data']['LowVegetation_reprojection_fn']   

    #B-采样-区域统计(Zonal statistics)
    rasterFNS_params_dict={0:[landuse_filename,2,-9999,['majority'],['frequency']],
                           1:[Building_Footprints_filename,1,-9999,['sum','mean'],[]],
                           2:[street_center_lines_filename,1,-9999,['sum'],[]],
                           3:[HighVegetation_reprojection_fn,1,65535,['sum'],[]],
                           4:[MediumVegetation_reprojection_fn,1,65535,['sum'],[]],
                           5:[LowVegetation_reprojection_fn,1,65535,['sum'],[]]}   
    # zonal_stats_dict=raster_zonal_stats(AoT_nodes_gdf,[10,1500,20],rasterFNS_params_dict)
    zonal_stats_dict_fn='../data/processed_data/zonal_stats_dict.pickle'
    # with open(zonal_stats_dict_fn,'wb') as f:
    #     pickle.dump(zonal_stats_dict,f)   
    with open(zonal_stats_dict_fn,'rb') as f:
        zonal_stats_dict=pickle.load(f)   
    zonal_stats_concat_dict=zonal_stats_dict_concat(zonal_stats_dict)    
        
    #C:偏相关|复相关分析（复相关系数）| 特征重要性（贡献度）
    #C-1_1_OLS Regression（Linear Regression Feature Importance）    
    buffer_radius=list(zonal_stats_concat_dict.keys())
    factors_dict={'landuse':[['frequency'],'split'],'BuildingHeight':[['sum_1'],'nosplit'],'street':[['sum_2'],'nosplit'],
                     'HighVegetation':[['sum_3'],'nosplit'],'MediumVegetation':[['sum_4'],'nosplit'],'LowVegetation':[['sum_5'],'nosplit']}    
    # model_dict,data_dict,rsquaredADJ_dict=air_buffer_changes_correlation_OLS_factors(TN_air,zonal_stats_concat_dict,factors_dict,buffer_radius)
    OLS_results_dict_fn='../data/processed_data/OLS_results_dict.pickle'
    # with open(OLS_results_dict_fn,'wb') as f:
    #       pickle.dump({'model_dict':model_dict,'data_dict':data_dict,'rsquaredADJ_dict':rsquaredADJ_dict},f) 
      
    #C-1_2_OLS结果图表打印
    with open(OLS_results_dict_fn,'rb') as f:
        OLS_results_dict=pickle.load(f)
   
    rsquaredADJ_dict=OLS_results_dict['rsquaredADJ_dict']
    #_a 打印每类影响因子['landuse', 'BuildingHeight', 'street', 'HighVegetation', 'MediumVegetation', 'LowVegetation']所有ADJ. R-squared([调整]决定系数)分布，确定分析特征中只有landuse与空气污染气体浓度相关
    # rsquaredADJ_boxplot(rsquaredADJ_dict)    
    #_b 观察ADJ. R-squared随缓冲距离的变化
    model_dict=OLS_results_dict['model_dict']
    # rsquaredADJ_landuse_df,model_landuse=rsquaredADJ_pvalue_linePlot(rsquaredADJ_dict,model_dict)
    #%%     
    #['CO', 'H2S', 'NO2', 'O3', 'SO2', 'oxidizing_gases', 'reducing_gases']
    # print(model_landuse[830]['CO'].summary())
    # print(model_landuse[850]['H2S'].summary())
    # print(model_landuse[610]['NO2'].summary())
    # print(model_landuse[930]['O3'].summary())
    # print(model_landuse[530]['SO2'].summary())
    # print(model_landuse[430]['oxidizing_gases'].summary())
    # print(model_landuse[850]['reducing_gases'].summary())
    
    # print(rsquaredADJ_landuse_df['reducing_gases'].to_dict())
    #%%
    #_c 给定气体类型稳定缓冲距离，打印系数热力图（heatmap）含p_value（***，**，*）标识
    air_best_bufferRadius={'CO':830, 'H2S':850, 'NO2':610, 'O3':930, 'SO2':530, 'oxidizing_gases':430, 'reducing_gases':850}
    # model_best_df,pvalue_best_reclassify_df=coefficient_heatmap(model_dict,air_best_bufferRadius,'landuse',landuse_LB_mapping['landuse_name'])
    #%%    
    #C-2_CART/RF Regression Feature Importance (DecisionTreeRegressor/Random Forest Regression) 
    data_dict=OLS_results_dict['data_dict']
    # importance_dict=Feature_Importance_CART(data_dict['landuse'],['frequency'],'Y_2018-12-31',landuse_LB_mapping['landuse_name'],model_option='RF')
    #%%
    #C-2_结果图表打印    
    #_a_CART/RF与OLS方法结果比较
    importance_df_dict,importance_norm_df_dict=importance_plot(importance_dict,model_dict['landuse'],air_best_bufferRadius,landuse_LB_mapping['landuse_name'])
    #%%
    #_b_OLS系数比较
    importance_concat,importance_concat_norm_df=OLS_coefficient_differentGases_plot(importance_df_dict)    
    #%%
    #D:提取首尾各n个值
    sorted_concat_df=sortValuesNselection(importance_concat,columns=['CO_830', 'H2S_850', 'NO2_610', 'O3_930', 'SO2_530','oxidizing_gases_430', 'reducing_gases_850'])
    sorted_concat_df.to_excel('../data/processed_data/sorted_concat_OLSCoefficient.xlsx',sheet_name='OLSCoefficient')
    #%%
```

###### 6) 气体浓度与风速相关性

计算结果显示，相关系数基本为正值，表明风速通常增加了污染气体（扩散）浓度。对测量点位按具有统计显著性的数量排序，依次为C0（21）、O3（21）、reducing_gases（14）、H2S（13）、oxidizing_gases（8）、NO2（8）。比较最大风速、最小风速和平均风速，与气体浓度具有一定相关性的为最大风速。

__Fig. 各气体浓度与风速相关系数空间分布__ 

<a href=""><img src="./imgs/3_3_2_85_s.jpg" height="auto" width="auto" title="caDesign"></a>

__Fig. 各气体浓度与风速相关系数值__ 

| Max_CO_correlation | Max_CO_pvalue | Avg_CO_correlation | Avg_CO_pvalue | Min_CO_correlation | Min_CO_pvalue | Max_H2S_correlation | Max_H2S_pvalue | Avg_H2S_correlation | Avg_H2S_pvalue | Min_H2S_correlation | Min_H2S_pvalue | Max_NO2_correlation | Max_NO2_pvalue | Avg_NO2_correlation | Avg_NO2_pvalue | Min_NO2_correlation | Min_NO2_pvalue | Max_O3_correlation | Max_O3_pvalue | Avg_O3_correlation | Avg_O3_pvalue | Min_O3_correlation | Min_O3_pvalue | Max_SO2_correlation | Max_SO2_pvalue | Avg_SO2_correlation | Avg_SO2_pvalue | Min_SO2_correlation | Min_SO2_pvalue | Max_oxidizing_gases_correlation | Max_oxidizing_gases_pvalue | Avg_oxidizing_gases_correlation | Avg_oxidizing_gases_pvalue | Min_oxidizing_gases_correlation | Min_oxidizing_gases_pvalue | Max_reducing_gases_correlation | Max_reducing_gases_pvalue | Avg_reducing_gases_correlation | Avg_reducing_gases_pvalue | Min_reducing_gases_correlation | Min_reducing_gases_pvalue | node_id      |
|--------------------|---------------|--------------------|---------------|--------------------|---------------|---------------------|----------------|---------------------|----------------|---------------------|----------------|---------------------|----------------|---------------------|----------------|---------------------|----------------|--------------------|---------------|--------------------|---------------|--------------------|---------------|---------------------|----------------|---------------------|----------------|---------------------|----------------|---------------------------------|----------------------------|---------------------------------|----------------------------|---------------------------------|----------------------------|--------------------------------|---------------------------|--------------------------------|---------------------------|--------------------------------|---------------------------|--------------|
| 0.599              | 0.024         | 0.293              | 0.309         | -0.163             | 0.577         | 0                   | 9999           | 0                   | 9999           | 0                   | 9999           | 0.814               | 0              | 0.375               | 0.186          | -0.214              | 0.463          | 0.815              | 0             | 0.367              | 0.197         | -0.215             | 0.46          | 0.76                | 0.002          | 0.348               | 0.223          | -0.235              | 0.418          | 0.812                           | 0                          | 0.345                           | 0.227                      | -0.269                          | 0.353                      | 0.764                          | 0.001                     | 0.344                          | 0.228                     | -0.232                         | 0.426                     | 001e0610890f |
| 0.386              | 0.051         | 0.461              | 0.018         | 0.263              | 0.193         | -0.004              | 0.986          | 0.147               | 0.484          | -0.013              | 0.951          | 0.347               | 0.082          | 0.488               | 0.011          | 0.344               | 0.085          | 0.13               | 0.525         | 0.22               | 0.281         | -0.057             | 0.784         | -0.232              | 0.254          | -0.166              | 0.417          | -0.323              | 0.107          | 0.069                           | 0.738                      | 0.219                           | 0.282                      | 0.352                           | 0.078                      | 0.408                          | 0.039                     | 0.487                          | 0.012                     | 0.296                          | 0.143                     | 001e06109416 |
| 0                  | 9999          | 0                  | 9999          | 0                  | 9999          | 0                   | 9999           | 0                   | 9999           | 0                   | 9999           | 0                   | 9999           | 0                   | 9999           | 0                   | 9999           | 0                  | 9999          | 0                  | 9999          | 0                  | 9999          | 0                   | 9999           | 0                   | 9999           | 0                   | 9999           | 0                               | 9999                       | 0                               | 9999                       | 0                               | 9999                       | 0                              | 9999                      | 0                              | 9999                      | 0                              | 9999                      | 001e0610b9e9 |
| 0.345              | 0.067         | 0.224              | 0.243         | 0.059              | 0.762         | 0.401               | 0.042          | 0.218               | 0.284          | 0.199               | 0.329          | -0.197              | 0.296          | -0.253              | 0.178          | -0.081              | 0.67           | -0.369             | 0.045         | -0.409             | 0.025         | -0.206             | 0.274         | -0.161              | 0.404          | -0.403              | 0.03           | -0.317              | 0.094          | 0.082                           | 0.71                       | -0.033                          | 0.883                      | 0.214                           | 0.328                      | 0                              | 9999                      | 0                              | 9999                      | 0                              | 9999                      | 001e0610ba13 |
| 0.149              | 0.297         | 0.076              | 0.597         | -0.153             | 0.283         | -0.142              | 0.463          | -0.18               | 0.351          | 0.093               | 0.632          | 0.06                | 0.758          | -0.095              | 0.623          | -0.174              | 0.365          | 0.468              | 0.01          | 0.247              | 0.196         | 0.103              | 0.594         | 0.047               | 0.743          | 0.005               | 0.97           | -0.08               | 0.575          | 0.027                           | 0.889                      | -0.246                          | 0.197                      | -0.249                          | 0.192                      | -0.307                         | 0.105                     | -0.364                         | 0.052                     | -0.174                         | 0.367                     | 001e0610ba15 |
| 0.075              | 0.735         | 0.053              | 0.809         | 0.141              | 0.522         | -0.055              | 0.751          | 0.036               | 0.835          | 0.074               | 0.669          | 0.146               | 0.306          | 0.181               | 0.203          | 0.171               | 0.23           | -0.062             | 0.666         | -0.052             | 0.719         | 0.222              | 0.118         | -0.103              | 0.642          | -0.275              | 0.204          | -0.183              | 0.404          | 0.444                           | 0.007                      | 0.283                           | 0.094                      | 0.102                           | 0.554                      | 0.107                          | 0.463                     | 0.089                          | 0.544                     | -0.088                         | 0.549                     | 001e0610ba46 |
| 0.071              | 0.71          | 0.222              | 0.238         | 0.372              | 0.043         | 0.241               | 0.268          | 0.183               | 0.402          | 0.129               | 0.557          | 0.085               | 0.699          | 0.102               | 0.644          | 0.007               | 0.976          | 0.088              | 0.689         | 0.138              | 0.531         | 0.054              | 0.807         | 0.156               | 0.418          | -0.103              | 0.596          | -0.141              | 0.465          | -0.008                          | 0.97                       | 0.002                           | 0.992                      | -0.272                          | 0.21                       | -0.131                         | 0.553                     | -0.267                         | 0.218                     | -0.288                         | 0.183                     | 001e0610bbe5 |
| 0.309              | 0.012         | 0.201              | 0.106         | 0.163              | 0.19          | -0.54               | 0.003          | -0.293              | 0.131          | 0.026               | 0.896          | 0.212               | 0.261          | -0.024              | 0.899          | -0.218              | 0.248          | 0.125              | 0.51          | 0.255              | 0.173         | 0.26               | 0.165         | -0.046              | 0.712          | -0.18               | 0.148          | -0.235              | 0.058          | -0.043                          | 0.82                       | 0.078                           | 0.681                      | 0.312                           | 0.093                      | -0.225                         | 0.241                     | -0.264                         | 0.167                     | -0.253                         | 0.185                     | 001e0610bc10 |
| 0.205              | 0.064         | -0.016             | 0.888         | -0.133             | 0.231         | -0.011              | 0.929          | -0.057              | 0.651          | -0.109              | 0.389          | 0.036               | 0.773          | -0.059              | 0.64           | -0.158              | 0.204          | 0.236              | 0.057         | 0.016              | 0.9           | -0.146             | 0.241         | 0.281               | 0.01           | 0.034               | 0.758          | -0.104              | 0.348          | -0.048                          | 0.703                      | -0.154                          | 0.218                      | -0.205                          | 0.099                      | -0.189                         | 0.128                     | -0.168                         | 0.178                     | -0.123                         | 0.325                     | 001e0610bc12 |
| 0.459              | 0.006         | 0.39               | 0.023         | 0.147              | 0.406         | -0.009              | 0.943          | -0.016              | 0.895          | -0.016              | 0.896          | -0.055              | 0.624          | -0.06               | 0.588          | 0.001               | 0.993          | 0.268              | 0.014         | 0.065              | 0.557         | -0.011             | 0.925         | -0.276              | 0.114          | -0.327              | 0.059          | -0.421              | 0.013          | -0.076                          | 0.496                      | -0.157                          | 0.157                      | -0.185                          | 0.093                      | -0.36                          | 0.001                     | -0.25                          | 0.023                     | -0.154                         | 0.165                     | 001e0610e537 |
| 0.347              | 0.01          | 0.344              | 0.011         | 0.172              | 0.214         | 0.196               | 0.267          | 0.136               | 0.444          | 0.093               | 0.602          | 0.288               | 0.099          | 0.258               | 0.14           | 0.075               | 0.674          | 0.38               | 0.027         | 0.328              | 0.058         | 0.067              | 0.707         | -0.02               | 0.886          | -0.012              | 0.932          | -0.122              | 0.374          | -0.041                          | 0.816                      | -0.075                          | 0.675                      | 0.002                           | 0.99                       | -0.381                         | 0.026                     | -0.478                         | 0.004                     | -0.381                         | 0.026                     | 001e0610e538 |
| 0.338              | 0.006         | 0.323              | 0.008         | 0.081              | 0.518         | -0.006              | 0.964          | 0.01                | 0.944          | -0.098              | 0.478          | -0.022              | 0.871          | -0.015              | 0.913          | -0.125              | 0.365          | -0.002             | 0.991         | -0.007             | 0.962         | -0.125             | 0.365         | -0.302              | 0.014          | -0.451              | 0              | -0.44               | 0              | -0.027                          | 0.844                      | -0.018                          | 0.896                      | -0.124                          | 0.366                      | -0.031                         | 0.824                     | -0.02                          | 0.884                     | -0.126                         | 0.359                     | 001e0610e539 |
| 0.044              | 0.787         | -0.034             | 0.832         | -0.022             | 0.891         | 0.16                | 0.203          | 0.083               | 0.509          | -0.062              | 0.623          | 0.344               | 0.005          | 0.311               | 0.011          | 0.098               | 0.435          | 0.124              | 0.323         | 0.029              | 0.819         | -0.129             | 0.303         | 0.364               | 0.019          | -0.039              | 0.806          | -0.241              | 0.129          | 0.168                           | 0.177                      | 0.131                           | 0.293                      | 0.091                           | 0.469                      | 0.095                          | 0.447                     | 0.03                           | 0.81                      | -0.137                         | 0.272                     | 001e0610e835 |
| 0                  | 9999          | 0                  | 9999          | 0                  | 9999          | 0                   | 9999           | 0                   | 9999           | 0                   | 9999           | 0.637               | 0              | 0.283               | 0.073          | -0.035              | 0.827          | 0.512              | 0.001         | 0.182              | 0.255         | -0.061             | 0.705         | 0                   | 9999           | 0                   | 9999           | 0                   | 9999           | 0.555                           | 0                          | 0.143                           | 0.371                      | -0.198                          | 0.214                      | -0.249                         | 0.116                     | -0.163                         | 0.308                     | -0.113                         | 0.483                     | 001e0610e8cb |
| 0.426              | 0             | 0.363              | 0.001         | 0.125              | 0.271         | 0                   | 9999           | 0                   | 9999           | 0                   | 9999           | 0.002               | 0.983          | -0.047              | 0.683          | -0.055              | 0.629          | 0                  | 9999          | 0                  | 9999          | 0                  | 9999          | -0.029              | 0.8            | -0.149              | 0.191          | -0.187              | 0.099          | 0                               | 9999                       | 0                               | 9999                       | 0                               | 9999                       | 0                              | 9999                      | 0                              | 9999                      | 0                              | 9999                      | 001e0610ee36 |
| 0.07               | 0.82          | 0.223              | 0.465         | 0.056              | 0.855         | -0.011              | 0.925          | -0.047              | 0.679          | -0.069              | 0.543          | -0.298              | 0.323          | -0.289              | 0.338          | -0.57               | 0.042          | 0.123              | 0.279         | -0.022             | 0.846         | -0.109             | 0.341         | -0.404              | 0.171          | -0.272              | 0.369          | -0.461              | 0.113          | -0.061                          | 0.594                      | -0.09                           | 0.431                      | -0.108                          | 0.342                      | -0.405                         | 0                         | -0.306                         | 0.006                     | -0.136                         | 0.231                     | 001e0610eef2 |
| 0                  | 9999          | 0                  | 9999          | 0                  | 9999          | 0.453               | 0.139          | 0.329               | 0.297          | 0.139               | 0.667          | 0.003               | 0.976          | 0.028               | 0.811          | 0.073               | 0.532          | -0.192             | 0.53          | -0.258             | 0.395         | -0.529             | 0.063         | 0                   | 9999           | 0                   | 9999           | 0                   | 9999           | -0.287                          | 0.342                      | -0.37                           | 0.214                      | -0.613                          | 0.026                      | -0.208                         | 0.495                     | -0.328                         | 0.273                     | -0.509                         | 0.075                     | 001e0610ef27 |
| 0.155              | 0.188         | 0.076              | 0.52          | -0.013             | 0.915         | 0.175               | 0.23           | 0.134               | 0.358          | 0.075               | 0.61           | 0.159               | 0.392          | 0.172               | 0.355          | 0.135               | 0.469          | 0                  | 9999          | 0                  | 9999          | 0                  | 9999          | -0.033              | 0.779          | -0.306              | 0.008          | -0.381              | 0.001          | -0.016                          | 0.892                      | -0.126                          | 0.281                      | -0.183                          | 0.115                      | 0                              | 9999                      | 0                              | 9999                      | 0                              | 9999                      | 001e0610f02f |
| 0.321              | 0.078         | 0.384              | 0.033         | 0.196              | 0.292         | 0.314               | 0.097          | 0.257               | 0.178          | 0.175               | 0.365          | -0.077              | 0.58           | -0.027              | 0.846          | -0.127              | 0.359          | 0.31               | 0.007         | 0.055              | 0.641         | -0.099             | 0.397         | 0.24                | 0.194          | -0.127              | 0.496          | -0.32               | 0.079          | 0.12                            | 0.52                       | 0.131                           | 0.483                      | 0.107                           | 0.566                      | 0.079                          | 0.502                     | 0.091                          | 0.443                     | 0.072                          | 0.545                     | 001e0610f05c |
| 0.449              | 0.001         | 0.153              | 0.27          | 0.015              | 0.916         | -0.066              | 0.638          | -0.018              | 0.898          | -0.106              | 0.451          | 0.247               | 0.042          | 0.269               | 0.027          | 0.216               | 0.077          | 0.353              | 0.051         | 0.204              | 0.27          | 0.058              | 0.756         | -0.046              | 0.741          | -0.042              | 0.761          | -0.142              | 0.307          | -0.053                          | 0.711                      | 0.003                           | 0.986                      | -0.088                          | 0.538                      | 0.102                          | 0.585                     | 0.13                           | 0.487                     | 0.13                           | 0.486                     | 001e0610f513 |
| 0.248              | 0.037         | 0.318              | 0.007         | 0.186              | 0.12          | 0.381               | 0.003          | 0.394               | 0.002          | 0.247               | 0.059          | 0.007               | 0.957          | -0.004              | 0.974          | -0.09               | 0.46           | 0.119              | 0.391         | 0.007              | 0.96          | -0.141             | 0.311         | 0.027               | 0.826          | -0.104              | 0.388          | -0.076              | 0.53           | 0.241                           | 0.043                      | 0.301                           | 0.011                      | 0.168                           | 0.16                       | -0.121                         | 0.384                     | -0.058                         | 0.676                     | -0.144                         | 0.298                     | 001e0610f6db |
| 0.098              | 0.423         | 0.103              | 0.4           | 0.003              | 0.983         | 0.307               | 0.011          | 0.286               | 0.018          | 0.177               | 0.148          | 0.014               | 0.896          | -0.023              | 0.825          | 0.028               | 0.787          | 0.252              | 0.037         | 0.319              | 0.008         | 0.193              | 0.112         | 0.034               | 0.785          | 0.11                | 0.377          | 0.008               | 0.949          | -0.233                          | 0.054                      | -0.198                          | 0.103                      | -0.118                          | 0.333                      | 0.126                          | 0.294                     | 0.161                          | 0.18                      | 0.15                           | 0.211                     | 001e0610f6dd |
| 0.28               | 0.006         | 0.229              | 0.025         | 0.101              | 0.33          | 0.329               | 0.003          | 0.26                | 0.021          | 0.149               | 0.191          | 0.019               | 0.915          | -0.032              | 0.858          | 0.06                | 0.742          | 0.087              | 0.477         | 0.098              | 0.421         | -0.047             | 0.7           | -0.12               | 0.245          | -0.37               | 0              | -0.349              | 0              | -0.239                          | 0.019                      | -0.302                          | 0.003                      | -0.162                          | 0.114                      | 0.068                          | 0.58                      | 0.076                          | 0.533                     | -0.026                         | 0.835                     | 001e0610f703 |
| 0.073              | 0.688         | 0.101              | 0.575         | -0.073             | 0.686         | -0.137              | 0.447          | -0.152              | 0.397          | 0.055               | 0.763          | -0.04               | 0.745          | -0.27               | 0.026          | -0.261              | 0.032          | 0.441              | 0             | 0.22               | 0.031         | 0.023              | 0.823         | -0.232              | 0.195          | -0.379              | 0.03           | -0.428              | 0.013          | -0.214                          | 0.231                      | -0.314                          | 0.075                      | -0.19                           | 0.29                       | -0.036                         | 0.727                     | -0.055                         | 0.595                     | -0.032                         | 0.759                     | 001e0610f732 |
| 0.207              | 0.091         | -0.018             | 0.886         | -0.021             | 0.867         | 0.044               | 0.73           | 0.036               | 0.782          | 0.059               | 0.648          | 0.203               | 0.088          | 0.132               | 0.268          | 0.155               | 0.194          | 0.273              | 0.124         | 0.26               | 0.143         | 0.15               | 0.405         | -0.134              | 0.275          | -0.371              | 0.002          | -0.371              | 0.002          | 0.034                           | 0.78                       | -0.071                          | 0.567                      | -0.211                          | 0.084                      | -0.403                         | 0.02                      | -0.505                         | 0.003                     | -0.302                         | 0.088                     | 001e0610f8f4 |
| 0.298              | 0.011         | 0.264              | 0.025         | 0.061              | 0.61          | 0.188               | 0.114          | 0.113               | 0.345          | 0.202               | 0.089          | 0                   | 9999           | 0                   | 9999           | 0                   | 9999           | 0.305              | 0.011         | 0.074              | 0.55          | -0.036             | 0.768         | -0.163              | 0.171          | -0.413              | 0              | -0.415              | 0              | -0.028                          | 0.818                      | 0.039                           | 0.747                      | 0.047                           | 0.692                      | -0.367                         | 0.002                     | -0.45                          | 0                         | -0.319                         | 0.008                     | 001e06112e77 |
| 0                  | 9999          | 0                  | 9999          | 0                  | 9999          | 0                   | 9999           | 0                   | 9999           | 0                   | 9999           | -0.075              | 0.484          | -0.064              | 0.551          | -0.004              | 0.967          | 0.408              | 0             | 0.092              | 0.445         | -0.08              | 0.505         | 0                   | 9999           | 0                   | 9999           | 0                   | 9999           | 0                               | 9999                       | 0                               | 9999                       | 0                               | 9999                       | -0.366                         | 0.002                     | -0.288                         | 0.014                     | -0.153                         | 0.2                       | 001e061130f4 |
| 0.3                | 0.004         | 0.134              | 0.206         | -0.037             | 0.727         | -0.06               | 0.579          | -0.046              | 0.672          | -0.02               | 0.855          | 0                   | 9999           | 0                   | 9999           | 0                   | 9999           | 0                  | 9999          | 0                  | 9999          | 0                  | 9999          | -0.097              | 0.362          | -0.163              | 0.125          | -0.157              | 0.14           | -0.068                          | 0.526                      | -0.055                          | 0.607                      | -0.025                          | 0.813                      | 0                              | 9999                      | 0                              | 9999                      | 0                              | 9999                      | 001e06113100 |
| 0                  | 9999          | 0                  | 9999          | 0                  | 9999          | 0                   | 9999           | 0                   | 9999           | 0                   | 9999           | -0.084              | 0.643          | -0.066              | 0.716          | -0.068              | 0.707          | 0.291              | 0.006         | 0.085              | 0.426         | -0.071             | 0.51          | 0                   | 9999           | 0                   | 9999           | 0                   | 9999           | 0                               | 9999                       | 0                               | 9999                       | 0                               | 9999                       | -0.097                         | 0.362                     | -0.087                         | 0.417                     | -0.043                         | 0.69                      | 001e06113107 |
| 0.213              | 0.233         | 0.077              | 0.671         | -0.119             | 0.51          | 0.208               | 0.353          | 0.032               | 0.889          | -0.295              | 0.183          | 0.516               | 0              | 0.16                | 0.196          | -0.105              | 0.396          | 0                  | 9999          | 0                  | 9999          | 0                  | 9999          | 0                   | 9999           | 0                   | 9999           | 0                   | 9999           | 0                               | 9999                       | 0                               | 9999                       | 0                               | 9999                       | 0                              | 9999                      | 0                              | 9999                      | 0                              | 9999                      | 001e06113a24 |
| 0.239              | 0.051         | 0.102              | 0.414         | -0.039             | 0.755         | 0.366               | 0.012          | 0.285               | 0.055          | 0.203               | 0.177          | -0.22               | 0.091          | -0.126              | 0.336          | -0.06               | 0.651          | 0                  | 9999          | 0                  | 9999          | 0                  | 9999          | -0.324              | 0.066          | -0.571              | 0.001          | -0.442              | 0.01           | 0.207                           | 0.248                      | 0.124                           | 0.493                      | -0.038                          | 0.832                      | -0.053                         | 0.77                      | -0.145                         | 0.422                     | -0.234                         | 0.189                     | 001e06113a48 |
| 0.379              | 0.003         | 0.245              | 0.06          | 0.125              | 0.339         | 0.106               | 0.515          | -0.014              | 0.931          | -0.054              | 0.739          | -0.062              | 0.723          | 0.013               | 0.943          | 0.068               | 0.697          | 0.445              | 0.01          | 0.399              | 0.021         | 0.19               | 0.29          | -0.039              | 0.755          | -0.259              | 0.034          | -0.222              | 0.071          | 0.081                           | 0.515                      | 0.075                           | 0.545                      | -0.078                          | 0.53                       | 0.046                          | 0.711                     | 0.107                          | 0.388                     | 0.057                          | 0.646                     | 001e06113acb |
| 0.216              | 0.213         | 0.031              | 0.859         | -0.214             | 0.218         | -0.153              | 0.603          | 0.112               | 0.704          | 0.568               | 0.034          | -0.134              | 0.355          | -0.055              | 0.706          | -0.165              | 0.252          | 0.423              | 0             | 0.21               | 0.087         | 0.083              | 0.503         | -0.259              | 0.046          | -0.494              | 0              | -0.391              | 0.002          | 0.045                           | 0.733                      | 0.077                           | 0.56                       | -0.057                          | 0.667                      | -0.194                         | 0.138                     | -0.106                         | 0.421                     | -0.045                         | 0.735                     | 001e06113ace |
| -0.007             | 0.963         | 0.057              | 0.692         | -0.113             | 0.435         | -0.101              | 0.491          | -0.032              | 0.825          | -0.14               | 0.337          | 0.025               | 0.879          | 0.046               | 0.78           | 0.014               | 0.933          | 0.293              | 0.023         | 0.007              | 0.959         | -0.078             | 0.555         | -0.045              | 0.796          | -0.11               | 0.53           | -0.083              | 0.636          | 0.075                           | 0.667                      | -0.082                          | 0.641                      | -0.207                          | 0.233                      | 0.093                          | 0.597                     | 0.071                          | 0.685                     | -0.18                          | 0.302                     | 001e06113ad6 |
| 0.308              | 0.056         | 0.332              | 0.039         | 0.221              | 0.177         | -0.28               | 0.084          | -0.247              | 0.13           | 0.036               | 0.829          | 0                   | 9999           | 0                   | 9999           | 0                   | 9999           | 0.181              | 0.297         | 0.064              | 0.715         | 0.067              | 0.701         | -0.124              | 0.39           | -0.125              | 0.388          | -0.195              | 0.175          | -0.07                           | 0.627                      | -0.011                          | 0.941                      | -0.157                          | 0.277                      | -0.101                         | 0.484                     | -0.023                         | 0.876                     | -0.144                         | 0.318                     | 001e06113ad8 |
| 0                  | 9999          | 0                  | 9999          | 0                  | 9999          | 0                   | 9999           | 0                   | 9999           | 0                   | 9999           | -0.102              | 0.728          | -0.044              | 0.882          | -0.291              | 0.312          | -0.045             | 0.755         | -0.018             | 0.902         | -0.095             | 0.513         | -0.102              | 0.535          | -0.172              | 0.294          | -0.159              | 0.334          | 0.005                           | 0.974                      | -0.026                          | 0.876                      | -0.087                          | 0.6                        | -0.262                         | 0.107                     | -0.343                         | 0.033                     | -0.223                         | 0.173                     | 001e06113cf1 |
| 0.613              | 0.02          | 0.606              | 0.022         | 0.362              | 0.203         | 0.354               | 0.215          | 0.433               | 0.122          | 0.189               | 0.518          | 0.057               | 0.624          | 0.092               | 0.43           | 0.1                 | 0.388          | 0.077              | 0.64          | 0.03               | 0.858         | -0.096             | 0.561         | 0                   | 9999           | 0                   | 9999           | 0                   | 9999           | 0                               | 9999                       | 0                               | 9999                       | 0                               | 9999                       | 0                              | 9999                      | 0                              | 9999                      | 0                              | 9999                      | 001e06113cff |
| 0.336              | 0.003         | 0.312              | 0.006         | 0.176              | 0.127         | 0.247               | 0.064          | 0.287               | 0.03           | 0.209               | 0.119          | -0.07               | 0.613          | -0.113              | 0.411          | -0.178              | 0.193          | 0                  | 9999          | 0                  | 9999          | 0                  | 9999          | 0.61                | 0.027          | 0.621               | 0.023          | 0.372               | 0.211          | 0.369                           | 0.195                      | 0.428                           | 0.127                      | 0.135                           | 0.645                      | 0.505                          | 0.066                     | 0.55                           | 0.042                     | 0.322                          | 0.261                     | 001e06113d22 |
| 0.333              | 0.013         | 0.039              | 0.775         | -0.143             | 0.298         | 0.049               | 0.734          | -0.04               | 0.782          | -0.146              | 0.308          | 0                   | 9999           | 0                   | 9999           | 0                   | 9999           | 0.464              | 0.094         | 0.447              | 0.109         | 0.298              | 0.301         | 0.067               | 0.565          | -0.13               | 0.265          | -0.17               | 0.143          | 0.247                           | 0.032                      | 0.206                           | 0.075                      | 0.041                           | 0.726                      | 0.035                          | 0.766                     | 0.099                          | 0.396                     | 0.02                           | 0.863                     | 001e06113d32 |
| 0                  | 9999          | 0                  | 9999          | 0                  | 9999          | 0                   | 9999           | 0                   | 9999           | 0                   | 9999           | 0.104               | 0.371          | -0.069              | 0.554          | -0.109              | 0.349          | 0.161              | 0.165         | 0.146              | 0.208         | 0.098              | 0.399         | -0.042              | 0.759          | -0.157              | 0.252          | -0.204              | 0.135          | 0.022                           | 0.875                      | -0.067                          | 0.628                      | -0.253                          | 0.062                      | -0.27                          | 0.046                     | -0.379                         | 0.004                     | -0.338                         | 0.012                     | 001e06113d83 |
| 0.554              | 0             | 0.239              | 0.037         | -0.036             | 0.755         | 0.525               | 0              | 0.134               | 0.292          | -0.124              | 0.331          | -0.075              | 0.632          | -0.005              | 0.977          | -0.012              | 0.941          | 0.103              | 0.456         | -0.017             | 0.904         | -0.147             | 0.284         | 0                   | 9999           | 0                   | 9999           | 0                   | 9999           | 0                               | 9999                       | 0                               | 9999                       | 0                               | 9999                       | 0                              | 9999                      | 0                              | 9999                      | 0                              | 9999                      | 001e06113dbc |
| 0.197              | 0.185         | 0.054              | 0.717         | 0.014              | 0.924         | -0.346              | 0.135          | -0.338              | 0.146          | -0.239              | 0.31           | -0.077              | 0.614          | -0.082              | 0.592          | -0.165              | 0.279          | 0                  | 9999          | 0                  | 9999          | 0                  | 9999          | -0.139              | 0.23           | -0.31               | 0.006          | -0.285              | 0.013          | -0.034                          | 0.77                       | -0.096                          | 0.409                      | -0.12                           | 0.303                      | 0.418                          | 0                         | 0.033                          | 0.779                     | -0.166                         | 0.152                     | 001e06113f54 |
| 0.457              | 0.002         | 0.255              | 0.091         | 0.085              | 0.581         | 0.588               | 0              | 0.257               | 0.105          | 0.005               | 0.975          | -0.15               | 0.368          | -0.028              | 0.866          | -0.149              | 0.373          | 0.062              | 0.598         | -0.088             | 0.451         | -0.111             | 0.341         | 0.011               | 0.944          | -0.126              | 0.398          | -0.112              | 0.453          | 0.316                           | 0.033                      | 0.127                           | 0.4                        | -0.111                          | 0.462                      | 0.039                          | 0.795                     | -0.072                         | 0.631                     | -0.097                         | 0.519                     | 001e0611441e |
| 0.443              | 0.005         | 0.179              | 0.283         | 0.026              | 0.876         | -0.171              | 0.424          | -0.022              | 0.919          | -0.044              | 0.837          | 0.45                | 0              | 0.08                | 0.496          | -0.148              | 0.209          | 0.316              | 0.03          | 0.106              | 0.478         | 0.054              | 0.718         | -0.047              | 0.761          | -0.267              | 0.076          | -0.383              | 0.009          | 0.002                           | 0.989                      | -0.02                           | 0.899                      | -0.197                          | 0.2                        | -0.36                          | 0.015                     | -0.446                         | 0.002                     | -0.292                         | 0.051                     | 001e061144be |
| 0.415              | 0             | 0.153              | 0.192         | -0.057             | 0.629         | 0.478               | 0              | 0.162               | 0.176          | -0.033              | 0.787          | 0                   | 9999           | 0                   | 9999           | 0                   | 9999           | 0.43               | 0.003         | 0.235              | 0.12          | -0.017             | 0.91          | -0.095              | 0.572          | -0.019              | 0.912          | 0.097               | 0.561          | -0.218                          | 0.19                       | -0.074                          | 0.661                      | -0.137                          | 0.412                      | 0.161                          | 0.334                     | 0.306                          | 0.062                     | 0.227                          | 0.17                      | 001e061144c0 |
| 0.503              | 0.096         | 0.286              | 0.367         | 0.051              | 0.874         | 0                   | 9999           | 0                   | 9999           | 0                   | 9999           | -0.023              | 0.911          | -0.032              | 0.876          | 0.107               | 0.596          | 0.36               | 0.026         | 0.415              | 0.01          | 0.308              | 0.06          | 0.141               | 0.232          | -0.23               | 0.049          | -0.325              | 0.005          | 0.359                           | 0.002                      | 0.077                           | 0.514                      | -0.188                          | 0.109                      | 0.48                           | 0                         | 0.117                          | 0.323                     | -0.122                         | 0.302                     | 001e06114500 |
| -0.123             | 0.534         | -0.209             | 0.286         | -0.373             | 0.05          | 0.014               | 0.945          | 0.018               | 0.93           | 0.124               | 0.546          | -0.125              | 0.389          | -0.157              | 0.277          | -0.2                | 0.164          | 0.486              | 0             | 0.116              | 0.327         | -0.128             | 0.277         | -0.15               | 0.625          | -0.003              | 0.991          | 0.147               | 0.633          | 0.401                           | 0.197                      | 0.27                            | 0.396                      | 0.062                           | 0.847                      | -0.152                         | 0.619                     | -0.004                         | 0.991                     | 0.147                          | 0.631                     | 001e06114503 |
| -0.06              | 0.678         | -0.068             | 0.641         | -0.134             | 0.353         | 0.203               | 0.229          | 0.216               | 0.2            | 0.058               | 0.733          | 0                   | 9999           | 0                   | 9999           | 0                   | 9999           | -0.143             | 0.642         | 0.006              | 0.986         | 0.154              | 0.617         | -0.357              | 0.063          | -0.396              | 0.037          | -0.314              | 0.103          | 0.056                           | 0.778                      | 0.065                           | 0.743                      | 0.176                           | 0.371                      | -0.058                         | 0.774                     | -0.059                         | 0.771                     | 0.03                           | 0.881                     | 001e061146bc |
| 0                  | 9999          | 0                  | 9999          | 0                  | 9999          | 0                   | 9999           | 0                   | 9999           | 0                   | 9999           | 0.707               | 0              | 0.337               | 0.048          | -0.055              | 0.753          | -0.029             | 0.885         | -0.015             | 0.938         | 0.095              | 0.629         | -0.15               | 0.298          | -0.174              | 0.226          | -0.182              | 0.205          | -0.116                          | 0.423                      | -0.161                          | 0.264                      | -0.249                          | 0.082                      | -0.061                         | 0.674                     | -0.068                         | 0.638                     | -0.134                         | 0.353                     | 001e061146cb |
| 0.669              | 0             | 0.253              | 0.142         | -0.116             | 0.506         | 0.517               | 0.003          | 0.6                 | 0              | 0.37                | 0.04           | -0.022              | 0.901          | -0.096              | 0.583          | -0.019              | 0.912          | 0.148              | 0.306         | -0.042             | 0.775         | -0.126             | 0.383         | 0                   | 9999           | 0                   | 9999           | 0                   | 9999           | 0                               | 9999                       | 0                               | 9999                       | 0                               | 9999                       | 0                              | 9999                      | 0                              | 9999                      | 0                              | 9999                      | 001e061146d6 |
| -0.24              | 0.164         | -0.034             | 0.848         | 0.009              | 0.958         | -0.051              | 0.862          | -0.005              | 0.987          | 0.137               | 0.64           | 0.256               | 0.032          | 0.284               | 0.017          | 0.151               | 0.213          | 0                  | 9999          | 0                  | 9999          | 0                  | 9999          | 0.705               | 0              | 0.337               | 0.051          | -0.058              | 0.743          | -0.02                           | 0.911                      | 0.03                            | 0.867                      | -0.033                          | 0.854                      | 0.681                          | 0                         | 0.275                          | 0.11                      | -0.102                         | 0.561                     | 001e06114fcf |
| 0.306              | 0.009         | 0.019              | 0.874         | -0.13              | 0.276         | -0.23               | 0.148          | -0.251              | 0.113          | -0.286              | 0.07           |                     |                |                     |                |                     |                | 0.707              | 0             | 0.501              | 0.002         | 0.085              | 0.626         | -0.361              | 0.033          | -0.303              | 0.077          | -0.113              | 0.517          | 0.093                           | 0.596                      | 0.107                           | 0.539                      | 0.058                           | 0.74                       | -0.293                         | 0.088                     | -0.116                         | 0.507                     | 0.007                          | 0.969                     | 001e06114fd4 |
|                    |               |                    |               |                    |               |                     |                |                     |                |                     |                |                     |                |                     |                |                     |                | 0.087              | 0.619         | -0.121             | 0.487         | -0.098             | 0.575         | -0.072              | 0.544          | -0.085              | 0.473          | -0.048              | 0.689          | 0.199                           | 0.091                      | 0.168                           | 0.155                      | 0.038                           | 0.749                      | -0.309                         | 0.008                     | -0.406                         | 0                         | -0.355                         | 0.002                     | 001e06115365 |
|                    |               |                    |               |                    |               |                     |                |                     |                |                     |                |                     |                |                     |                |                     |                | 0.364              | 0.002         | 0.348              | 0.003         | 0.17               | 0.15          |                     |                |                     |                |                     |                |                                 |                            |                                 |                            |                                 |                            |                                |                           |                                |                           |                                |                           | 001e06115369 |


__Fig. 各气体浓度与风速相关系数p_value（统计显著性）统计__ 

|     | Max_CO_pvalue | Avg_CO_pvalue | Min_CO_pvalue | Max_H2S_pvalue | Avg_H2S_pvalue | Min_H2S_pvalue | Max_NO2_pvalue | Avg_NO2_pvalue | Min_NO2_pvalue | Max_O3_pvalue | Avg_O3_pvalue | Min_O3_pvalue | Max_SO2_pvalue | Avg_SO2_pvalue | Min_SO2_pvalue | Max_oxidizing_gases_pvalue | Avg_oxidizing_gases_pvalue | Min_oxidizing_gases_pvalue | Max_reducing_gases_pvalue | Avg_reducing_gases_pvalue | Min_reducing_gases_pvalue |
|-----|---------------|---------------|---------------|----------------|----------------|----------------|----------------|----------------|----------------|---------------|---------------|---------------|----------------|----------------|----------------|----------------------------|----------------------------|----------------------------|---------------------------|---------------------------|---------------------------|
|     | 33            | 41            | 53            | 44             | 49             | 52             | 46             | 48             | 52             | 33            | 47            | 54            | 46             | 40             | 42             | 46                         | 52                         | 53                         | 40                        | 42                        | 50                        |
| *   | 7             | 9             | 1             | 3              | 3              | 2              | 2              | 6              | 2              | 10            | 4             |               | 6              | 6              | 4              | 4                          | 1                          | 1                          | 5                         | 5                         | 2                         |
| **  | 10            | 4             |               | 4              | 1              |                | 1              |                |                | 5             | 3             |               | 1              | 4              | 5              | 2                          | 1                          |                            | 5                         | 5                         | 2                         |
| *** | 4             |               |               | 3              | 1              |                | 5              |                |                | 6             |               |               | 1              | 4              | 3              | 2                          |                            |                            | 4                         | 2                         |                           |


`chicago_windSpeed.py`
```python
# -*- coding: utf-8 -*-
"""
Created on Sun Jun 19 20:16:45 2022

@author: Richie Bao-caDesign设计(cadesign.cn)
"""
def chicago_windSpeed_excel2df(xlsx_fn,sheet_name):
    '''
    读取含有风速的xlsx文件为DaraFrame数据格式，并写入到数据库中

    Parameters
    ----------
    xlsx_fn : string
        含有风速的xlsx文件.
    sheet_name : string
        xlsx文件表名.

    Returns
    -------
    chicago_ws_date_df : DataFrame
        读取并转换为DataFrame格式的风速数据.

    '''
    import pandas as pd
    
    chicago_ws_df_lst=[]
    for sn in sheet_name:
        chicago_windspeed=pd.read_excel(xlsx_fn,sheet_name='{}'.format(sn),header=[0,1])
        chicago_windspeed_ws=chicago_windspeed['Wind Speed (mph)']
        dates=pd.date_range('2018-0{}'.format(sn),periods=len(chicago_windspeed_ws),freq='D')
        chicago_windspeed_ws.rename(index=dict(zip(chicago_windspeed_ws.index,dates)),inplace=True)

        chicago_ws_df_lst.append(chicago_windspeed_ws)
    chicago_ws_df=pd.concat(chicago_ws_df_lst)
    chicago_ws_date_df=chicago_ws_df.reset_index().rename(columns={'index':'date'})
    return chicago_ws_date_df

if __name__=="__main__":
    import sys
    sys.path.append('..')
    import util    
    import geopandas as gpd
    import pandas as pd
    import os
    import pickle
    from database import cfg_load_yaml,df2postSQL,postSQL2df 
    parent_path=os.path.dirname(os.getcwd())
    
    cfg=cfg_load_yaml('./config.yml')  
    UN=cfg["postgreSQL"]["myusername"]
    PW=cfg["postgreSQL"]["mypassword"]
    DB=cfg["postgreSQL"]["mydatabase"] 
    GC='geometry'      
    
    Chicago_epsg=cfg['Chicago_epsg']    
    
    xlsx_fn='./data/raw_data/Chicago weather data_20184AOT.xlsx'
    sheet_name=['1','2','3','4','5']
    # chicago_ws_df=chicago_windSpeed_excel2df(xlsx_fn,sheet_name)
    # print(chicago_ws_df)
    
    # df2postSQL(chicago_ws_df,table_name='chicago_windspeed',myusername=UN,mypassword=PW,mydatabase=DB)
    chicago_ws_df=postSQL2df(table_name='chicago_windspeed',myusername=UN,mypassword=PW,mydatabase=DB)    
```

`database.py`
```python
def df2postSQL(df,table_name,if_exists='replace',**kwargs):
    '''
    function - 将DataFrame格式数据写入PostgreSQL数据库
    
    Paras:
        df - DataFrame格式数据
        table_name - 写入数据库中的表名
        **kwargs - 连接数据库相关信息，包括myusername（数据库的用户名），mypassword（用户密钥），mydatabase（数据库名）
    '''     
    from sqlalchemy import create_engine
    #The URI should start with postgresql:// instead of postgres://. SQLAlchemy used to accept both, but has removed support for the postgres name.
    engine=create_engine("postgresql://{myusername}:{mypassword}@localhost:5432/{mydatabase}".format(myusername=kwargs['myusername'],mypassword=kwargs['mypassword'],mydatabase=kwargs['mydatabase']))  
    conn=engine.connect()
    df.to_sql(table_name, con=conn, if_exists=if_exists,index=False)    
    # gdf.to_postgis(table_name, con=engine, if_exists='replace', index=False,)  
    print("_"*50)    
    print('The GeoDataFrame has been written to the PostgreSQL database.The table name is {}.'.format(table_name))     

def postSQL2df(table_name,**kwargs):    
    '''
    function - 读取PostgreSQL数据库中的表为DataFrame格式数据
    
    Paras:
        table_name - 待读取数据库中的表名
        **kwargs - 连接数据库相关信息，包括myusername（数据库的用户名），mypassword（用户密钥），mydatabase（数据库名）
    '''
    from sqlalchemy import create_engine
    import pandas as pd   
    
    engine=create_engine("postgresql://{myusername}:{mypassword}@localhost:5432/{mydatabase}".format(myusername=kwargs['myusername'],mypassword=kwargs['mypassword'],mydatabase=kwargs['mydatabase']))  
    conn=engine.connect()
    df=pd.read_sql('SELECT * FROM {}'.format(table_name), conn)

    print("_"*50)
    print('The data has been read from PostgreSQL database. The table name is {}.'.format(table_name))    
    return df    
```

`air_time_series_wind_correlation.py`
```python
# -*- coding: utf-8 -*-
"""
Created on Sun Jun 19 21:52:59 2022

@author: Richie Bao-caDesign设计(cadesign.cn)
"""
def correlation_pvalue_inpairs(chicago_ws_df,TN,n=10):
    '''
    逐个计算风速数据（含最大Max，最小Min和平均Avg三个风速值），与各个测量点气体浓度年均值的相关系数

    Parameters
    ----------
    chicago_ws_df : DataFrame
        风速数据.
    TN : dict
        气体测量值.
    n : int, optional
        如果测量值样本数小于该值则不计算相关系数. The default is 10.

    Returns
    -------
    correlation_pvalue_gdf : GeoDataFrame
        包含相关系数、p_value，及测量点位坐标的地理空间数据.

    '''
    from scipy import stats
    from tqdm import tqdm
    from database import postSQL2gpd
    import geopandas as gpd
    
    correlation_pvalue_lst=[]
    air_ID_gdf=pd.DataFrame()
    for k,v in tqdm(TN.items()):    
        air_gdf=postSQL2gpd(table_name=v,geom_col=GC,myusername=UN,mypassword=PW,mydatabase=DB)
        if len(air_gdf)>len(air_ID_gdf):
            air_ID_gdf=air_gdf
        air_co_D_df=air_gdf[[i for i in air_gdf.columns if i.split('_')[0] in ['D',]]] #'node'
        air_co_D_df.rename(columns={i:pd.to_datetime(i.split("_")[1]) for i in  air_co_D_df.columns},inplace=True)
        air_co_D_idx_df=air_co_D_df.T
        
        ws_co_df=pd.merge(chicago_ws_df,air_co_D_idx_df,left_index=True, right_index=True)    
 
        factors_columns=['Max','Avg','Min']
        ppm_D_columns=[i for i in ws_co_df.columns if i not in factors_columns]
        correlation_pvalue={}
        for factor in factors_columns:
            cp_temp={}
            for p in ppm_D_columns:
                f_p_df=ws_co_df[[factor,p]]
                f_p_df.dropna(inplace=True)
                if len(f_p_df)>n:
                    cp_temp[p]=stats.pearsonr(f_p_df[factor].values,f_p_df[p].values)
                else:
                    cp_temp[p]=(0,9999)
            correlation_pvalue["{}_{}".format(factor,k)]=cp_temp
            
        correlation_pvalue_df=pd.DataFrame.from_dict(correlation_pvalue)
        columns=correlation_pvalue_df.columns.to_list()
        for column in columns:
            correlation_pvalue_df["{}_correlation".format(column)],correlation_pvalue_df["{}_pvalue".format(column)]=zip(*correlation_pvalue_df[column])
        correlation_pvalue_df.drop(columns=columns,inplace=True)
        # correlation_pvalue_df=pd.DataFrame.from_dict(correlation_pvalue, orient='index').stack().to_frame(name='corr_pV')
        # correlation_pvalue_df['correlation']=correlation_pvalue_df.corr_pV.apply(lambda row:row[0])
        # correlation_pvalue_df['p_value']=correlation_pvalue_df.corr_pV.apply(lambda row:row[1])
        
        correlation_pvalue_lst.append(correlation_pvalue_df)
    correlation_pvalue_concat_df=pd.concat(correlation_pvalue_lst,axis=1)
    correlation_pvalue_concat_geometry_df=pd.merge(correlation_pvalue_concat_df,air_ID_gdf[['geometry','node_id']],left_index=True,right_index=True)
    correlation_pvalue_gdf=gpd.GeoDataFrame(correlation_pvalue_concat_geometry_df,geometry='geometry',crs=air_ID_gdf.crs)
    return correlation_pvalue_gdf

if __name__=="__main__":
    import sys
    sys.path.append('..')
    import util    
    import geopandas as gpd
    import pandas as pd
    import os
    import pickle
    from database import cfg_load_yaml,postSQL2gpd,postSQL2df,gpd2postSQL 
    parent_path=os.path.dirname(os.getcwd())
    
    cfg=cfg_load_yaml('../config.yml')  
    UN=cfg["postgreSQL"]["myusername"]
    PW=cfg["postgreSQL"]["mypassword"]
    DB=cfg["postgreSQL"]["mydatabase"] 
    GC='geometry'      
    
    Chicago_epsg=cfg['Chicago_epsg']  
    
    #A-计算风速数据与各个测量点气体浓度年均值的相关系数
    TN={"CO":"air_co_resample_value_hrf",
        "H2S":'air_h2s_resample_value_hrf',
        'NO2':'air_no2_resample_value_hrf',
        'O3':'air_o3_resample_value_hrf',
        'SO2':'air_so2_resample_value_hrf',
        'oxidizing_gases':'air_oxidizing_gases_resample_value_hrf',
        'reducing_gases':'air_reducing_gases_resample_value_hrf'}
    chicago_ws_df=postSQL2df(table_name='chicago_windspeed',myusername=UN,mypassword=PW,mydatabase=DB)
    chicago_ws_df['date']=pd.to_datetime(chicago_ws_df['date'])
    chicago_ws_df.set_index('date',inplace=True)
    #%%    
    # correlation_pvalue_gdf=correlation_pvalue_inpairs(chicago_ws_df,TN)
    #%%    
    # gpd2postSQL(correlation_pvalue_gdf.round(3),table_name='air_wind_correlation_pvalue',myusername=UN,mypassword=PW,mydatabase=DB) 
    #%%
    air_wind_correlation_pvalue_gdf=postSQL2gpd(table_name='air_wind_correlation_pvalue',myusername=UN,mypassword=PW,mydatabase=DB)    
    #%%
    # air_wind_correlation_pvalue_gdf.drop(columns=['geometry']).round(3).to_excel('../data/processed_data/air_wind_correlation_pvalue.xlsx')    
    #%%
    import numpy as np
    pvalue_columns=[i for i in air_wind_correlation_pvalue_gdf.columns if i.split("_")[-1]=='pvalue']    
    pvalue_df=air_wind_correlation_pvalue_gdf[pvalue_columns]
    conds=[(pvalue_df.values<0.05) & (pvalue_df.values>=0.01),(pvalue_df.values<0.01) & (pvalue_df.values>=0.001),pvalue_df.values<0.001]
    choices=['*', '**','***']
    pvalue_reclassify_df=pd.DataFrame(np.select(conds,choices,default=''),index=pvalue_df.index,columns=pvalue_df.columns)
    correlation_gdf=air_wind_correlation_pvalue_gdf.drop(columns=pvalue_columns)
    # air_wind_correlation_pvalue_reclassify_gdf=pd.merge(correlation_gdf,pvalue_reclassify_df,left_index=True,right_index=True)
    # gpd2postSQL(air_wind_correlation_pvalue_reclassify_gdf,table_name='air_wind_correlation_pvalue_reclassify',myusername=UN,mypassword=PW,mydatabase=DB) 
    # #%%
    # rowCount_ONpvalue=pvalue_reclassify_df.apply(pd.value_counts)
    # rowCount_ONpvalue.to_excel('../data/processed_data/air_wind_rowCount_ONpvalue.xlsx')   
    #%%  
```


###### 7) 各测量点位气体浓度之间是否具有相关性

从计算结果来看，测量点气体浓度之间基本不具有相关性。其中` Y_H2S:Y_SO2 `为-0.366 少许负相关；`Y_NO2:Y_O3 `为0.407，正相关；`Y_NO2:Y_oxidizing_gases `为0.339；` Y_NO2:Y_reducing_gases`为0.792，较强的正相关，是因为`reducing_gases`类气体包括`NO2`。

__Fig. 各测量点位气体浓度两两之间相关系数__ 

|                                    | correlation | pvalue | pvalue_mark |
|------------------------------------|-------------|--------|-------------|
| Y_CO:Y_H2S                         | -0.056      | 0.702  |             |
| Y_CO:Y_NO2                         | 0.035       | 0.813  |             |
| Y_CO:Y_O3                          | 0.096       | 0.513  |             |
| Y_CO:Y_SO2                         | 0.163       | 0.263  |             |
| Y_CO:Y_oxidizing_gases             | -0.134      | 0.36   |             |
| Y_CO:Y_reducing_gases              | 0.172       | 0.238  |             |
| Y_H2S:Y_NO2                        | 0.155       | 0.287  |             |
| Y_H2S:Y_O3                         | 0.213       | 0.142  |             |
| Y_H2S:Y_SO2                        | -0.366      | 0.01   | **          |
| Y_H2S:Y_oxidizing_gases            | 0.045       | 0.758  |             |
| Y_H2S:Y_reducing_gases             | 0.113       | 0.44   |             |
| Y_NO2:Y_O3                         | 0.407       | 0.004  | **          |
| Y_NO2:Y_SO2                        | -0.181      | 0.213  |             |
| Y_NO2:Y_oxidizing_gases            | 0.339       | 0.017  | *           |
| Y_NO2:Y_reducing_gases             | 0.792       | 0      | ***         |
| Y_O3:Y_SO2                         | -0.1        | 0.493  |             |
| Y_O3:Y_oxidizing_gases             | -0.106      | 0.469  |             |
| Y_O3:Y_reducing_gases              | 0.256       | 0.075  |             |
| Y_SO2:Y_oxidizing_gases            | -0.163      | 0.263  |             |
| Y_SO2:Y_reducing_gases             | -0.085      | 0.563  |             |
| Y_oxidizing_gases:Y_reducing_gases | 0.041       | 0.781  |             |


__Fig. 各测量点位气体浓度年均值__ 

<img src="./imgs/3_3_2_86_s.jpg" height="auto" width="auto" title="caDesign">

`air_time_series_wind_correlation.py`
```python
def gases_Y_correlation(TN):
    '''
    提取各个单独气体浓度年均值数据为一个GeoDataFrame文件

    Parameters
    ----------
    TN : dict
        包含气体数据文件路径的字典.

    Returns
    -------
    air_Y_concat_gdf : GeoDataFrame
        提取的气体浓度年均值数据.

    '''
    from scipy import stats
    from tqdm import tqdm
    from database import postSQL2gpd
    import geopandas as gpd
    import pandas as pd
    from functools import reduce
    
    air_gdf_lst=[]
    for k,v in TN.items():    
        air_gdf=postSQL2gpd(table_name=v,geom_col=GC,myusername=UN,mypassword=PW,mydatabase=DB)
        air_Y_columns=['Y_2018-12-31','geometry', 'node_id']
        air_Y_gdf=air_gdf[air_Y_columns]            
        air_Y_gdf.rename(columns={'Y_2018-12-31':'Y_{}'.format(k)},inplace=True)
        air_gdf_lst.append(air_Y_gdf)

    air_Y_concat_gdf=reduce(lambda  left,right: pd.merge(left,right,on=['node_id','geometry'],how='inner'), air_gdf_lst)
    # air_Y_concat_gdf=pd.concat(air_gdf_lst,axis=1)
    return air_Y_concat_gdf

def df_correlation_pvalue_inpairs(df):
    '''
    计算DataFrame格式数据，两两列之间的相关系数，并包含p_value和其中区间星号标识

    Parameters
    ----------
    df : DataFrame
        待计算的数据.

    Returns
    -------
    DataFrame
        两两相关系数结果.

    '''
    from scipy import stats
    import itertools
    import pandas as pd
    import numpy as np
    
    columns=df.columns.to_list()
    columns_inpairs=[list(i) for i in list(itertools.combinations(columns, 2))]
    pearsonr_dict={}
    for i in columns_inpairs:
        # print(i)
        factors=df[i]
        correlation_pvalue=stats.pearsonr(factors[i[0]].values,factors[i[1]].values)
        pearsonr_dict['{}:{}'.format(i[0],i[1])]={'correlation':correlation_pvalue[0],'pvalue':correlation_pvalue[1]}
    pearsonr_df=pd.DataFrame.from_dict(pearsonr_dict).T
    
    conds=[(pearsonr_df.pvalue.values<0.05) & (pearsonr_df.pvalue.values>=0.01),(pearsonr_df.pvalue.values<0.01) & (pearsonr_df.pvalue.values>=0.001),pearsonr_df.pvalue.values<0.001]
    choices=['*', '**','***']
    pvalue_reclassify_df=pd.DataFrame(np.select(conds,choices,default=''),index=pearsonr_df.index,columns=['pvalue_mark'])
    pearsonr_reclassify_df=pd.merge(pearsonr_df,pvalue_reclassify_df,left_index=True,right_index=True)
    
    return pearsonr_reclassify_df.round(3)

if __name__=="__main__":
    #B-计算气体浓度之间的相关系数
    air_Y_concat_gdf=gases_Y_correlation(TN)
    gpd2postSQL(air_Y_concat_gdf.round(3),table_name='air_Y_concat_round',myusername=UN,mypassword=PW,mydatabase=DB) 
    #%%
    air_Y_concat_gdf=postSQL2gpd(table_name='air_Y_concat',myusername=UN,mypassword=PW,mydatabase=DB)    
    air_Y_concat_df=air_Y_concat_gdf.drop(columns=['geB-ometry', 'node_id'])
    #%%   
    pearsonr_reclassify_df=df_correlation_pvalue_inpairs(air_Y_concat_df)
    pearsonr_reclassify_df.to_excel('../data/processed_data/gases_ppm_pearsonr.xlsx')
    #%%  
```


##### B.2.3.2 颗粒类




##### B.2.3.3 热环境


##### B.2.3.4 噪音


##### B.2.3.5 光环境


### B.3 讨论与结论


#### B.参考文献


## C. 研究代码更新、发布与安装