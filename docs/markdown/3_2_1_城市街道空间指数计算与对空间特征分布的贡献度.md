> Created on Wed Apr 28 14:46:58 2021 @author: Richie Bao-caDesign设计(cadesign.cn)__+updated on Tue Jan 18 20:45:54 2022 by Richie Bao 

# 3.2.1 城市街道空间指数计算与对空间特征分布的贡献度

## A. 建立研究代码项目

1. 建立本地仓库与GitHub仓库

2. 建立数据库

使用[pgAdmin](https://www.pgadmin.org/)创建本地关系数据库`PAPER_Urban_Street_Space_Metrics`，并在`Query Editor`中执行`CREATE EXTENSION postgis;`，使能够存储具有坐标系统的地理几何对象。随书写研究代码进展读写数据库。

3. 建立配置文件

使用[YAML](https://en.wikipedia.org/wiki/YAML)文件格式，书写配置文件。随书写研究代码进展完善配置内容。因为每一个.py的代码文件通常是解决某一类问题的代码函数和类的汇总，因此在配置文件时，通常按照代码文件分组，方便查找相关配置。本次实验涉及处理的数据和内容较多，因此配置项也相对较多。

`config.yml`
```yaml
---
data_path:
   region_merge: './data/raw_data/region_merge/region_merge.shp'      
   region: './data/raw_data/region/region.shp'
   road: './data/raw_data/Xian road/Xian road.shp'
   tour_line: './data/raw_data/tour line.kml'
   tour_line_seg: './data/raw_data/tour_line_seg/tour_line_seg.shp'

xian_epsg: 32649

postgreSQL:
    myusername: 'postgres'
    mypassword: '123456'
    mydatabase: 'PAPER_Urban_Street_Space_Metrics'
    geom_col: 'geometry'    

streetview:
    ak: 'rSxNX840wLxwVVhs5RDInfPqegZ12G78'
    distance_region: 200
    save_path_BSV_region: './data/raw_data/panoramic imgs'
    save_path_BSV_retrival_info: 
        pt_fns: './data/raw_data/pt_fns_region.pkl'
        coords: './data/raw_data/coords_region.pkl'
        downloadError_idx: './data/raw_data/downloadError_idx_region.pkl'
    save_path_img_valid:
        img_val: './data/raw_data/imgVal_fns.pkl'  
        img_inval: './data/raw_data/imgInval_fns.pkl' 
    panoramic_imgs_valid_root: 'G:\data\PAPER_Urban_Street_Space_Metrics/data/raw_data/panoramic imgs valid'  #'./data/raw_data/panoramic imgs valid'    
    save_path_BSV_street: './data/raw_data/panoramic imgs_tour line'
    distance_street: 8
    save_path_BSV_street: './data/raw_data/panoramic imgs_tour line'
    save_path_BSV_retrival_info_street: 
        pt_fns: './data/raw_data/pt_fns_street.pkl'
        coords: './data/raw_data/coords_street.pkl'
        downloadError_idx: './data/raw_data/downloadError_idx_street.pkl'   
    panoramic_imgs_valid_root_street: 'G:\data\PAPER_Urban_Street_Space_Metrics/data/raw_data/panoramic imgs_tour line valid' #'./data/raw_data/panoramic imgs_tour line valid'   
  
POI:
    poi_path: './data/raw_data/poi_batchCrawler'    
    fields_extraction: ['name','location_lat', 'location_lng','detail_info_tag','detail_info_overall_rating', 'detail_info_price']
    save_path_POI: {'geojson':'./data/processed_data/poiAll_gpd.geojson',
                    'shp':'./data/processed_data/poiAll_gpd/poiAll_gpd.shp',
                    'pkl':'./data/processed_data/poiAll_gpd.pkl'} 
 
panaSeg:
    pano_path: './data/processed_data/img_seg'
    label_seg_path: './data/processed_data/label_seg' 
    
panaSeg_street:
    tour_line_seg: 'G:\data\PAPER_Urban_Street_Space_Metrics/data/processed_data/tour line seg' #'./data/processed_data/tour line seg'
    tourline_label_seg: 'G:\data\PAPER_Urban_Street_Space_Metrics/data/processed_data/tourline_label_seg' #'./data/processed_data/tourline_label_seg'    
    
equi2cube:
    face_size: 1000
    cube_img: 'G:\data\PAPER_Urban_Street_Space_Metrics/data/processed_data/cube_img' #'./data/processed_data/cube_img'
    region:
        img_seg_cube_root:  'G:\data\PAPER_Urban_Street_Space_Metrics/data/processed_data/cube_img_seg'#'./data/processed_data/cube_img_seg'
        label_seg_cube_root: 'G:\data\PAPER_Urban_Street_Space_Metrics/data/processed_data/cube_label_seg' #'./data/processed_data/cube_label_seg'
        img_seg_redefined_color_root: './data/processed_data/img_seg_redefined_color'
        img_cube: './data/processed_data/cube_img'
    street:
        img_seg_cube_root: './data/processed_data/cube_tourline_img_seg'
        label_seg_cube_root: './data/processed_data/cube_tourline_label_seg'
        img_seg_redefined_color_root: './data/processed_data/tourline_img_seg_redefined_color'

equi2polar:
    output_shape: (1024,1024)
    little_planet: 'little_planet_1'
    region:
        polar_seg_root: './data/processed_data/polar_seg'
        polar_img_root: './data/processed_data/polar_img'
        polar_sky_root: 'G:\data\PAPER_Urban_Street_Space_Metrics/data/processed_data/polar_sky' #'./data/processed_data/polar_sky'
    street:
        polar_tourline_sky_root: './data/processed_data/polar_tourline_sky'
        
spherical_panorama:
    panorama_example_fn: './data/raw_data/panoramic imgs valid/1e32241a3f2fe5a796ec847f_12.jpg'
    panorama_seg_example_fn: './data/processed_data/img_seg_redefined_color/1e32241a3f2fe5a796ec847f_12.jpg'
    img_sphere_root:  './data/processed_data/sphere_img'
    seg_sphere_root:  './data/processed_data/sphere_seg'
    
imgs_arranging:
    panoramic_transform_example_fn: '1e32241a3f2fe5a796ec847f_12.jpg' 
    cube_object_percentage_example_fn: {
        'vegetation':[['75245f2d4aed015a5fd4feb1_8','e88007042407fd57dd1e523a_0'],['033aa8624525bbe9c5f50dda_2','aa9dda69d2a493b92a06ce3a_1'],['c67fdf4bcf598975e8e582b1_11','36599cece30ad8582ab97cf0_3'],['b8866242b45bfb1ff80cad76_24','edbfbdf04a242554326212f5_6']],   
        'sky':[['ec02702c6c3b0e5e09ccddf0_15','36599cece30ad8582ab97cf0_2'],['c488235565ebb27fcd04efb1_1','73bb194cf5cb2cfcc236443a_0'],['2a8cd76df35285eb8515417d_32','dad50595f02890440969d9c9_2'],['b69c7b856514af4a28201ab6_23','c71309f0f7fb2fddbbdf8ff7_15']], 
        'sky_vegettion':[['415741155551fea63786f4d7_2','56023b6835284eacd618b780_2'],['ddcf30f710b5a7a511882493_2','cd0533f0f7fb2fddbbdf8fc5_0'],['3426adf70958ecccda1318f7_19','f293941cfc56794e0582c2fb_3'],['91df45f82d1625bed6b74eb0_18','0c15a38935dc0df92eb96d22_4']],  
        'ground':[['9beb8e887af77d1e8c7727fa_1','5317936ea1ee78e232169bdd_28'],['f96b591ea8a6e39141e1924c_1','a5f8bae0792cf934912ca3f6_2'],['db0318a07af2be0baf080fd0_2','b605ba58bdeb6544e0110382_3'],['61f2074cf5cb2cfcc23644fd_0','51eb85fc0e4b738514b54bb1_0']], 
        'equilibrium degree':[['9beb8e887af77d1e8c7727fa_1','fe0bb711c7dc4b206da3ccf0_5'],['f41ec51774e4f36840d63e4c_36','3e4c285cb209994de7e9653d_0'],['91df45f82d1625bed6b74eb0_18','36599cece30ad8582ab97cf0_2'],['1e32241a3f2fe5a796ec847f_27','0d70191440a0a7beacee7ab0_0']]        
        }
    object_percentage_cube_save_path: './charts/object_percentage_cube.png'
    skyline_metrics_domain: {
        'PA':[0,58,400], #400
        'SI':[0,1.9,4.3], #4.3
        'FD':[0,1.061,1.153] #1.153
        }    
    skyline_metrics_imgs_save_path: './charts'
    theme_color_cluster_save_path: './charts'
    theme_color_cluster_example_fn: ['320915fc28cd251103ec01b3_0.jpg','0a30d7fca993829688b988b0_6.jpg']
    kp_stats_example_fn: ['320915fc28cd251103ec01b3_1','daf31942100f17f0611809f5_2'] 
    kp_stats_example_save_path: './charts/KPSize.png' 
    
semantic_segmention_object_pixel_ratio:
        bins: [0,15,25,50,100]
        columns: ['vege','sky','sky_vege','ground','equilibrium_degree',]
        percentage2excel_path: './charts/objects_percentage.xlsx'
        digits: 3
    
skyline_shape_metrics:
    tiff_sky_save_root: 'G:\data\PAPER_Urban_Street_Space_Metrics/data/processed_data/tiff_sky'  
    hsv_lower: [0,0,200]
    hsv_upper: [180,255,255]  
    correlation_columns: ['number_of_patches','perimeter_area_ratio_mn','shape_index_mn', 'fractal_dimension_mn',]
    correlation_save_path: './charts/metrics_skyline_shape_correlation.xlsx'
    digits: 3    
    
color_metrics:
    number_of_colors: 16
    resize_scale: 0.5
    resize_scale_cluster: 0.1
    table_name_img_dominant_color: 'img_dominant_color'
    colors_dominant2cluster_path: 'G:\data\PAPER_Urban_Street_Space_Metrics\data\processed_data\colors_dominant2cluster.pkl' #'./data/processed_data/colors_dominant2cluster.pkl'
    colors_dominant_entropy_table_name: 'colors_dominant_entropy'     
    
KP_metrics:
    visual_BOW_region_fn: './data/processed_data/visual_BOW_region.pkl'
    feature_map_region_fn: 'G:\data\PAPER_Urban_Street_Space_Metrics\data\processed_data\feature_map_region.pkl'#'./data/processed_data/feature_map_region.pkl'
    featureMap_table_name: 'featureMap'
    num_cluster: 32
    kp_size_stats_table_name: 'kp_size_stats'
    bins: [0,10,20,30,40]

metrics_clustering:
    metrics_panorama_object_percent: ['vege','sky','ground','equilibrium_degree']
    metrics_sky_class_level_metrics: ['number_of_patches','perimeter_area_ratio_mn','shape_index_mn','fractal_dimension_mn']
    metrics_colors_dominant_entropy: ['counter']
    metrics_kp_size_stats: ['-0.001_10.0', '10.0_20.0','30.0_40.0', '20.0_30.0']    
    metrics_auxiliary: ['fn_stem', 'fn_key', 'fn_idx', 'geometry']
    fields_mapping: {'vege':'Green view index', 
                    'sky':'Sky view factor', 
                    'ground':'Ground view index', 
                    'equilibrium_degree':'Equilibrium degree',
                    'number_of_patches':'number of patches', 
                    'perimeter_area_ratio_mn':'Perimeter area ratio(mn)', 
                    'shape_index_mn':'Shape index(mn)',
                    'fractal_dimension_mn':'Fractal dimension(mn)', 
                    'counter':'Color richness index', 
                    '-0.001_10.0':'Key point size(0-10]', 
                    '10.0_20.0':'Key point size(10-20]',
                    '30.0_40.0':'Key point size(30-40]', 
                    '20.0_30.0':'Key point size(20-30]'}      
    n_clusters: 8
    #fields: ['Green view index','Sky view factor', 'Ground view index','Equilibrium degree', 'number of patches', 'Perimeter area ratio(mn)','Shape index(mn)', 'Fractal dimension(mn)', 'Color richness index','Key point size(0-10]', 'Key point size(10-20]','Key point size(30-40]', 'Key point size(20-30]',]
    fields: ['Green view index','Sky view factor', 'Ground view index','Equilibrium degree', 'Perimeter area ratio(mn)','Shape index(mn)', 'Fractal dimension(mn)', 'Color richness index','Key point size(0-10]', 'Key point size(10-20]','Key point size(30-40]', 'Key point size(20-30]',]
    distortion_score_save_path: './charts' 
    kneighbors_graph_n_neighbors: 100
    kneighbors_graph_n_neighbors_list: [5,10,15,20,25,30,35,40,45,50,60,70,80,90,100,110,120,130,140,150]
    elbow_score_dict_save_fn: './data/processed_data/elbow_score.pkl'
    featureScores_dict_fn: './data/processed_data/featureScores_dict.pkl'
    elbow_score_plot_fn: './charts/elbow_score_plot.png'
    contribution_kneighbors_plot_fn: './charts/contribution_kneighbors_plot.png'
    kneighbors_clusters_table_name: 'kneighbors_clusters'
    cluster_column_name_list_fn: './data/processed_data/cluster_column_name_list.pkl'
    KElbowVisualizer_k: (2,12)
    cluster_kneighbors_save_path: './charts/cluster_kneighbors'
    clustering_stat_save_fn: './charts/clustering_stat.xlsx'
    GVF_save_fn: './charts/GVF_boxplot.png'
    
clustering_entropy:
    walking_speed: 4.39
    clustering_entropy_table_name: 'clustering_entropy'
    LC_entropy_table_name: 'LC_entropy'
    LC_entropy_save_path: './charts/LC_entropy'
 
vanishing_position:
    tourLine_panorama_object_percent_table_name: 'tourLine_panorama_object_percent'
    tourLine_vanishing_save_fn: './data/processed_data/tourLine_vanishing.pkl'
    vanishing_segment_mark_save_fn: './charts/vanishing_segment_mark.png'
    
visual_field_objects_position_changes:
    img_object_change_path: './charts/'                
    pixels_diff_array_pkl_save_path: './data/processed_data/'          
    
POI_street_feature:
    pos_poi_dict_pkl_fn: './data/processed_data/pos_poi_dict.pkl'     
    buffer_radius:  350
    featureScores_save_fn: './charts/poi_features scores.xlsx' 
    clustering_POI_stats_save_fn: './charts/clustering_POI_stats.png'
```

4. 项目文件结构



5. requirements文件

通常一个环境下，包含了非常多的依赖库，这些依赖库往往是安装了某些库，例如`geopandas`，`pytorch`等安装时，自身同时安装了大量依赖库。因此通过导出对应环境下`requirements.txt`文件，再安装会忽略研究所真正使用的库。这里给出了项目所有需要安装的库和安装方法，方便有目的性的安装。

`requirements_install info.txt`
```txt
geopandas - conda install -c conda-forge geopandas 
sqlalchemy - conda install -c anaconda sqlalchemy 
psycopg2 -  conda install -c anaconda psycopg2 
geoalchemy2 -  conda install -c conda-forge geoalchemy2 
tqdm -  conda install -c conda-forge tqdm 
pillow  -  conda install -c anaconda pillow 
benedict -  conda install -c conda-forge python-benedict 
pytorch - conda install pytorch torchvision torchaudio cudatoolkit=10.2 -c pytorch
cv2 - pip install opencv-python and pip install opencv-contrib-python 
skimage -  conda install -c anaconda scikit-image 
mayavi - conda install -c anaconda mayavi   Specifications:- mayavi -> python[version='>=3.6,<3.7.0a0|>=3.7,<3.8.0a0']
openpyxl -  conda install -c anaconda openpyxl 
rasterio -  conda install -c conda-forge rasterio  | conda create --name rio python=3.7 rasterio
pylandstats -  conda install -c conda-forge pylandstats  (transonic landscape.py -b numba)
seaborn  - conda install -c anaconda seaborn 
yellowbrick -  conda install -c districtdatalabs yellowbrick   #in sklearn v0.22.0 they deprecated utils.safe_indexing to private (utils._safe_indexing)
scikit-learn -  conda install -c anaconda scikit-learn  
mapclassify -  conda install -c conda-forge mapclassify 

[matplotlib] -  conda install -c conda-forge matplotlib 
```


## B. 专项研究与代码实现

### B.1 背景


### B.2 研究方法与结果

#### B.2.1 研究区域

选取西安市（34° 15'N，108°56'E）碑林区、莲湖区、雁塔区、新城区、未央区和灞桥区等6个行政区域为区域尺度研究对象。选取荐福寺路、朱雀大街北段、友谊西路、长安北路、南大街、西大街、回民路、西华门大街等8段部分道路，及南门盘道和钟楼环道连续的部分区段作为街道尺度的研究对象。

> 在数据选择上，实际不需要划分为区域及连续街道两种形式，可以直接下载每8m(百度地图应用限制)为一个采样点的全城全景图数据。百度街道全景图及Google街道全景图下载需要支付数据费用，因此在资金支付和研究内容上做了平衡。

#### B.2.2 数据

| 序号  | 数据名称  | 数据来源  | 说明  |大小|数据类型|
|---|---|---|---|---|---|
| 1  | 道路  | 来源于中国专业IT社区CSDN (Chinese Software Developer Network)的开放数据  | 由道路提取采样点，用于全景图检索下载  |/ |.shp，.kml|
| 2  |  行政区域 | CSDN  | 用于数据裁切至研究区域  |/ |.shp|
| 3  |  全景静态图 | 百度地图应用  | 用于像素级图像语义分割，计算城市街道空间指数  |区域：13,359张； 街道：599张|.jpg|
|  4 |  POI | 百度地图应用  | 计算业态分布指数  |街道：13,732个 |.csv或.json|

##### B.2.2.1 数据获取及预处理

###### 1) 原数据转换为GeoDataFrame数据格式，并写入数据库，用于后续分析，及QGIS地图的建立

处理数据包括：道路（.shp格式和.kml格式两种）、行政区划（.shp格式）

`database.py`
```python
# -*- coding: utf-8 -*-
"""
Created on Wed Apr 28 10:45:39 2021
updated on Wed Jan 19 09:25:11 2022

@author: Richie Bao-caDesign设计(cadesign.cn)
"""

def gpd2postSQL(gdf,table_name,**kwargs):  
    '''
    function - 将GeoDataFrame格式数据写入PostgreSQL数据库
    
    Paras:
        gdf - GeoDataFrame格式数据，含geometry字段（几何对象，点、线和面，数据值对应定义的坐标系统）
        table_name - 写入数据库中的表名
        **kwargs - 连接数据库相关信息，包括myusername（数据库的用户名），mypassword（用户密钥），mydatabase（数据库名）
    '''    
    from sqlalchemy import create_engine
    
    engine=create_engine("postgres://{myusername}:{mypassword}@localhost:5432/{mydatabase}".format(myusername=kwargs['myusername'],mypassword=kwargs['mypassword'],mydatabase=kwargs['mydatabase']))  
    gdf.to_postgis(table_name, con=engine, if_exists='replace', index=False,)  
    print("_"*50)
    print('The GeoDataFrame has been written to the PostgreSQL database.The table name is {}.'.format(table_name))

def postSQL2gpd(table_name,geom_col='geometry',**kwargs):    
    '''
    function - 读取PostgreSQL数据库中的表为GeoDataFrame格式数据
    
    Paras:
        table_name - 待读取数据库中的表名
        geom_col='geometry' - 几何对象，常规默认字段为'geometry'
        **kwargs - 连接数据库相关信息，包括myusername（数据库的用户名），mypassword（用户密钥），mydatabase（数据库名）
    '''
    from sqlalchemy import create_engine
    import geopandas as gpd   
    
    engine=create_engine("postgres://{myusername}:{mypassword}@localhost:5432/{mydatabase}".format(myusername=kwargs['myusername'],mypassword=kwargs['mypassword'],mydatabase=kwargs['mydatabase']))  
    gdf=gpd.read_postgis(table_name, con=engine,geom_col=geom_col)
    print("_"*50)
    print('The data has been read from PostgreSQL database. The table name is {}.'.format(table_name))    
    return gdf  

def shp2gdf(fn,epsg=None,boundary=None,encoding='utf-8'):    
    '''
    function - 转换.shp地理信息数据为GeoDataFrame(geopandas)数据格式，可以配置投影
    
    Paras:
        fn - .shp文件路径
        epsg - 配置投影，默认为None
        boundary - 配置裁切边界，默认为None
        encoding - 配置编码，默认为'utf-8'
    '''
    import geopandas as gpd
    
    shp_gdf=gpd.read_file(fn,encoding=encoding)
    print('original data info:{}'.format(shp_gdf.shape))
    shp_gdf.dropna(how='all',axis=1,inplace=True)
    print('dropna-how=all,result:{}'.format(shp_gdf.shape))
    shp_gdf.dropna(inplace=True)
    print('dropna-several rows,result:{}'.format(shp_gdf.shape))
    # print(shp_gdf)
    if epsg is not None:
        shp_gdf_proj=shp_gdf.to_crs(epsg=epsg)
    if boundary:
        shp_gdf_proj['mask']=shp_gdf_proj.geometry.apply(lambda row:row.within(boundary))
        shp_gdf_proj.query('mask',inplace=True)        
    
    return shp_gdf_proj

def kml2gdf_folder(fn,epsg=None,boundary=None): 
    '''
    转换.kml（Google Eath）为GeoDataFrame格式

    Parameters
    ----------
    fn : .kml
        在Google Earth中绘制的格式.
    epsg : epsg编号, optional
        地理投影信息.
    boundary : GeoDataFrame, optional
        裁切边界. The default is None.

    Returns
    -------
    kml_gdf_proj : GeoDataFrame
        转换.kml为GeoDataFrame.

    '''
    import pandas as pd
    import geopandas as gpd
    import fiona,io
    from tqdm import tqdm

    # Enable fiona driver
    gpd.io.file.fiona.drvsupport.supported_drivers['KML'] = 'rw'
    kml_gdf=gpd.GeoDataFrame()
    for layer in tqdm(fiona.listlayers(fn)):
        # print("_"*50)
        # print(layer)
        src=fiona.open(fn, layer=layer)
        meta = src.meta
        meta['driver'] = 'KML'        
        with io.BytesIO() as buffer:
            with fiona.open(buffer, 'w', **meta) as dst:            
                for i, feature in enumerate(src):
                    # print(feature)
                    # print("_"*50)
                    # print(feature['geometry']['coordinates'])
                    if len(feature['geometry']['coordinates'][0]) > 1:
                        # print(feature['geometry']['coordinates'])
                        
                        dst.write(feature)
                        # break
            buffer.seek(0)
            one_layer=gpd.read_file(buffer,driver='KML')
            # print(one_layer)
            one_layer['group']=layer
            kml_gdf=kml_gdf.append(one_layer,ignore_index=True)

    if epsg is not None:
        kml_gdf_proj=kml_gdf.to_crs(epsg=epsg)

    if boundary:
        kml_gdf_proj['mask']=kml_gdf_proj.geometry.apply(lambda row:row.within(boundary))
        kml_gdf_proj.query('mask',inplace=True)        

    return kml_gdf_proj    


def cfg_load_yaml(ymlf_fp):
    '''
    读取 yaml 格式的配置文件

    Parameters
    ----------
    ymlf_fp : string
        配置文件路径.

    Returns
    -------
    cfg : yaml-dict
        读取到python中的配置信息.
    '''
    import yaml
    with open (ymlf_fp,'r') as ymlfile:
        cfg=yaml.safe_load(ymlfile)   
    return cfg

if __name__=="__main__":
    cfg=cfg_load_yaml('config.yml')
    print(cfg["data_path"]) 
    #help(cfg_load_yaml)
    
    #1.转换.shp格式的行政区划region_merge（合并的）为GeoDataFrame格式，并写入数据库
    region_merge=shp2gdf(cfg['data_path']['region_merge'],epsg=cfg['xian_epsg'],boundary=None,encoding='utf8')
    #region_merge.plot() 
    gpd2postSQL(region_merge,
                table_name='region_merge',
                myusername=cfg["postgreSQL"]["myusername"],
                mypassword=cfg["postgreSQL"]["mypassword"],
                mydatabase=cfg["postgreSQL"]["mydatabase"])  
    
    #2.配置行政区划的英文名称（拆分的），并写入数据库
    region=shp2gdf(cfg['data_path']['region'],epsg=cfg['xian_epsg'],boundary=None,encoding='utf8') 
    #region.plot()
    region_name_mapping={'bqq':'Baoqiao District','wyq':'Weiyang District','lhq':'Lianhu District','ytq':'Yanta District','xcq':'Xincheng District','blq':'Beilin District'}    
    region['name_en']=region['PYNAME'].map(region_name_mapping)
    gpd2postSQL(region,
                table_name='region',
                myusername=cfg["postgreSQL"]["myusername"],
                mypassword=cfg["postgreSQL"]["mypassword"],
                mydatabase=cfg["postgreSQL"]["mydatabase"])  
    
    #3.提取研究区域内的道路，并写入数据库
    road=shp2gdf(cfg["data_path"]['road'],epsg=cfg['xian_epsg'],boundary=region_merge.geometry[0],encoding='GBK')
    road.plot()
    gpd2postSQL(road,
                table_name='road',
                myusername=cfg["postgreSQL"]["myusername"],
                mypassword=cfg["postgreSQL"]["mypassword"],
                mydatabase=cfg["postgreSQL"]["mydatabase"])      
    
    #4.转换.kml街道路径(合并的)为GeoDataFrame格式，并写入数据库
    tour_line=kml2gdf_folder(cfg['data_path']['tour_line'],epsg=cfg['xian_epsg'],boundary=None) 
    tour_line.plot()
    gpd2postSQL(tour_line,
                table_name='tour_line',
                myusername=cfg["postgreSQL"]["myusername"],
                mypassword=cfg["postgreSQL"]["mypassword"],
                mydatabase=cfg["postgreSQL"]["mydatabase"])      
    
    #5.转换.kml街道路径（拆分的）为GeoDataFrame格式，并写入数据库
    tour_line_seg=shp2gdf(cfg['data_path']['tour_line_seg'],epsg=cfg['xian_epsg'],boundary=None,encoding='utf8')
    # tour_line_seg.plot()
    gpd2postSQL(tour_line_seg,
                table_name='tour_line_seg',
                myusername=cfg["postgreSQL"]["myusername"],
                mypassword=cfg["postgreSQL"]["mypassword"],
                mydatabase=cfg["postgreSQL"]["mydatabase"])      

```

###### 2)  全景静态图检索下载

基本流程：根据道路线，给定距离获取采样点；->给定采样点从百度地图应用中检索全景图下载；->验证下载图像的有效性，并复制有效的图像至新建的文件夹下。

`baidu_streetview_crawler.py`
```python
# -*- coding: utf-8 -*-
"""
Created on Wed Apr 28 14:46:58 2021
updated on Wed Jan 19 16:00:24 2022

@author: Richie Bao-caDesign设计(cadesign.cn)
"""

def roads_pts4bsv(roads_gdf,distance=10):
    '''
    给定GeoDataFrame的道路中心线，和采样距离，返回采样点

    Parameters
    ----------
    roads_gdf : GeoDataFrame
        GeoDataFrame的道路中心线.
    distance : numerical value, optional
        采样距离. The default is 10.

    Returns
    -------
    GeoDataFrame
        采样点.

    '''
    from tqdm import tqdm
    import numpy as np
    from shapely.geometry import MultiPoint
    import pyproj
    from shapely.ops import transform
    import geopandas as gpd
    
    tqdm.pandas()    
    def line_pts(line):
        dists=np.arange(0,line.length,distance)
        pts=MultiPoint([line.interpolate(d,normalized=False) for d in dists])
        return pts      
        
    roads_gdf['pts']=roads_gdf.geometry.progress_apply(line_pts)
    
    wgs84=pyproj.CRS('EPSG:4326')
    utm=roads_gdf.crs #pyproj.CRS(roads_gpd.crs.srs)
    project=pyproj.Transformer.from_crs(utm, wgs84, always_xy=True).transform
    roads_gdf['pts_wgs84']=roads_gdf.pts.progress_apply(lambda row:transform(project,row))    
    
    pts_gdf=gpd.GeoDataFrame(roads_gdf[['Name','Uid']],geometry=roads_gdf.pts_wgs84.to_list(),crs=wgs84) #roads_gdf.drop(['geometry'],axis=1)    
    return pts_gdf

   
def baidu_steetview_crawler(pts_gdf,save_path,ak,save_path_BSV_retrival_info):
    '''
    从百度地图应用中，根据采样点检索下载全景图
    
    Parameters
    ----------
    pts_gdf : GeoDataFrame
        采样点.
    save_path : string
        全景图的保存路径.
    ak : string
        访问应用的AK值，在百度应用中注册申请.
    save_path_BSV_retrival_info : dict
        pickle方式保存下载信息，包括pt_fns-以路径为键，全景图下载地址列表为值；coords-以路径为键，采样点坐标列表为值；
                                 downloadError_idx-错误索引列表.

    Returns
    -------
    coords : dict
        以路径为键，值为采样点坐标列表.
    pts_num : int
        下载全景图的数量.
        
    '''
    import urllib,os
    from tqdm import tqdm
    import pickle
    
    downloadError_idx=[]
    coords={}
    pts_num={}    
    pt_fns={}
    for idx,row in pts_gdf.iterrows():
        pt_coords=[(pt.x,pt.y) for pt in row.geometry]
        coords[row.Name]=pt_coords
        pts_num[row.Name]=len(pt_coords)
    print("\npts_num={}".format(sum(pts_num.values())))
    
    urlRoot=r"http://api.map.baidu.com/panorama/v2?"
    query_dic={
        'width':'1024',
        'height':'512', 
        'fov':'360',
        'heading':'0',
        'pitch':'0',
        'coordtype':'wgs84ll',
        'ak':ak,
    }   
    # tt=0
    for k,v in tqdm(coords.items()):
        pt_fn=[]
        for i,coord in enumerate(v):
            pic_fn=os.path.join(save_path,"{}_{}.jpg".format(k,i))                        
            if not os.path.exists(pic_fn):
                #update query arguments
                query_dic.update({
                                  'location':str(coord[0])+','+str(coord[1]),
                                 })         
                url=urlRoot+urllib.parse.urlencode(query_dic)
                try:
                    data=urllib.request.urlopen(url)
                    pt_fn.append(pic_fn)
                    with open(pic_fn,'wb') as fp:
                        fp.write(data.read())           
                except:
                    downloadError_idx.append((k,i))
                    print('download_error:{},{}'.format(k,i))
            else:
                print("file existed.")
                
        pt_fns[k]=pt_fn
        # if tt==2:break
        # tt+=1
        
    with open(save_path_BSV_retrival_info["pt_fns"],'wb') as f:
        pickle.dump(pt_fns,f)
    with open(save_path_BSV_retrival_info["coords"],'wb') as f:
        pickle.dump(coords,f)       
    with open(save_path_BSV_retrival_info["downloadError_idx"],'wb') as f:
        pickle.dump(downloadError_idx,f)      
            
    return coords,pts_num

def img_valid(img_fns,save_path_img_valid):
    '''
    验证图像是否有效，即是否可以被打开

    Parameters
    ----------
    img_fns : dict
        图像路径字典.
    save_path_img_valid : dict
        保存路径字典.

    Returns
    -------
    img_val : dict
        返回有效图像字典.

    '''
    from tqdm import tqdm
    import pickle
    from PIL import Image
    
    img_val={}
    img_inval=[]
    for k,v in tqdm(img_fns.items()):
        fns=[]
        for fn in v:
            try:
                im=Image.open(fn)
                fns.append(fn)
            except:
                img_inval.append(fn)        
        img_val[k]=fns
            
    with open(save_path_img_valid["img_val"],'wb') as f:
        pickle.dump(img_val,f)        
    with open(save_path_img_valid["img_inval"],'wb') as f:
        pickle.dump(img_inval,f)                 
    return img_val

def img_valid_copy_folder(imgs_root,panoramic_imgs_valid_root):
    '''
    功能基本同img_valid(img_fns,save_path_img_valid)函数。除了验证图像是否有效，同时将其复制到新建的文件夹下

    Parameters
    ----------
    imgs_root : string
        图像根目录.
    panoramic_imgs_valid_root : string
        新建文件夹，复制有效图像至该文件夹.

    Returns
    -------
    None.

    '''
    from tqdm import tqdm
    import pickle
    import glob,os 
    from PIL import Image
    import shutil
    
    img_fns=glob.glob(os.path.join(imgs_root,'*.jpg'))
    # print(img_fns)  
    img_val=[]
    img_inval=[]
    for fn in tqdm(img_fns):
        try:
            im=Image.open(fn)
            img_val.append(fn)
        except:
            img_inval.append(fn)    
    # print(img_val)
    for fn in tqdm(img_val):
        shutil.copy(fn,panoramic_imgs_valid_root)   
        
def roads_pts4bsv_tourLine(roads_gdf,distance=10):
    '''
    由道路GeoDataFrame数据，提取给定距离的采样点

    Parameters
    ----------
    roads_gdf : GeoDataFrame
        道路线.
    distance : numericle value, optional
        指定采样距离. The default is 10.

    Returns
    -------
    GeoDataFrame
        采样点.

    '''
    from tqdm import tqdm
    import numpy as np
    from shapely.geometry import MultiPoint
    import pyproj
    from shapely.ops import transform
    import geopandas as gpd
    
    tqdm.pandas()    
    def line_pts(line):
        dists=np.arange(0,line.length,distance)
        pts=MultiPoint([line.interpolate(d,normalized=False) for d in dists])
        return pts      
        
    roads_gdf['pts']=roads_gdf.geometry.progress_apply(line_pts)
    
    wgs84=pyproj.CRS('EPSG:4326')
    utm=roads_gdf.crs #pyproj.CRS(roads_gpd.crs.srs)
    project=pyproj.Transformer.from_crs(utm, wgs84, always_xy=True).transform
    roads_gdf['pts_wgs84']=roads_gdf.pts.progress_apply(lambda row:transform(project,row))    
    
    pts_gdf=gpd.GeoDataFrame(roads_gdf[['Name','group']],geometry=roads_gdf.pts_wgs84.to_list(),crs=wgs84) #roads_gdf.drop(['geometry'],axis=1)    
    return pts_gdf

def pts_number_check(pts):
    '''
    查看采样点，打印数量

    Parameters
    ----------
    pts : GeoDataFrame
        输入点数据.

    Returns
    -------
    None.

    '''
    
    downloadError_idx=[]
    coords={}
    pts_num={}    
    pt_fns={}
    for idx,row in pts.iterrows():
        pt_coords=[(pt.x,pt.y) for pt in row.geometry]
        coords[row.Name]=pt_coords
        pts_num[row.Name]=len(pt_coords)
    # print(coords)
    print("\npts_num={}".format(sum(pts_num.values())))

if __name__=="__main__":
    from database import postSQL2gpd,gpd2postSQL,cfg_load_yaml   
    import pickle
    
    cfg=cfg_load_yaml('config.yml')
    
    #1.读取道路，提取采样点后写入数据库
    roads=postSQL2gpd(table_name='road',
                geom_col=cfg["postgreSQL"]["geom_col"],
                myusername=cfg["postgreSQL"]["myusername"],
                mypassword=cfg["postgreSQL"]["mypassword"],
                mydatabase=cfg["postgreSQL"]["mydatabase"])     
    pts_gdf=roads_pts4bsv(roads,cfg['streetview']['distance_region'])
    gpd2postSQL(pts_gdf,
                table_name='pts_region',
                myusername=cfg["postgreSQL"]["myusername"],
                mypassword=cfg["postgreSQL"]["mypassword"],
                mydatabase=cfg["postgreSQL"]["mydatabase"])  
    
    #2.从百度地图应用中下载全景静态图
    coords,pts_num=baidu_steetview_crawler(pts_gdf,
                                           cfg["streetview"]["save_path_BSV_region"],
                                           cfg["streetview"]["ak"],
                                           cfg["streetview"]["save_path_BSV_retrival_info"])
    #3.验证下载的全景图是否有效，并将有效全景图复制到新建文件夹中
    with open(cfg["streetview"]["save_path_BSV_retrival_info"]["pt_fns"],'rb') as f:
        pt_fns=pickle.load(f)    
    img_val=img_valid(pt_fns,cfg["streetview"]["save_path_img_valid"])  #14973 /13359  14973-13359=1614
 
    img_valid_copy_folder(cfg["streetview"]["save_path_BSV_region"],cfg["streetview"]["panoramic_imgs_valid_root"])
    
    #4. 过去街道采样点，从百度地图应用检索街道全景图下载，并验证有效性，将有效图像保存到新建文件夹下。代码同上（区域检索）
    tour_line=postSQL2gpd(table_name='tour_line',
                geom_col=cfg["postgreSQL"]["geom_col"],
                myusername=cfg["postgreSQL"]["myusername"],
                mypassword=cfg["postgreSQL"]["mypassword"],
                mydatabase=cfg["postgreSQL"]["mydatabase"]) 
    pts_tourLine_gdf=roads_pts4bsv_tourLine(tour_line,cfg['streetview']['distance_street']) 
    pts_number_check(pts_tourLine_gdf)
    gpd2postSQL(pts_tourLine_gdf,
                table_name='pts_tourline',
                myusername=cfg["postgreSQL"]["myusername"],
                mypassword=cfg["postgreSQL"]["mypassword"],
                mydatabase=cfg["postgreSQL"]["mydatabase"]) 
    coords_street,pts_num_street=baidu_steetview_crawler(pts_tourLine_gdf,
                                                        cfg["streetview"]["save_path_BSV_street"],
                                                        cfg["streetview"]["ak"],
                                                        cfg["streetview"]["save_path_BSV_retrival_info_street"])     
    img_valid_copy_folder(cfg["streetview"]["save_path_BSV_street"],cfg["streetview"]["panoramic_imgs_valid_root_street"])

```

###### 3)  全景图像素级语义分割（Pixel-wise semantic segmentation）

应用[PASS（ERF-PSPNet）深度学习模型](https://github.com/elnino9ykl/PASS)实现全景图像素级语义分割。可以从给定的链接处下载计算。

###### 4)  百度POI数据检索下载，转换为GeoDataFrame后保存到数据库

POI数据检索方法可以参考‘数据POI与描述性统计和正态分布’章节部分。新定义的转换方法追加到`database.py`中。

`database.py`（追加）
```python

def filePath_extraction(dirpath,fileType):  
    '''
    funciton  -以所在文件夹路径为键，值为包含该文件夹下所有文件名的列表。文件类型可以自行定义 
    
    Paras:
        dirpath - 根目录，存储所有待读取的文件
        fileType - 待读取文件的类型
    '''
    import os
    filePath_Info={}
    i=0
    for dirpath,dirNames,fileNames in os.walk(dirpath): #os.walk()遍历目录，使用help(os.walk)查看返回值解释
       i+=1
       if fileNames: #仅当文件夹中有文件时才提取
           tempList=[f for f in fileNames if f.split('.')[-1] in fileType]
           if tempList: #剔除文件名列表为空的情况，即文件夹下存在不为指定文件类型的文件时，上一步列表会返回空列表[]
               filePath_Info.setdefault(dirpath,tempList)
    return filePath_Info

def csv2df(poi_fn_csv):
    '''
    转换.csv格式的POI数据为pandas的DataFrame

    Parameters
    ----------
    poi_fn_csv : string
        单个.csv文件路径.

    Returns
    -------
    poi_df : DataFrame
        POI点数据.

    '''
    import pandas as pd
    from benedict import benedict #benedict库是dict的子类，支持键列表（keylist）/键路径（keypath），应用该库的flatten方法展平嵌套的字典，准备用于DataFrame数据结构
    import csv

    n=0
    with open(poi_fn_csv, newline='',encoding='utf-8') as csvfile:
        poi_reader=csv.reader(csvfile)
        poi_dict={}    
        poiExceptions_dict={}
        for row in poi_reader:    
            if row:
                try:
                    row_benedict=benedict(eval(row[0])) #用eval方法，将字符串字典"{}"转换为字典{}
                    flatten_dict=row_benedict.flatten(separator='_') #展平嵌套字典
                    poi_dict[n]=flatten_dict
                except:                    
                    print("incorrect format of data_row number:%s"%n)                    
                    poiExceptions_dict[n]=row
            n+=1
            #if n==5:break #因为循环次数比较多，在调试代码时，可以设置停止的条件，节省时间与方便数据查看
    poi_df=pd.concat([pd.DataFrame(poi_dict[d_k].values(),index=poi_dict[d_k].keys(),columns=[d_k]).T for d_k in poi_dict.keys()], sort=True,axis=0)
    # print("_"*50)
    for col in poi_df.columns:
        try:
            poi_df[col]=pd.to_numeric(poi_df[col])
        except:
            pass
            #print("%s data type is not converted..."%(col))
    print("_"*50)
    print(".csv to DataFrame is completed!")
    #print(poi_df.head()) #查看最终DataFrame格式下POI数据
    #print(poi_df.dtypes) #查看数据类型
    return poi_df

def poi_csv2GeoDF_batch(poi_paths,fields_extraction,save_path):
    '''
    .csv格式POI数据批量转换为GeoDataFrame，需要调用转换.csv格式的POI数据为pandas的DataFrame函数csv2df(poi_fn_csv)'

    Parameters
    ----------
    poi_paths : dict
        poi路径字典.
    fields_extraction : list
        待提取的字段列表.
    save_path : dict
        GeoJSON、Shapefile和pickle三种数据格式各自的保存路径.

    Returns
    -------
    poiAll_gpd : GeoDataFrame
        poi的GeoDataFrame数据格式.

    '''
    import os,pathlib
    import pandas as pd
    import geopandas as gpd
    from shapely.geometry import Point
    #循环读取与转换poi的.csv文件为pandas的DataFrame数据格式
    poi_df_dic={}
    i=0
    for key in poi_paths:
        for val in poi_paths[key]:
            poi_csvPath=os.path.join(key,val)
            poi_df=csv2df(poi_csvPath) #注释掉了了csv2df()函数内部的print("%s data type is not converted..."%(col))语句，以pass替代，减少提示内容，避免干扰
            print(val)
            poi_df_path=pathlib.Path(val)
            poi_df_dic[poi_df_path.stem]=poi_df
            
            #if i==2:break
            i+=1
    poi_df_concat=pd.concat(poi_df_dic.values(),keys=poi_df_dic.keys(),sort=True)
    #print(poi_df_concat.loc[['poi_0_delicacy'],:]) #提取index为 'poi_0_delicacy'的行，验证结果
    poi_fieldsExtraction=poi_df_concat.loc[:,fields_extraction]
    poi_geoDF=poi_fieldsExtraction.copy(deep=True)
    poi_geoDF['geometry']=poi_geoDF.apply(lambda row:Point(row.location_lng,row.location_lat),axis=1) 
    # crs_4326=CRS('epsg:4326') #配置坐标系统，参考：https://spatialreference.org/     
    crs_4326='epsg:4326'
    poiAll_gpd=gpd.GeoDataFrame(poi_geoDF,crs=crs_4326)     
    
    poiAll_gpd.to_pickle(save_path['pkl'])
    # poiAll_gpd.to_file(save_path['geojson'],driver='GeoJSON')
    
    poiAll_gpd2shp=poiAll_gpd.reset_index() #不指定level参数，例如Level=0，会把多重索引中的所有索引转换为列
    poiAll_gpd2shp.rename(columns={
        'location_lat':'lat', 'location_lng':'lng',
        'detail_info_tag':'tag','detail_info_overall_rating':'rating', 'detail_info_price':'price'},inplace=True)
    poiAll_gpd2shp.to_file(save_path['shp'],encoding='utf-8')
        
    return poiAll_gpd

if __name__=="__main__":
    #6.转换POI(.csv,.json)为GeoDataFrame格式，并写入数据库
    fileType=["csv"]
    poi_paths=filePath_extraction(cfg["POI"]["poi_path"],fileType)
    #分别存储为GeoJSON、Shapefile和pickle三种数据格式
    poi_gpd=poi_csv2GeoDF_batch(poi_paths,cfg["POI"]["fields_extraction"],cfg["POI"]["save_path_POI"])
    gpd2postSQL(poi_gpd,
                table_name='poi',
                myusername=cfg["postgreSQL"]["myusername"],
                mypassword=cfg["postgreSQL"]["mypassword"],
                mydatabase=cfg["postgreSQL"]["mydatabase"]) 
```

至此数据获取及预处理部分基本完成。后续的分析可以直接从本地关系数据库`PAPER_Urban_Street_Space_Metrics`中读取数据，以及写入分析过程中新产生的数据。

##### B.2.2.2 QGIS建立地图

除了在python中从数据库中读入数据，打印查看外，最终出图推荐用QGIS通过`PostGIS`配置连接到数据库，读取和查看数据。可以用`Project->New print layout`建立布局，打印输出。

__Fig. 区域尺度全景图采样点__  

<a href=""><img src="./imgs/3_2_1_01.png" height="auto" width="auto" title="caDesign"></a>

__Fig. 街道尺度区段与POI数据__  

<a href=""><img src="./imgs/3_2_1_02.png" height="auto" width=800 title="caDesign"></a>

##### B.2.2.3 全景与语义分割图的投影变换

在城市街道空间的组成结构分析过程中，需要根据不同的分析内容对数据进行预先处理满足分析的要求和改善计算的准确性。极坐标格式全景图(小行星视角360度全景)用于天空相关指数的计算，避免等量矩形投影图未闭合的天空形状影响；等量矩形投影图和极坐标格式全景图因为投影变形，对象像素所占比例不能最大限度的反应实际视觉下对象比例关系。而立方体型全景格式由前，后，左，右，上，下6张透视图组成，用于语义分割对象所占像素百分比的统计相对合理；球面全景，可以反应对象在实际空间中的位置关系，用于语义分割对象空间位置变化的分析。

变换等量矩形投影图到极坐标格式全景图和立方体型全景格式计算量较大（13,359张全景图），因此调用`from multiprocessing import Pool`模块实现多进程计算，以节约大量计算时间。因为调用多进程，避免出错，通常需要从一个.py文件调用另一个.py文件的函数，因此通常多进程部分包括两个.py文件，例如从等量矩形投影图到立方体型全景格式，包括`equi2cube.py`和`equi2cube_pool.py`两个文件。其中前者为多进程处理文件，后者为包含具体功能计算函数的文件。

这个过程需要计算图像部分（保存为.jpg格式）和对应的类标部分（label，保存为.pkl格式），文件保存路径相对较多，需要在配置文件`config.yml`中清晰配置。

###### 1)  等量矩形投影图到立方体型全景格式

`equi2cube_pool.py`
```python
# -*- coding: utf-8 -*-
"""
Created on Sun May  9 12:44:29 2021
Updated on Thu Jan 20 10:14:26 2022

@author: Richie Bao-caDesign设计(cadesign.cn)
ref:https://github.com/bingsyslab/360projection
"""
import sys
sys.path.append('..')

label_color={
    0:(117,115,102), #"pole",
    1:(212,209,156),#"slight",
    2:(224,9,9),#"bboard",
    3:(227,195,66),#"tlight",
    4:(137,147,169),#"car",
    5:(53,67,98),#"truck",
    6:(185,181,51),#"bicycle",
    7:(238,108,91),#"motor",
    8:(247,5,5),#"bus",
    9:(127,154,82),#"tsignf",
    10:(193,209,167),#"tsignb",
    11:(82,83,76),#"road",
    12:(141,142,133),#"sidewalk",
    13:(208,212,188),#"curbcut",
    14:(98,133,145),#"crosspln",
    15:(194,183,61),#"bikelane",
    16:(141,139,115),#"curb",
    17:(157,186,133),#"fence",
    18:(114,92,127),#"wall",
    19:(78,61,76),#"building",
    20:(100,56,67),#"person",
    21:(240,116,148),#"rider",
    22:(32,181,191),#"sky",
    23:(55,204,26),#"vege",
    24:(84,97,82),#"terrain",
    25:(231,24,126),#"markings",
    26:(141,173,166),#"crosszeb",
    27:(0,0,0),#"Nan",                
    }    
    
def deg2rad(d):
    import numpy as np
    return float(d) * np.pi / 180

def rotate_image(old_image,channel_num=1):
    import cv2
    if channel_num==3:
        (old_height, old_width, _) = old_image.shape
    elif channel_num==1:
        (old_height, old_width, ) = old_image.shape
    M = cv2.getRotationMatrix2D(((old_width - 1) / 2., (old_height - 1) / 2.), 270, 1)
    rotated = cv2.warpAffine(old_image, M, (old_width, old_height))
    return rotated

def xrotation(th):
    import numpy as np
    c = np.cos(th)
    s = np.sin(th)
    return np.array([[1, 0, 0], [0, c, s], [0, -s, c]])

def yrotation(th):
    import numpy as np
    c = np.cos(th)
    s = np.sin(th)
    return np.array([[c, 0, s], [0, 1, 0], [-s, 0, c]])

def render_image_np(theta0, phi0, fov_h, fov_v, width, img,channel_num=1):
    """
    theta0 is pitch
    phi0 is yaw
    render view at (pitch, yaw) with fov_h by fov_v
    width is the number of horizontal pixels in the view
    """
    import numpy as np
    m = np.dot(yrotation(phi0), xrotation(theta0))
    
    if channel_num==3:
        (base_height, base_width, _) = img.shape
    elif channel_num==1:
        (base_height, base_width, ) = img.shape    
    
    height = int(width * np.tan(fov_v / 2) / np.tan(fov_h / 2))
    
    if channel_num==3:
        new_img = np.zeros((height, width, 3), np.uint8)
    elif channel_num==1:
        new_img = np.zeros((height, width, ), np.uint8)    
      
    DI = np.ones((height * width, 3), np.int)
    trans = np.array([[2.*np.tan(fov_h / 2) / float(width), 0., -np.tan(fov_h / 2)],
                      [0., -2.*np.tan(fov_v / 2) / float(height), np.tan(fov_v / 2)]])
    
    xx, yy = np.meshgrid(np.arange(width), np.arange(height))
    
    DI[:, 0] = xx.reshape(height * width)
    DI[:, 1] = yy.reshape(height * width)
    
    v = np.ones((height * width, 3), np.float)
    
    v[:, :2] = np.dot(DI, trans.T)
    v = np.dot(v, m.T)
    
    diag = np.sqrt(v[:, 2] ** 2 + v[:, 0] ** 2)
    theta = np.pi / 2 - np.arctan2(v[:, 1], diag)
    phi = np.arctan2(v[:, 0], v[:, 2]) + np.pi
    
    ey = np.rint(theta * base_height / np.pi).astype(np.int)
    ex = np.rint(phi * base_width / (2 * np.pi)).astype(np.int)
    
    ex[ex >= base_width] = base_width - 1
    ey[ey >= base_height] = base_height - 1  
    
    # print(ey.shape,ex.shape)
    new_img[DI[:, 1], DI[:, 0]] = img[ey, ex]
    return new_img
  
def equi_to_cube(face_size, img,channel_num=1):        
      """
      given an equirectangular spherical image, project it onto standard cube
      """
      import numpy as np
      cube_img_h = face_size * 3
      cube_img_w = face_size * 2
      if channel_num==3:
          cube_img = np.zeros((cube_img_h, cube_img_w, 3), np.uint8)
      elif channel_num==1:
         cube_img = np.zeros((cube_img_h, cube_img_w, ), np.uint8)
    
      ii = render_image_np(np.pi / 2, np.pi, \
              np.pi / 2, np.pi / 2, \
              face_size, img,channel_num=channel_num)
    #   cv2.imwrite('g_top.jpg', ii)

      cube_img[:int(cube_img_h / 3), int(cube_img_w / 2):] = ii.copy()
    
      ii = render_image_np(0, 0, \
              np.pi / 2, np.pi / 2, \
              face_size, img,channel_num=channel_num)
    #   cv2.imwrite('g_front.jpg', ii)
    
      cube_img[int(cube_img_h / 3):int(cube_img_h * 2 / 3), :int(cube_img_w / 2)] = rotate_image(ii,channel_num=channel_num).copy()
    
      ii = render_image_np(0, np.pi / 2, \
              np.pi / 2, np.pi / 2, \
              face_size, img,channel_num=channel_num)
    #   cv2.imwrite('g_right.jpg', ii)
    
      cube_img[int(cube_img_h * 2 / 3):, :int(cube_img_w / 2)] = rotate_image(ii,channel_num=channel_num).copy()
    
      ii = render_image_np(0, np.pi, \
              np.pi / 2, np.pi / 2, \
              face_size, img,channel_num=channel_num)
    #   cv2.imwrite('g_back.jpg', ii)
    
      cube_img[int(cube_img_h / 3):int(cube_img_h * 2 / 3), int(cube_img_w / 2):] = ii.copy()
    
      ii = render_image_np(0, np.pi * 3 / 2, \
              np.pi / 2, np.pi / 2, \
              face_size, img,channel_num=channel_num)
    #   cv2.imwrite('g_left.jpg', ii)
    
      cube_img[:int(cube_img_h / 3), :int(cube_img_w / 2)] = rotate_image(ii,channel_num=channel_num).copy()
    
      ii = render_image_np(-np.pi / 2, np.pi, \
              np.pi / 2, np.pi / 2, \
              face_size, img,channel_num=channel_num)
    #   cv2.imwrite('g_bottom.jpg', ii)
    
      cube_img[int(cube_img_h * 2 / 3):, int(cube_img_w / 2):] = ii.copy()
    
    #   cv2.imwrite('g_cube.jpg', cube_img)
      return cube_img

def labels_equi2cube(label_seg_path,face_size,save_path_dict):
    '''
    转换等量矩形全景图的语义分割图为立方体型全景格式

    Parameters
    ----------
    label_seg_path : string
        语义分割图label 索引图，.pkl文件.
    face_size : numerical val
        立方体型全景格式单元大小.
    save_path_dict : dict
        保存立方体型label（label_seg_cube_root），分类图像（img_seg_cube_root）和重新映射颜色值的图像（img_seg_redefined_color_root）根目录.

    Returns
    -------
    None.

    '''
    import glob,os,pickle
    from tqdm import tqdm
    from pathlib import Path
    import numpy as np
    from PIL import Image
    
    label_seg_cube_root=save_path_dict["label_seg_cube_root"]
    img_seg_redefined_color_root=save_path_dict["img_seg_redefined_color_root"]
    img_seg_cube_root=save_path_dict["img_seg_cube_root"]    
    
    label_seg_fns=glob.glob(os.path.join(label_seg_path,'*.pkl'))
    #print(label_seg_fns)
    for label_seg_fn in tqdm(label_seg_fns):
        with open(label_seg_fn,'rb') as f:
            label_seg=pickle.load(f) #.cpu().detach().numpy() 
        fn_stem=Path(label_seg_fn).stem
        fn_key,fn_idx=fn_stem.split("_")
        
        label_seg_cube=equi_to_cube(face_size,label_seg)
        with open(os.path.join(label_seg_cube_root,'{}.pkl'.format(fn_stem)),'wb') as f:
            pickle.dump(label_seg_cube,f)        
        
        label_seg=label_seg.cpu().detach().numpy()
        label_seg_panorama=np.array([label_color[v] for v in label_seg.flatten()]).reshape((label_seg.shape[0],label_seg.shape[1],3))
        label_panorama=Image.fromarray(label_seg_panorama.astype(np.uint8))   
        label_panorama.save(os.path.join(img_seg_redefined_color_root,'{}.jpg'.format(fn_stem)))        
        
        label_seg_cube_color=np.array([label_color[v] for v in label_seg_cube.flatten()]).reshape((label_seg_cube.shape[0],label_seg_cube.shape[1],3))
        label_cube=Image.fromarray(label_seg_cube_color.astype(np.uint8))  
        label_cube=label_cube.rotate(90, expand=1)
        label_cube.save(os.path.join(img_seg_cube_root,'{}.jpg'.format(fn_stem)))        
        break
    
def labels_equi2cube_pool(label_seg_fn,args): 
    '''
    函数labels_equi2cube(label_seg_path,face_size,save_path_dict)的多线程版

    Parameters
    ----------
    label_seg_fn : string
        单个语义分割图label 索引图，.pkl文件.
    args : list
        包含参数：save_path_dict,face_size.

    Returns
    -------
    None.

    '''
    import glob,os,pickle
    from tqdm import tqdm
    from pathlib import Path
    import numpy as np
    from PIL import Image
    
    save_path_dict,face_size=args
    label_seg_cube_root=save_path_dict["label_seg_cube_root"]
    img_seg_redefined_color_root=save_path_dict["img_seg_redefined_color_root"]
    img_seg_cube_root=save_path_dict["img_seg_cube_root"]      
    
    with open(label_seg_fn,'rb') as f:
        label_seg=pickle.load(f)#.cpu().detach().numpy() 
    fn_stem=Path(label_seg_fn).stem
    fn_key,fn_idx=fn_stem.split("_")
    
    label_seg_cube=equi_to_cube(face_size,label_seg)
    with open(os.path.join(label_seg_cube_root,'{}.pkl'.format(fn_stem)),'wb') as f: #'./processed data/label_seg_cube'
        pickle.dump(label_seg_cube,f)        
    
    label_seg=label_seg.cpu().detach().numpy()
    label_seg_panorama=np.array([label_color[v] for v in label_seg.flatten()]).reshape((label_seg.shape[0],label_seg.shape[1],3))
    label_panorama=Image.fromarray(label_seg_panorama.astype(np.uint8))   
    label_panorama.save(os.path.join(img_seg_redefined_color_root,'{}.jpg'.format(fn_stem)))  #'./processed data/img_seg_redefined_color'      
    
    label_seg_cube_color=np.array([label_color[v] for v in label_seg_cube.flatten()]).reshape((label_seg_cube.shape[0],label_seg_cube.shape[1],3))
    label_cube=Image.fromarray(label_seg_cube_color.astype(np.uint8))  
    label_cube=label_cube.rotate(90, expand=1)
    label_cube.save(os.path.join(img_seg_cube_root,'{}.jpg'.format(fn_stem)))    #'./processed data/img_seg_cube'

def imgs__equi2cube(pano_path,face_size,save_path):
    '''
    转换等量矩形全景图为立方体型全景格式

    Parameters
    ----------
    pano_path : string
        等量矩形全景图根路径.
    face_size : numerical val
        立方体型全景格式单元大小.
    save_path : string
        立方体型全景格式保存路径.

    Returns
    -------
    None.

    '''
    import glob,os
    from tqdm import tqdm
    from pathlib import Path
    import cv2
    import numpy as np
    
    pano_path_fns=glob.glob(os.path.join(pano_path,'*.jpg'))
    # print(pano_path_fns)
    for fn in tqdm(pano_path_fns):
        fn_stem=Path(fn).stem
        fn_key,fn_idx=fn_stem.split("_")
        
        img=cv2.imread(fn)
        cube_img=equi_to_cube(face_size,img,channel_num=3)
        cube_img=np.rot90(cube_img)
        cv2.imwrite(os.path.join(save_path,'{}.jpg'.format(fn_stem)), cube_img) 
        break

if __name__ == '__main__':    
    import os
    from database import cfg_load_yaml
    cfg=cfg_load_yaml('../config.yml')
    face_size=cfg["equi2cube"]["face_size"]
    
    parent_path=os.path.dirname(os.getcwd())
    label_seg_path=os.path.join(parent_path,cfg["panaSeg"]["label_seg_path"])    
    save_path_dict={"label_seg_cube_root":os.path.join(parent_path,cfg["equi2cube"]["region"]["label_seg_cube_root"]),
                    "img_seg_redefined_color_root":os.path.join(parent_path,cfg["equi2cube"]["region"]["img_seg_redefined_color_root"]),
                    "img_seg_cube_root":os.path.join(parent_path,cfg["equi2cube"]["region"]["img_seg_cube_root"])}
    labels_equi2cube(label_seg_path,face_size,save_path_dict)
 
    #pano_path=os.path.join(parent_path,cfg["panaSeg"]["pano_path"])
    #imgs__equi2cube(pano_path,face_size,os.path.join(parent_path,cfg["equi2cube"]["region"]["img_cube"]))
```

`equi2cube.py`
```python
# -*- coding: utf-8 -*-
"""
Created on Sun May  9 19:14:17 2021
Updated on Thu Jan 20 13:56:01 2022

@author: Richie Bao-caDesign设计(cadesign.cn)
"""


if __name__ == '__main__':  
    import glob,os
    from multiprocessing import Pool
    from tqdm import tqdm
    from equi2cube_pool import labels_equi2cube_pool
    from functools import partial
    
    import sys
    sys.path.append('..')
    from database import cfg_load_yaml
    cfg=cfg_load_yaml('../config.yml')
    
    parent_path=os.path.dirname(os.getcwd())
    label_seg_path=os.path.join(parent_path,cfg["panaSeg"]["label_seg_path"]) 
    label_seg_fns=glob.glob(os.path.join(label_seg_path,'*.pkl'))
    
    save_path_dict={"label_seg_cube_root":os.path.join(parent_path,cfg["equi2cube"]["region"]["label_seg_cube_root"]),
                    "img_seg_redefined_color_root":os.path.join(parent_path,cfg["equi2cube"]["region"]["img_seg_redefined_color_root"]),
                    "img_seg_cube_root":os.path.join(parent_path,cfg["equi2cube"]["region"]["img_seg_cube_root"])}    
    face_size=cfg["equi2cube"]["face_size"]
    args=partial(labels_equi2cube_pool, args=[save_path_dict,face_size])
    with Pool(8) as p:
        p.map(args, tqdm(label_seg_fns))      
```

> 街道部分计算同上述区域计算。

###### 2)  等量矩形投影图到极坐标格式全景图

`equi2polar_pool.py`
```python
# -*- coding: utf-8 -*-
"""
Created on Sat May  1 20:38:23 2021
updated on Thu Jan 20 09:23:48 2022

@author: Richie Bao-caDesign设计(cadesign.cn)
ref: http://www.richwareham.com/little-planet-projection/
"""
import sys
sys.path.append('..')

def output_coord_to_r_theta(coords):
    """Convert co-ordinates in the output image to r, theta co-ordinates.
    The r co-ordinate is scaled to range from from 0 to 1. The theta
    co-ordinate is scaled to range from 0 to 1.
    
    A Nx2 array is returned with r being the first column and theta being
    the second.
    """
    import numpy as np
    # Calculate x- and y-co-ordinate offsets from the centre:
    x_offset = coords[:,0] - (output_shape[1]/2)
    y_offset = coords[:,1] - (output_shape[0]/2)
    
    # Calculate r and theta in pixels and radians:
    r = np.sqrt(x_offset ** 2 + y_offset ** 2)
    theta = np.arctan2(y_offset, x_offset)
    
    # The maximum value r can take is the diagonal corner:
    max_x_offset, max_y_offset = output_shape[1]/2, output_shape[0]/2
    max_r = np.sqrt(max_x_offset ** 2 + max_y_offset ** 2)
    
    # Scale r to lie between 0 and 1
    r = r / max_r
    
    # arctan2 returns an angle in radians between -pi and +pi. Re-scale
    # it to lie between 0 and 1
    theta = (theta + np.pi) / (2*np.pi)
    
    # Stack r and theta together into one array. Note that r and theta are initially
    # 1-d or "1xN" arrays and so we vertically stack them and then transpose
    # to get the desired output.
    return np.vstack((r, theta)).T

def r_theta_to_input_coords(r_theta):
    """Convert a Nx2 array of r, theta co-ordinates into the corresponding
    co-ordinates in the input image.
    
    Return a Nx2 array of input image co-ordinates.
    
    """
    import numpy as np
    # Extract r and theta from input
    r, theta = r_theta[:,0], r_theta[:,1]
    
    # Theta wraps at the side of the image. That is to say that theta=1.1
    # is equivalent to theta=0.1 => just extract the fractional part of
    # theta
    theta = theta - np.floor(theta)
    
    # Calculate the maximum x- and y-co-ordinates
    max_x, max_y = input_shape[1]-1, input_shape[0]-1
    
    # Calculate x co-ordinates from theta
    xs = theta * max_x
    
    # Calculate y co-ordinates from r noting that r=0 means maximum y
    # and r=1 means minimum y
    ys = (1-r) * max_y
    
    # Return the x- and y-co-ordinates stacked into a single Nx2 array
    return np.hstack((xs, ys))

def little_planet_1(coords):
    """Chain our two mapping functions together."""
    r_theta = output_coord_to_r_theta(coords)
    input_coords = r_theta_to_input_coords(r_theta)
    return input_coords

def little_planet_2(coords):
    """Chain our two mapping functions together with modified r."""
    import numpy as np
    r_theta = output_coord_to_r_theta(coords)
    # Take square root of r
    r_theta[:,0] = np.sqrt(r_theta[:,0])
    input_coords = r_theta_to_input_coords(r_theta)
    return input_coords

def little_planet_3(coords):
    """Chain our two mapping functions together with modified r
    and shifted theta.
    
    """
    import numpy as np
    r_theta = output_coord_to_r_theta(coords)
    
    # Take square root of r
    r_theta[:,0] = np.sqrt(r_theta[:,0])
    
    # Shift theta
    r_theta[:,1] += 0.1
    
    input_coords = r_theta_to_input_coords(r_theta)
    return input_coords

def little_planet_4(coords):
    """Chain our two mapping functions together with modified and
    scaled r and shifted theta.
    
    """
    import numpy as np
    r_theta = output_coord_to_r_theta(coords)
    
    # Scale r down a little to zoom in
    r_theta[:,0] *= 0.75
    
    # Take square root of r
    r_theta[:,0] = np.sqrt(r_theta[:,0])
    
    # Shift theta
    r_theta[:,1] += 0.1
    
    input_coords = r_theta_to_input_coords(r_theta)
    return input_coords

def equi2polar(imgs_root,output_shape,little_planet,save_path):
    '''
    转换等量矩形全景图为极坐标格式全景图

    Parameters
    ----------
    imgs_root : string
        全景图根目录.
    output_shape : tuple
        极坐标格式全景图的图像大小（width,height）.
    little_planet : function
        极坐标格式全景图可选类型：little_planet_1，little_planet_2，little_planet_3，little_planet_4.
    save_path : string
        图像保存根目录.

    Returns
    -------
    None.

    '''
    import glob,os 
    from tqdm import tqdm
    from PIL import Image,ImageOps
    import numpy as np
    from skimage.transform import warp
    from PIL import Image
    from pathlib import Path
    
    img_fns=glob.glob(os.path.join(imgs_root,'*.jpg'))
    for fn in tqdm(img_fns):        
        pano=np.asarray(ImageOps.flip(Image.open(fn)))
        global input_shape
        input_shape=pano.shape      
        pano_warp=warp(pano, little_planet, output_shape=output_shape)
        # The image is a NxMx3 array of floating point values from 0 to 1. Convert this to
        # bytes from 0 to 255 for saving the image:
        pano_warp=(255 * pano_warp).astype(np.uint8)       
        im=Image.fromarray(pano_warp)
        # im_save_fn=os.path.join('./processed data/polar_img','{}.jpg'.format(Path(fn).stem))
        im_save_fn=os.path.join(save_path,'{}.jpg'.format(Path(fn).stem))
        im.save(im_save_fn)     
        break  

def equi2polar_pool(fn,args): 
    '''
    equi2polar(imgs_root,output_shape,little_planet,save_path)函数的多进程版。转换等量矩形全景图为极坐标格式全景图

    Parameters
    ----------
    fn : string
        单个图像路径.
    args : list
        包括：output_shape,little_planet,save_path 等3个参数.

    Returns
    -------
    None.

    '''
    import glob,os 
    from tqdm import tqdm
    from PIL import Image,ImageOps
    import numpy as np
    from skimage.transform import warp
    from PIL import Image
    from pathlib import Path   
    
    global output_shape
    output_shape,little_planet,save_path=args
       
    pano=np.asarray(ImageOps.flip(Image.open(fn)))
    global input_shape
    input_shape = pano.shape     
    pano_warp=warp(pano, eval(little_planet), output_shape=output_shape)
    pano_warp = (255 * pano_warp).astype(np.uint8)    
    im=Image.fromarray(pano_warp)
    im_save_fn=os.path.join(save_path,'{}.jpg'.format(Path(fn).stem))
    im.save(im_save_fn)   

if __name__=="__main__":
    import os
    from database import cfg_load_yaml
    cfg=cfg_load_yaml('../config.yml')  
    
    parent_path=os.path.dirname(os.getcwd())
    imgs_root=os.path.join(parent_path,cfg["equi2cube"]["region"]["img_seg_redefined_color_root"]) 
    output_shape=eval(cfg["equi2polar"]["output_shape"])
    little_planet=eval(cfg["equi2polar"]["little_planet"])
    save_path=os.path.join(parent_path,cfg["equi2polar"]["region"]["polar_seg_root"])
    equi2polar(imgs_root,output_shape,little_planet,save_path)      
```

`equi2polar.py`
```python
# -*- coding: utf-8 -*-
"""
Created on Sun May  2 10:11:12 2021
Updated on Thu Jan 20 16:13:33 2022

@author: Richie Bao-caDesign设计(cadesign.cn)
"""


if __name__ == '__main__':  
    import glob,os
    from multiprocessing import Pool
    from tqdm import tqdm
    from equi2polar_pool import equi2polar_pool
    from functools import partial
    
    import sys
    sys.path.append('..')
    from database import cfg_load_yaml
    cfg=cfg_load_yaml('../config.yml')
    
    parent_path=os.path.dirname(os.getcwd())
    imgs_root=os.path.join(parent_path,cfg["equi2cube"]["region"]["img_seg_redefined_color_root"]) 
    img_fns=glob.glob(os.path.join(imgs_root,'*.jpg'))
    
    output_shape=eval(cfg["equi2polar"]["output_shape"])
    little_planet=cfg["equi2polar"]["little_planet"]
    save_path=os.path.join(parent_path,cfg["equi2polar"]["region"]["polar_seg_root"]) 
    args=partial(equi2polar_pool, args=[output_shape,little_planet,save_path])
    
    with Pool(8) as p:
        p.map(args, tqdm(img_fns))  

```

> 全景图转极坐标格式全景图，同语义分割全景图转极坐标格式的方法，通过替换`imgs_root`图像位置根目录，和重新定义`save_path`输出目录实现。街道部分同。

###### 3) 等量矩形投影图到球面全景

使用[mayavi](https://docs.enthought.com/mayavi/mayavi/)三维科学数据可视化绘图工具实现。`mlab.show()`方法可以交互显示三维图像，也可以通过`mlab.savefig`方法保存图像。

`spherical_panorama.py`
```python
# -*- coding: utf-8 -*-
"""
Created on Thu Apr 29 21:45:02 2021
Updated on Thu Jan 20 18:24:48 2022

@author: Richie Bao-caDesign设计(cadesign.cn)
"""

def sphere_panorama_label(image_file):
    '''
    转换等量矩形投影图到球面全景

    Parameters
    ----------
    image_file : string
        单张全景图文件路径.

    Returns
    -------
    None.

    '''
    import math
    import numpy as np
    from mayavi import mlab
    from tvtk.api import tvtk # python wrappers for the C++ vtk ecosystem
    
    # create a figure window (and scene)
    fig = mlab.figure(size=(600, 600),bgcolor=(1, 1, 1))

    # load and map the texture
    img = tvtk.JPEGReader()
    img.file_name = image_file
    texture = tvtk.Texture(input_connection=img.output_port, interpolate=1)
    # print(texture)
    # (interpolate for a less raster appearance when zoomed in)

    # use a TexturedSphereSource, a.k.a. getting our hands dirty
    R = 50
    Nrad = 180

    # create the sphere source with a given radius and angular resolution
    sphere = tvtk.TexturedSphereSource(radius=R, theta_resolution=Nrad,phi_resolution=Nrad)

    # assemble rest of the pipeline, assign texture    
    sphere_mapper = tvtk.PolyDataMapper(input_connection=sphere.output_port)
    sphere_actor = tvtk.Actor(mapper=sphere_mapper, texture=texture)
    fig.scene.add_actor(sphere_actor)
    
    # Plot the equator and the tropiques
    theta_equator=np.linspace(0, 2 * np.pi, 100)
    veiw_scope_dic={}
    for i,angle in enumerate([-math.radians(70), 0, math.radians(50)]):
        x_equator=R * np.cos(theta_equator) * np.cos(angle)
        y_equator=R * np.sin(theta_equator) * np.cos(angle)
        z_equator=R * np.ones_like(theta_equator) * np.sin(angle)    
        mlab.plot3d(x_equator, y_equator, z_equator, color=(0, 0, 0),opacity=0.6, tube_radius=None)  
        veiw_scope_dic[i]=[x_equator,y_equator,z_equator]    
    
    str_info={0:'lower limit of visual filed:-70',1:'Standard line of sight:0',2:'Upper limit of visual filed:+50'}
    for k,v in str_info.items():
        mlab.text(veiw_scope_dic[k][0][0], veiw_scope_dic[k][1][0], v, z=veiw_scope_dic[k][2][0],width=0.029 * len(v), name=v,color=(0,0,0))
    
    vertical_label_radians=np.linspace(0, np.pi,14)
    vertical_label_degree=["{:.2f}".format(90-math.degrees(radi)) for radi in vertical_label_radians]
    phi_label=0
    for idx in range(len(vertical_label_radians)):
        theta_labe=vertical_label_radians[idx]
        x_label=R * np.sin(theta_labe) * np.cos(phi_label)
        y_label=R * np.sin(theta_labe) * np.sin(phi_label)
        z_label=R * np.cos(theta_labe)         
        mlab.points3d(x_label, y_label, z_label,scale_factor=1,color=(0,0,0))
        label=vertical_label_degree[idx]
        mlab.text(x_label, y_label, label, z=z_label,width=0.028 * len(label), name=label,color=(0,0,0))    
        
    # mlab.savefig('./processed data/img_sphere/x.jpg',size=(50,50))
    mlab.show()

if __name__ == "__main__":
    from database import cfg_load_yaml 
    cfg=cfg_load_yaml('config.yml')
    
    panorama_example_fn=cfg["spherical_panorama"]["panorama_example_fn"]
    sphere_panorama_label(panorama_example_fn)  
    #panorama_seg_example_fn=cfg["spherical_panorama"]["panorama_seg_example_fn"]
    #sphere_panorama_label(panorama_seg_example_fn)      
```

__Fig. 球面全景交互可视化__  

<a href=""><img src="./imgs/3_2_1_03.gif" height="auto" width=800 title="caDesign"></a>

__Fig. 语义分割球面全景交互可视化__  

<a href=""><img src="./imgs/3_2_1_04.gif" height="auto" width=800 title="caDesign"></a>

###### 4) 全景图投影变换示例排布绘图

`imgs_arranging.py`
```python
# -*- coding: utf-8 -*-
"""
Created on Wed May 12 12:44:51 2021
Updated on Thu Jan 20 17:13:05 2022

@author: Richie Bao-caDesign设计(cadesign.cn)
"""


def panoramic_transform_example_show(*args):
    '''
    全景图投影变换示例排布绘图

    Parameters
    ----------
    *args : 图像路径参数
        包括：panorama_fn,polar_fn,cube_fn,sphere_fn.

    Returns
    -------
    None.

    '''
    from PIL import Image,ImageOps
    import numpy as np
    import matplotlib.pyplot as plt
    import cv2
    import matplotlib
    
    panorama_fn,polar_fn,cube_fn,sphere_fn=args
    
    font = {
            # 'family' : 'normal',
            # 'weight' : 'bold',
            'size'   : 28}
    matplotlib.rc('font', **font)
    title_fontsize=55
    
    # vertical_label_radians=np.linspace(0, np.pi,14)
    # vertical_label_degree=["{:.2f}".format(90-math.degrees(radi)) for radi in vertical_label_radians]
    vertical_label_degree=90-np.linspace(0, 180,17)
    horizontal_label_degree=180-np.linspace(0, 360,17)    
    print(horizontal_label_degree)
    
    pano=np.asarray(Image.open(panorama_fn))
    # pano=cv2.imread(panorama_fn)
    pano_height,pano_width,_=pano.shape
    print(pano_width,pano_height)
    
    # fig, (ax1, ax2)=plt.subplots(ncols=2, figsize=(20,10))
    fig=plt.figure(figsize=(20,10))
    
    #01-pano
    # ax1=plt.subplot(131, frameon=False)  
    ax1_coords=[0, 0, 1, 1] #rect : This parameter is the dimensions [left, bottom, width, height] of the new axes.
    ax1=fig.add_axes(ax1_coords)    
    
    ax1.imshow(pano,)     #extent=[x0, x1, y0, y1]  interpolation='bilinear',aspect='auto',origin='lower',
    ax1.set_yticks(np.linspace(0,pano_height,len(vertical_label_degree)))    
    ax1.set_yticklabels(vertical_label_degree) # provide name to the x axis tick marks   
    ax1.set_xticks(np.linspace(0,pano_width,len(horizontal_label_degree)))    
    ax1.set_xticklabels(horizontal_label_degree) # provide name to the x axis tick marks   
    ax1.axhline(y=pano_height/2,color='gray',linestyle='-.',linewidth=1)
    ax1.axvline(x=pano_width/2,color='gray',linestyle='-.',linewidth=1)
    ax1.set_title("Equirectangular format", va = 'bottom',fontsize=title_fontsize)

    #02-polar
    # polar=cv2.imread(polar_fn)
    polar=np.asarray(Image.open(polar_fn))
    polar_height,polar_width,_=polar.shape   
    ax2_coords = [0.8, 0, 1, 1]
    
    ax2_image = fig.add_axes(ax2_coords)
    ax2_image.imshow(polar, alpha = 1)
    ax2_image.axis('off')  # don't show the axes ticks/lines/etc. associated with the image    

    #theta = np.linspace(0, 2 * np.pi, 73)       
    ax2_coords_=[0.80000001, 0, 1, 1] #如果位置重叠，可能会提示ValueError: Unknown element o错误
    ax2_polar = fig.add_axes(ax2_coords_, projection='polar')
    ax2_polar.patch.set_alpha(0)
    ax2_polar.set_ylim(30, 41)
    ax2_polar.set_yticks(np.arange(30, 41, 2))
    ax2_polar.set_yticklabels([])
    ax2_polar.set_rlabel_position(-22.5)  # get radial labels away from plotted line
    ax2_polar.grid(True)
    ax2_polar.set_title("Polar format", va = 'bottom',fontsize=title_fontsize)    

    #03-cube
    ax3_coords=[1.47, 0, 1, 1]
    ax3=fig.add_axes(ax3_coords)
    # cube=cv2.imread(cube_fn)
    cube=np.asarray(Image.open(cube_fn))
    cube_height,cube_width,_=cube.shape
    ax3.imshow(cube, alpha = 1)
    ax3.axis('off')    
    ax3.axvline(x=cube_width*(1/3),color='gray',linestyle='-.',linewidth=1)
    ax3.axvline(x=cube_width*(2/3),color='gray',linestyle='-.',linewidth=1)    
    ax3.set_title("Cubic format", va = 'bottom',fontsize=title_fontsize)
    bbox_props = dict(boxstyle="round", fc="w", ec="0.5", alpha=0.4)
    ax3.text(cube_width*(1/6), cube_height*(1/4), "Top", ha="center", va="center", size=40,bbox=bbox_props)
    ax3.text(cube_width*(3/6), cube_height*(1/4), "Back", ha="center", va="center", size=40,bbox=bbox_props)
    ax3.text(cube_width*(5/6), cube_height*(1/4), "Down", ha="center", va="center", size=40,bbox=bbox_props)
    ax3.text(cube_width*(1/6), cube_height*(3/4), "Left", ha="center", va="center", size=40,bbox=bbox_props)
    ax3.text(cube_width*(3/6), cube_height*(3/4), "Front", ha="center", va="center", size=40,bbox=bbox_props)
    ax3.text(cube_width*(5/6), cube_height*(3/4), "Right", ha="center", va="center", size=40,bbox=bbox_props)    
    
    #04-sphere
    ax4_coords=[2.15, 0, 1, 1]
    ax4=fig.add_axes(ax4_coords)    
    # sphere=cv2.imread(sphere_fn)    
    sphere=np.asarray(Image.open(sphere_fn))
    ax4.imshow(sphere)     
    ax4.axis('off') 
    ax4.set_title("Spherical format", va = 'bottom',fontsize=title_fontsize)
    
    fig.tight_layout()    
    # fig.savefig('./graph/preprocessed data_01',dpi=300)
    plt.show()

if __name__=="__main__":
    from database import cfg_load_yaml   
    import os    
    cfg=cfg_load_yaml('config.yml')    
    
    #A.全景图投影变换示例排布绘图
    panoramic_transform_example_fn=cfg["imgs_arranging"]["panoramic_transform_example_fn"]
    # PT_img_fns=[os.path.join(cfg["streetview"]["panoramic_imgs_valid_root"],panoramic_transform_example_fn),
    #             os.path.join(cfg["equi2polar"]["region"]["polar_img_root"],panoramic_transform_example_fn),
    #             os.path.join(cfg["equi2cube"]["cube_img"],panoramic_transform_example_fn),
    #             os.path.join(cfg["spherical_panorama"]["img_sphere_root"],panoramic_transform_example_fn)]
    # panoramic_transform_example_show(*PT_img_fns)
    
    PT_seg_fns=[os.path.join(cfg["panaSeg"]["pano_path"],panoramic_transform_example_fn),
                os.path.join(cfg["equi2polar"]["region"]["polar_seg_root"],panoramic_transform_example_fn),
                os.path.join(cfg["equi2cube"]["region"]["img_seg_cube_root"],panoramic_transform_example_fn),
                os.path.join(cfg["spherical_panorama"]["seg_sphere_root"],panoramic_transform_example_fn)]
    panoramic_transform_example_show(*PT_seg_fns)
```

__Fig. 全景变换数据类型__  

<a href=""><img src="./imgs/3_2_1_05.png" height="auto" width="auto" title="caDesign"></a>


#### B.2.3 分析与结果

分析城市街道空间特征的指数主要包括基于立方体型360度全景图语义分割对象像素占比，即绿视率、天空视域因子和地面视域占比，及视觉（熵）均衡度和域对象位置变化；基于极坐标格式全景图语义分割天空对象的景观指数，包括周长面积比、形状指数和分维数；基于等量矩形投影全景图颜色的主题色提取和色彩丰富度指数；基于尺度不变特征转换特征关键点信息的关键点邻域尺度(i,j]区间频数、标准差和视域特征匹配消失距离；基于行业分类服务内容兴趣点的POI点数、POI均衡度和POI特征映射，总共16个指数。其中反应视域城市街道物质空间组成结构，基于全景图计算机视觉分析的指数13个；反应居民日常活动，基于具有社会属性，即服务空间的兴趣点指数3个。

| 序号  | 指数名称  |  值个数 | 内容  |  公式 |  描述 |   
|---|---|---|---|---|---|
|  1 | 绿视率（Seg object_Green view index, Seg_GVI）  | 1  | 基于立方体型360度全景图语义分割对象像素占比  | $Seg\_GVI= \frac{ P_{seg\_green} }{P}  \times 100$  |  绿视率（$Seg\_GVI$）等于立方体型360度全景图语义分割对象中植被像素数$P_{seg\_green}$ 占全部像素数P的百分比。 |   
|  2 | 天空视域因子（Seg object Sky view factor, Seg_SVF）  | 1  |   | $Seg\_SVF= \frac{ P_{seg\_sky} }{P}  \times 100$  | 天空视域因子（$Seg\_SVF$ ）等于立方体型360度全景图语义分割对象中天空像素数$P_{seg\_sky}$ 占全部像素数 P的百分比。  |   
|  3 | 地面视域占比（Seg object Ground view factor, Seg_GVF）  | 1  |   | $Seg\_GVF= \frac{ P_{seg\_ground} }{P}  \times 100$  | 地面视域占比（$Seg\_GVF$ ）等于立方体型360度全景图语义分割对象中地面像素数$P_{seg\_ground}$ 占全部像素数P的百分比。  |   
|  4 | 视觉（熵）均衡度（Seg object equilibrium degree, Seg_ED）  |  1 |   |  $Seg\_ED= \frac{- \sum_{i=1}^n  P_{i}logP_{i}  }{logN}$  | 视觉（熵）均衡度（$Seg\_ED$）为立方体型360度全景图语义分割对象信息熵与最大熵值$logN$之比。 $P_{i}$ 为第$i$个语义分割对象像素数与全部像素数的比值。  |  
| 5  | 视域对象位置变化（Variation degree of objects , VDO）  | 多个值  |   |  $VDO_{ij}= \Delta  ( A_{0} ) _{ij} +  \Delta  ( A_{1} ) _{ij} +  \ldots  + \Delta  ( A_{k-1} ) _{ij};  \Delta  (A) _{ij}=\begin{cases}1 & \Delta  (A) _{ij}> 0\\0 & \Delta  (A) _{ij}=0\end{cases} $ |  视域对象位置变化$VDO$为分析路径下各个地理位置点的球面全景语义分割对象在球面各像素点位置上的变化，即任意球面位置$(i,j)$在路径上相邻两位置语义分割对象发生了改变则加1，即$\Delta  (A) _{ij}=1$否则加0，未发生改变，得球面位置$(i,j)$的变化次数$VDO_{ij}$。$VDO$矩阵即为视域对象位置变化。 |  
|  6 | 天际线周长面积比（均值）（Skyline perimeter area ratio, Sky_PARA(mn)） |  1 | 基于极坐标格式全景图语义分割天空对象的景观指数  |  $Sky\_PARA_{(mn)} = \frac{ \sum_{i=1}^n  \frac{ p_{i} }{ a_{i} }  }{n}$  |  天际线周长面积比（均值）（$Sky\_PARA_{(mn)}$）等于极坐标格式全景图语义分割对象中各个天空斑块周长$p_{i}$与面积$a_{i}$ 比之和除以天空的斑块数$n$。由PyLandStats库（Python）计算。 |   
|  7 | 天际线形状指数（均值）（Skyline shape index, Sky_ SHAPE(mn)）  | 1  |   | $ Sky\_SHAPE_{(mn)} = \frac{ \sum_{i=1}^n  \frac{.25 p_{i} }{ \sqrt{ a_{i} } } }{n} $  |  天际线形状指数（均值）（$ Sky\_SHAPE_{(mn)}$）等于极坐标格式全景图语义分割对象中各个天空斑块周长$p_{i}$与面积$a_{i}$ 平方根比值乘以调整系数的和除以天空的斑块数 $n$。 由PyLandStats库（Python）计算。|   
|  8 | 天际线分维数（均值）（Skyline fractal dimension, Sky_ FRAC(mn) ）  |  1 |   | $Sky\_FRAC_{(mn)} = \frac{ \sum_{i=1}^n  \frac{2ln(.25 p_{i} )}{ln( a_{i} )}  }{n} $  | 天际线分维数（均值）（$Sky\_FRAC_{(mn)}$ ）等于极坐标格式全景图语义分割对象中各个天空斑块周长$p_{i}$乘以调整系数后取其对数的2倍与面积$a_{i}$ 的对数比值的和除以天空的斑块数 $n$。 由PyLandStats库（Python）计算。 |   
|  9 | 主题色（Theme color, TC）  | 多个值  | 基于等量矩形投影全景图城市街道色彩  | $argmin_{S} \sum_{i=1}^k  \sum_{x \in  S_{i} }\|x-  \mu _{i}   \|^{2}  $;$TC=\{ TC_{i} : TC_{i} =  \frac{1}{ \| S_{i} \| }  \sum_{ x_{j}  \in   S_{i} }  x_{j} \}$ | 主题色（$TC$）为等量矩形投影全景图颜色值聚类各簇中心值 $TC_{i}$的集合，即第$i$个类簇所有颜色点各属性值（R、G、B）的和除以该簇个数$\|S_{i}\|$。聚类条件为使得所有簇内各颜色点$x$到该簇中心值（经验均值）$μ_{i}$的平方误差和最小。 由scikit-learn库（Python）的K-Means方法聚类。 |   
|  10 | 色彩丰富度指数（Color richness index, CRI）   |  1 |   | $CRI= \frac{- \sum_{i=1}^k  P_{i}logP_{i}  }{log\| S\| } $;$P_{i} = \frac{\| S_{i} \|  }{ \sum_{i=1}^k \| S_{i} \|  } , S_{i} \in S$  | 色彩丰富度指数（CRI）为等量矩形投影全景图主题色聚类的信息熵与最大熵值log⌈S⌉的比值， ⌈S⌉ 即主题色聚类数，全景图各颜色点所属主题色由主题色TC计算时获取。P_i为第i个主题色聚类簇颜色点数（像素数）⌈S_i ⌉与全部像素数的比值。  |   
|  11 |关键点邻域尺度(i,j]区间频数（Key point size(i-j] frequency,KPSF_(i,j] )   | 多个值  | 尺度不变特征转换（Scale Invariant Feature Transform, SIFT）  |  $ KPSF_{(i,j]} =\{ x_{k} :i \leq  x_{k} <j,  x_{k}  \in KPS  \}$ | 关键点邻域尺度$(i,j]$区间频数（$KPSF_{(i,j]}$) 为关键点邻域尺度$x_{k}$, 即提取的等量矩形投影全景图特征关键点的大小 $KPS$, 满足条件$i≤ x_{k} < j$的集合。  由opencv-python库（Python）StarDetector_create()方法提取特征关键点。|   
| 12 | 关键点邻域尺度标准差（Key point size std, KPS_STD）  | 1  |   | $KPS\_STD= \sqrt{ \frac{1}{N} \sum_{i=1}^N   ( x_{i}- \mu  )^{2}  } ,  x_{i}  \epsilon KPS$  | 关键点邻域尺度标准差（$KPS\_STD$）为各个关键点邻域尺度$x_{i}$ 与均值 $μ$的差值平方除以关键点数的平方根。 由opencv-python库（Python）StarDetector_create()方法提取特征关键点。 |    
| 13  | 视域特征匹配消失距离 （Vanishing distance of feature matching, VDFM ）   |  1 |   | $VDFM=f( x_{1} ), where  \triangle (x)== \triangle ( \triangle (x)) \& \triangle (x)!=0$  | 视域特征匹配消失距离  $VDFM$为分析路径某一位置等量矩形投影全景图与之后所有位置全景图图像匹配特征点数变化趋于平缓的位置与该位置的路径距离。$\triangle (x)$为连续相邻图像匹配特征点数的差值，$\triangle ( \triangle (x))$为差值的差值；$f(x_{1} )$为满足条件的第一个值$x_{1}$作为参数输入函数$f$，返回其间的路径距离。  由opencv-python库（Python）BFMatcher()方法计算图像匹配。  |   
| 14  | 兴趣点数（Number of POI, POI_NUM）  |  1 |  POI | $POI\_NUM=n$  | 兴趣点数$POI\_NUM$为分析路径某一位置给定缓冲区下兴趣点的数量。|   
| 15  | POI均衡度（Equilibrium degree of POI, POI_ED）  |  1 |   |  $POI\_ED= \frac{- \sum_{i=1}^k  P_{i}logP_{i}  }{log\|S\|} $; $P_{i}= \frac{\| S_{i} \|}{ \sum_{i=1}^k \| S_{i} \| }  , S_{i} \in S$| $POI$均衡度$POI\_ED$为分析路径某一位置给定缓冲区下兴趣点一级行业分类的信息熵与最大熵值$log\|S\|$的比值，$\|S\|$为兴趣点一级行业分类数。$P_{i}$为第$i$个一级行业分类数$\| S_{i} \|$与全部一级行业分类数的比值。  |   
| 16  | POI特征映射（码本映射）（Codewords of POI, POI_CW）  | 多个值  |   |  POI\_CW=[w_{0},w_{1},⋯,w_{k} ] |  $POI$特征映射（码本映射）$POI\_CW$为分析路径某一位置给定缓冲区下兴趣点各一级行业分类的数量或其与总数的比值的矩阵或向量。$k$为一级行业分类的数量，即为矩阵的长度。 |   


##### B.2.3.1 街道空间对象视域占比指数测量

###### 1) 指数计算

语义分割立方体型全景图，计算植被（绿视率）、天空（天空视域因子）、地面视域所占百分比，以及视觉熵均衡度。将计算结果划分为4个数量级区间，(0,15], (15,25], (25,50]和(50,100]，可以描述为较少，正常，较多，多。街道空间对象视域占比指数与城市街区类型，空间体验，市民活动行为，建筑外热环境（微气候）等内容相关。从计算结果的表中可以初步判断分析区域不同视域占比频数比例的分布，绿视率低于15%的接近一半数量，道路以车行为主，高于25%适宜于步行体验，易于放松身心的占到约30%；天空视域因子高于50%的基本没有，以25%为数量级划分，高低各占约一半；将绿视率和天空视域因子综合考虑，即自然因素视域占比，高于25%的达到95%的数量；地面视域占比有约1/4的数量高于50%，通常为道路交叉口以及快速路、主干路等路面宽阔的空间。街道空间对象的混合程度以50%为数量级划分，上下各占约一半，即约有一半数量的街道空间对象均质性相对较强，对象视域数量分布均衡；而一半数量均质性较弱，以某一类对象占主导。

|                | vege_percentage | sky_percentage | sky_vege_percentage | ground_percentage | equilibrium_degree_percentage |
|----------------|-----------------|----------------|---------------------|-------------------|-------------------------------|
| (-0.001, 15.0] | 46.837          | 21.229         | 1.594               | 0.03              | 0.052                         |
| (15.0, 25.0]   | 23.116          | 24.141         | 3.369               | 0.12              | 0.142                         |
| (25.0, 50.0]   | 28.812          | 54.6           | 66.809              | 72.857            | 47.96                         |
| (50.0, 100.0]  | 1.235           | 0.03           | 28.228              | 26.993            | 51.845                        |

`visual_field_proportion_metrics.py`
```python
# -*- coding: utf-8 -*-
"""
Created on Thu Apr 29 19:21:17 2021
Updated on Mon Jan 24 10:54:54 2022

@author: Richie Bao-caDesign设计(cadesign.cn)
"""

def metrics_seg_pano_proportion(label_seg_path,img_Seg_path,coords):
    '''
    给定语义分割图像，计算各个对象占图像的百分比

    Parameters
    ----------
    label_seg_path : string
        语义分割标签根目录.
    img_Seg_path : string
        语义分割图像根目录.
    coords : pickle
        各个道路对应全景图的采集坐标点.

    Returns
    -------
    panorama_object_percent_gdf : GeoDataFrame
        包含各个对象占比.

    '''
    import glob,os    
    import pickle
    from pathlib import Path
    from PIL import Image
    from tqdm import tqdm
    import numpy as np
    import pandas as pd
    from shapely.geometry import Point
    import geopandas as gpd
    import pyproj
    
    panorama_object_num=pd.DataFrame(columns=["fn_stem","fn_key","fn_idx","geometry",]+list(range(28)))
    label_mapping={
        0:"pole",
        1:"slight",
        2:"bboard",
        3:"tlight",
        4:"car",
        5:"truck",
        6:"bicycle",
        7:"motor",
        8:"bus",
        9:"tsignf",
        10:"tsignb",
        11:"road",
        12:"sidewalk",
        13:"curbcut",
        14:"crosspln",
        15:"bikelane",
        16:"curb",
        17:"fence",
        18:"wall",
        19:"building",
        20:"person",
        21:"rider",
        22:"sky",
        23:"vege",
        24:"terrain",
        25:"markings",
        26:"crosszeb",
        27:"Nan",                           
        }    
    label_seg_fns=glob.glob(os.path.join(label_seg_path,'*.pkl'))
    # print(label_seg_fns)
    i=0
    for label_seg_fn in tqdm(label_seg_fns):
        with open(label_seg_fn,'rb') as f:
            label_seg=pickle.load(f)  
        fn_stem=Path(label_seg_fn).stem
        fn_key,fn_idx=fn_stem.split("_")      
        
        unique_elements, counts_elements=np.unique(label_seg, return_counts=True)
        object_frequency=dict(zip(unique_elements, counts_elements))
        object_frequency_update={k:object_frequency[k] if k in object_frequency.keys() else 0 for k in range(28) }
        coord=coords[fn_key][int(fn_idx)]
        object_frequency_update.update({"fn_stem":fn_stem,"fn_key":fn_key,"fn_idx":int(fn_idx),"geometry":Point(coord)})
        panorama_object_num=panorama_object_num.append(object_frequency_update,ignore_index=True)
        
        # if i==0:break
        # i+=1
    panorama_object_percent=panorama_object_num.copy(deep=True)
    panorama_object_percent[list(range(28))]=panorama_object_num[list(range(28))].div(np.prod(label_seg.shape)/100)   

    panorama_object_percent=panorama_object_percent.rename(columns=label_mapping)
    panorama_object_percent['ground_diff']=panorama_object_percent.apply(lambda row:100-row.sky-row.vege-row.building-row.wall-row.fence-row.bboard,axis=1)
    panorama_object_percent['sky_vege']=panorama_object_percent.apply(lambda row:row.sky+row.vege,axis=1)
    
    wgs84=pyproj.CRS('EPSG:4326')
    panorama_object_percent_gdf=gpd.GeoDataFrame(panorama_object_percent,geometry=panorama_object_percent.geometry,crs=wgs84) 

    return panorama_object_percent_gdf

def metrics_visual_entropy(panorama_object_percent_gdf):
    '''
    计算每幅语义分割图像，对象的信息和均衡度

    Parameters
    ----------
    panorama_object_percent_gdf : GeoDataFrame
        语义分割图像各个对象占图像的百分比.

    Returns
    -------
    GeoDataFrame
        包含对象的信息和均衡度.

    '''
    panorama_object_percent_gdf['ground']=panorama_object_percent_gdf.apply(lambda row:100-row.sky-row.vege-row.building,axis=1)
    def ve_row(row):
        import math
        import pandas as pd
        label=['pole', 'slight', 'bboard', 'tlight', 'car', 'truck', 'bicycle', 'motor', 'bus', 'tsignf', 'tsignb', 'road', 'sidewalk', 'curbcut', 'crosspln', 'bikelane', 'curb', 'fence', 'wall', 'building', 'person', 'rider', 'sky', 'vege', 'terrain', 'markings', 'crosszeb', 'Nan']
        ve=0.0
        for i in label:
            decimal_percentage=row[i]/100
            # print(decimal_percentage)
            if decimal_percentage!=0.:
                ve-=decimal_percentage*math.log(decimal_percentage)
        max_entropy=math.log(len(label))
        frank_e=ve/max_entropy*100
        
        return pd.Series([ve,frank_e])
    
    panorama_object_percent_gdf[['ve','equilibrium_degree']]=panorama_object_percent_gdf.apply(ve_row,axis=1)
    return panorama_object_percent_gdf

def percent_frequency(df,columns,bins,digits):
    '''
    计算给定区间的百分比频数（percent frequency）

    Parameters
    ----------
    df : DataFrame or GeoDataFrame
        DataFrame数据.
    columns : list
        需要计算的列字段列表.
    bins : list
        频数宽度列表.

    Returns
    -------
    frequency : DataFrame
        给定区间的百分比频数.

    '''
    import pandas as pd
    frequency=df[columns].apply(pd.Series.value_counts,bins=bins,)
    column_names=[]
    for column_name in columns:
        cn=column_name+'_percentage'
        frequency[cn]=round((frequency[column_name] / frequency[column_name].sum()) * 100,3)
        column_names.append(cn)
    return frequency,column_names

if __name__=="__main__":
    import sys,os
    sys.path.append('..')  
    
    from database import postSQL2gpd,gpd2postSQL,cfg_load_yaml   
    import pickle
    parent_path=os.path.dirname(os.getcwd())
    cfg=cfg_load_yaml('../config.yml')  
    UN=cfg["postgreSQL"]["myusername"]
    PW=cfg["postgreSQL"]["mypassword"]
    DB=cfg["postgreSQL"]["mydatabase"] 
    GC='geometry'
    
    #A.街道空间对象视域占比
    label_seg_path=cfg['equi2cube']['region']['label_seg_cube_root'] #r'./processed data/label_seg_cube'    
    img_Seg_path=cfg['equi2cube']['region']['label_seg_cube_root'] #r'./processed data/img_seg_cube'
    img_path=cfg['streetview']['panoramic_imgs_valid_root']  #r'./data/panoramic imgs valid'
        
    with open(os.path.join(parent_path,cfg['streetview']['save_path_BSV_retrival_info']['coords']),'rb') as f: 
        coords=pickle.load(f)       
    
    cube_object_percent_gdf=metrics_seg_pano_proportion(label_seg_path,img_Seg_path,coords,)
    cube_object_percent_gdf.plot()       
    gpd2postSQL(cube_object_percent_gdf,table_name='cube_object_percent',myusername=UN,mypassword=PW,mydatabase=DB)
    
    #B.视觉（熵）均衡度    
    cube_object_percent_gdf=postSQL2gpd(table_name='cube_object_percent',geom_col=GC,myusername=UN,mypassword=PW,mydatabase=DB)
    cube_object_VE_gdf=metrics_visual_entropy(cube_object_percent_gdf)
    gpd2postSQL(cube_object_VE_gdf,table_name='cube_object_percent',myusername=UN,mypassword=PW,mydatabase=DB)
    
    #C.街道空间对象视域占比区间统计 
    cube_object_metrics=postSQL2gpd(table_name='cube_object_percent',geom_col=GC,myusername=UN,mypassword=PW,mydatabase=DB)
    columns=cfg['semantic_segmention_object_pixel_ratio']['columns']
    bins=cfg['semantic_segmention_object_pixel_ratio']['bins']
    digits=cfg['semantic_segmention_object_pixel_ratio']['digits']
    percentage,column_names=percent_frequency(cube_object_metrics,columns,bins,digits)
    percentage[column_names].to_excel(os.path.join(parent_path,cfg['semantic_segmention_object_pixel_ratio']['percentage2excel_path']))
```

###### 2) 示例

列出了不同数量级下立方体型全景图的示例，可以视觉感知判断之间的差异。

`imgs_arranging.py`
```python

def imgs_arranging(imgs_root,img_fns,save_path):
    '''
    语义分割立方体型全景图不同对象视域占比示例

    Parameters
    ----------
    imgs_root : dict
        图像根目录.
    img_fns : dict
        选择不同区间像素占比的图像.
    save_path : string
        保持排布图像的路径.

    Returns
    -------
    None.

    '''
    import os
    import numpy as np
    import matplotlib.pyplot as plt
    from mpl_toolkits.axes_grid1 import ImageGrid
    from PIL import Image,ImageOps
    import matplotlib
    
    font = {
            # 'family' : 'normal',
            # 'weight' : 'bold',
            'size'   : 28}
    matplotlib.rc('font', **font)    
    
    rows=['(-0.001, 15.0]','(15.0, 25.0]','(25.0, 50.0]','(50.0, 100.0]']
    img_list=[]
    for k,fns in img_fns.items():
        img_list.append([os.path.join(imgs_root,i[1]+'.jpg') for i in fns])
    img_list=list(map(list,zip(*img_list)))
    
    flatten_lst=lambda lst: [m for n_lst in lst for m in flatten_lst(n_lst)] if type(lst) is list else [lst]
    img_list=flatten_lst(img_list)
    nrows_ncols=(len(list(img_fns.values())[0]),len(img_fns.keys()),)
    print(nrows_ncols)
    fig=plt.figure(figsize=(30.+1, 20.-3))
    grid=ImageGrid(fig, 111,  # similar to subplot(111)
                   nrows_ncols=nrows_ncols,  # creates 2x2 grid of axes
                   axes_pad=0.05,  # pad between axes in inch.
                     )    
    i=0
    for ax,im_fn in zip(grid,img_list):
        # print(ax)
        ax.imshow(Image.open(im_fn))           
        # ax.axis('off')         
        
        if i<5:ax.set_title(list(img_fns.keys())[i])        
        if i%5==0:ax.set_ylabel(rows[i//5], )
        i+=1
    fig.tight_layout()
    # plt.show()
    plt.savefig(save_path,dpi=300)

if __name__=="__main__":
    from database import cfg_load_yaml   
    import os    
    cfg=cfg_load_yaml('config.yml')

    #B.语义分割立方体型全景图不同对象视域占比示例
    cube_object_percentage_example_fn=cfg['imgs_arranging']['cube_object_percentage_example_fn']
    object_percentage_cube_save_path=cfg['imgs_arranging']['object_percentage_cube_save_path']
    cube_imgs_root=cfg['equi2cube']['cube_img']
    imgs_arranging(cube_imgs_root,cube_object_percentage_example_fn,object_percentage_cube_save_path)        
```


__Fig. 语义分割立方体型全景图不同对象视域占比示例__ 

<a href=""><img src="./imgs/3_2_1_06.png" height="auto" width="auto" title="caDesign"></a>

###### 3) 视觉（熵）均衡度

较高的均衡度具有较高的均质性。如果延道路计算均衡度的变化值，可以用于评估街道对象变化的程度，这也是街道自身特征的一个映射。

地图构建是在QGIS中从`PostGIS`中调入数据库中保存的`cube_object_percent`表，包含`equilibrium_degree`字段。在`Symbology`项选择`Heatmap`可视化数据。

__Fig. 视觉（熵）均衡度__  

<a href=""><img src="./imgs/3_2_1_07.png" height="auto" width="auto" title="caDesign"></a>

##### B.2.3.2 天际线变化指数

###### 1) 指数计算

语义分割后的等量矩形投影全景图转换为极坐标格式的小行星全景图，提取天空对象计算斑块数量(NP)、周长面积比、形状指数、分维数等4个景观指数。计算4个指数的相关系数，相关性值高于0.5的两对指数分别为周长面积比和斑块数量（0.600），及形状指数和分维数（0.512）。使用自然最佳断裂点分级方法（Natural break, Jenks）划分指数，尽量使得划分的聚类簇示例偏离划分界限值观察天际线的形状差异。


|                         | number_of_patches | perimeter_area_ratio_mn | shape_index_mn | fractal_dimension_mn |
|-------------------------|-------------------|-------------------------|----------------|----------------------|
| number_of_patches       | 1                 | 0.6                     | -0.227         | 0.058                |
| perimeter_area_ratio_mn | 0.6               | 1                       | -0.249         | 0.029                |
| shape_index_mn          | -0.227            | -0.249                  | 1              | 0.512                |
| fractal_dimension_mn    | 0.058             | 0.029                   | 0.512          | 1                    |

__Fig. 天际线变化指数相关系数__  

<a href=""><img src="./imgs/3_2_1_08.png" height="auto" width="auto" title="caDesign"></a>

`skyline_shape_metrics.py`
```python
# -*- coding: utf-8 -*-
"""
Created on Sun May  2 14:01:09 2021
Updated on Mon Jan 24 22:32:44 2022

@author: Richie Bao-caDesign设计(cadesign.cn)
"""

def metrics_skyline_shape(img_root,coords,hsv_lower,hsv_upper,save_root):
    '''
    天际线景观指数计算

    Parameters
    ----------
    img_root : string
        极坐标格式全景图所在根目录.
    coords : dict
        各个道路对应全景图的采集坐标点.
    hsv_lower : list
        颜色最小值控制.
    hsv_upper : list
        颜色最大值控制.
    save_root : string
        TIFF 格式图像保存根目录.

    Returns
    -------
    metrics_skyline_shape_gdf : GeoDataFrame
        天际线景观指数.

    '''
    from tqdm import tqdm
    import glob,os 
    import numpy as np
    import cv2
    import matplotlib.pyplot as plt
    import rasterio as rio
    from rasterio.transform import from_origin
    from pathlib import Path 
    import pylandstats as pls
    import pandas as pd
    from shapely.geometry import Point
    import geopandas as gpd
    import pyproj        
    
    polar_seg_fns=glob.glob(os.path.join(img_root,'*.jpg'))
    hsv_lower_=np.asarray(hsv_lower)
    hsv_upper_=np.asarray(hsv_upper)
    
    transform=from_origin(472137, 5015782, 100, 100)  #472137, 5015782, 0.5, 0.5
    
    '''
    columns=["fn_stem","fn_key","fn_idx","geometry",]+['total_area', 'proportion_of_landscape', 'number_of_patches',
       'patch_density', 'largest_patch_index', 'total_edge', 'edge_density',
       'landscape_shape_index', 'effective_mesh_size', 'area_mn', 'area_am',
       'area_md', 'area_ra', 'area_sd', 'area_cv', 'perimeter_mn',
       'perimeter_am', 'perimeter_md', 'perimeter_ra', 'perimeter_sd',
       'perimeter_cv', 'perimeter_area_ratio_mn', 'perimeter_area_ratio_am',
       'perimeter_area_ratio_md', 'perimeter_area_ratio_ra',
       'perimeter_area_ratio_sd', 'perimeter_area_ratio_cv', 'shape_index_mn',
       'shape_index_am', 'shape_index_md', 'shape_index_ra', 'shape_index_sd',
       'shape_index_cv', 'fractal_dimension_mn', 'fractal_dimension_am',
       'fractal_dimension_md', 'fractal_dimension_ra', 'fractal_dimension_sd',
       'fractal_dimension_cv', 'euclidean_nearest_neighbor_mn',
       'euclidean_nearest_neighbor_am', 'euclidean_nearest_neighbor_md',
       'euclidean_nearest_neighbor_ra', 'euclidean_nearest_neighbor_sd',
       'euclidean_nearest_neighbor_cv']
    '''
    metrics=['total_area','area_mn','perimeter_mn','perimeter_area_ratio_mn','number_of_patches','landscape_shape_index','shape_index_mn','fractal_dimension_mn',]
    columns=["fn_stem","fn_key","fn_idx","geometry",]+metrics
    
    sky_class_level_metrics=pd.DataFrame(columns=columns)    
    i=0
    for fn in tqdm(polar_seg_fns):
        fn_stem=Path(fn).stem
        fn_key,fn_idx=fn_stem.split("_")    
        coord=coords[fn_key][int(fn_idx)]
        img=cv2.imread(fn)
        img_hsv=cv2.cvtColor(img, cv2.COLOR_BGR2HSV)
        mask=cv2.inRange(img_hsv, hsv_lower_, hsv_upper_)        
        mask=np.where(mask==255,1,mask) #.astype(np.float64)       
        tiff_fn=os.path.join(save_root,'{}.tif'.format(Path(fn).stem))
        dst=rio.open(tiff_fn, 'w', driver='GTiff',
                                  height=mask.shape[0], width=mask.shape[1],
                                  count=1, dtype=str(mask.dtype),#dtype=rio.uint8,
                                  crs='+proj=utm +zone=10 +ellps=GRS80 +datum=NAD83 +units=m +no_defs',
                                  transform=transform)        
        dst.nodata=0
        dst.write(mask,1)
        dst.close()
        
        ls=pls.Landscape(tiff_fn)
        try:      
            class_metrics_df=ls.compute_class_metrics_df(metrics=metrics) 
            class_metrics_dict=class_metrics_df.transpose().to_dict()[1]
        except:
            class_metrics_dict={k:0 for k in metrics}              
        
        class_metrics_dict.update({"fn_stem":fn_stem,"fn_key":fn_key,"fn_idx":int(fn_idx),"geometry":Point(coord)})
        sky_class_level_metrics=sky_class_level_metrics.append(class_metrics_dict,ignore_index=True)
        
        # if i==3:break
        # i+=1

    wgs84='EPSG:4326' #pyproj.CRS('EPSG:4326')
    metrics_skyline_shape_gdf=gpd.GeoDataFrame(sky_class_level_metrics,geometry=sky_class_level_metrics.geometry,crs=wgs84) 
    return metrics_skyline_shape_gdf

def correlation_df(df,idxes,save_path,digits):
        '''
    有DataFrame数据格式计算相关系数

    Parameters
    ----------
    df : dataframe
        待计算的数据.
    idxes : list
        待计算的指数列名.
    save_path : string
        excel文件保存路径.
    digits : int
        保留小位数.

    Returns
    -------
    None.

    '''
    import seaborn as sns
    import matplotlib.pyplot as plt
    import numpy as np
    
    corr=df[idxes].corr()
    corr_round=corr.round(digits)
    corr_round.to_excel(save_path)
    
    # Generate a mask for the upper triangle
    mask=np.triu(np.ones_like(corr, dtype=bool))
    
    # Set up the matplotlib figure
    f, ax=plt.subplots(figsize=(11, 9))    
    
    # Generate a custom diverging colormap
    cmap=sns.diverging_palette(230, 20, as_cmap=True)    
    # Draw the heatmap with the mask and correct aspect ratio
    sns.heatmap(corr_round, mask=mask, cmap=cmap, vmax=.3, center=0, annot=True, square=True, linewidths=.5, cbar_kws={"shrink": .5})    

if __name__=="__main__":
    import sys,os
    sys.path.append('..')  
    
    from database import postSQL2gpd,gpd2postSQL,cfg_load_yaml   
    import pickle
    parent_path=os.path.dirname(os.getcwd())
    cfg=cfg_load_yaml('../config.yml')  

    cfg=cfg_load_yaml('../config.yml')  
    UN=cfg["postgreSQL"]["myusername"]
    PW=cfg["postgreSQL"]["mypassword"]
    DB=cfg["postgreSQL"]["mydatabase"] 
    GC='geometry'       
    
    #A.计算天际线变化指数
    with open(os.path.join(parent_path,cfg['streetview']['save_path_BSV_retrival_info']['coords']),'rb') as f: 
        coords=pickle.load(f) 
        
    polar_seg_root=cfg['equi2polar']['region']['polar_sky_root'] 
    tiff_sky_save_root=cfg['skyline_shape_metrics']['tiff_sky_save_root']
    hsv_lower=cfg['skyline_shape_metrics']['hsv_lower']
    hsv_upper=cfg['skyline_shape_metrics']['hsv_upper']
    metrics_skyline_shape_gdf=metrics_skyline_shape(polar_seg_root,coords,hsv_lower,hsv_upper,tiff_sky_save_root)
    gpd2postSQL(metrics_skyline_shape_gdf,table_name='metrics_skyline_shape',myusername=UN,mypassword=PW,mydatabase=DB)
    
    #B.天际线景观指数间的相关系数
    metrics_skyline_shape_gdf=postSQL2gpd(table_name='metrics_skyline_shape',geom_col=GC,myusername=UN,mypassword=PW,mydatabase=DB)
    correlation_columns=cfg['skyline_shape_metrics']['correlation_columns']
    correlation_save_path=os.path.join(parent_path,cfg['skyline_shape_metrics']['correlation_save_path'])
    digits=cfg['skyline_shape_metrics']['digits']
    correlation_df(metrics_skyline_shape_gdf,correlation_columns,correlation_save_path,digits)
```

###### 2) 示例

其中形状指数、分维数能够较好分离天际线形状差异。

`imgs_arranging.py`
```python

def skyline_metrics_imgs_arranging(idxes_df,imgs_root,save_path,domain,idx='PA'):
    '''
    不同数量级的天际线形状指数的极坐标形式示例

    Parameters
    ----------
    idxes_df : DataFrame
        天际线景观指数.
    imgs_root : string
        极坐标格式全景图根目录.
    save_path : string
        排布图像保存路径.
    domain : dict
        不同指数计算对应提取区间的配置.
    idx : string, optional
        所要计算的指数. The default is 'PA'.

    Returns
    -------
    None.

    '''
    import os
    import numpy as np
    import matplotlib.pyplot as plt
    from mpl_toolkits.axes_grid1 import ImageGrid
    from PIL import Image,ImageOps
    import matplotlib
    
    idx_domain=domain[idx]
    if idx=='PA':
        lower_df=idxes_df[idxes_df.perimeter_area_ratio_mn<idx_domain[1]-20]
        upper_df=idxes_df[idxes_df.perimeter_area_ratio_mn>=idx_domain[1]+140]
        title_n='Perimeter area ratio'
    elif idx=='SI':
        lower_df=idxes_df[idxes_df.shape_index_mn<idx_domain[1]-0.5]
        upper_df=idxes_df[idxes_df.shape_index_mn>=idx_domain[1]+1]
        title_n='Shape index'
    elif idx=='FD':
        lower_df=idxes_df[idxes_df.fractal_dimension_mn<idx_domain[1]-0.01]
        upper_df=idxes_df[idxes_df.fractal_dimension_mn>=idx_domain[1]+0.01]  
        title_n='Fractal dimension'
        
    lower_fns=lower_df.fn_stem.sample(n=10)
    upper_fns=upper_df.fn_stem.sample(n=10)        

    lower_upper_fns=lower_fns.append(upper_fns)
    lower_upper_fns=[os.path.join(imgs_root,i+'.jpg') for i in lower_upper_fns]

    font = {
            # 'family' : 'normal',
            # 'weight' : 'bold',
            'size'   : 26}
    matplotlib.rc('font', **font) 
    
    nrows_ncols=(2,10)
    fig=plt.figure(figsize=(30, 7.))
    grid=ImageGrid(fig, 111,  # similar to subplot(111)
                   nrows_ncols=nrows_ncols,  # creates 2x2 grid of axes
                   axes_pad=0.0,  # pad between axes in inch.
                     )      
    i=0
    rows=['({},{}]'.format(idx_domain[0],idx_domain[1]),'({},{}]'.format(idx_domain[1],idx_domain[2])]
    for ax,im_fn in zip(grid,lower_upper_fns):
        # print(ax)
        ax.axes.xaxis.set_ticklabels([])
        ax.axes.yaxis.set_ticklabels([])
        ax.set_frame_on(False)
        ax.imshow(Image.open(im_fn),cmap='Greys',  interpolation='nearest')  
        if i==1:ax.set_title(title_n)   
        if i%10==0:ax.set_ylabel(rows[i//10], )
        i+=1
        
    # plt.title(title_n)      
    fig.tight_layout()    
    # plt.show()        
    plt.savefig(os.path.join(save_path,'{}.png'.format(title_n)),dpi=300)        

if __name__=="__main__":
    from database import postSQL2gpd,gpd2postSQL,cfg_load_yaml      
    import os    
    cfg=cfg_load_yaml('config.yml')   

    #C.不同数量级的天际线形状指数的极坐标形式示例
    UN=cfg["postgreSQL"]["myusername"]
    PW=cfg["postgreSQL"]["mypassword"]
    DB=cfg["postgreSQL"]["mydatabase"] 
    GC='geometry'  
    metrics_skyline_shape_gdf=postSQL2gpd(table_name='metrics_skyline_shape',geom_col=GC,myusername=UN,mypassword=PW,mydatabase=DB)
    skyline_metrics_domain=cfg['imgs_arranging']['skyline_metrics_domain']
    polar_seg_root=cfg['equi2polar']['region']['polar_sky_root'] 
    skyline_metrics_imgs_save_path=cfg['imgs_arranging']['skyline_metrics_imgs_save_path']
    for idx in skyline_metrics_domain.keys():
        skyline_metrics_imgs_arranging(metrics_skyline_shape_gdf,polar_seg_root,skyline_metrics_imgs_save_path,skyline_metrics_domain,idx=idx)
```

__Fig. 不同数量级的天际线形状指数的极坐标形式示例__ 

<a href=""><img src="./imgs/3_2_1_09.png" height="auto" width="auto" title="caDesign"></a>

<a href=""><img src="./imgs/3_2_1_10.png" height="auto" width="auto" title="caDesign"></a>

<a href=""><img src="./imgs/3_2_1_11.png" height="auto" width="auto" title="caDesign"></a>

##### B.2.3.3 街道空间的色彩

色彩属性表征城市街道空间的类型和视觉感受。计算区域尺度全景图主题色，通过主题色分布邻近像素聚类，计算获取每一全景图对应街道空间位置的主题色分布信息熵及均衡度。在衡量均衡度分布时，将其划分为(0,50], (50,65], (65,75]和(75,100]等4个区间，可以描述为单调，正常，较丰富，丰富，其频数百分比为分别为0.621，24.380，59.870，15.128。一半以上的街道空间为较丰富，分布于分析区域各处；而大于75%的丰富区域通常位于具有生活性的街巷空间。

###### 1) 指数计算

`color_metrics_pool.py`
```python
# -*- coding: utf-8 -*-
"""
Created on Mon May  3 15:23:09 2021
Created on Tue Jan 25 16:41:36 2022

@author: Richie Bao-caDesign设计(cadesign.cn)
"""
def RGB2HEX(color):
    '''
    转换RGB色彩位HEX格式

    Parameters
    ----------
    color : list
        RGB颜色值.

    Returns
    -------
    string
        HEX格式颜色值.

    '''
    return "#{:02x}{:02x}{:02x}".format(int(color[0]), int(color[1]), int(color[2]))
def get_image(image_path):
    '''
    cv2方法读取图像

    Parameters
    ----------
    image_path : string
        图像路径.

    Returns
    -------
    image : array/list
        RGB颜色值.

    '''
    import cv2
    
    image=cv2.imread(image_path)
    image=cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    return image

def find_dominant_colors(imgs_root,coords,resize_scale=0.5,number_of_colors=10,show_chart=False):
    '''
    计算图像的主题色

    Parameters
    ----------
    imgs_root : string
        图像根目录.
    coords : dict
        各个道路对应全景图的采集坐标点.
    resize_scale : numerical val, optional
        调整图像大小的比例. The default is 0.5.
    number_of_colors : int, optional
        主题色提取的数量. The default is 10.
    show_chart : bool, optional
        是否打印主题色的饼状图. The default is False.

    Returns
    -------
    img_dominant_color_gdf : GeoDataFrame
        图像的主题色.

    '''
    import glob,os  
    from tqdm import tqdm
    import cv2
    from sklearn.cluster import KMeans
    from collections import Counter
    import matplotlib.pyplot as plt
    from pathlib import Path
    import pandas as pd
    from shapely.geometry import Point
    import pyproj
    import geopandas as gpd
    
    img_fns=glob.glob(os.path.join(imgs_root,'*.jpg'))[:1] #[-133:]
    img_dominant_color=pd.DataFrame(columns=["fn_stem","fn_key","fn_idx","geometry",]+list(range(number_of_colors)))
    i=0
    for fn in tqdm(img_fns):
        fn_stem=Path(fn).stem
        fn_key,fn_idx=fn_stem.split("_")   
        
        img=get_image(fn)
        img_h,img_w,_=img.shape
        modified_img=cv2.resize(img, (int(img_w*resize_scale),int(img_h*resize_scale),), interpolation = cv2.INTER_AREA)
        modified_img=modified_img.reshape(modified_img.shape[0]*modified_img.shape[1], 3)
        clf=KMeans(n_clusters=number_of_colors)
        labels=clf.fit_predict(modified_img)
        
        counts=Counter(labels)
        center_colors=clf.cluster_centers_
        ordered_colors=[center_colors[i] for i in counts.keys()] # We get ordered colors by iterating through the keys
        hex_colors=[RGB2HEX(ordered_colors[i]) for i in counts.keys()]
        rgb_colors=[ordered_colors[i] for i in counts.keys()]
        
        if (show_chart):
            plt.figure(figsize = (8, 6))
            plt.pie(counts.values(), labels=hex_colors, colors=hex_colors)       
        
        coord=coords[fn_key][int(fn_idx)]
        color_dic={k:hex_colors[k] for k in range(number_of_colors) }    
        color_dic.update({"fn_stem":fn_stem,"fn_key":fn_key,"fn_idx":int(fn_idx),"geometry":Point(coord)})    
        img_dominant_color=img_dominant_color.append(color_dic,ignore_index=True)        
        
        # break
        if i==2:break
        i+=1
        
    wgs84=pyproj.CRS('EPSG:4326')
    img_dominant_color_gdf=gpd.GeoDataFrame(img_dominant_color,geometry=img_dominant_color.geometry,crs=wgs84) 
    
    return img_dominant_color_gdf

def find_dominant_colors_pool(fn,args):
    '''
    计算图像的主题色(多进程调用)

    Parameters
    ----------
    fn : string
        图像路径.
    args : list
        包括coords,resize_scale,number_of_colors.

    Returns
    -------
    color_dic : dict
        图像的主题色.

    '''
    import cv2
    from sklearn.cluster import KMeans
    from collections import Counter
    from pathlib import Path
    from shapely.geometry import Point
    
    coords,resize_scale,number_of_colors=args
    fn_stem=Path(fn).stem
    fn_key,fn_idx=fn_stem.split("_")   
    
    img=get_image(fn)
    img_h,img_w,_=img.shape
    modified_img=cv2.resize(img, (int(img_w*resize_scale),int(img_h*resize_scale),), interpolation = cv2.INTER_AREA)
    modified_img=modified_img.reshape(modified_img.shape[0]*modified_img.shape[1], 3)
    clf=KMeans(n_clusters=number_of_colors)
    labels=clf.fit_predict(modified_img)
    
    counts=Counter(labels)
    center_colors=clf.cluster_centers_
    ordered_colors=[center_colors[i] for i in counts.keys()] # We get ordered colors by iterating through the keys
    hex_colors=[RGB2HEX(ordered_colors[i]) for i in counts.keys()]
    rgb_colors=[ordered_colors[i] for i in counts.keys()]
    
    coord=coords[fn_key][int(fn_idx)]
    color_dic={k:hex_colors[k] for k in range(number_of_colors) }    
    color_dic.update({"fn_stem":fn_stem,"fn_key":fn_key,"fn_idx":int(fn_idx),"geometry":Point(coord)})    
    
    return color_dic

def dominant2cluster_colors(imgs_root,coords,resize_scale=0.5,number_of_colors=10,show_chart=False):
    '''
    主题色聚类

    Parameters
    ----------
    imgs_root : string
        图像所在根目录.
    coords : dict
        各个道路对应全景图的采集坐标点.
    resize_scale : numerical val, optional
        调整图像大小的比例. The default is 0.5.
    number_of_colors : int, optional
        主题色提取的数量. The default is 10.
    show_chart : bool, optional
        是否打印主题色的饼状图. The default is False.

    Returns
    -------
    None.

    '''
    import glob,os  
    from tqdm import tqdm
    import cv2
    from sklearn.cluster import KMeans 
    import matplotlib.pyplot as plt
    import numpy as np
    from pathlib import Path
    import pandas as pd
    from collections import Counter
    
    img_fns=glob.glob(os.path.join(imgs_root,'*.jpg'))
    img_dominant_color=pd.DataFrame(columns=["fn_stem","fn_key","fn_idx","geometry",]+list(range(number_of_colors)))
    i=0
    for fn in tqdm(img_fns):
        fn_stem=Path(fn).stem
        fn_key,fn_idx=fn_stem.split("_")   
        print('\n',fn_stem)
        
        img=get_image(fn)
        img_h,img_w,_=img.shape
        modified_img_w,modified_img_h=int(img_w*resize_scale),int(img_h*resize_scale),
        modified_img=cv2.resize(img, (modified_img_w,modified_img_h), interpolation = cv2.INTER_AREA)
        modified_img=modified_img.reshape(modified_img.shape[0]*modified_img.shape[1], 3)
        clf=KMeans(n_clusters=number_of_colors)
        labels=clf.fit_predict(modified_img)
        center_colors=clf.cluster_centers_
        labels_RGB=np.array([center_colors[i] for i in labels])
        labels_RGB_restore=labels_RGB.reshape((modified_img_h,modified_img_w,3))     
        plt.imshow(labels_RGB_restore/255)
        plt.show()
        
        labels_restored=labels.reshape((modified_img_h,modified_img_w,))
        plt.imshow(labels_restored,cmap="gist_ncar")      
        plt.show()
        
        counts=Counter(labels)
        ordered_colors=[center_colors[i] for i in counts.keys()] # We get ordered colors by iterating through the keys
        hex_colors=[RGB2HEX(ordered_colors[i]) for i in counts.keys()]
        if (show_chart):
            plt.figure(figsize = (8, 6))
            plt.pie(counts.values(), labels=hex_colors, colors=hex_colors)   
            plt.show()

        
        from skimage import measure
        img_labeled = measure.label(labels_restored, connectivity=1)
        plt.imshow(img_labeled,cmap="gist_ncar")
        plt.show()

        if i==0:break
        i+=1 

def dominant2cluster_colors_pool(fn,args):
    '''
    主题色聚类(多进程调用)

    Parameters
    ----------
    fn : string
        图像路径.
    args : list
        包括coords,resize_scale,number_of_colors.

    Returns
    -------
    color_dic : dict
        主题色聚类信息.

    '''
    import cv2
    from sklearn.cluster import KMeans
    from collections import Counter
    import matplotlib.pyplot as plt
    from pathlib import Path
    from shapely.geometry import Point
    from skimage import measure
    
    coords,resize_scale,number_of_colors=args
    fn_stem=Path(fn).stem
    fn_key,fn_idx=fn_stem.split("_")
    
    img=get_image(fn)
    img=img[:int(img.shape[0]*(70/100))]

    img_h,img_w,_=img.shape
    modified_img_w,modified_img_h=int(img_w*resize_scale),int(img_h*resize_scale),
    modified_img=cv2.resize(img, (modified_img_w,modified_img_h), interpolation = cv2.INTER_AREA)
    modified_img=modified_img.reshape(modified_img.shape[0]*modified_img.shape[1], 3)
    clf=KMeans(n_clusters=number_of_colors)
    labels=clf.fit_predict(modified_img)
    center_colors=clf.cluster_centers_
    
    labels_restored=labels.reshape((modified_img_h,modified_img_w,))    
    img_labeled=measure.label(labels_restored, connectivity=1)

    counts=Counter(img_labeled.flatten())
    coord=coords[fn_key][int(fn_idx)]
    color_dic={"fn_stem":fn_stem,"fn_key":fn_key,"fn_idx":int(fn_idx),"geometry":Point(coord),'counter':dict(counts)} 

    return color_dic

if __name__=="__main__":
    import sys,os
    sys.path.append('..')      
    from database import postSQL2gpd,gpd2postSQL,cfg_load_yaml 
    parent_path=os.path.dirname(os.getcwd())
    cfg=cfg_load_yaml('../config.yml')   
    
    import pickle
    with open(os.path.join(parent_path,cfg['streetview']['save_path_BSV_retrival_info']['coords']),'rb') as f: 
        coords=pickle.load(f)    

    #A. 计算图像主题色（非多进程）
    img_path=cfg['streetview']['panoramic_imgs_valid_root']
    number_of_colors=cfg['color_metrics']['number_of_colors']
    img_dominant_color_gdf=find_dominant_colors(img_path,coords,number_of_colors,show_chart=True)    
    
    #B. 主题色聚类（非多进程）
    dominant2cluster_colors(img_path,coords,resize_scale=0.1,number_of_colors=number_of_colors,show_chart=True)  
```

`color_metrics.py`
```python
# -*- coding: utf-8 -*-
"""
Created on Mon May  3 15:23:09 2021
Updated on Tue Jan 25 16:39:09 2022

@author: richie bao -Spatial structure index value distribution of urban streetscape
"""

def find_dominant_colors_pool_main(img_path,args_):
    '''
    计算图像的主题色(多进程)

    Parameters
    ----------
    img_path : string
        图像根目录.
    args_ : list
        包括[coords,resize_scale,number_of_colors].

    Returns
    -------
    img_dominant_color_gdf : ＧｅｏＤａｔａＦｒａｍｅ
        图像的主题色.

    '''
    from color_metrics_pool import find_dominant_colors_pool
    import glob
    from functools import partial
    from multiprocessing import Pool
    from tqdm import tqdm
    import pandas as pd
    import pyproj
    import geopandas as gpd
    
    coords,resize_scale,number_of_colors=args_
    img_fns=glob.glob(os.path.join(img_path,'*.jpg')) #[:3]
    args=partial(find_dominant_colors_pool, args=args_)
    with Pool(8) as p:
        color_dic_list=p.map(args, tqdm(img_fns))  

    img_dominant_color=pd.DataFrame(columns=["fn_stem","fn_key","fn_idx","geometry",]+list(range(number_of_colors)))
    for color_dic in color_dic_list:    
        img_dominant_color=img_dominant_color.append(color_dic,ignore_index=True)
    
    wgs84=pyproj.CRS('EPSG:4326')
    img_dominant_color_gdf=gpd.GeoDataFrame(img_dominant_color,geometry=img_dominant_color.geometry,crs=wgs84)
    return img_dominant_color_gdf

def dominant2cluster_colors_pool_main(img_path,colors_dominant2cluster_path,args_):
    '''
    主题色聚类(多进程)

    Parameters
    ----------
    img_path : string
        图像根目录.
    colors_dominant2cluster_path : string
        文件保持路径.
    args_ : list
        包括[coords,resize_scale,number_of_colors].

    Returns
    -------
    color_dic_list : dict
        主题色聚类信息.

    '''
    from multiprocessing import Pool
    from color_metrics_pool import dominant2cluster_colors_pool
    import pickle    
    from functools import partial
    import glob
    from tqdm import tqdm
    
    img_fns=glob.glob(os.path.join(img_path,'*.jpg')) #[:3]
    args=partial(dominant2cluster_colors_pool, args=args_)    
    with Pool(8) as p:
        color_dic_list=p.map(args, tqdm(img_fns))        
    with open(colors_dominant2cluster_path,'wb') as f: 
        pickle.dump(color_dic_list,f) 
        
    return color_dic_list
        
def colors_entropy(colors_dominant_clustering_fn):
    '''
    计算图像主题色聚类信息熵

    Parameters
    ----------
    colors_dominant_clustering_fn : string
        主题色聚类信息.

    Returns
    -------
    GeoDataFrame
        图像主题色聚类信息熵.

    '''
    from tqdm import tqdm
    import math,copy
    import pyproj
    import pandas as pd
    import geopandas as gpd
    
    with open(colors_dominant_clustering_fn,'rb') as f:
        colors_dominant_clustering=pickle.load(f) #[:10]
    print(sum(colors_dominant_clustering[0]['counter'].values()))
    def entropy(counter_dict):
        percentage=[i/sum(counter_dict.values()) for i in counter_dict.values()]
        ve=0.0
        for perc in percentage:
            if perc!=0.:
                ve-=perc*math.log(perc)            
        max_entropy=math.log(len(counter_dict.keys()))
        frank_e=ve/max_entropy*100    
        return frank_e
            
    color_dominant_entropy=[entropy(dic['counter']) for dic in tqdm(colors_dominant_clustering)]
    wgs84=pyproj.CRS('EPSG:4326')
    colors_dominant_clustering_copy=copy.deepcopy(colors_dominant_clustering)
    [colors_dominant_clustering_copy[i].update({'counter':color_dominant_entropy[i]}) for i in range(len(colors_dominant_clustering_copy))]
    
    colors_dominant_entropy=pd.DataFrame(columns=["fn_stem","fn_key","fn_idx","geometry",'counter'])
    for colors_dominant_dic in colors_dominant_clustering_copy:    
        colors_dominant_entropy=colors_dominant_entropy.append(colors_dominant_dic,ignore_index=True)        
    
    colors_dominant_entropy_gdf=gpd.GeoDataFrame(colors_dominant_entropy,geometry=colors_dominant_entropy.geometry,crs=wgs84)        
    return colors_dominant_entropy_gdf

if __name__=="__main__":
    import sys,os
    sys.path.append('..')      
    from database import postSQL2gpd,gpd2postSQL,cfg_load_yaml 
    parent_path=os.path.dirname(os.getcwd())
    cfg=cfg_load_yaml('../config.yml')  
    
    UN=cfg["postgreSQL"]["myusername"]
    PW=cfg["postgreSQL"]["mypassword"]
    DB=cfg["postgreSQL"]["mydatabase"]     
    
    #A.计算图像主题色（多进程）    
    import pickle
    with open(os.path.join(parent_path,cfg['streetview']['save_path_BSV_retrival_info']['coords']),'rb') as f: 
        coords=pickle.load(f)         
    resize_scale=cfg['color_metrics']['resize_scale']
    number_of_colors=cfg['color_metrics']['number_of_colors']
    img_path=cfg['streetview']['panoramic_imgs_valid_root']
    img_dominant_color_gdf=find_dominant_colors_pool_main(img_path,[coords,resize_scale,number_of_colors]) 
    
    table_name_img_dominant_color=cfg['color_metrics']['table_name_img_dominant_color']
    gpd2postSQL(img_dominant_color_gdf,table_name='img_dominant_color',myusername=UN,mypassword=PW,mydatabase=DB)
    
    #B. 主题色聚类（多进程）
    colors_dominant2cluster_path=cfg['color_metrics']['colors_dominant2cluster_path']
    resize_scale_cluster=cfg['color_metrics']['resize_scale_cluster']
    _=dominant2cluster_colors_pool_main(img_path,colors_dominant2cluster_path,[coords,resize_scale_cluster,number_of_colors])
    
    #C. 色彩丰富度指数计算    
    colors_dominant_entropy_gdf=colors_entropy(colors_dominant2cluster_path)
    colors_dominant_entropy_table_name=cfg['color_metrics']['colors_dominant_entropy_table_name']
    gpd2postSQL(colors_dominant_entropy_gdf,table_name=colors_dominant_entropy_table_name,myusername=UN,mypassword=PW,mydatabase=DB)
```

###### 2) 示例

`imgs_arranging.py`
```python
def dominant2cluster_colors_imshow(fn,coords,save_path,colors_dominant_entropy,resize_scale=0.1,number_of_colors=16):
    '''
    色彩丰富度指数示例排布

    Parameters
    ----------
    fn : string
        示例图像路径.
    coords : dict
        各个道路对应全景图的采集坐标点.
    save_path : string
        待保持图像的根目录.
    colors_dominant_entropy: df
        色彩丰富度（均衡都）指数
    resize_scale : numerical val, optional
        调整图像大小的比例. The default is 0.1.
    number_of_colors : int, optional
        主题色提取的数量. The default is 16.

    Returns
    -------
    None.

    '''
    import cv2
    from sklearn.cluster import KMeans
    from collections import Counter
    import matplotlib.pyplot as plt
    import numpy as np
    from pathlib import Path
    from skimage import measure
    import matplotlib
    
    font = {
            # 'family' : 'normal',
            # 'weight' : 'bold',
            'size'   : 22}
    matplotlib.rc('font', **font)      
        
    fig, axs=plt.subplots(1, 4, figsize=(30, 8))
    
    fn_stem=Path(fn).stem
    fn_key,fn_idx=fn_stem.split("_")
    
    img=get_image(fn)
    img=img[:int(img.shape[0]*(70/100))]
    axs[0].imshow(img)
    axs[0].set_title('Panorama') 
    axs[0].set_ylabel('color richness index:{}'.format(round(colors_dominant_entropy.loc[colors_dominant_entropy['fn_stem']==os.path.basename(fn).split('.')[0]].counter.values.item(),3))) #64.178

    img_h,img_w,_=img.shape
    modified_img_w,modified_img_h=int(img_w*resize_scale),int(img_h*resize_scale),
    modified_img=cv2.resize(img, (modified_img_w,modified_img_h), interpolation = cv2.INTER_AREA)
    modified_img=modified_img.reshape(modified_img.shape[0]*modified_img.shape[1], 3)
    clf=KMeans(n_clusters=number_of_colors)
    labels=clf.fit_predict(modified_img)
    center_colors=clf.cluster_centers_
    
    labels_RGB=np.array([center_colors[i] for i in labels])
    labels_RGB_restore=labels_RGB.reshape((modified_img_h,modified_img_w,3))
    axs[1].imshow(labels_RGB_restore/255)
    axs[1].set_title('Theme color distribution') 
    
    labels_restored=labels.reshape((modified_img_h,modified_img_w,))    
    img_labeled=measure.label(labels_restored, connectivity=1)
    axs[3].imshow(img_labeled,cmap="gist_ncar")
    axs[3].set_title('Theme color proximity clustering')
    
    counts=Counter(labels)    
    ordered_colors=[center_colors[i] for i in counts.keys()] # We get ordered colors by iterating through the keys
    hex_colors=[RGB2HEX(ordered_colors[i]) for i in counts.keys()]
    rgb_colors=[ordered_colors[i] for i in counts.keys()]

    axs[2].pie(counts.values(), labels=hex_colors, colors=hex_colors,rotatelabels =True,radius=0.5)   #labels=hex_colors,
    axs[2].set_title('Theme color') 
    
    fig.tight_layout() 
    # plt.show()
    plt.savefig(os.path.join(save_path,os.path.basename(fn)),dpi=300)      

if __name__=="__main__":
    from database import postSQL2gpd,gpd2postSQL,cfg_load_yaml      
    import os    
    cfg=cfg_load_yaml('config.yml')       
    UN=cfg["postgreSQL"]["myusername"]
    PW=cfg["postgreSQL"]["mypassword"]
    DB=cfg["postgreSQL"]["mydatabase"]    
    GC='geometry'  

    #D.色彩丰富度指数示例
    from analysis_n_results.color_metrics_pool import get_image,RGB2HEX
    import pickle    
    with open(cfg['streetview']['save_path_BSV_retrival_info']['coords'],'rb') as f: 
        coords=pickle.load(f)    
    theme_color_cluster_save_path=cfg['imgs_arranging']['theme_color_cluster_save_path']
    resize_scale_cluster=cfg['color_metrics']['resize_scale_cluster']
    number_of_colors=cfg['color_metrics']['number_of_colors']
    img_path=cfg['streetview']['panoramic_imgs_valid_root']
    theme_color_cluster_example_fn=cfg['imgs_arranging']['theme_color_cluster_example_fn']
    colors_dominant_entropy_table_name=cfg['color_metrics']['colors_dominant_entropy_table_name']
    colors_dominant_entropy_gdf=postSQL2gpd(table_name=colors_dominant_entropy_table_name,geom_col=GC,myusername=UN,mypassword=PW,mydatabase=DB)
    for img_fn in theme_color_cluster_example_fn:        
        dominant2cluster_colors_imshow(os.path.join(img_path,img_fn),coords,theme_color_cluster_save_path,colors_dominant_entropy_gdf,resize_scale_cluster,number_of_colors)     
```

给出均衡度分别为61.235和90.204两个地点的分析过程结果，说明色彩丰富度指数对城市街道空间特征的指示。

__Fig. 色彩丰富度指数示例__  

<a href=""><img src="./imgs/3_2_1_12.jpg" height="auto" width="auto" title="caDesign"></a>

<a href=""><img src="./imgs/3_2_1_13.jpg" height="auto" width="auto" title="caDesign"></a>

##### B.2.3.4 街道空间的色彩

尺度不变特征变换（SIFT）在不同的尺度上寻找关键点。关键点邻域大小反映了对象具有的尺度特征。图中两幅全景影像提取了图像的关键点，对关键点的邻域大小划分为 (0,10], (10,20], (20,30] 和 (30,40] 等4个区间，可以描述为小尺度，中尺度，较大尺度和大尺度。当图像内的对象较小时，例如窗户的角点、招牌的边缘等，通常是实际当中较为细碎的对象；当对象如天空，成片的墙面时，所提取的边缘特征的邻域尺度则较大。因此尺度不变特征变换关键点邻域尺度大小一定程度上反应了街道视域空间繁复的程度。分别计算所有全景图像给定4个区间的频数，如果图像关键点某一区间的邻域尺度频数接近时，则这些图像在该区间具有相似尺度的对象。

###### 1) 指数计算

`Key_point_size_metrics.py`
```python
# -*- coding: utf-8 -*-
"""
Created on Sat May 15 09:50:24 2021
Updated on Wed Jan 26 15:42:37 2022

@author: Richie Bao-caDesign设计(cadesign.cn)
"""
class feature_builder_BOW:
    '''
    class - 根据所有图像关键点描述子聚类建立图像视觉词袋，获取每一图像的特征（码本）映射的频数统计
    '''   
    def __init__(self,num_cluster=32):
        self.num_clusters=num_cluster

    def extract_features(self,img):
        import cv2 as cv
        '''
        function - 提取图像特征
        
        Paras:
        img - 读取的图像
        '''
        star=cv.xfeatures2d.StarDetector_create() 
        key_point=star.detect(img)
        cv.drawKeypoints(img,key_point,img,flags=cv.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)        
        # Initiate BRIEF extractor
        brief=cv.xfeatures2d.BriefDescriptorExtractor_create()    
        # compute the descriptors with BRIEF
        kp, des=brief.compute(img, key_point)   

        return des,kp
    
    def visual_BOW(self,des_all):
        from sklearn.cluster import KMeans
        '''
        function - 聚类所有图像的特征（描述子/SIFT），建立视觉词袋
        
        des_all - 所有图像的关键点描述子
        '''
        print("start KMean...")
        kmeans=KMeans(self.num_clusters)
        kmeans=kmeans.fit(des_all)
        print("end KMean...")
        return kmeans         
    
    def get_visual_BOW(self,training_data):
        import cv2 as cv
        from tqdm import tqdm
        '''
        function - 提取图像特征，返回所有图像关键点聚类视觉词袋
        
        Paras:
        training_data - 训练数据集
        '''
        des_all=[]
        # i=0        
        for item in tqdm(training_data):
            img=cv.imread(item)
            img=img[:int(img.shape[0]*(70/100))]  
            
            des,_=self.extract_features(img)
            des_all.extend(des)           

            # if i==10:break
            # i+=1        
        kmeans=self.visual_BOW(des_all)      
        return kmeans
    
    def normalize(self,input_data):
        import numpy as np
        '''
        fuction - 归一化数据
        
        input_data - 待归一化的数组
        '''
        sum_input=np.sum(input_data)
        if sum_input>0:
            return input_data/sum_input #单一数值/总体数值之和，最终数值范围[0,1]
        else:
            return input_data               
    
    def construct_feature(self,img,kmeans):
        import numpy as np
        '''
        function - 使用聚类的视觉词袋构建图像特征（构造码本）
        
        Paras:
        img - 读取的单张图像
        kmeans - 已训练的聚类模型
        '''
        des,kp=self.extract_features(img)
        labels=kmeans.predict(des.astype(np.float)) #对特征执行聚类预测类标
        feature_vector=np.zeros(self.num_clusters)
        for i,item in enumerate(labels): #计算特征聚类出现的频数/直方图
            feature_vector[labels[i]]+=1
        feature_vector_=np.reshape(feature_vector,((1,feature_vector.shape[0])))
        return feature_vector_,labels,kp
    
    def get_feature_map(self,training_data,kmeans):
        import cv2 as cv
        from pathlib import Path
        from tqdm import tqdm
        '''
        function - 返回每个图像的特征映射（码本映射）
        Paras:
        training_data - 训练数据集
        kmeans - 已训练的聚类模型
        '''
        feature_map=[]
        for item in tqdm(training_data):            
            fn_stem=Path(item).stem
            fn_key,fn_idx=fn_stem.split("_")
            
            temp_dict={}
            temp_dict['fn_stem']=fn_stem
            img=cv.imread(item)
            img=img[:int(img.shape[0]*(70/100))]  
            
            feature_vector,labels,kp=self.construct_feature(img,kmeans)
            temp_dict['feature_vector']=feature_vector
            temp_dict['labels']=labels
            temp_dict['kp']=[{'pt':kp[i].pt, 
                             'size':kp[i].size, 
                             'angle':kp[i].angle,
                             'response':kp[i].response, 
                             'octave':kp[i].octave, 
                             'class_id':kp[i].class_id} for i in range(len(kp))]
            if temp_dict['feature_vector'] is not None:
                feature_map.append(temp_dict)
        return feature_map

def kps_desciptors_BOW_feature(feature_map,coords,num_cluster=32):
    '''
    码本映射转换为GeoDataFrame

    Parameters
    ----------
    feature_map : list
        图像的特征映射（码本映射）.
    coords : dict
        各个道路对应全景图的采集坐标点.
    num_cluster : int, optional
        聚类的数量. The default is 32.

    Returns
    -------
    featureMap_gdf : GeoDataFrame
        码本映射(GDF格式).

    '''
    from tqdm import tqdm
    import pandas as pd
    from shapely.geometry import Point
    import geopandas as gpd
    import pyproj
    
    panorama_object_df=pd.DataFrame(columns=["fn_stem","fn_key","fn_idx","geometry",]+list(range(num_cluster)))
    for feature_info in tqdm(feature_map):
        fn_stem=feature_info['fn_stem']
        fn_key,fn_idx=fn_stem.split("_")
        featureMap_dict=dict(zip(list(range(num_cluster)),feature_info['feature_vector'].tolist()[0]))
        coord=coords[fn_key][int(fn_idx)]
        featureMap_dict.update({"fn_stem":fn_stem,"fn_key":fn_key,"fn_idx":int(fn_idx),"geometry":Point(coord)})   
        panorama_object_df=panorama_object_df.append(featureMap_dict,ignore_index=True)
        # break
    wgs84=pyproj.CRS('EPSG:4326')
    featureMap_gdf=gpd.GeoDataFrame(panorama_object_df,geometry=panorama_object_df.geometry,crs=wgs84)     
    
    return featureMap_gdf

def kp_stats(feature_map,coords,bins): 
    '''
    给定分割区间，统计关键点邻域尺度

    Parameters
    ----------
    feature_map : list
        图像的特征映射（码本映射）.
    coords : dict
        各个道路对应全景图的采集坐标点.
    bins : list
        分割区间.

    Returns
    -------
    kp_size_stats_gdf : GeoDataFrame
        统计关键点邻域统计.

    '''
    from tqdm import tqdm
    import pandas as pd 
    from shapely.geometry import Point
    import geopandas as gpd
    import pyproj    
    
    kp_dict={i['fn_stem']:i['kp'] for i in feature_map}
    i=0
    size_stats_dict_list=[]
    bins=bins
    for fn_stem,v in tqdm(kp_dict.items()):
        kp_df=pd.DataFrame(v)
        size_stats_dict=kp_df['size'].describe().to_dict()
        size_stats_dict['num']=len(v)        
        
        size_stats_dict['fn_stem']=fn_stem
        fn_key,fn_idx=fn_stem.split("_")
        size_stats_dict['fn_key']=fn_key
        size_stats_dict['fn_idx']=fn_idx
        
        coord=coords[fn_key][int(fn_idx)]
        size_stats_dict['geometry']=Point(coord)
        # print(size_stats_dict)        
        
        # print(kp_df['size'])
        fre_size=kp_df[['size']].apply(pd.Series.value_counts,bins=bins,).to_dict()['size']
        fre_size={'{}_{}'.format(k.left,k.right):v for k,v in fre_size.items()}
        # print(fre_size)
        size_stats_dict.update(fre_size)
        
        size_stats_dict_list.append(size_stats_dict)
        # if i==10:break
        # i+=1
    kp_size_stats_df=pd.DataFrame.from_dict(size_stats_dict_list)
    wgs84=pyproj.CRS('EPSG:4326')
    kp_size_stats_gdf=gpd.GeoDataFrame(kp_size_stats_df,geometry=kp_size_stats_df.geometry,crs=wgs84) 
    return kp_size_stats_gdf 

if __name__=="__main__":
    import pickle
    import glob
    import sys,os
    sys.path.append('..')      
    from database import postSQL2gpd,gpd2postSQL,cfg_load_yaml 
    parent_path=os.path.dirname(os.getcwd())
    cfg=cfg_load_yaml('../config.yml')  
    
    UN=cfg["postgreSQL"]["myusername"]
    PW=cfg["postgreSQL"]["mypassword"]
    DB=cfg["postgreSQL"]["mydatabase"]
    
    img_path=cfg['streetview']['panoramic_imgs_valid_root']    
    img_fp_list=glob.glob(os.path.join(img_path,'*.jpg'))
    
    #A.提取图像特征，返回所有图像关键点聚类视觉词袋    
    num_cluster=cfg['KP_metrics']['num_cluster']
    kmeans=feature_builder_BOW(num_cluster).get_visual_BOW(img_fp_list)  
    visual_BOW_region_fn=os.path.join(parent_path,cfg['KP_metrics']['visual_BOW_region_fn'])

    with open(visual_BOW_region_fn,'wb') as f: 
        pickle.dump(kmeans,f) #存储kmeans聚类模型    
    
    #B.图像的特征映射（码本映射）
    with open(visual_BOW_region_fn,'rb') as f:
        kmeans=pickle.load(f)    
    feature_map=feature_builder_BOW(num_cluster).get_feature_map(img_fp_list,kmeans) 
    feature_map_region_fn=cfg['KP_metrics']['feature_map_region_fn']    
    with open(feature_map_region_fn,'wb') as f: 
        pickle.dump(feature_map,f)  
    
    #C.码本映射转换为GeoDataFrame，写入数据库
    with open(feature_map_region_fn,'rb') as f:
        feature_map_region=pickle.load(f)     
    with open(os.path.join(parent_path,cfg['streetview']['save_path_BSV_retrival_info']['coords']),'rb') as f: 
        coords=pickle.load(f)       
    featureMap_gdf=kps_desciptors_BOW_feature(feature_map_region,coords,num_cluster) 
    featureMap_table_name=cfg['KP_metrics']['featureMap_table_name']
    gpd2postSQL(featureMap_gdf,table_name=featureMap_table_name,myusername=UN,mypassword=PW,mydatabase=DB)
    
    #D.给定分割区间，统计关键点邻域尺度 
    bins=cfg['KP_metrics']['bins']
    kp_size_stats_gdf=kp_stats(feature_map_region,coords,bins)
    kp_size_stats_table_name=cfg['KP_metrics']['kp_size_stats_table_name']
    gpd2postSQL(kp_size_stats_gdf,table_name=kp_size_stats_table_name,myusername=UN,mypassword=PW,mydatabase=DB)
```

###### 2) 示例

`imgs_arranging.py`
```python

def kp_show(feature_map,imgs_path_list,imgs_root,save_path):
    '''
    特征点邻域大小比较示例排布

    Parameters
    ----------
    feature_map : list
        图像的特征映射（码本映射）.
    imgs_path_list : list
        示例文件名列表.
    imgs_root : string
        图像根目录.
    save_path : string
        图像保存文件名.

    Returns
    -------
    None.

    '''
    import matplotlib.pyplot as plt
    from matplotlib.patches import Arrow, Circle,Patch
    from tqdm import tqdm  
    import pandas as pd
    import matplotlib
    from analysis_n_results.color_metrics_pool import get_image
    font = {
        # 'family' : 'normal',
        # 'weight' : 'bold',
        'size'   : 28}
    matplotlib.rc('font', **font)
    
    fig, axs=plt.subplots(1, 2, constrained_layout=True,figsize=(50,10))
    axs=axs.flat
    bins=[0,10,20,30,40]
    for idx,fn_stem in enumerate(imgs_path_list):        
        img=get_image(os.path.join(imgs_root,fn_stem+'.jpg'))
        # print(img.shape)
        img=img[:int(img.shape[0]*(70/100))]    
        # plt.imshow(img)   
        kp_dict={i['fn_stem']:i['kp'] for i in feature_map}
        kp=kp_dict[fn_stem]
        # print(kp)
        kp_df=pd.DataFrame.from_dict(kp)
        # print(kp_df)
        fre_size=kp_df[['size']].apply(pd.Series.value_counts,bins=bins,).to_dict()['size']
        fre_size={'{}-{}'.format(k.left,k.right):v for k,v in fre_size.items()}
        # print(fre_size)
        patches_1=[Circle((kp[i]['pt'][0], kp[i]['pt'][1]), radius=3, color='red',fill=True,alpha=0.8) if kp[i]['size'] in range(0,10) 
                 else Circle((kp[i]['pt'][0], kp[i]['pt'][1]), radius=3, color='b',fill=True,alpha=0.8) for i in range(len(kp))]
        patches_2=[Circle((kp[i]['pt'][0], kp[i]['pt'][1]),radius=kp[i]['size'], color='red',fill=True,alpha=0.8) if kp[i]['size'] in range(0,10) 
                 else Circle((kp[i]['pt'][0], kp[i]['pt'][1]), radius=kp[i]['size'], color='b',fill=False,alpha=0.8) for i in range(len(kp))]        
        
        axs[idx].imshow(img)
        for p in patches_2:
            axs[idx].add_patch(p) 
        axs[idx].set_title('key-points size:{}'.format(fre_size))
    C_1=Patch(color='red',fill=True,alpha=0.8,label='kp size in (0,10]')
    C_2=Patch(color='b',fill=False,alpha=0.8,label='kp size not in (0,10]')        
    plt.legend(handles=[C_1,C_2])    
    # plt.show()  
    plt.savefig(save_path,dpi=300)       

if __name__=="__main__":
    from database import postSQL2gpd,gpd2postSQL,cfg_load_yaml      
    import os    
    import pickle
    cfg=cfg_load_yaml('config.yml') 

    #E.特征点邻域大小比较示例
    img_path=cfg['streetview']['panoramic_imgs_valid_root']
    feature_map_region_fn=cfg['KP_metrics']['feature_map_region_fn']
    with open(feature_map_region_fn,'rb') as f:
        feature_map_region=pickle.load(f)     
    kp_stats_example_fn=cfg['imgs_arranging']['kp_stats_example_fn']
    kp_stats_example_save_path=cfg['imgs_arranging']['kp_stats_example_save_path']
    kp_show(feature_map_region,kp_stats_example_fn,img_path,kp_stats_example_save_path)   
```

__Fig. 特征点邻域大小比较示例__  

<a href=""><img src="./imgs/3_2_1_14.png" height="auto" width="auto" title="caDesign"></a>

##### B.2.3.5 邻里尺度街道空间特征聚类分布与指数特征贡献度

`AgglomerativeClustering`层次聚类算法中`connectivity`参数可以为每个样本指定连接矩阵（Connectivity matrix）。该连接矩阵可以通过`kneighbors_graph`方法，给定每个样本的邻元数计算。越少的邻元数，在聚类中所考虑的邻里关系相对越少，即邻里尺度趋于小范围；反之则越多，邻里尺度趋于大范围。不同邻里尺度下对给定多个街道空间景观指数聚类，计算指数特征的贡献度不仅可以发现主导街区特征的景观指数和对街区特征形成影响较小的景观指数，还可以发现指数作用不同邻里尺度的变化。

`AgglomerativeClustering`方法需要指定聚类的数量，给定`KElbowVisualizer`方法计算的拐点作为最有簇数。

###### 1) 不同邻里尺度最优簇数选择

通过给定多个簇数（聚类数）分别聚类，计算每个点到其所属聚类中心的平方距离之和(distortion score)，曲线拐点即为最优的簇数选择。从下述计算结果来看，各个不同邻里尺度的最优簇数多为4，次之为5，只有当邻元数为15的邻里尺度簇数为3。

__Fig. 不同邻里尺度最优簇数__ 

<a href=""><img src="./imgs/3_2_1_15.png" height="auto" width="auto" title="caDesign"></a>

###### 2) 不同邻里尺度景观指数贡献度

给定不同邻里尺度的连接矩阵，和对应的最优簇数，通过特征选择（SelectKBest）方法，计算给定连续邻元数下景观指数贡献度及其变化。计算结果显示，不同邻里尺度下Seg_GVF基本占绝对优势，其次为KPSF(10-20]、KPSF(0-10]和Seg_SVF。其中当邻元数小于30时，Seg_GVF和Seg_SVF占主导；大于30时，主要以Seg_GVF和KPSF(10-20]、KPSF(0-10]占主导。再者为CRI、KPSF(20-30]、Seg_ED、Sky_PARA；对聚类特征贡献度最小的是Seg_GVI、Sky_SHAPE、Sky_FRAC。

__Fig.不同邻里尺度指数贡献度 __ 

<a href=""><img src="./imgs/3_2_1_16.png" height="auto" width=800 title="caDesign"></a>

###### 3) 不同邻里尺度特征聚类

从聚类结果可以得知，当以Seg_GVF和Seg_SVF为聚类特征主导，在邻元数小于等于15时，聚类结果具有明显的分区特征。例如当邻元数为5时，可以明显区分为西北区域、二环到绕城区间、老城（中心城区）和雁塔区、汉长安城未央宫区域，及灞桥区纺织城区域。当邻里尺度增加，关键点邻域尺度(i,j]区间频数对特征聚类的影响开始增加，并超过Seg_SVF，聚类明显的分区特征开始分解为特征区段。

__Fig. 聚类示例__ 

<a href=""><img src="./imgs/3_2_1_17.png" height="auto" width=800 title="caDesign"></a>

###### 4) Seg_GVF单个指数的聚类和统计

以邻元数为10，计算最优簇数为5，单独聚类Seg_GVF。统计各个聚类簇，从箱型图观察聚类结果的分离性除簇1和簇4之外，分离性较好。虽簇1和簇4具有类似的聚类特征，但是从打印地图来看，两个簇类分别位于不同的区域，表明这两个不同区域具有类似的Seg_GVF指数特征。

|                             | Green view index |        |        |        |       |        |
|-----------------------------|------------------|--------|--------|--------|-------|--------|
|                             | min              | max    | mean   | median | count | std    |
| clustering_Green view index |                  |        |        |        |       |        |
| 0                           | 0                | 68.294 | 18.677 | 17.648 | 6231  | 11.782 |
| 1                           | 0.025            | 71.993 | 34.905 | 35.91  | 1809  | 10.608 |
| 2                           | 0                | 65.886 | 10.586 | 9.109  | 4770  | 8.171  |
| 3                           | 8.056            | 63.039 | 41.782 | 43.331 | 202   | 8.609  |
| 4                           | 10.453           | 56.494 | 34.312 | 33.461 | 347   | 9.471  |

__Fig. 聚类指数统计__ 

<a href=""><img src="./imgs/3_2_1_18.png" height="auto" width=500 title="caDesign"></a>

__Fig. SEG_GVI聚类__ 

<a href=""><img src="./imgs/3_2_1_19.png" height="auto" width="auto" title="caDesign"></a>

`metrics_clustering.py`
```python
# -*- coding: utf-8 -*-
"""
Created on Sun May 16 18:08:28 2021
Updated on Wed Jan 26 19:06:56 2022

@author: Richie Bao-caDesign设计(cadesign.cn)
"""
def distortion_score_elbow(idxes_df,fields,save_path,kneighbors_graph_n_neighbors=9,k=(2,12)):
    '''
    KElbowVisualizer方法计算最优簇数，详细查看:https://www.scikit-yb.org/en/latest/api/cluster/elbow.html

    Parameters
    ----------
    idxes_df : DataFrame
        指数数据.
    fields : list
        计算的指数列名.
    save_path : string
        图表保存根目录.
    kneighbors_graph_n_neighbors : list, optional
        kneighbors_graph方法参数输入项，邻元数. The default is 9.
    k : tuple, optional
        簇数元组区间. The default is (2,12).

    Returns
    -------
    visualizer : TYPE
        包括elbow_value_（最优簇数），elbow_score_（最优簇数分值），k_scores_（所有簇数分值）.

    '''
    from sklearn.neighbors import kneighbors_graph
    from sklearn.preprocessing import normalize   
    from sklearn import cluster
    from yellowbrick.cluster import KElbowVisualizer

    pts_geometry=idxes_df[['geometry']]    
    pts_geometry[['x','y']]=pts_geometry.geometry.apply(lambda row:pd.Series([row.x,row.y]))
    pts_coordis=pts_geometry[['x','y']].to_numpy()
    connectivity=kneighbors_graph(pts_coordis,kneighbors_graph_n_neighbors,include_self=False)    
    X_=idxes_df[fields].to_numpy()
    X=normalize(X_,axis=0, norm='max')
    
    clustering_=cluster.AgglomerativeClustering(connectivity=connectivity,) 
    visualizer = KElbowVisualizer(clustering_, timings=False,size=(500, 500), k=k) #metric='calinski_harabasz'
    visualizer.fit(X)    
    # help(visualizer)
    visualizer.show(outpath=os.path.join(save_path,'KEIbow-{}.png'.format(kneighbors_graph_n_neighbors))) 
    
    return visualizer

def distortion_score_elbow_kneighbors(idxes_df,fields,save_path,kneighbors_graph_n_neighbors_list,save_fn,k): 
    '''
    跟定邻元数列表，批量计算最优簇数

    Parameters
    ----------
    idxes_df : DataFrame
        指数数据.
    fields : list
        计算的指数列名.
    save_path : string
        图表保存根目录.
    kneighbors_graph_n_neighbors_list : list
        kneighbors_graph方法参数输入项，邻元数.
    save_fn : string
        最优簇数保存路径名.
    k : tuple
        簇数元组区间.

    Returns
    -------
    elbow_score_dict : pickle(dict)
        最优簇数计算结果信息，包括k_scores，k_scores和elbow_score.

    '''
    from tqdm import tqdm
    import pickle
    
    elbow_score_dict={}
    # j=0
    for i in tqdm(kneighbors_graph_n_neighbors_list):    
        visualizer=distortion_score_elbow(idxes_df,fields,save_path,i,k)      
        elbow_score_dict[i]={'k_scores':visualizer.k_scores_,
                             'elbow_value':visualizer.elbow_value_,
                             'elbow_score':visualizer.elbow_score_} 
        # if j==2:break
        # j+=1
    # print(visualizer.k_scores_,visualizer.elbow_value_,visualizer.elbow_score_ )
    with open(save_fn,'wb') as f: 
        pickle.dump(elbow_score_dict,f)     
    return elbow_score_dict
   
def elbow_score_plot(elbow_score_dict,save_fn,k): 
    '''
    不同邻里尺度，最优簇数图表打印

    Parameters
    ----------
    elbow_score_dict : dicit
        最优簇数计算结果信息,包括k_scores，k_scores和elbow_score.
    save_fn : string
        图表保存路径名.
    k : tuple
        簇数元组区间.

    Returns
    -------
    None.

    '''
    import matplotlib.pyplot as plt    
    import numpy as np
    from pylab import mpl
    
    mpl.rcParams['font.sans-serif']=['DengXian'] #解决中文字符乱码问题
    
    kneighbors=list(elbow_score_dict.keys())
    n_clusters=list(range(k[0],k[1]))
    k_scores=np.array([elbow_score_dict[k]['k_scores'] for k in kneighbors])
    # print(k_scores)
    y_min=k_scores.min()-100
    y_max=k_scores.max()+100
    
    fig, ax=plt.subplots(1, 1, figsize=(12, 14))
    # These are the colors that will be used in the plot
    ax.set_prop_cycle(color=[
        '#1f77b4', '#aec7e8', '#ff7f0e', '#ffbb78', '#2ca02c', '#98df8a',
        '#d62728', '#ff9896', '#9467bd', '#c5b0d5', '#8c564b', '#c49c94',
        '#e377c2', '#f7b6d2', '#7f7f7f', '#c7c7c7', '#bcbd22', '#dbdb8d',
        '#17becf', '#9edae5'])    
    # Remove the plot frame lines. They are unnecessary here.
    # ax.spines[:].set_visible(False)  
    for i in ['top','right','bottom','left']:
        ax.spines[i].set_visible(False)
    
    # Ensure that the axis ticks only show up on the bottom and left of the plot.
    # Ticks on the right and top of the plot are generally unnecessary.
    ax.xaxis.tick_bottom()
    ax.yaxis.tick_left()    
    
    fig.subplots_adjust(left=.06, right=.75, bottom=.02, top=.94)
    # Limit the range of the plot to only where the data is.
    # Avoid unnecessary whitespace.
    ax.set_xlim(min(n_clusters),max(n_clusters))
    ax.set_ylim(y_min,y_max)    
    
    # Provide tick lines across the plot to help your viewers trace along
    # the axis ticks. Make sure that the lines are light and small so they
    # don't obscure the primary data lines.
    ax.grid(True, 'major', 'y', ls='--', lw=.5, c='k', alpha=.3)   
            
    # Remove the tick marks; they are unnecessary with the tick lines we just
    # plotted. Make sure your axis ticks are large enough to be easily read.
    # You don't want your viewers squinting to read your plot.
    ax.tick_params(axis='both', which='both', labelsize=14,
                   bottom=False, top=False, labelbottom=True,
                   left=False, right=False, labelleft=True)    
            
    # Now that the plot is prepared, it's time to actually plot the data!
    # Note that I plotted the majors in order of the highest % in the final year.  
    info={kn:"kneighbors={};elbow at k={},score={}".format(kn,elbow_score_dict[kn]['elbow_value'],round(elbow_score_dict[kn]['elbow_score'],3)) for kn in kneighbors}    
    # info={kn:"邻元数={};最佳簇数 k={},分值={}".format(kn,elbow_score_dict[kn]['elbow_value'],round(elbow_score_dict[kn]['elbow_score'],3)) for kn in kneighbors}    
    # print(info)   
    
    y_offsets={70:15,140:-60,150:-45,130:-35,110:-25,120:-15,80:-3}    
    for kn in kneighbors:
        # Plot each line separately with its own color.    
        line,=ax.plot(n_clusters,elbow_score_dict[kn]['k_scores'] ,lw=2.5)    
        ax.scatter(elbow_score_dict[kn]['elbow_value'],elbow_score_dict[kn]['elbow_score'],marker='X',s=100)
        y_pos=elbow_score_dict[kn]['k_scores'][-1]
        if kn in y_offsets:
            y_pos+=y_offsets[kn]
        ax.text(n_clusters[-1]+0.1,y_pos,info[kn] ,fontsize=14, color=line.get_color())
        
    ax.set_ylabel('Scores',fontsize=15)    
    ax.set_xlabel('Number of clusters',fontsize=15)
    # ax.set_ylabel('分值',fontsize=15)    
    # ax.set_xlabel('簇数',fontsize=15)    
    fig.savefig(save_fn,bbox_inches="tight",dpi=300)
    plt.show()

def idxes_clustering(idxes_df,fields,n_clusters=10,epsg=4326,kneighbors_graph_n_neighbors=9):
    '''
    多个指数（字段）的聚类

    Parameters
    ----------
    idxes_df : DataFrame
        指数.
    fields : list
        用于指数计算的列名列表.
    n_clusters : int, optional
        聚类数量. The default is 10.
    epsg : string or int, optional
        坐标投影系统，epsg编号. The default is 4326.

    Returns
    -------
    idxes_df_gdf : GeoDataFrame
        多个指数（字段）的聚类.

    '''
    import pandas as pd
    from sklearn.neighbors import NearestNeighbors
    from sklearn import cluster
    import geopandas as gpd
    import pyproj
    from sklearn.preprocessing import normalize
    from sklearn.neighbors import kneighbors_graph
    
    pts_geometry=idxes_df[['geometry']]    
    pts_geometry[['x','y']]=pts_geometry.geometry.apply(lambda row:pd.Series([row.x,row.y]))
    pts_coordis=pts_geometry[['x','y']].to_numpy()

    connectivity=kneighbors_graph(pts_coordis,kneighbors_graph_n_neighbors,include_self=False)    
    
    X_=idxes_df[fields].to_numpy()
    X=normalize(X_,axis=0, norm='max')
    clustering=cluster.AgglomerativeClustering(connectivity=connectivity,n_clusters=n_clusters).fit(X)
    cluster_column_name='clustering_{}_{}'.format(kneighbors_graph_n_neighbors,n_clusters)
    idxes_df[cluster_column_name]=clustering.labels_
    idxes_df[cluster_column_name+"_"]=idxes_df[cluster_column_name].apply(lambda row:row+1)
    
    wgs84=pyproj.CRS('EPSG:4326')
    idxes_df_gdf=gpd.GeoDataFrame(idxes_df,geometry=idxes_df.geometry,crs=wgs84)   
    idxes_df_gdf=idxes_df_gdf.to_crs(epsg)
    
    return idxes_df_gdf,cluster_column_name

def idxes_clustering_kneighbors(idxes_df,fields,kneighbors_ncluster,epsg=4326):
    '''
    不同邻里尺度（邻元数）指数贡献度计算

    Parameters
    ----------
    idxes_df : DataFrame
        指数.
    fields : list
        用于指数计算的列名列表.
    kneighbors_ncluster : dict
        邻元数:簇数对应字典.
    epsg : int, optional
        投影坐标系统epsg编号. The default is 4326.

    Returns
    -------
    kneighbors_clusters_concat_gdf : DataFrame
        指数贡献度.
    cluster_column_name_list : list
        不同邻元数指数贡献度列名.

    '''
    from tqdm import tqdm    
    import pyproj
    import geopandas as gpd
    
    kneighbors_clusters_dict={}
    cluster_column_name_list=[]
    # i=0
    for kneighbors,n_cluster in tqdm(kneighbors_ncluster.items()):
        idxes_df_gdf,cluster_column_name=idxes_clustering(idxes_df.copy(deep=True),fields,n_cluster,epsg,kneighbors)
        # print(idxes_df_gdf.columns)
        kneighbors_clusters_dict[cluster_column_name]=idxes_df_gdf[[cluster_column_name]]
        cluster_column_name_list.append(cluster_column_name)
        # if i==2:break
        # i+=1
        
    kneighbors_clusters_concat=pd.concat([idxes_df.copy(deep=True)]+list(kneighbors_clusters_dict.values()),axis=1) 
    wgs84=pyproj.CRS('EPSG:4326')
    kneighbors_clusters_concat_gdf=gpd.GeoDataFrame(kneighbors_clusters_concat,geometry=kneighbors_clusters_concat.geometry,crs=wgs84) 
    # print(cluster_column_name_list)
    kneighbors_clusters_concat_gdf=kneighbors_clusters_concat_gdf.to_crs(epsg)    
    return kneighbors_clusters_concat_gdf,cluster_column_name_list     
       
def idxes_clustering_contribution(idxes_df,fields,n_clusters=10,kneighbors_graph_n_neighbors=9):
    '''
    聚类指数贡献度计算

    Parameters
    ----------
    idxes_df : DataFrame
        指数.
    fields : list
        用于指数计算的列名列表.
    n_clusters : int, optional
        聚类簇数. The default is 10.
    kneighbors_graph_n_neighbors : int, optional
        kneighbors_graph方法参数输入项，邻元数. The default is 9.

    Returns
    -------
    featureScores : DataFrame
        贡献度.

    '''
    import pandas as pd
    from sklearn.neighbors import NearestNeighbors
    from sklearn import cluster
    from sklearn.preprocessing import normalize    
    from yellowbrick.cluster import KElbowVisualizer   
    from sklearn.feature_selection import SelectKBest,f_classif
    import matplotlib.pyplot as plt
    from sklearn.neighbors import kneighbors_graph

    # import matplotlib    
    # font = {
    #         # 'family' : 'normal',
    #         # 'weight' : 'bold',
    #         'size'   : 28}
    # matplotlib.rc('font', **font) 
    
    pts_geometry=idxes_df[['geometry']]    
    pts_geometry[['x','y']]=pts_geometry.geometry.apply(lambda row:pd.Series([row.x,row.y]))
    pts_coordis=pts_geometry[['x','y']].to_numpy()
    
    # nbrs=NearestNeighbors(n_neighbors=kneighbors_graph_n_neighbors, algorithm='ball_tree').fit(pts_coordis)
    # connectivity=nbrs.kneighbors_graph(pts_coordis)
    connectivity=kneighbors_graph(pts_coordis,kneighbors_graph_n_neighbors,include_self=False)
    
    X_=idxes_df[fields].to_numpy()
    X=normalize(X_,axis=0, norm='max')

    clustering=cluster.AgglomerativeClustering(connectivity=connectivity,n_clusters=n_clusters).fit(X)
    y=clustering.labels_
    selector=SelectKBest(score_func=f_classif, k=len(fields)) #score_func=chi2    
    selector.fit(X,y)
    
    dfscores = pd.DataFrame(selector.scores_)
    dfpvalues=pd.DataFrame(selector.pvalues_)
    dfcolumns = pd.DataFrame(fields)  
    featureScores=pd.concat([dfcolumns,dfscores,dfpvalues],axis=1)
    featureScores.columns=['Factor','Score','p_value']  #naming the dataframe columns
    # print(featureScores)
    
    featureScores_=featureScores.set_index('Factor')    
    featureScores_.nlargest(len(fields),'Score').Score.plot(kind='barh',figsize=(30,20),fontsize=38)
    featureScores_.Score.plot(kind='barh')
    plt.show()    

    return featureScores

def idxes_clustering_contribution_kneighbors(idxes_df,fields,elbow_score_dict,save_fn):
    '''
    不同邻里尺度，聚类指数贡献度计算

    Parameters
    ----------
    idxes_df : DataFrame
        指数.
    fields : list
        用于指数计算的列名列表.
    elbow_score_dict : dict
        最优簇数计算结果信息，包括k_scores，k_scores和elbow_score.
    save_fn : string
        保存路径名.

    Returns
    -------
    featureScores_dict : dict
        聚类指数贡献度.

    '''    
    from tqdm import tqdm
    import pickle
    
    kneighbors=list(elbow_score_dict.keys())
    elbow_value={k:elbow_score_dict[k]['elbow_value'] for k in kneighbors}
    featureScores_dict={}
    for k in tqdm(kneighbors):
        featureScores=idxes_clustering_contribution(idxes_df,fields,elbow_value[k],k)
        featureScores_dict[k]=featureScores
    with open(save_fn, 'wb') as f:
        pickle.dump(featureScores_dict,f)
        
    return featureScores_dict

def idxes_clustering_contribution_kneighbors_plot(featureScores_dict,save_fn):
    '''
    不同邻里尺度（邻元数），对应最优簇数的指数贡献度图表打印

    Parameters
    ----------
    featureScores_dict : dict
        聚类指数贡献度.
    save_fn : string
        保存路径名.

    Returns
    -------
    None.

    '''
    import matplotlib.pyplot as plt    
    import numpy as np
    from pylab import mpl
    mpl.rcParams['font.sans-serif']=['DengXian'] #解决中文字符乱码问题
    
    kneighbors=list(featureScores_dict.keys())
    # print(kneighbors)
    featurescores_array=np.array([featureScores_dict[k]['Score'].to_list() for k in kneighbors])
    pValue_array=np.array([featureScores_dict[k]['p_value'].to_list() for k in kneighbors])
    factors=featureScores_dict[kneighbors[0]]['Factor'].to_list() 
    factors_mapping={'Green view index':'Seg_GVF',
                     'Sky view factor':'Seg_SVF',
                     'Ground view index':'Seg_GVI',
                     'Equilibrium degree':'Seg_ED',
                     'Perimeter area ratio(mn)':'Sky_PARA(mn)',
                     'Shape index(mn)':'Sky_SHAPE(mn)',
                     'Fractal dimension(mn)':'Sky_FRAC(mn)',
                     'Color richness index':'CRI',
                     'Key point size(0-10]':'KPSF (0-10]',
                     'Key point size(10-20]':'KPSF (10-20]',
                     'Key point size(30-40]':'KPSF(30-40]',
                     'Key point size(20-30]':'KPSF(20-30]'
                         }
    # print(factors)    
    y_min=featurescores_array.min()-100
    y_max=featurescores_array.max()+100    
    
    fig, ax=plt.subplots(1, 1, figsize=(12, 14))
    ax.set_prop_cycle(color=[
        '#1f77b4', '#aec7e8', '#ff7f0e', '#ffbb78', '#2ca02c', '#98df8a',
        '#d62728', '#ff9896', '#9467bd', '#c5b0d5', '#8c564b', '#c49c94',
        '#e377c2', '#f7b6d2', '#7f7f7f', '#c7c7c7', '#bcbd22', '#dbdb8d',
        '#17becf', '#9edae5']) 
    for i in ['top','right','bottom','left']:
        ax.spines[i].set_visible(False)
    ax.xaxis.tick_bottom()
    ax.yaxis.tick_left()    
    fig.subplots_adjust(left=.06, right=.75, bottom=.02, top=.94)
    ax.set_xlim(min(kneighbors),max(kneighbors))
    ax.set_ylim(y_min,y_max) 
    ax.grid(True, 'major', 'y', ls='--', lw=.5, c='k', alpha=.3) 
    ax.tick_params(axis='both', which='both', labelsize=14,
                   bottom=False, top=False, labelbottom=True,
                   left=False, right=False, labelleft=True)    
    # factor_score_pValue={f:[s,p] for f,s,p in zip(factors, featurescores_array.T,pValue_array.T)}
    factor_score={f:s for f,s in zip(factors, featurescores_array.T)}
    # print(factor_score)
    # y_offsets={}
    y_offsets={'Key point size(30-40]':150,'Perimeter area ratio(mn)':150,'Equilibrium degree':100,'Fractal dimension(mn)':-100} 
    for f in factors:
        line,=ax.plot(kneighbors,factor_score[f] ,lw=2.5) 
        y_pos=factor_score[f][-1]
        if f in y_offsets:
            y_pos+=y_offsets[f]
        # ax.text(kneighbors[-1]+0.1,y_pos,f ,fontsize=14, color=line.get_color())
        ax.text(kneighbors[-1]+0.1,y_pos,factors_mapping[f] ,fontsize=14, color=line.get_color())
    
    ax.set_ylabel('Scores',fontsize=20)    
    ax.set_xlabel('kneighbors',fontsize=20)
    # ax.set_ylabel('分值',fontsize=20)    
    # ax.set_xlabel('邻元数',fontsize=20)   
    fig.savefig(save_fn,bbox_inches="tight",dpi=300)
    plt.show()  
    
def gpd_plot(df,columns,save_path,**kwargs):
    '''
    不同列，GeoDataFrame地图打印

    Parameters
    ----------
    df : DataFrame
        待打印地图的数据.
    columns : list
        打印列名.
    save_path : string
        图表保存根目录.
    **kwargs : TYPE
        打印属性配置.

    Returns
    -------
    None.

    '''
    import matplotlib.pyplot as plt 
    import os
    
    plot_params={'figsize':(10,10),'markersize':2,'marker':'o','cmap':'rainbow'}
    plot_params.update(kwargs)
    for column in columns:
        df.plot(column=column,
                figsize=plot_params['figsize'],
                markersize=plot_params['markersize'],
                marker=plot_params['marker'],
                cmap=plot_params['cmap']) 
        plt.axis('off')
        plt.title(column)
        plt.savefig(os.path.join(save_path,'{}.png'.format(column)))
        plt.show()        
        plt.close() 
        
def idx_clustering(idxes_df,field,n_clusters=10,kneighbors_graph_n_neighbors=9):
    '''
    单个指数（字段）的聚类

    Parameters
    ----------
    idxes_df : DataFrame
        指数.
    field : string
        用于指数计算的列名.
    n_clusters : int, optional
        聚类数量. The default is 10.

    Returns
    -------
    idxes_df_gdf : GeoDataFrame
        单个指数（字段）的聚类.

    '''
    import pandas as pd
    from sklearn.neighbors import NearestNeighbors
    import numpy as np
    from sklearn import cluster
    import geopandas as gpd
    import pyproj
    from sklearn.neighbors import kneighbors_graph
    from yellowbrick.cluster import KElbowVisualizer 
    
    pts_geometry=idxes_df[['geometry']]    
    pts_geometry[['x','y']]=pts_geometry.geometry.apply(lambda row:pd.Series([row.x,row.y]))
    pts_coordis=pts_geometry[['x','y']].to_numpy()
    
    # nbrs=NearestNeighbors(n_neighbors=kneighbors_graph_n_neighbors, algorithm='ball_tree').fit(pts_coordis)
    # connectivity=nbrs.kneighbors_graph(pts_coordis)
    connectivity=kneighbors_graph(pts_coordis,kneighbors_graph_n_neighbors,include_self=False)
    
    X=np.expand_dims(idxes_df[field].to_numpy(),axis=1)
    clustering=cluster.AgglomerativeClustering(connectivity=connectivity,n_clusters=n_clusters).fit(X)
    idxes_df['clustering_'+field]=clustering.labels_
    
    mean=idxes_df.groupby(['clustering_'+field])[field].mean() #.reset_index()
    idxes_df['clustering_'+field+'_mean']=idxes_df['clustering_'+field].map(mean.to_dict())
    
    wgs84=pyproj.CRS('EPSG:4326')
    idxes_df_gdf=gpd.GeoDataFrame(idxes_df,geometry=idxes_df.geometry,crs=wgs84)    
    
    clustering_=cluster.AgglomerativeClustering(connectivity=connectivity,) #n_clusters=n_clusters
    visualizer = KElbowVisualizer(clustering_, timings=False,size=(500, 500), ) #k=(4,12) metric='calinski_harabasz'
    visualizer.fit(X)    # Fit the data to the visualizer
    visualizer.show()    # Finalize and render the figure    
    
    return idxes_df_gdf
    
        
if __name__=="__main__":
    import pickle
    import pandas as pd
    import sys,os
    sys.path.append('..')      
    from database import postSQL2gpd,gpd2postSQL,cfg_load_yaml 
    parent_path=os.path.dirname(os.getcwd())
    cfg=cfg_load_yaml('../config.yml')  
    
    UN=cfg["postgreSQL"]["myusername"]
    PW=cfg["postgreSQL"]["mypassword"]
    DB=cfg["postgreSQL"]["mydatabase"]  
    GC='geometry' 

    panorama_object_percent_gdf=postSQL2gpd(table_name='cube_object_percent',geom_col=GC,myusername=UN,mypassword=PW,mydatabase=DB)
    sky_class_level_metrics_gdf=postSQL2gpd(table_name='metrics_skyline_shape',geom_col=GC,myusername=UN,mypassword=PW,mydatabase=DB)
    colors_dominant_entropy_gdf=postSQL2gpd(table_name='colors_dominant_entropy',geom_col=GC,myusername=UN,mypassword=PW,mydatabase=DB)
    kp_size_stats_gdf=postSQL2gpd(table_name='kp_size_stats',geom_col=GC,myusername=UN,mypassword=PW,mydatabase=DB)

    metrics_panorama_object_percent=cfg['metrics_clustering']['metrics_panorama_object_percent']
    metrics_sky_class_level_metrics=cfg['metrics_clustering']['metrics_sky_class_level_metrics']
    metrics_colors_dominant_entropy=cfg['metrics_clustering']['metrics_colors_dominant_entropy']
    metrics_kp_size_stats=cfg['metrics_clustering']['metrics_kp_size_stats']  
    metrics_auxiliary=cfg['metrics_clustering']['metrics_auxiliary']
    metrics_merge=pd.concat([panorama_object_percent_gdf[metrics_panorama_object_percent],
                            sky_class_level_metrics_gdf[metrics_sky_class_level_metrics],
                            colors_dominant_entropy_gdf[metrics_colors_dominant_entropy],
                            kp_size_stats_gdf[metrics_kp_size_stats],
                            panorama_object_percent_gdf[metrics_auxiliary]],axis=1)    
    
    fields_mapping=cfg['metrics_clustering']['fields_mapping']   
    metrics_merge=metrics_merge.rename(columns=fields_mapping)
    
    kneighbors_graph_n_neighbors=cfg['metrics_clustering']['kneighbors_graph_n_neighbors']
    n_clusters=cfg['metrics_clustering']['n_clusters'] 
    
    #A.不同邻里尺度（邻元数）最优簇数计算-多指数 
    fields=cfg['metrics_clustering']['fields']  
    kneighbors_graph_n_neighbors_list=cfg['metrics_clustering']['kneighbors_graph_n_neighbors_list']
    elbow_score_dict_save_fn=os.path.join(parent_path,cfg['metrics_clustering']['elbow_score_dict_save_fn'])
    KElbowVisualizer_k=eval(cfg['metrics_clustering']['KElbowVisualizer_k'])
    distortion_score_save_path=os.path.join(parent_path,cfg['metrics_clustering']['distortion_score_save_path']) 
    
    elbow_score_dict=distortion_score_elbow_kneighbors(metrics_merge,fields,distortion_score_save_path,kneighbors_graph_n_neighbors_list,elbow_score_dict_save_fn,k=KElbowVisualizer_k)    
    
    #B.不同邻里尺度，最优簇数图表打印-多指数
    with open(elbow_score_dict_save_fn,'rb') as f: 
        elbow_score_dict=pickle.load(f)     
    elbow_score_plot_fn=os.path.join(parent_path,cfg['metrics_clustering']['elbow_score_plot_fn'])  
    elbow_score_plot(elbow_score_dict,elbow_score_plot_fn,k=KElbowVisualizer_k) 
    
    #C.不同邻里尺度（邻元数），对应最优簇数的指数贡献度计算及图表打印-多指数
    featureScores_dict_fn=os.path.join(parent_path,cfg['metrics_clustering']['featureScores_dict_fn'])
    featureScores_dict=idxes_clustering_contribution_kneighbors(metrics_merge,fields,elbow_score_dict,featureScores_dict_fn)  
    with open(featureScores_dict_fn,'rb') as f: 
        featureScores_dict=pickle.load(f)      
    contribution_kneighbors_plot_fn=os.path.join(parent_path,cfg['metrics_clustering']['contribution_kneighbors_plot_fn'])    
    idxes_clustering_contribution_kneighbors_plot(featureScores_dict,contribution_kneighbors_plot_fn)     
    
    #D.不同邻里尺度（邻元数）指数聚类计算-多指数
    kneighbors_ncluster={k:v['elbow_value'] for k,v in elbow_score_dict.items()}
    kneighbors_clusters_gdf,cluster_column_name_list=idxes_clustering_kneighbors(metrics_merge.copy(deep=True),fields,kneighbors_ncluster,cfg['xian_epsg'])
    kneighbors_clusters_table_name=cfg['metrics_clustering']['kneighbors_clusters_table_name']
    gpd2postSQL(kneighbors_clusters_gdf,table_name=kneighbors_clusters_table_name,myusername=UN,mypassword=PW,mydatabase=DB)
    cluster_column_name_list_fn=os.path.join(parent_path,cfg['metrics_clustering']['cluster_column_name_list_fn'])
    with open(cluster_column_name_list_fn,'wb') as f:
        pickle.dump(cluster_column_name_list,f)  
    
    #E.不同邻里尺度，聚类地图打印-多指数
    kneighbors_clusters_gdf=postSQL2gpd(table_name=kneighbors_clusters_table_name,geom_col=GC,myusername=UN,mypassword=PW,mydatabase=DB)
    with open(cluster_column_name_list_fn,'rb') as f:
        cluster_column_name_list=pickle.load(f)
    contribution_kneighbors_plot_fn=os.path.join(parent_path,cfg['metrics_clustering']['contribution_kneighbors_plot_fn']) 
    cluster_kneighbors_save_path=os.path.join(parent_path,cfg['metrics_clustering']['cluster_kneighbors_save_path'])
    gpd_plot(kneighbors_clusters_gdf,cluster_column_name_list,cluster_kneighbors_save_path) #cmap='terrain'
    
    #F.GVF最优簇数计算-单指数
    field_single='Green view index'
    kneighbors_graph_n_neighbors=10
    n_clusters=5
    idx_clustering_gdf=idx_clustering(metrics_merge.copy(deep=True),field=field_single,n_clusters=n_clusters,kneighbors_graph_n_neighbors=kneighbors_graph_n_neighbors)
    idx_clustering_table_name="cluster_{}_{}".format(field_single,n_clusters)
    gpd2postSQL(idx_clustering_gdf,table_name=idx_clustering_table_name,myusername=UN,mypassword=PW,mydatabase=DB)    
    clustering_stat=idx_clustering_gdf.groupby('clustering_'+field_single).agg({field_single:[min,max,'mean','median','count','std']}).round(3)
    clustering_stat_save_fn=os.path.join(parent_path,cfg['metrics_clustering']['clustering_stat_save_fn'])
    clustering_stat.to_excel(clustering_stat_save_fn)  
    print(clustering_stat)    
    
    grouped=idx_clustering_gdf[['Green view index','clustering_'+field_single]].groupby('clustering_'+field_single,)['Green view index']
    grouped_=[i[-1].tolist() for i in grouped] 
    
    import matplotlib.pyplot as plt
    import matplotlib.pylab as pylab
    params = {
         # 'legend.fontsize': 'x-large',
         # 'figure.figsize': (15, 5),
         # 'axes.labelsize': 'x-large',
         # 'axes.titlesize':'x-large',
         'xtick.labelsize':'x-large',
         'ytick.labelsize':'x-large'
         }
    pylab.rcParams.update(params)
    fig,ax=plt.subplots(figsize=(10, 10)) 
    ax.boxplot(grouped_,labels=[0,1,2,3,4],showmeans=True)
    GVF_save_fn=os.path.join(parent_path,cfg['metrics_clustering']['GVF_save_fn'])
    fig.savefig(GVF_save_fn,bbox_inches="tight",dpi=300)
    plt.show()
```

###### 5) 多指数聚类特征15分钟步行生活圈的熵值

图为邻里尺度邻元数为30，最优簇数为4，关键点邻域尺度开始起主导作用，步行15分钟（半径约1100米）步行圈景观指数聚类特征簇类频数信息熵。从计算结果可以明显划分出城市街道空间特征分区，较高的信息熵通常为具有较多特征簇类，且分布数均匀；较低信息熵为包含较少簇类，且分布数不均匀。

__Fig. 聚类簇信息熵（15min）__ 

<a href=""><img src="./imgs/3_2_1_20.png" height="auto" width="auto" title="caDesign"></a>

`clustering_entropy.py`
```python
# -*- coding: utf-8 -*-
"""
Created on Mon Jan 31 14:32:16 2022

@author: Richie Bao-caDesign设计(cadesign.cn)
"""
def clustering_entropy(kneighbors_clusters_gdf,life_circle_radius,clusters):
    '''
    指定缓冲半径，计算各个点缓冲半径内（生活圈）的信息熵，即聚类簇混杂程度

    Parameters
    ----------
    kneighbors_clusters_gdf : GeoDataFrame
        聚类数据.
    life_circle_radius : numerical val
        计算缓冲半径.
    clusters : list
        不同空间尺度下聚类列名.

    Returns
    -------
    GeoDataFrame
        包含'LC_clusters_entropy'（信息熵）,'LC_clusters_unique'（簇类）,'LC_clusters_unique_num'（簇数量）.

    '''
    import pandas as pd
    from tqdm import tqdm
    import numpy as np
    from scipy.stats import entropy    
    tqdm.pandas()
    
    kneighbors_clusters_gdf['buffer']=kneighbors_clusters_gdf.geometry.apply(lambda row: row.buffer(life_circle_radius))
    cluster_vals=kneighbors_clusters_gdf[clusters].to_dict('split')
    pts=kneighbors_clusters_gdf.geometry.to_list()
    def life_circle_clusters_entropy(buffer):        
        contains_bool=[buffer.contains(pt) for pt in pts]
        cluster_vals_contained=np.array(cluster_vals['data'])[contains_bool] 
        LC_clusters_entropy=[entropy(np.unique(i,return_counts=True)[-1]) for i in cluster_vals_contained.T]
        LC_clusters_unique=[np.unique(i) for i in cluster_vals_contained.T]
        LC_clusters_unique_num=[len(np.unique(i)) for i in cluster_vals_contained.T]
        
        return [LC_clusters_entropy, LC_clusters_unique,LC_clusters_unique_num]       
    kneighbors_clusters_gdf[['LC_clusters_entropy','LC_clusters_unique','LC_clusters_unique_num']]=kneighbors_clusters_gdf['buffer'].progress_apply(life_circle_clusters_entropy).to_list()

    return kneighbors_clusters_gdf

if __name__=="__main__":
    import geopandas as gpd
    import pickle
    import pandas as pd
    import sys,os
    sys.path.append('..')      
    from database import postSQL2gpd,gpd2postSQL,cfg_load_yaml 
    parent_path=os.path.dirname(os.getcwd())
    cfg=cfg_load_yaml('../config.yml')  
    
    UN=cfg["postgreSQL"]["myusername"]
    PW=cfg["postgreSQL"]["mypassword"]
    DB=cfg["postgreSQL"]["mydatabase"]  
    GC='geometry' 
    
    kneighbors_clusters_table_name=cfg['metrics_clustering']['kneighbors_clusters_table_name']
    kneighbors_clusters_gdf=postSQL2gpd(table_name=kneighbors_clusters_table_name,geom_col=GC,myusername=UN,mypassword=PW,mydatabase=DB)
    cluster_column_name_list_fn=os.path.join(parent_path,cfg['metrics_clustering']['cluster_column_name_list_fn'])
    with open(cluster_column_name_list_fn,'rb') as f:
        cluster_column_name_list=pickle.load(f)
    
    walking_speed=cfg['clustering_entropy']['walking_speed']
    life_circle_radius_meter_15min=walking_speed*1000/60*15
    clustering_entropy_gdf=clustering_entropy(kneighbors_clusters_gdf,life_circle_radius_meter_15min,cluster_column_name_list)
    clustering_entropy_table_name=cfg['clustering_entropy']['clustering_entropy_table_name']
    gpd2postSQL(clustering_entropy_gdf,table_name=clustering_entropy_table_name,myusername=UN,mypassword=PW,mydatabase=DB)
    clustering_entropy_gdf=postSQL2gpd(table_name=clustering_entropy_table_name,geom_col=GC,myusername=UN,mypassword=PW,mydatabase=DB)
    
    clustering_entropy_gdf['LC_clusters_entropy_list']=clustering_entropy_gdf['LC_clusters_entropy'].apply(lambda row:eval(row))
    LC_entropy_df=pd.DataFrame(clustering_entropy_gdf['LC_clusters_entropy_list'].to_list(),columns=cluster_column_name_list)
    LC_entropy_df['geometry']=clustering_entropy_gdf.geometry
    LC_entropy_gdf=gpd.GeoDataFrame(LC_entropy_df,crs=cfg['xian_epsg']).round(3)
    LC_entropy_table_name=cfg['clustering_entropy']['LC_entropy_table_name']
    gpd2postSQL(LC_entropy_gdf,table_name=LC_entropy_table_name,myusername=UN,mypassword=PW,mydatabase=DB)

    from metrics_clustering import gpd_plot
    LC_entropy_gdf=postSQL2gpd(table_name=LC_entropy_table_name,geom_col=GC,myusername=UN,mypassword=PW,mydatabase=DB)
    LC_entropy_save_path=os.path.join(parent_path,cfg['clustering_entropy']['LC_entropy_save_path'])
    gpd_plot(LC_entropy_gdf,cluster_column_name_list,LC_entropy_save_path,cmap='Set1') #cmap='terrain'   
```

##### B.2.3.6 连续街道尺度指数计算与街道空间特征聚类分布与指数特征贡献度

同上述区域分析（略）。

##### B.2.3.7 双向视域特征匹配消失距离

图像匹配可以返回两幅图像中特征点基本相似的关键点，那么对于连续影像而言，假设确定一个固定位置，即选择该位置上的一张影像，将其分别与之后的所有影像进行图像匹配，返回关键点，计算每一对的特征点匹配数量。这个特征点匹配数量的变化体现了当前位置的图像与之后顺序影像相似的程度。因为后一帧（后一位置）影像包含前一影像的一部分，当距离越近，两者匹配返回的特征点匹配数量越多；反之，离当前位置越远，匹配的数量越少，而且这个过程基本上是逐渐减少的。因此可以由上述计算推测一条街道视觉感知变化的情况，找到感知消失的距离；同时，也可以比较不同街道感知变化的差异；甚至，可以比较不同街道感知的相似度。

图像匹配的分析会受到结束位置的影响，以及正逆行走顺应的影响，因此图像匹配的分析是延道路做双向分析。从分析结果来看，Hui street 消失距离平均最小，而该条街道为步行街；South street, South gate bend和Changan road为城市南北向的主要通行道路，具有较大的消失距离，而其它道路次之。因此视域特征匹配消失的距离是可以表征街道空间的特征。

__Fig. 双向消失距离__ 

<a href=""><img src="./imgs/3_2_1_21.png" height="auto" width="auto" title="caDesign"></a>

`vanishing_position.py`
```python
# -*- coding: utf-8 -*-
"""
Created on Wed May  5 18:27:47 2021
Updated on Mon Jan 31 20:53:47 2022

@author: Richie Bao-caDesign设计(cadesign.cn)
"""
class dynamicStreetView_visualPerception:
    #代码参考'图像特征提取与动态街景视觉感知'

class movingAverage_inflection:
    #代码参考'图像特征提取与动态街景视觉感知'

def vanishing_position_length(matches_num,coordi_df,epsg,**kwargs):
    #代码参考'图像特征提取与动态街景视觉感知'


def fns_sort_ordinal(imgs_root,suffix="jpg",reverse=False):
    '''
    对文件名末尾含‘_number’，例如img_0.jpg的多个文件排序

    Parameters
    ----------
    imgs_root : string
        图像根目录.

    Returns
    -------
    img_fp_list_sorted : list
        排序后的图像路径列表.

    '''
    import glob,os
    from pathlib import Path
    
    img_fp_list=glob.glob(os.path.join(imgs_root,'*.{}'.format(suffix)))
    img_fp_dict={int(Path(p).stem.split('_')[-1]):p for p in img_fp_list}
    img_fp_key=list(img_fp_dict.keys())
    img_fp_key.sort()
    img_fp_list_sorted=[img_fp_dict[k] for k in img_fp_key]
    if reverse:
        img_fp_list_sorted.reverse()

    return img_fp_list_sorted    

def vanishing_sequence(img_path,coordi_df,epsg=4326,reverse=False):
    '''
    组合计算：序列图像匹配计算，每一位置图像与后续所有位置匹配分析->计算图像匹配特征点几乎无关联的距离

    Parameters
    ----------
    img_path : string
        图像根目录.
    coordi_df : DataFrame
        包含经纬度的DataFrame，其列名为：lon,lat.
    epsg : int, optional
        坐标投影系统，epsg编号. The default is 4326.
    reverse : bool, optional
        是否反转图像列表. The default is False.

    Returns
    -------
    vanishing_gpd : GeoDataFrame
        图像匹配特征点几乎无关联的距离.

    '''
    img_fp_list_sorted=fns_sort_ordinal(img_path,reverse=reverse)
    dsv_vp=dynamicStreetView_visualPerception(img_fp_list_sorted) #[:200]
    matches_num=dsv_vp.sequence_statistics()
    vanishing_gpd=vanishing_position_length(matches_num,coordi_df,epsg="EPSG:{}".format(epsg),threshold=0)
    print("感知消失距离统计:","_"*50,"\n")
    print(vanishing_gpd[vanishing_gpd["length"] >1].length.describe())
    print("频数统计：","_"*50,"\n")
    print(vanishing_gpd[vanishing_gpd["length"] >1]["length"].value_counts(bins=5)) 
    return vanishing_gpd

def movingAverage(series,window):
    '''
    平滑数据

    Parameters
    ----------
    series : series 
        待平滑的数据.
    window : int
        Size of the moving window.

    Returns
    -------
    rolling_mean : series 
        平滑后的数据.

    '''
    rolling_mean=series.rolling(window=window).mean()        
    return rolling_mean

def tourLine_segs_vanishing_position_length(tourLine_segment,img_fp_list_sorted,coordi_df,epsg,save_fn):
    '''
    计算消失距离长度

    Parameters
    ----------
    tourLine_segment : dict
        道路区段，索引标识.
    img_fp_list_sorted : list
        图像路径列表.
    coordi_df : DataFrame
        包含经纬度的DataFrame，其列名为：lon,lat.
    epsg : int
       坐标投影系统，epsg编号.
    save_fn : string
        保存路径名.

    Returns
    -------
    vanishing_dict : dict
        消失距离长度.

    '''
    from tqdm import tqdm
    
    vanishing_dict={}
    for k,v in tqdm(tourLine_segment.items()):
        img_fp_seg_list=img_fp_list_sorted[v[0]:v[1]]
        dsv_vp=dynamicStreetView_visualPerception(img_fp_seg_list) #[:200]
        matches_num=dsv_vp.sequence_statistics()        
        
        coordi_seg_df=coordi_df[v[0]:v[1]]
        vanishing_gpd=vanishing_position_length(matches_num,coordi_seg_df,epsg="EPSG:{}".format(epsg),threshold=0)        
        vanishing_dict[k]=vanishing_gpd        
    with open(save_fn,'wb') as f:
        pickle.dump(vanishing_dict,f)
    return vanishing_dict

def segs_vanishing_statistics(vanishing_dict):
    '''
    按道路区段统计消失距离长度

    Parameters
    ----------
    vanishing_dict : dict
        消失距离长度.

    Returns
    -------
    segs_Vanishing_stat : dict
        按道路区段统计消失距离.

    '''
    segs_Vanishing_stat={}
    for k,vanishing_gpd in vanishing_dict.items():        
        vanishing_length_desc=vanishing_gpd.length.describe()
        vanishing_fre=vanishing_gpd.length.value_counts(bins=5)
        
        segs_Vanishing_stat[k]={'vanishing_length_desc':vanishing_length_desc,'vanishing_fre':vanishing_fre}
    return segs_Vanishing_stat

def vanishing_segment_mark(vanishing_length,length_moving_reverse,tourLine_segment,segment_name,save_fn):
    '''
    图表打印

    Parameters
    ----------
    vanishing_length : DataFrame
        图像匹配特征点几乎无关联的距离-正向.
    length_moving_reverse : DataFrame
        图像匹配特征点几乎无关联的距离-反向.
    tourLine_segment : dict
        道路区段，索引标识.
    segment_name : dict
        道路区段名称.
    save_fn : string
        图像保存路径.

    Returns
    -------
    None.

    '''
    import matplotlib.pyplot as plt
    import matplotlib
    
    font = {
    # 'family' : 'normal',
    # 'weight' : 'bold',
    'size'   : 28}
    matplotlib.rc('font', **font)
    
    fig, ax=plt.subplots(figsize=(30,10))
    ax.plot(vanishing_length,label='vanishing distance_north')
    
    length_moving_reverse_list=length_moving_reverse.to_list()
    length_moving_reverse_list.reverse()
    ax.plot(length_moving_reverse_list,'--',label='vanishing distance_south')
    
    
    v_length=[]
    for k,v in tourLine_segment.items():
        # print(k,v)
        # v_length_seg=vanishing_length.iloc[v[0]:v[1]].to_list()
        # print(length_seg)
        # print(segment_name[k])
        ax.vlines(v[1],0,800,colors='r',linestyle='--',) #label=segment_name[k]
        ax.text(v[1],920, segment_name[k], fontsize=22,rotation=-90, rotation_mode='anchor',va='top')
    plt.legend(loc=3)
    ax.spines['right'].set_visible(False)
    ax.spines['top'].set_visible(False)
    # plt.show()
    plt.savefig(save_fn,bbox_inches="tight",dpi=300)

if __name__=="__main__":
    import pickle
    import pandas as pd
    import sys,os
    sys.path.append('..')      
    from database import postSQL2gpd,gpd2postSQL,cfg_load_yaml 
    parent_path=os.path.dirname(os.getcwd())
    cfg=cfg_load_yaml('../config.yml')  
    
    UN=cfg["postgreSQL"]["myusername"]
    PW=cfg["postgreSQL"]["mypassword"]
    DB=cfg["postgreSQL"]["mydatabase"]  
    GC='geometry'     
    
    #A.语义分割对象占图像的百分比
    tourLine_seg_path=cfg['panaSeg_street']['tour_line_seg']
    tourline_label_seg_path=cfg['panaSeg_street']['tourline_label_seg']
    coords_street=os.path.join(parent_path,cfg['streetview']['save_path_BSV_retrival_info_street']['coords'])
    with open(coords_street,'rb') as f:
        coords_tourLine=pickle.load(f)
    # from visual_field_proportion_metrics import metrics_seg_pano_proportion
    # tourLine_panorama_object_percent_gdf=metrics_seg_pano_proportion(tourline_label_seg_path,tourLine_seg_path,coords_tourLine,)
    tourLine_panorama_object_percent_table_name=cfg['vanishing_position']['tourLine_panorama_object_percent_table_name']    
    # gpd2postSQL(tourLine_panorama_object_percent_gdf,table_name=tourLine_panorama_object_percent_table_name,myusername=UN,mypassword=PW,mydatabase=DB)  
    
    #B.序列图像匹配计算，每一位置图像与后续所有位置匹配分析->计算图像匹配特征点几乎无关联的距离
    tourLine_panorama_object_percent_gdf=postSQL2gpd(table_name=tourLine_panorama_object_percent_table_name,geom_col=GC,myusername=UN,mypassword=PW,mydatabase=DB)
    coordi_df=tourLine_panorama_object_percent_gdf.sort_values(by='fn_idx')
    tourLine_img_path=cfg['streetview']['panoramic_imgs_valid_root_street']
    vanishing_gpd=vanishing_sequence(tourLine_img_path,coordi_df,epsg=cfg['xian_epsg'],reverse=False)   
    gpd2postSQL(vanishing_gpd,table_name='tourLine_vanishing',myusername=UN,mypassword=PW,mydatabase=DB) 
    
    vanishing_reverse_gpd=vanishing_sequence(tourLine_img_path,coordi_df,epsg=cfg['xian_epsg'],reverse=True) #[::-1] 
    gpd2postSQL(vanishing_reverse_gpd,table_name='tourLine_vanishing_reverse',myusername=UN,mypassword=PW,mydatabase=DB)    

    #C.数据平滑
    tourLine_vanishing_gdf=postSQL2gpd(table_name='tourLine_vanishing',geom_col=GC,myusername=UN,mypassword=PW,mydatabase=DB)
    length_moving=movingAverage(tourLine_vanishing_gdf.length,window=15)
    length_moving.plot(figsize=(20,10))    
    
    tourLine_vanishing_reverse_gdf=postSQL2gpd(table_name='tourLine_vanishing_reverse',geom_col=GC,myusername=UN,mypassword=PW,mydatabase=DB)
    length_moving_reverse=movingAverage(tourLine_vanishing_reverse_gdf.length,window=15)
    length_moving_reverse.plot(figsize=(20,10))    
    
    #D.计算消失距离长度，并按道路区段统计
    tourLine_segment={
                0:(0,39),
                1:(39,101),
                2:(101,191),
                3:(191,290),
                4:(290,367),
                5:(367,437),
                6:(437,462),
                7:(462,488),
                8:(488,565),
                9:(565,603)
                }
    img_fp_list_sorted=fns_sort_ordinal(tourLine_img_path,reverse=False)
    tourLine_vanishing_save_fn=os.path.join(parent_path,cfg['vanishing_position']['tourLine_vanishing_save_fn'])
    vanishing_dict=tourLine_segs_vanishing_position_length(tourLine_segment,img_fp_list_sorted,coordi_df,cfg['xian_epsg'],tourLine_vanishing_save_fn)
    with open(tourLine_vanishing_save_fn,'rb') as f:
        vanishing_dict=pickle.load(f)     
    segs_Vanishing_stat=segs_vanishing_statistics(vanishing_dict)    
    segs_vanishing_desc={k:segs_Vanishing_stat[k]['vanishing_length_desc'] for k in segs_Vanishing_stat.keys()}
    segs_vanishing_desc_df=pd.DataFrame.from_dict(segs_vanishing_desc)
    
    #E.图表打印
    tour_line_seg_gdf=postSQL2gpd(table_name='tour_line_seg',geom_col=GC,myusername=UN,mypassword=PW,mydatabase=DB)
    tourLine_segment_name={
                0:'Jianfu Temple Road',
                1:'North section of Zhuque Street',
                2:'Friendship Road',
                3:'Changan Road',
                4:'South Gate Bends',
                5:'South Street',
                6:'Bell Tower Loop',
                7:'West Street',
                8:'Hui Street',
                9:'Xihuamen Street' }
    vanishing_segment_mark_save_fn=os.path.join(parent_path,cfg['vanishing_position']['vanishing_segment_mark_save_fn'])
    vanishing_segment_mark(length_moving,length_moving_reverse,tourLine_segment,tourLine_segment_name,vanishing_segment_mark_save_fn)      
```


##### B.2.3.8 视域对象位置变化 

街道不同位置上的视域相对位置，即全景坐标位置的每一像素代表一个语义图像分割对象，随着实际街道位置的变化，全景坐标位置像素会根据对象的变化而不同，将每一次的变化记为1次，而不变记为0，则可以观察相对街道位置的变化程度。从计算结果可以判断，在视线水平位置下，及稍上变化幅度最大，正是居民生活的尺度；再往上的树木和建筑空间因为高于人们的街道生活空间，变化开始减小；地面区域，因为受到全景图拍摄车的影响，不能解释地面的变化。同时，街道空间为线性空间，街道两侧对象变化幅度相对偏高，而前后相对偏弱。

__Fig. 视域对象位置变化累加值__ 

<a href=""><img src="./imgs/3_2_1_22.jpg" height="auto" width="auto" title="caDesign"></a>

__Fig. 视域对象位置变化累加值-球面全景显示__ 


<a href=""><img src="./imgs/3_2_1_23.gif" height="auto" width="auto" title="caDesign"></a>

__Fig. 视域对象位置变化累加值-重分类__ 

<a href=""><img src="./imgs/3_2_1_24.jpg" height="auto" width="auto" title="caDesign"></a>

`visual_field_objects_position_changes.py`
```python
# -*- coding: utf-8 -*-
"""
Created on Thu Apr 29 21:45:02 2021
Updated on Tue Feb  1 15:01:34 2022

@author: Richie Bao-caDesign设计(cadesign.cn)
"""
label_color={
    0:(117,115,102), #"pole",
    1:(212,209,156),#"slight",
    2:(224,9,9),#"bboard",
    3:(227,195,66),#"tlight",
    4:(137,147,169),#"car",
    5:(53,67,98),#"truck",
    6:(185,181,51),#"bicycle",
    7:(238,108,91),#"motor",
    8:(247,5,5),#"bus",
    9:(127,154,82),#"tsignf",
    10:(193,209,167),#"tsignb",
    11:(82,83,76),#"road",
    12:(141,142,133),#"sidewalk",
    13:(208,212,188),#"curbcut",
    14:(98,133,145),#"crosspln",
    15:(194,183,61),#"bikelane",
    16:(141,139,115),#"curb",
    17:(157,186,133),#"fence",
    18:(114,92,127),#"wall",
    19:(78,61,76),#"building",
    20:(100,56,67),#"person",
    21:(240,116,148),#"rider",
    22:(32,181,191),#"sky",
    23:(55,204,26),#"vege",
    24:(84,97,82),#"terrain",
    25:(231,24,126),#"markings",
    26:(141,173,166),#"crosszeb",
    27:(0,0,0),#"Nan",                
    }

def spherical_segs_pts_show(label_seg_fn,label_color):
    '''
    点云方式显示语义分割球面全景

    Parameters
    ----------
    label_seg_fn : string（pkl）
        全景图语义分割标签根目录.
    label_color : dict
        自定义的分类颜色值.

    Returns
    -------
    None.

    '''
    import numpy as np
    from mayavi import mlab
    
    fig=mlab.figure(size=(600, 600))    
    print(label_seg_fn)
    with open(label_seg_fn,'rb') as f:
        label_seg=pickle.load(f).numpy()             
    print('\nseg shape={}'.format(label_seg.shape))
    
    # define a grid matching the map size, subsample along with pixels
    theta=np.linspace(0, np.pi, label_seg.shape[0])
    phi=np.linspace(0, 2*np.pi, label_seg.shape[1])        
    print("theta shape={};phi shape={}".format(theta.shape,phi.shape))        
    theta,phi=np.meshgrid(theta, phi)
    print("theta shape={};phi shape={}".format(theta.shape,phi.shape))
    
    label_seg_color=np.array([label_color[v] for v in label_seg.flatten()]).reshape((label_seg.shape[0],label_seg.shape[1],3))
    print("\nlabel_seg_color shape={}".format(label_seg_color.shape))    

    R=10
    x=R * np.sin(theta) * np.cos(phi)
    y=R * np.sin(theta) * np.sin(phi)
    z=R * np.cos(theta)                
    print("x,y,z shape={},{},{}".format(x.shape,y.shape,z.shape))       
    mask=label_seg==22
    mlab.points3d(x.T, y.T, z.T, label_seg_color[:,:,0]/255,) #opacity=0.75,scale_factor=0.1        
    theta_phi=np.dstack((theta,phi))   
    mlab.show()

def fns_sort(fns_list):
    '''
    对文件名末尾含‘_number’，例如img_0.jpg的多个文件排序

    Parameters
    ----------
    fns_list : list
        文件路径名列表.

    Returns
    -------
    fns_dict_sorted : list
        排序后的文件路径名列表.

    '''
    from pathlib import Path  
    
    fns_dict={int(Path(p).stem.split('_')[-1]):p for p in fns_list}
    fns_dict_key=list(fns_dict.keys())
    fns_dict_key.sort()
    fns_dict_sorted=[fns_dict[k] for k in fns_dict_key]    
    return fns_dict_sorted  
    
def panorama_object_change(label_seg_path,label_color,img_save_path,pixels_diff_array_save_path):
    '''
    视域对象位置变化

    Parameters
    ----------
    label_seg_path : string
        全景图语义分割标签根目录.
    label_color : dict
        自定义的分类颜色值.
    img_save_path : string
        图像保存路径名.
    pixels_diff_array_save_path : string
        视域对象位置变化数组保存根目录.

    Returns
    -------
    img_object_change : Image
        视域对象位置变化图像.
    pixels_diff_array_standardization : array
        视域对象位置变化标准化数组.

    '''
    from tqdm import tqdm
    import os 
    import pickle
    import numpy as np
    from pathlib import Path   
    from sklearn import preprocessing
    from PIL import Image
  
    label_seg_fns=glob.glob(os.path.join(label_seg_path,'*.pkl'))
    label_seg_fns_sorted=fns_sort(label_seg_fns)   
    
    pixels={}
    # i=0
    for label_seg_fn in tqdm(label_seg_fns_sorted):
        with open(label_seg_fn,'rb') as f:
            label_seg=pickle.load(f).numpy()            
        fn_stem=Path(label_seg_fn).stem
        fn_key,fn_idx=fn_stem.split("_")        
        pixels[fn_stem]=label_seg.flatten()        
        
        # if i==10:break        
        # i+=1
    img_pixels_df=pd.DataFrame.from_dict(pixels,orient='index')
    pixels_diff=img_pixels_df.diff()
    pixels_diff[pixels_diff!=0]=1
    # print(img_pixels_df)
    pixels_diff_sum=pixels_diff.sum(axis=0)
    pixels_diff_array=np.array(pixels_diff_sum).reshape(label_seg.shape)
    
    min_max_scaler=preprocessing.MinMaxScaler()
    pixels_diff_array_standardization=min_max_scaler.fit_transform(pixels_diff_array)
    img_object_change=Image.fromarray(np.uint8(pixels_diff_array_standardization * 255) , 'L')
    
    img_object_change.save(os.path.join(img_save_path,'img_object_change.jpg'))
    with open(os.path.join(pixels_diff_array_save_path,'pixels_diff_array_standardization.pkl'),'wb') as f:
        pickle.dump(pixels_diff_array_standardization,f)    
    with open(os.path.join(pixels_diff_array_save_path,'pixels_diff_array.pkl'),'wb') as f:
        pickle.dump(pixels_diff_array,f)          
    
    return img_object_change,pixels_diff_array_standardization

def auto_sphere(image_file):
    '''
    全景图转换为球面全景

    Parameters
    ----------
    image_file : string
        图像路径名.

    Returns
    -------
    None.

    '''
    from mayavi import mlab
    from tvtk.api import tvtk
    # create a figure window (and scene)
    fig = mlab.figure(size=(600, 600))
    # load and map the texture
    img = tvtk.JPEGReader()
    img.file_name = image_file
    texture = tvtk.Texture(input_connection=img.output_port, interpolate=1)
    # use a TexturedSphereSource, a.k.a. getting our hands dirty
    R = 1
    Nrad = 180
    # create the sphere source with a given radius and angular resolution
    sphere = tvtk.TexturedSphereSource(radius=R, theta_resolution=Nrad,phi_resolution=Nrad)
    # assemble rest of the pipeline, assign texture    
    sphere_mapper = tvtk.PolyDataMapper(input_connection=sphere.output_port)
    sphere_actor = tvtk.Actor(mapper=sphere_mapper, texture=texture)
    fig.scene.add_actor(sphere_actor)
    
    mlab.show() 
    
def spherical_img_pts_show(panorama_fn,FOV=False):
    '''
    点云方式显示全景图为球面全景，含标注信息

    Parameters
    ----------
    panorama_fn : string
        图像路径名.
    FOV : bool, optional
        球面裁切. The default is False.

    Returns
    -------
    None.

    '''
    import numpy as np
    import matplotlib.pyplot as plt
    from mayavi import mlab
    import math
    
    img=plt.imread(panorama_fn)       
    print('\nseg shape={}'.format(img.shape))
    
    # define a grid matching the map size, subsample along with pixels
    theta=np.linspace(0, np.pi, img.shape[0])
    phi=np.linspace(0, 2*np.pi, img.shape[1])        
    print("theta shape={};phi shape={}".format(theta.shape,phi.shape))    
    theta,phi=np.meshgrid(theta, phi)
    theta=theta.T
    phi=phi.T
       
    print("theta shape={};phi shape={}".format(theta.shape,phi.shape))
    theta_phi=np.dstack((theta,phi))
    if FOV==True:
        verticalFOV_limit_ofVisual_field=[50,90-(-70)]
        horizontalFOV_visual_limit_field=[62,90-(-62)]
        horizontal_offset=0
        
        verticalFOV_limit_ofVisual_field_radians=[math.radians(d) for d in verticalFOV_limit_ofVisual_field]
        horizontalFOV_visual_limit_field_radians=[math.radians(d) for d in horizontalFOV_visual_limit_field]
        horizontal_offset_radians=math.radians(horizontal_offset)
        print(verticalFOV_limit_ofVisual_field_radians,horizontalFOV_visual_limit_field_radians,horizontal_offset_radians)
        
        mask=np.bitwise_and(theta>=verticalFOV_limit_ofVisual_field_radians[0], theta<=verticalFOV_limit_ofVisual_field_radians[1])
        theta=theta[mask]
        phi=phi[mask]
        img=img[mask]               

    R=50
    # sphere
    x=R * np.sin(theta) * np.cos(phi)
    y=R * np.sin(theta) * np.sin(phi)
    z=R * np.cos(theta)                
    print("x,y,z shape={},{},{}".format(x.shape,y.shape,z.shape))       

    # print(img)
    fig=mlab.figure(size=(600, 600),bgcolor=(1, 1, 1))  
    mlab.points3d(x, y, z, img/255,scale_factor=.25) #opacity=0.75,scale_factor=0.1     
    mlab.points3d(0, 0, 0,scale_factor=3,color=(1,0,0))
    
    # Plot the equator and the tropiques
    theta_equator=np.linspace(0, 2 * np.pi, 100)
    veiw_scope_dic={}
    for i,angle in enumerate([-math.radians(70), 0, math.radians(50)]):
        x_equator=R * np.cos(theta_equator) * np.cos(angle)
        y_equator=R * np.sin(theta_equator) * np.cos(angle)
        z_equator=R * np.ones_like(theta_equator) * np.sin(angle)    
        mlab.plot3d(x_equator, y_equator, z_equator, color=(0, 0, 0),opacity=0.6, tube_radius=None)  
        veiw_scope_dic[i]=[x_equator,y_equator,z_equator]
    
    str_info={0:'lower limit of visual filed:-70',1:'Standard line of sight:0',2:'Upper limit of visual filed:+50'}
    for k,v in str_info.items():
        mlab.text(veiw_scope_dic[k][0][0], veiw_scope_dic[k][1][0], v, z=veiw_scope_dic[k][2][0],width=0.025 * len(v), name=v,color=(0,0,0))
    
    vertical_label_radians=np.linspace(0, np.pi,14)
    vertical_label_degree=["{:.2f}".format(90-math.degrees(radi)) for radi in vertical_label_radians]
    phi_label=0
    for idx in range(len(vertical_label_radians)):
        theta_labe=vertical_label_radians[idx]
        x_label=R * np.sin(theta_labe) * np.cos(phi_label)
        y_label=R * np.sin(theta_labe) * np.sin(phi_label)
        z_label=R * np.cos(theta_labe)         
        mlab.points3d(x_label, y_label, z_label,scale_factor=1,color=(0,0,0))
        label=vertical_label_degree[idx]
        mlab.text(x_label, y_label, label, z=z_label,width=0.02 * len(label), name=label,color=(0,0,0))        
    mlab.show()    
    
def array_classifier_label(array,save_path,n_classes=9,figsize=(30,15)):
    '''
    重分类数组（图像）

    Parameters
    ----------
    array : array
        待重分类的数组（图像）.
    save_path : string
        图像保存根目录.
    n_classes : int, optional
        重分类数. The default is 9.
    figsize : tuple, optional
        图像打印大小. The default is (30,15).

    Returns
    -------
    None.

    '''
    import mapclassify as mc
    import numpy as np
    import pandas as pd
    from sklearn import preprocessing
    import matplotlib.pyplot as plt
    import matplotlib
    
    font = {
            # 'family' : 'normal',
            # 'weight' : 'bold',
            'size'   : 28}
    matplotlib.rc('font', **font)
    title_fontsize=55

    vertical_label_degree=90-np.linspace(0, 180,17)
    horizontal_label_degree=180-np.linspace(0, 360,17)    
    print(horizontal_label_degree)
 
    pano_height,pano_width,=array.shape
    print(pano_width,pano_height)    

    fig, ax=plt.subplots(figsize=figsize)    
    array_shape=array.shape
    array_flatten=array.flatten()
    classifier=mc.NaturalBreaks(array_flatten,k=n_classes)
    print(classifier)
    
    classifications=pd.DataFrame(array).apply(classifier)
    classifications_array=classifications.to_numpy().reshape(array_shape)
    
    min_max_scaler=preprocessing.MinMaxScaler()
    classifications_array_standardization=min_max_scaler.fit_transform(classifications_array)
    
    ax.imshow(np.uint8(classifications_array_standardization * 255),) #cmap=cm.gray
    ax.set_yticks(np.linspace(0,pano_height,len(vertical_label_degree)))    
    ax.set_yticklabels(vertical_label_degree) # provide name to the x axis tick marks   
    ax.set_xticks(np.linspace(0,pano_width,len(horizontal_label_degree)))    
    ax.set_xticklabels(horizontal_label_degree) # provide name to the x axis tick marks   
    ax.axhline(y=pano_height/2,color='r',linestyle='-.',linewidth=1)
    ax.axvline(x=pano_width/2,color='r',linestyle='-.',linewidth=1)    
    plt.legend()
    plt.savefig(os.path.join(save_path,'classifications_object_change.jpg'))    
    # plt.show()    
    
if __name__=="__main__":
    import pickle
    import pandas as pd
    import sys,os,glob
    sys.path.append('..')      
    from database import postSQL2gpd,gpd2postSQL,cfg_load_yaml 
    parent_path=os.path.dirname(os.getcwd())
    cfg=cfg_load_yaml('../config.yml')  
    
    UN=cfg["postgreSQL"]["myusername"]
    PW=cfg["postgreSQL"]["mypassword"]
    DB=cfg["postgreSQL"]["mydatabase"]  
    GC='geometry' 
    
    label_seg_path=cfg['panaSeg_street']['tourline_label_seg']
    from vanishing_position import fns_sort_ordinal
    label_seg_fns=fns_sort_ordinal(label_seg_path,suffix='pkl')
    
    #A. 点云方式显示语义分割球面全景
    spherical_segs_pts_show(label_seg_fns[10],label_color)
    
    #B.视域对象位置变化及打印球面全景
    img_object_change_path=os.path.join(parent_path,cfg['visual_field_objects_position_changes']['img_object_change_path'])
    pixels_diff_array_pkl_save_path=os.path.join(parent_path,cfg['visual_field_objects_position_changes']['pixels_diff_array_pkl_save_path'])
    img_object_change,pixels_diff_array_standardization=panorama_object_change(label_seg_path,label_color,img_object_change_path,pixels_diff_array_pkl_save_path)
    
    img_object_change_fn=os.path.join(img_object_change_path,'img_object_change.jpg')
    auto_sphere(img_object_change_fn) #全景图转换为球面全景
    spherical_img_pts_show(img_object_change_fn,FOV=False) #点云方式显示全景图为球面全景，含标注信息
    
    #C.重分类数组（图像）
    with open(os.path.join(pixels_diff_array_pkl_save_path,'pixels_diff_array_standardization.pkl'),'rb') as f:
        pixels_diff_array_standardization=pickle.load(f)      
    array_classifier_label(pixels_diff_array_standardization,img_object_change_path,n_classes=5)
```


##### B.2.3.9 街道行业分类服务空间组成结构

每一位置点建立350m的缓冲区域，提取落于缓冲区内的POI点数据。计算每一位置点对应的POI点数量，信息熵和均衡度如图左1、2。POI的数量越多，街道空间提供的服务越多，其中数量最多的区域为中贸广场商业圈，最少的区域位于朱雀大街北段和荐福寺路。而均衡度最大的区域在POI数量最少的区域，是因为主要的行业分类，例如购物、生活服务、美食和酒店等在该区域分布较少，减少了不同行业数量的差异。

__Fig. 指数与聚类__ 

<a href=""><img src="./imgs/3_2_1_25.png" height="auto" width=600 title="caDesign"></a>

借鉴视觉词袋构建特征映射的方法，计算每一位置点一级行业分类的频数即特征映射（码本映射），然后进行空间距离关联的AgglomerativeClustering层次聚类。以聚类数12为例， 特征贡献度如表，以丽人分值500为界，之下行业分类较多多于之上分类的贡献度，这与居民日常生活需求相关联。通常需求越多的行业分类，其贡献度也会较高。

|    | Factor | Score    | p_value | poi_name                |
|----|--------|----------|---------|-------------------------|
| 24 | 24     | inf      | 0       | businessDistrict        |
| 23 | 23     | 1295.732 | 0       | subwayStop              |
| 19 | 19     | 1105.765 | 0       | administrativeLandmarks |
| 2  | 2      | 922.863  | 0       | shopping                |
| 0  | 0      | 920.428  | 0       | delicacy                |
| 20 | 20     | 900.62   | 0       | address                 |
| 4  | 4      | 855.991  | 0       | beauty                  |
| 17 | 17     | 766.926  | 0       | entrance                |
| 1  | 1      | 743.639  | 0       | hotel                   |
| 3  | 3      | 724.401  | 0       | lifeService             |
| 16 | 16     | 652.263  | 0       | government              |
| 8  | 8      | 606.163  | 0       | education               |
| 12 | 12     | 563.747  | 0       | trafficFacilities       |
| 13 | 13     | 437.455  | 0       | finance                 |
| 15 | 15     | 420.55   | 0       | corporation             |
| 6  | 6      | 392.76   | 0       | entertainment           |
| 11 | 11     | 318.319  | 0       | carService              |
| 10 | 10     | 307.029  | 0       | medicalTreatment        |
| 21 | 21     | 292.361  | 0       | road                    |
| 9  | 9      | 290.681  | 0       | media                   |
| 22 | 22     | 277.675  | 0       | busStop                 |
| 5  | 5      | 202.642  | 0       | spot                    |
| 7  | 7      | 173.217  | 0       | sports                  |
| 14 | 14     | 166.79   | 0       | realEstate              |
| 18 | 18     |          |         | naturalFeatures         |


每一簇下，POI的总数和行业类频数会有所差异，从图可以观察到，虽然各簇的总数有明显不同，但是生活服务（lifeService）、美食（delicacy）和购物（shopping）通常占据组要成分。行业分类频数的组合结构表征了每一簇的服务特点。

__Fig. 簇的行业类别频数__ 

<a href=""><img src="./imgs/3_2_1_26.png" height="auto" width="auto" title="caDesign"></a>

`POI_street_feature.py`
```python
# -*- coding: utf-8 -*-
"""
Created on Wed May 19 10:28:35 2021
Updated on Tue Feb  1 19:50:14 2022

@author: Richie Bao-caDesign设计(cadesign.cn)
"""
poi_classificationName_={
        "美食":"delicacy",
        "酒店":"hotel",
        "购物":"shopping",
        "生活服务":"lifeService",
        "丽人":"beauty",
        "旅游景点":"spot",
        "休闲娱乐":"entertainment",
        "运动健身":"sports",
        "教育培训":"education",
        "文化传媒":"media",
        "医疗":"medicalTreatment",
        "汽车服务":"carService",
        "交通设施":"trafficFacilities",
        "金融":"finance",
        "房地产":"realEstate",
        "公司企业":"corporation",
        "政府机构":"government",
        "出入口":"entrance",
        "自然地物":"naturalFeatures",        
        "行政地标":"administrativeLandmarks",
        "门址":"address",       
        "道路":"road",
        "公交车站":"busStop",
        "地铁站":"subwayStop",
        "商圈":"businessDistrict",
        }

poi_classificationName={
        0:"delicacy",
        1:"hotel",
        2:"shopping",
        3:"lifeService",
        4:"beauty",
        5:"spot",
        6:"entertainment",
        7:"sports",
        8:"education",
        9:"media",
        10:"medicalTreatment",
        11:"carService",
        12:"trafficFacilities",
        13:"finance",
        14:"realEstate",
        15:"corporation",
        16:"government",
        17:"entrance",
        18:"naturalFeatures", 
        19:"administrativeLandmarks",
        20:"address",
        21:"road",
        22:"busStop",
        23:"subwayStop",
        24:"businessDistrict"        
        }
poi_classificationName_reverse={v:k for k,v in poi_classificationName.items()}

def street_poi_structure(poi,position,save_fn,distance=350):
    '''
    计算给定道路上点，指定半径内，POI的组成结构，包括：数量、一级分类占比、频数、信息熵

    Parameters
    ----------
    poi : GeoDataFrame
        poi数据，含提取的一级分类标签，列名为'level_0'.
    position : GeoDataFrame
        道路采样点，用排序的'geometry'列.
    save_fn : string
        数据保存路径名 为.pkl.
    distance : numerical val, optional
        缓冲半径. The default is 350.

    Returns
    -------
    pos_poi_idxes_gdf : GeoDataFrame
        含数量、一级分类占比、信息熵.
    pos_poi_feature_vector_gdf : GeoDataFrame
        频数信息.

    '''
    from tqdm import tqdm
    import pickle,math
    import pandas as pd
    import numpy as np
    import geopandas as gpd

    poi_num=len(poi_classificationName.keys())    
    feature_vector=np.zeros(poi_num)
    
    poi_=poi.copy(deep=True)
    pos_poi_dict={}
    pos_poi_idxes_df=pd.DataFrame(columns=['geometry','frank_e','num'])
    pos_poi_feature_vector_df=pd.DataFrame(columns=['geometry']+list(range(poi_num)))
    for idx,row in tqdm(position.iterrows(),total=position.shape[0]):
        poi_['within']=poi_.geometry.apply(lambda pt: pt.within(row.geometry.buffer(distance)))
        poi_selection_df=poi_[poi_['within']==True]
        counts=poi_selection_df.level_0.value_counts().to_dict()
        num=len(poi_selection_df)
        counts_percent={k:v/num for k,v in counts.items()}        
        ve=0.0
        for v in counts_percent.values():
            if v!=0.:
                ve-=v*math.log(v)
        max_entropy=math.log(num)
        frank_e=ve/max_entropy*100        
        
        for k,v in counts.items(): #计算特征聚类出现的频数/直方图
            poi_name=k.split("_")[-1]
            poi_idx=poi_classificationName_reverse[poi_name]
            feature_vector[poi_idx]=v        
        pos_poi_dict.update({idx:{'fn_stem':row.fn_stem, 'fn_key':row.fn_key, 'fn_idx':row.fn_idx ,'counts':counts,'counts_percent':counts_percent,'feature_vector':feature_vector,'num':num,'frank_e':frank_e,'geometry':row.geometry}})
        pos_poi_idxes_df=pos_poi_idxes_df.append({'fn_stem':row.fn_stem, 'fn_key':row.fn_key, 'fn_idx':row.fn_idx,'geometry':row.geometry,'frank_e':frank_e,'num':num},ignore_index=True)
        feature_vector_dict={i:feature_vector[i] for i in range(len(feature_vector))}
        feature_vector_dict.update({'geometry':row.geometry,'fn_stem':row.fn_stem, 'fn_key':row.fn_key, 'fn_idx':row.fn_idx,})
        pos_poi_feature_vector_df=pos_poi_feature_vector_df.append(feature_vector_dict,ignore_index=True)
        
        # if idx==3:break        
    pos_poi_idxes_gdf=gpd.GeoDataFrame(pos_poi_idxes_df,geometry=pos_poi_idxes_df.geometry,crs=position.crs)   
    pos_poi_idxes_gdf['num_diff']=pos_poi_idxes_gdf.num.diff()
    pos_poi_feature_vector_gdf=gpd.GeoDataFrame(pos_poi_feature_vector_df,geometry=pos_poi_feature_vector_df.geometry,crs=position.crs)   
    with open(save_fn,'wb') as f:
        pickle.dump(pos_poi_dict,f)    
        
    return pos_poi_idxes_gdf,pos_poi_feature_vector_gdf

def poi_feature_clustering(feature_vector,fields,save_fn,n_clusters=7,n_neighbors=10,feature_analysis=True):
    '''
    poi聚类及最优簇数和特征贡献度计算

    Parameters
    ----------
    feature_vector : GeoDataFrame
        频数信息.
    fields : list
        指定参与聚类计算的列名.
    save_fn : string
        特征贡献度保存路径名.
    n_clusters : int, optional
        聚类数量. The default is 7.
    n_neighbors:int
        邻元数
    feature_analysis : bool, optional
        是否计算特征贡献度. The default is True.

    Returns
    -------
    feature_vector : GeoDataFrame
        返回聚类.

    '''
    import pandas as pd
    from sklearn.neighbors import NearestNeighbors
    from sklearn import cluster  
    from yellowbrick.cluster import KElbowVisualizer    
    from sklearn.preprocessing import normalize
    import matplotlib.pyplot as plt
    from sklearn.feature_selection import SelectKBest,f_classif
    from sklearn.neighbors import kneighbors_graph
    
    pts_geometry=feature_vector[['geometry']]    
    pts_geometry[['x','y']]=pts_geometry.geometry.apply(lambda row:pd.Series([row.x,row.y]))
    pts_coordis=pts_geometry[['x','y']].to_numpy()
    connectivity=kneighbors_graph(pts_coordis,n_neighbors,include_self=False)
    
    X_=feature_vector[fields].to_numpy()
    X=normalize(X_,axis=0, norm='max')    

    clustering=cluster.AgglomerativeClustering(connectivity=connectivity,n_clusters=n_clusters).fit(X)
    feature_vector['clustering']=clustering.labels_
    
    #_________________________________________________________________________
    if feature_analysis==True:
        y=clustering.labels_
        selector=SelectKBest(score_func=f_classif, k=len(fields)) #score_func=chi2    
        selector.fit(X,y)
        
        dfscores = pd.DataFrame(selector.scores_)
        dfpvalues=pd.DataFrame(selector.pvalues_)
        dfcolumns = pd.DataFrame(fields)  
        featureScores = pd.concat([dfcolumns,dfscores,dfpvalues],axis=1)
        featureScores.columns = ['Factor','Score','p_value']  #naming the dataframe columns
        featureScores['Factor']=featureScores['Factor'].apply(lambda row:int(row))
        featureScores['poi_name']=featureScores['Factor'].map(poi_classificationName)
        featureScores=featureScores.sort_values(by=['Score']).round(3)
        print(featureScores)
        featureScores.to_excel(save_fn) 
        
        featureScores_=featureScores.set_index('Factor')    
        featureScores_.nlargest(len(fields),'Score').Score.plot(kind='barh',figsize=(30,20),fontsize=38)
        featureScores_.Score.plot(kind='barh')
        plt.show()    
        
        clustering_=cluster.AgglomerativeClustering(connectivity=connectivity,) #n_clusters=n_clusters
        visualizer = KElbowVisualizer(clustering_, timings=False,size=(500, 500), k=(4,12)) #k=(4,12) metric='calinski_harabasz'
        visualizer.fit(X)    # Fit the data to the visualizer
        # visualizer.show(outpath="./graph/tl_poi_clustering_KEIbow_.png")    # Finalize and render the figure   
    return feature_vector 

def clustering_POI_stats(df,save_fn):
    '''
    poi聚类业态频数打印

    Parameters
    ----------
    df : DataFrame
        聚类业态类频数.
    save_fn : string
        图像保存路径.

    Returns
    -------
    None.

    '''
    from matplotlib import cm
    import matplotlib.pyplot as plt
    
    stats_sum=df.groupby(['clustering_POI']).sum()
    stats_sum=stats_sum.rename(columns={str(k):v for k,v in poi_classificationName.items()})
    print(stats_sum)   
    fig, ax=plt.subplots(figsize=(30, 12),) #figsize=(40, 20),
    cmap=cm.get_cmap('tab20') # Colour map (there are many others)
    plot=stats_sum.plot(kind='bar',stacked=True, legend=True,ax=ax,rot=0,fontsize=35,cmap=cmap)
    ax.set_facecolor("w")
    plt.legend(prop={"size":20},bbox_to_anchor=(1, 1))
    plt.savefig(save_fn,dpi=300,bbox_inches="tight")
    plt.show()

if __name__=="__main__":
    import geopandas as gpd
    import pickle
    import pandas as pd
    import sys,os
    sys.path.append('..')      
    from database import postSQL2gpd,gpd2postSQL,cfg_load_yaml 
    parent_path=os.path.dirname(os.getcwd())
    cfg=cfg_load_yaml('../config.yml')  
    
    UN=cfg["postgreSQL"]["myusername"]
    PW=cfg["postgreSQL"]["mypassword"]
    DB=cfg["postgreSQL"]["mydatabase"]  
    GC='geometry'  
    
    #A.计算街道行业分类服务空间组成结构，包括数量、一级分类占比、频数、信息熵等
    poi_gdf=postSQL2gpd(table_name='poi',geom_col=GC,myusername=UN,mypassword=PW,mydatabase=DB)
    poi_gdf=poi_gdf.to_crs(cfg['xian_epsg'])
    poi_gdf=poi_gdf[pd.notnull(poi_gdf['detail_info_tag'])]
    poi_gdf['level_0']=poi_gdf.detail_info_tag.apply(lambda row:poi_classificationName_[row.split(";")[0]])
    
    tourLine_panorama_object_percent_table_name=cfg['vanishing_position']['tourLine_panorama_object_percent_table_name']  
    tourLine_panorama_object_percent_gdf=postSQL2gpd(table_name=tourLine_panorama_object_percent_table_name,geom_col=GC,myusername=UN,mypassword=PW,mydatabase=DB)
    coordi_df=tourLine_panorama_object_percent_gdf.sort_values(by='fn_idx')
    coordi_df=coordi_df.to_crs(cfg['xian_epsg'])    
    
    pos_poi_dict_pkl_fn=os.path.join(parent_path,cfg['POI_street_feature']['pos_poi_dict_pkl_fn'])
    buffer_radius=cfg['POI_street_feature']['buffer_radius']
    pos_poi_idxes_gdf,pos_poi_feature_vector_gdf=street_poi_structure(poi=poi_gdf,position=coordi_df,save_fn=pos_poi_dict_pkl_fn,distance=buffer_radius)
    gpd2postSQL(pos_poi_idxes_gdf,table_name='pos_poi_idxes',myusername=UN,mypassword=PW,mydatabase=DB) 
    gpd2postSQL(pos_poi_feature_vector_gdf,table_name='pos_poi_feature_vector',myusername=UN,mypassword=PW,mydatabase=DB) 
    
    #B.poi聚类及最优簇数和特征贡献度计算
    pos_poi_feature_vector_gdf=postSQL2gpd(table_name='pos_poi_feature_vector',geom_col=GC,myusername=UN,mypassword=PW,mydatabase=DB)
    fields=[str(i) for i in poi_classificationName.keys()]
    featureScores_save_fn=os.path.join(parent_path,cfg['POI_street_feature']['featureScores_save_fn'])
    n_clusters=12 #7,12
    n_neighbors=10
    feature_vector=poi_feature_clustering(pos_poi_feature_vector_gdf,fields,featureScores_save_fn,n_clusters=n_clusters,n_neighbors=n_neighbors,feature_analysis=True)
    gpd2postSQL(feature_vector,table_name='pos_poi_feature_vector_{}'.format(n_clusters),myusername=UN,mypassword=PW,mydatabase=DB) 
    
    #C.poi聚类业态频数打印
    feature_vector=postSQL2gpd(table_name='pos_poi_feature_vector_{}'.format(n_clusters),geom_col=GC,myusername=UN,mypassword=PW,mydatabase=DB)
    pos_poi_feature_vector_gdf['clustering_POI']=feature_vector['clustering']
    clustering_POI_stats_save_fn=os.path.join(parent_path,cfg['POI_street_feature']['clustering_POI_stats_save_fn'])
    clustering_POI_stats(pos_poi_feature_vector_gdf[fields+['clustering_POI']],clustering_POI_stats_save_fn)
```

### B.3 讨论与结论



#### B.参考文献


## B. 研究代码更新与发布




