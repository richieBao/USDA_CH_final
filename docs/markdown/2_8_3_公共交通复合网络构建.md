> Created on Wed Dec 28 10:36:48 2022 @author: Richie Bao-caDesign设计(cadesign.cn)

## 2.8.3 公共交通复合网络构建

### 2.8.3.1 数据预处理

南京（32°4'N，118°47'E）为中国东部地区重要的中心城市，江苏省省会，南京都市圈核心城市，常住人口850万人。公共交通网络（图1）包括地铁系统和公交系统，其地铁线路长度居中国第6位、世界第7位，10条线路覆盖全市13个市辖区县，包含站点348个；其公交线路1 304条（往返），包含站点32 660个，日均客流量约200万人次。南京市公共交通线路和站点数据（2020年数据），以及人口分布数据（425×425 m间隔的采样点，2020年数据）均来源于中国专业IT社区[CSDN（Chinese Software Developer Network）](https://www.csdn.net/)<sup>①</sup>的开放数据。其中公共交通（地铁和公交）的站点数据包括站点名称和ID、所属线路名称和ID、经纬度坐标等；线路数据包括线路名称和ID、几何对象等。人口分布数据包括采样点经纬度坐标、人口数等。根据南京市绿化园林局发布的《南京市绿地系统规划》中心城区规划综合公园一览表中确定保留和扩建的53个综合公园作为研究对象，在Google Earth中绘制各个公园范围边界。

> 参数管理使用`AttrDict()`方法（具体查看“Cityscapes数据集——参数管理”一节）。db子属性存储数据库信息；gi子属性存储地理坐标投影信息；data子属性存储数据文件路径。


```python
from database import postSQL2gpd,gpd2postSQL,df2postSQL,postSQL2df
from util_misc import AttrDict
import warnings
warnings.filterwarnings('ignore')

__C=AttrDict() 
args=__C

__C.db=AttrDict() 
__C.db.UN='postgres'
__C.db.PW='123456'
__C.db.DB='public_transportation'
__C.db.GC='geometry' 
__C.db.db_info=dict(geom_col=args.db.GC,myusername=args.db.UN,mypassword=args.db.PW,mydatabase=args.db.DB)

__C.gi=AttrDict()
__C.gi.nanjing_epsg=32650
__C.gi.beijing_epsg=32750
__C.gi.epsg_wgs84=4326

__C.data=AttrDict()
__C.data.bus_routes='./data/nanjing_bus_route_and_station/bus_routes.shp' # 公交站
__C.data.bus_stations='./data/nanjing_bus_route_and_station/bus_stations.shp' # 公交线路
__C.data.subway_stations='./data/nanjing_subway_station_and_line/subway_stations.shp' # 地铁站
__C.data.subway_lines='./data/nanjing_subway_station_and_line/subway_lines.shp' # 地铁线路
__C.data.region='./data/nanjing_region/region.shp' # 南京市域边界
__C.data.administrative_districts='./data/nanjing_administrative_districts/nanjing_administrative_districts.shp' # 南京行政区划
__C.data.population='./data/nanjing_population/population.shp' # 南京人口分布
__C.data.comprehensive_park='./data/NanjingParks.kml' # 南京公园
__C.data.geolife='G:\data\Geolife' # Geolife GPS trajectory 数据集（下载的原始数据）
__C.data.geolife_gdf='E:\data\geolife.gpkg' # Geolife GPS trajectory 数据集（合并后存储的数据对象）
```

#### 1) 公交和地铁站点及路径数据读写

* 南京省市边界读写

将“不平等性和空间隔离”一章中定义的`shp2gdf()`函数置于模块`database`中调用读取SHP数据格式文件为GeoDataFrame格式。


```python
from database import shp2gdf

region=shp2gdf(args.data.region,epsg=args.gi.nanjing_epsg)
region.plot(color='none', edgecolor='red');
region
```

    original data info:(1, 3)
    dropna-how=all,result:(1, 3)
    dropna-several rows,result:(1, 3)
    EPSG:32650
    




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>NAME</th>
      <th>KIND</th>
      <th>geometry</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>南京市</td>
      <td>0137</td>
      <td>POLYGON ((661383.381 3609433.909, 661397.682 3...</td>
    </tr>
  </tbody>
</table>
</div>



<img src="./imgs/2_8_3/output_4_2.png" height='auto' width='auto' title="caDesign">
    
    


将市域边界写入名为“public_transportation”的数据库中，表名为'region'。


```python
gpd2postSQL(region,table_name='region',**args.db.db_info)   
```

    __________________________________________________
    The GeoDataFrame has been written to the PostgreSQL database.The table name is region.
    

* 南京公交线路读写

读取SHP格式南京公交线路数据为GeoDataFrame格式，并写入数据库，表名为'bus_routes'。读取数据时，指定了`boundary`参数配置裁切边界为市域边界矩形区域的包络线。同时中文字体为GBK编码。


```python
bus_routes=shp2gdf(args.data.bus_routes,epsg=args.gi.nanjing_epsg,boundary=region.envelope[0],encoding='GBK')
```

    original data info:(1304, 9)
    dropna-how=all,result:(1304, 8)
    dropna-several rows,result:(1304, 8)
    EPSG:32650
    


```python
import matplotlib.pyplot as plt
fig, ax=plt.subplots(figsize=(10,10))
bus_routes.plot(ax=ax,edgecolor='black',linewidth=0.5,zorder=1)
plt.show()
```

<img src="./imgs/2_8_3/output_9_0.png" height='auto' width='auto' title="caDesign">
    

    


公交线路的字段（列名）包括线路名`LineName`，线路ID`LineUid`，运营开始时间`StartTime`，运营结束时间`EndTime`，工作日和周末运营时间`WorkTimeDe`，方向`Direction`，价格`Price`和Polyline几何对象`geometry`等。其中公交线路和公交站点各自数据中均有，用于链接的字段为`LineUid`。


```python
bus_routes.head(3)
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>LineName</th>
      <th>LineUid</th>
      <th>StartTime</th>
      <th>EndTime</th>
      <th>WorkTimeDe</th>
      <th>Direction</th>
      <th>Price</th>
      <th>geometry</th>
      <th>mask</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>100路(安德门-南医大二附院总站)</td>
      <td>079645c8210ef240754ff11b</td>
      <td>05:15</td>
      <td>22:00</td>
      <td>周一至周五 05:15-22:00  周六日 05:15-22:00</td>
      <td>南医大二附院总站方向</td>
      <td>2</td>
      <td>LINESTRING (666050.917 3541333.928, 666097.166...</td>
      <td>True</td>
    </tr>
    <tr>
      <th>1</th>
      <td>100路(南医大二附院总站-安德门)</td>
      <td>36ee56fea9cfa740cb09f01b</td>
      <td>06:00</td>
      <td>22:45</td>
      <td>周一至周五 06:00-22:45  周六日 06:00-22:45</td>
      <td>安德门方向</td>
      <td>2</td>
      <td>LINESTRING (664155.059 3551020.254, 664158.656...</td>
      <td>True</td>
    </tr>
    <tr>
      <th>2</th>
      <td>100路区间(下午班)(定坊工业园-安德门)</td>
      <td>0c835f11c853cb5cb5147fdf</td>
      <td>15:30</td>
      <td>18:40</td>
      <td>周一至周五 晚15:30-18:40</td>
      <td>安德门方向</td>
      <td>2</td>
      <td>LINESTRING (664034.596 3535151.892, 664093.486...</td>
      <td>True</td>
    </tr>
  </tbody>
</table>
</div>




```python
gpd2postSQL(bus_routes,table_name='bus_routes',**args.db.db_info)   
```

    __________________________________________________
    The GeoDataFrame has been written to the PostgreSQL database.The table name is bus_routes.
    

* 南京公交站点读写

同公交线路的读写，公交站点字段包括站点名称`PointName`，站点（点）ID`PointUid`，经纬度`Lng`和`Lat`，所在公交线路名和ID`LineName`及`LineUid`，以及点（Point）几何对象`geometry`。写入数据库的表名为`bus_stations`。


```python
bus_stations=shp2gdf(args.data.bus_stations,epsg=args.gi.nanjing_epsg,boundary=region.envelope[0],encoding='GBK')
bus_stations.head(3)
```

    original data info:(32661, 7)
    dropna-how=all,result:(32661, 7)
    dropna-several rows,result:(32661, 7)
    EPSG:32650
    




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>PointName</th>
      <th>PointUid</th>
      <th>Lng</th>
      <th>Lat</th>
      <th>LineName</th>
      <th>LineUid</th>
      <th>geometry</th>
      <th>mask</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>安德门</td>
      <td>aa03446d998e65a4b45f1e9f</td>
      <td>118.757782715597</td>
      <td>31.9959552933912</td>
      <td>100路(安德门-南医大二附院总站)</td>
      <td>079645c8210ef240754ff11b</td>
      <td>POINT (666050.771 3541337.257)</td>
      <td>True</td>
    </tr>
    <tr>
      <th>1</th>
      <td>能仁里</td>
      <td>78128091a7676747364aae39</td>
      <td>118.76325592867</td>
      <td>32.0017671207637</td>
      <td>100路(安德门-南医大二附院总站)</td>
      <td>079645c8210ef240754ff11b</td>
      <td>POINT (666557.365 3541990.011)</td>
      <td>True</td>
    </tr>
    <tr>
      <th>2</th>
      <td>雨花西路</td>
      <td>03d556af603b624329fc48b1</td>
      <td>118.766595750239</td>
      <td>32.0060341836557</td>
      <td>100路(安德门-南医大二附院总站)</td>
      <td>079645c8210ef240754ff11b</td>
      <td>POINT (666865.156 3542468.234)</td>
      <td>True</td>
    </tr>
  </tbody>
</table>
</div>




```python
fig, ax=plt.subplots(figsize=(10,10))
bus_stations.plot(ax=ax,color='black',markersize=1)
plt.show()
```


<img src="./imgs/2_8_3/output_15_0.png" height='auto' width='auto' title="caDesign">    




```python
gpd2postSQL(bus_stations,table_name='bus_stations',**args.db.db_info)   
```

    __________________________________________________
    The GeoDataFrame has been written to the PostgreSQL database.The table name is bus_stations.
    

* 地铁线路读写

地铁线路字段名包括线路名`LineName`，线路ID`LineName`和Polyline几何对象`geometry`。写入数据库的表名为`subway_lines`。


```python
subway_lines=shp2gdf(args.data.subway_lines,epsg=args.gi.nanjing_epsg,boundary=region.envelope[0],encoding='GBK')
subway_lines.head(3)
```

    original data info:(20, 3)
    dropna-how=all,result:(20, 3)
    dropna-several rows,result:(20, 3)
    EPSG:32650
    




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>LineName</th>
      <th>LineUid</th>
      <th>geometry</th>
      <th>mask</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>地铁s9号线(高淳-翔宇路南)</td>
      <td>79743ab26a494368f8dc8594</td>
      <td>LINESTRING (678118.443 3469180.910, 679000.152...</td>
      <td>True</td>
    </tr>
    <tr>
      <th>1</th>
      <td>地铁s3号线(高家冲-南京南站)</td>
      <td>d4a8b8c00653bd44c17da208</td>
      <td>LINESTRING (642965.556 3531558.066, 644261.635...</td>
      <td>True</td>
    </tr>
    <tr>
      <th>2</th>
      <td>地铁s7号线(无想山-空港新城江宁)</td>
      <td>de67974fbfba8d7ca1d2309c</td>
      <td>LINESTRING (693615.069 3499371.258, 693565.026...</td>
      <td>True</td>
    </tr>
  </tbody>
</table>
</div>




```python
fig, ax=plt.subplots(figsize=(10,10))
subway_lines.plot(ax=ax,edgecolor='black',linewidth=0.5,zorder=1)
plt.show()
```

<img src="./imgs/2_8_3/output_19_0.png" height='auto' width='auto' title="caDesign">
    



```python
gpd2postSQL(subway_lines,table_name='subway_lines',**args.db.db_info)  
```

    __________________________________________________
    The GeoDataFrame has been written to the PostgreSQL database.The table name is subway_lines.
    

* 地铁站点读写

地铁站点的字段包括站点名`PointName`，站点ID`PointUid`，经纬度坐标`Lng`和`Lat`，所在地铁线路ID`LineUid`和点几何对象`geometry`。写入至数据库的表名为`subway_stations`。


```python
subway_stations=shp2gdf(args.data.subway_stations,epsg=args.gi.nanjing_epsg,boundary=region.envelope[0],encoding='GBK')
subway_stations.head(3)
```

    original data info:(348, 8)
    dropna-how=all,result:(348, 8)
    dropna-several rows,result:(348, 8)
    EPSG:32650
    




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>PointName</th>
      <th>PointUid</th>
      <th>Lng</th>
      <th>Lat</th>
      <th>IsPractica</th>
      <th>LineName</th>
      <th>LineUid</th>
      <th>geometry</th>
      <th>mask</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>高淳</td>
      <td>e4fe1091444ba694e311039c</td>
      <td>118.872368478559</td>
      <td>31.3434577890014</td>
      <td>0</td>
      <td>地铁s9号线(高淳-翔宇路南)</td>
      <td>79743ab26a494368f8dc8594</td>
      <td>POINT (678118.443 3469180.910)</td>
      <td>True</td>
    </tr>
    <tr>
      <th>1</th>
      <td>团结圩</td>
      <td>41396371183dc24fb9df8fea</td>
      <td>118.882721967772</td>
      <td>31.3979546349684</td>
      <td>1</td>
      <td>地铁s9号线(高淳-翔宇路南)</td>
      <td>79743ab26a494368f8dc8594</td>
      <td>POINT (679000.152 3475239.180)</td>
      <td>True</td>
    </tr>
    <tr>
      <th>2</th>
      <td>明觉</td>
      <td>2f7777a37adc2c0d88db732f</td>
      <td>118.897155970304</td>
      <td>31.5482455693243</td>
      <td>0</td>
      <td>地铁s9号线(高淳-翔宇路南)</td>
      <td>79743ab26a494368f8dc8594</td>
      <td>POINT (680084.557 3491924.198)</td>
      <td>True</td>
    </tr>
  </tbody>
</table>
</div>




```python
fig, ax=plt.subplots(figsize=(10,10))
subway_stations.plot(ax=ax,color='black',markersize=1)
plt.show()
```


<img src="./imgs/2_8_3/output_23_0.png" height='auto' width='auto' title="caDesign">    




```python
gpd2postSQL(subway_stations,table_name='subway_stations',**args.db.db_info)  
```

    __________________________________________________
    The GeoDataFrame has been written to the PostgreSQL database.The table name is subway_stations.
    

#### 2) 分析用数据预处理

* 城市公园数据读写

城市公园边界数据是根据《南京市绿地系统规划》中心城区规划综合公园一览表在Google Earth中绘制，再导出为KML格式数据。定义`kml2gdf()`函数读取KML格式数据为GeoDataFrame格式。并将其写入至数据库，表名为`comprehensive_park`。


```python
def kml2gdf(fn,epsg=None,boundary=None): 
    '''
    读取KML格式数据为GeoDataFrame（GeoPandas）

    Parameters
    ----------
    fn : string
        .kml数据文件路径名.
    epsg : pyproj.crs.crs.CRS[int], optional
        投影epsg编号. The default is None.
    boundary : shp, optional
        配置裁切边界. The default is None.

    Returns
    -------
    kml_gdf_proj : GeoDataFrame
        读取KML格式为GeoDataFrame.

    '''    
    import pandas as pd
    import geopandas as gpd
    import fiona,io
    from tqdm import tqdm        
    
    from fiona.drvsupport import supported_drivers
    supported_drivers['LIBKML'] = 'rw'
    fiona.drvsupport.supported_drivers['KML'] = 'rw'

    kml_gdf=gpd.GeoDataFrame()
    for layer in tqdm(fiona.listlayers(fn)):
        src=fiona.open(fn, layer=layer)
        meta=src.meta
        meta['driver']='KML'        
        with io.BytesIO() as buffer:
            with fiona.open(buffer, 'w', **meta) as dst:            
                for i, feature in enumerate(src):
                    if len(feature['geometry']['coordinates'][0]) > 1:
                        dst.write(feature)

            buffer.seek(0)
            one_layer=gpd.read_file(buffer,driver='KML')
            one_layer['group']=layer
            kml_gdf=kml_gdf.append(one_layer,ignore_index=True)

    if epsg is not None:
        kml_gdf_proj=kml_gdf.to_crs(epsg=epsg)

    if boundary:
        kml_gdf_proj['mask']=kml_gdf_proj.geometry.apply(lambda row:row.within(boundary))
        kml_gdf_proj.query('mask',inplace=True)        

    return kml_gdf_proj
```


```python
comprehensive_park=kml2gdf(args.data.comprehensive_park,epsg=args.gi.nanjing_epsg,boundary=None) 
```

    100%|██████████| 1/1 [00:00<00:00,  7.60it/s]
    


```python
fig, ax=plt.subplots(figsize=(10,10))
comprehensive_park.plot(ax=ax,color='black')
plt.show()

comprehensive_park.head(3)
```

<img src="./imgs/2_8_3/output_28_0.png" height='auto' width='auto' title="caDesign">
    




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Name</th>
      <th>Description</th>
      <th>geometry</th>
      <th>group</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>八字山公园</td>
      <td></td>
      <td>POLYGON Z ((664351.229 3551540.582 0.000, 6643...</td>
      <td>NanjingParks</td>
    </tr>
    <tr>
      <th>1</th>
      <td>北崮山公园</td>
      <td></td>
      <td>POLYGON Z ((667855.803 3553692.487 0.000, 6678...</td>
      <td>NanjingParks</td>
    </tr>
    <tr>
      <th>2</th>
      <td>大桥公园</td>
      <td></td>
      <td>POLYGON Z ((664898.358 3554394.776 0.000, 6648...</td>
      <td>NanjingParks</td>
    </tr>
  </tbody>
</table>
</div>



同时翻译中文公园名为英文，建立映射字典（为可选项，根据后续需求确定）。增加字段`Name_EN`存储英文名。


```python
comprehensive_park_name_mapping={
    '八字山公园':'Bazi Mountain',
    '北崮山公园':'Beigu Mountain',
    '大桥公园':'Bridge park',
    '古林公园':'Ancient Forest',
    '鼓楼公园':'Drum Tower',
    '老虎山公园':'Tiger Mountain',
    '幕府山公园':'Mufu Mountain',
    '清凉山公园':'Qingliang Mountain',
    '狮子山公园':'Lion Rock Mountain',
    '石头城公园':'Stone City Park',
    '乌龙潭公园':'Wulong Pool',
    '绣球公园':'Xiuqing Park',
    '河西中央公园':'Hexi Central Park',
    '绿博园':'Green EXPO Garden',
    '滨江公园':'Riverside Park',
    '莫愁湖公园':'Mochou Lake',
    '南湖公园':'South Lake',
    '百家湖公园':'Baijia Lake',
    '凤凰公园':'Phoenix Park',
    '九龙湖公园':'Jiulong Park',
    '竹山公园':'Zhushan Park',
    '九龙公园':'Jiulong Park',
    '六合凤凰山公园':'Liuhe Phoenix Mountain',
    '龙池公园':'Dragon Pool',
    '平顶山公园':'Pingding Mountain',
    '太子山公园':'Prince Mountain',
    '宝塔山公园':'Pagoda Hill',
    '北堡公园':'North Fort',
    '凤凰山公园':'Phoenix Mountain',
    '浦口公园':'Pukou Park',
    '二桥公园':'Two Bridges Park',
    '南炼公园':'Nanlian Park',
    '三叶湖公园':'Three Leaf Lake',
    '太平山公园':'Taiping Hill',
    '乌龙山公园':'Wulong Mountain',
    '燕子矶公园':'Swallow Rock',
    '白鹭洲公园':'Egret Island',
    '七桥瓮公园':'Qiqiaoweng Park',
    '午朝门公园':'Wuchaomen Park',
    '月牙湖公园':'Crescent Lake',
    '郑和公园':'Zhenghe Park',
    '白马公园':'White House Park',
    '北极阁公园':'Arctic Pavilion',
    '九华山公园':'Jiuhua Mountain',
    '聚宝山公园':'Treasure Hill',
    '梅花谷公园':'Plum Blossom Valley',
    '情侣园':'Couples Garden',
    '体育学院南公园':'South Park of Sports Institute',
    '玄武湖公园':'Xuanwu Lake',
    '花神湖公园':'Flora Lake',
    '菊花台公园':'Chrysanthemums Terrace',
    '莲花湖公园':'Lotus Lake',
    '梅山公园':'Plum Blossom Hill',          
    }
```


```python
comprehensive_park['Name']=comprehensive_park.Name.apply(lambda row:row.strip())
comprehensive_park['Name_EN']=comprehensive_park['Name'].map(comprehensive_park_name_mapping)
comprehensive_park.head(3)
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Name</th>
      <th>Description</th>
      <th>geometry</th>
      <th>group</th>
      <th>Name_EN</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>八字山公园</td>
      <td></td>
      <td>POLYGON Z ((664351.229 3551540.582 0.000, 6643...</td>
      <td>NanjingParks</td>
      <td>Bazi Mountain</td>
    </tr>
    <tr>
      <th>1</th>
      <td>北崮山公园</td>
      <td></td>
      <td>POLYGON Z ((667855.803 3553692.487 0.000, 6678...</td>
      <td>NanjingParks</td>
      <td>Beigu Mountain</td>
    </tr>
    <tr>
      <th>2</th>
      <td>大桥公园</td>
      <td></td>
      <td>POLYGON Z ((664898.358 3554394.776 0.000, 6648...</td>
      <td>NanjingParks</td>
      <td>Bridge park</td>
    </tr>
  </tbody>
</table>
</div>




```python
gpd2postSQL(comprehensive_park,table_name='comprehensive_park',**args.db.db_info)  
```

    __________________________________________________
    The GeoDataFrame has been written to the PostgreSQL database.The table name is comprehensive_park.
    

* 邻里站点提取

公共交通以站点为上下车位置，因此需要确定各个公园的邻近站点。计算每个公园5 min约400 m步行距离缓冲区，提取缓冲区内邻近公园的站点。定义`adjacent_pts()`函数，可以根据输入的GeoDataFrame格式的Polygon对象`polygons_gdf`根据配置的缓冲区大小`buffer_distance`提取缓冲区内的Point点对象`pts_gdf`。

读取已经存入到数据库中的公交和地铁站点，调用`concat`方法执行合并，统一考虑公园缓冲区内的公交和地铁站点。为了区别公交和地铁站点的`PointUid`标识，避免可能的重复，在地铁`PointUid`标识前增加`s_`以示区别。


```python
import pandas as pd

bus_stations=postSQL2gpd(table_name='bus_stations',**args.db.db_info)   
subway_stations=postSQL2gpd(table_name='subway_stations',**args.db.db_info)   
subway_stations['PointUid']=subway_stations.PointUid.apply(lambda row:'s_'+row)

columns=['PointUid','geometry']
stations=pd.concat([bus_stations[columns],subway_stations[columns]],ignore_index=True)
stations.head(3)
```

    __________________________________________________
    The data has been read from PostgreSQL database. The table name is bus_stations.
    __________________________________________________
    The data has been read from PostgreSQL database. The table name is subway_stations.
    




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>PointUid</th>
      <th>geometry</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>aa03446d998e65a4b45f1e9f</td>
      <td>POINT (666050.771 3541337.257)</td>
    </tr>
    <tr>
      <th>1</th>
      <td>78128091a7676747364aae39</td>
      <td>POINT (666557.365 3541990.011)</td>
    </tr>
    <tr>
      <th>2</th>
      <td>03d556af603b624329fc48b1</td>
      <td>POINT (666865.156 3542468.234)</td>
    </tr>
  </tbody>
</table>
</div>




```python
def adjacent_pts_within_polygons(polygons_gdf,pts_gdf,buffer_distance=200):
    '''
    提取位于Polygons几何对象缓冲区域内中的点几何对象

    Parameters
    ----------
    polygons_gdf : GeoDataFrame
        含有Polygon对象的地理空间数据.
    pts_gdf : GeoDataFrame
        含有Point点对象的地理空间数据.
    buffer_distance : float, optional
        缓冲距离. The default is 200.

    Returns
    -------
    adjacentpts_gdf : GeoDataFrame
        位于Polygons对象缓冲区域内的点对象.
    buffer_gdf :  GeoDataFrame   
        缓冲区几何对象.
    '''   
    
    from shapely.geometry import MultiPoint,Polygon,Point
    from copy import deepcopy
    import geopandas as gpd
    
    adjacentpts_gdf=deepcopy(polygons_gdf)
    
    def adjacent_pts_gdf_single_multipoint(geo_polygon,return_type='mp'):
        buffer=geo_polygon.buffer(buffer_distance,join_style=1)
        pts_gdf['within']=pts_gdf.geometry.apply(lambda g:g.within(buffer)) 
        pts_gdf_within=pts_gdf[pts_gdf['within'].values]
                
        if return_type=='mp':
            return MultiPoint(pts_gdf_within['geometry'].to_list())
        elif return_type=='pu':
            return pts_gdf_within.PointUid.to_list()
        
    adjacentpts_gdf['adjacent_pts_gdf']=adjacentpts_gdf.geometry.apply(adjacent_pts_gdf_single_multipoint,args=('mp',))
    adjacentpts_gdf['adjacent_PointUid']=adjacentpts_gdf.geometry.apply(adjacent_pts_gdf_single_multipoint,args=('pu',))
    adjacentpts_gdf.rename(columns={'geometry':'geo_park','adjacent_pts_gdf':'geometry'},inplace=True)   
    adjacentpts_gdf['adjacent_num']=adjacentpts_gdf.adjacent_PointUid.apply(lambda row:len(row))
    adjacentpts_gdf['park_perimeter']=adjacentpts_gdf.apply(lambda row:row.geo_park.length,axis=1)
    adjacentpts_gdf['park_area']=adjacentpts_gdf.apply(lambda row:row.geo_park.area,axis=1)
    adjacentpts_gdf['adjacent_perimeterRatio']=adjacentpts_gdf.apply(lambda row:len(row.adjacent_PointUid)/row.geo_park.length,axis=1)
    adjacentpts_gdf['adjacent_areaRatio']=adjacentpts_gdf.apply(lambda row:len(row.adjacent_PointUid)/row.geo_park.area,axis=1)    
    
    buffer_gdf=deepcopy(adjacentpts_gdf)
    buffer_gdf['buffer']=buffer_gdf.geo_park.apply(lambda row:row.buffer(buffer_distance,join_style=1))
    buffer_gdf.drop(['geometry','geo_park'],axis=1,inplace=True)
    buffer_gdf.rename(columns={'buffer':'geometry'},inplace=True)
        
    adjacentpts_gdf.drop(['geo_park'],axis=1,inplace=True)
    return adjacentpts_gdf,buffer_gdf
```


```python
comprehensive_park=postSQL2gpd(table_name='comprehensive_park',**args.db.db_info)  

comprehensivePark_adjacentStations,comprehensivePark_buffer=adjacent_pts_within_polygons(comprehensive_park,stations,buffer_distance=400) 
comprehensivePark_buffer.head(3)
```

    __________________________________________________
    The data has been read from PostgreSQL database. The table name is comprehensive_park.
    




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Name</th>
      <th>Description</th>
      <th>group</th>
      <th>Name_EN</th>
      <th>adjacent_PointUid</th>
      <th>adjacent_num</th>
      <th>park_perimeter</th>
      <th>park_area</th>
      <th>adjacent_perimeterRatio</th>
      <th>adjacent_areaRatio</th>
      <th>geometry</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>八字山公园</td>
      <td>None</td>
      <td>NanjingParks</td>
      <td>Bazi Mountain</td>
      <td>[3176ab8f267a522adc1e5249, 13627db9677fe868086...</td>
      <td>58</td>
      <td>1498.063650</td>
      <td>58555.986474</td>
      <td>0.038717</td>
      <td>0.000991</td>
      <td>POLYGON ((663972.964 3551670.642, 663979.695 3...</td>
    </tr>
    <tr>
      <th>1</th>
      <td>北崮山公园</td>
      <td>None</td>
      <td>NanjingParks</td>
      <td>Beigu Mountain</td>
      <td>[c7b453844859a109e6e96551, 3a35fc72daefc4b516a...</td>
      <td>46</td>
      <td>3374.373940</td>
      <td>429974.743870</td>
      <td>0.013632</td>
      <td>0.000107</td>
      <td>POLYGON ((667455.811 3553695.094, 667456.223 3...</td>
    </tr>
    <tr>
      <th>2</th>
      <td>大桥公园</td>
      <td>None</td>
      <td>NanjingParks</td>
      <td>Bridge park</td>
      <td>[e16200a462b5e86eaf080f13, 9bb91a554c924a9629f...</td>
      <td>14</td>
      <td>1501.575973</td>
      <td>152867.454776</td>
      <td>0.009324</td>
      <td>0.000092</td>
      <td>POLYGON ((664485.150 3553599.191, 664459.012 3...</td>
    </tr>
  </tbody>
</table>
</div>




```python
comprehensivePark_adjacentStations.head(3)
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Name</th>
      <th>Description</th>
      <th>group</th>
      <th>Name_EN</th>
      <th>geometry</th>
      <th>adjacent_PointUid</th>
      <th>adjacent_num</th>
      <th>park_perimeter</th>
      <th>park_area</th>
      <th>adjacent_perimeterRatio</th>
      <th>adjacent_areaRatio</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>八字山公园</td>
      <td>None</td>
      <td>NanjingParks</td>
      <td>Bazi Mountain</td>
      <td>MULTIPOINT (664855.439 3551547.768, 664432.335...</td>
      <td>[3176ab8f267a522adc1e5249, 13627db9677fe868086...</td>
      <td>58</td>
      <td>1498.063650</td>
      <td>58555.986474</td>
      <td>0.038717</td>
      <td>0.000991</td>
    </tr>
    <tr>
      <th>1</th>
      <td>北崮山公园</td>
      <td>None</td>
      <td>NanjingParks</td>
      <td>Beigu Mountain</td>
      <td>MULTIPOINT (668098.717 3554664.629, 668137.023...</td>
      <td>[c7b453844859a109e6e96551, 3a35fc72daefc4b516a...</td>
      <td>46</td>
      <td>3374.373940</td>
      <td>429974.743870</td>
      <td>0.013632</td>
      <td>0.000107</td>
    </tr>
    <tr>
      <th>2</th>
      <td>大桥公园</td>
      <td>None</td>
      <td>NanjingParks</td>
      <td>Bridge park</td>
      <td>MULTIPOINT (664957.333 3553981.379, 664934.772...</td>
      <td>[e16200a462b5e86eaf080f13, 9bb91a554c924a9629f...</td>
      <td>14</td>
      <td>1501.575973</td>
      <td>152867.454776</td>
      <td>0.009324</td>
      <td>0.000092</td>
    </tr>
  </tbody>
</table>
</div>




```python
fig, ax=plt.subplots(figsize=(10,10))
comprehensivePark_buffer.plot(ax=ax,color='black')
comprehensivePark_adjacentStations.plot(ax=ax,color='red',markersize=1)
plt.show()
```


<img src="./imgs/2_8_3/output_38_0.png" height='auto' width='auto' title="caDesign">    

    


将公园邻里站点的返回结果邻里站点和缓冲区域均写入至数据库，表名分别为`adjacent_stations`和`park_buffer`。


```python
gpd2postSQL(comprehensivePark_adjacentStations,table_name='adjacent_stations',**args.db.db_info)  
gpd2postSQL(comprehensivePark_buffer,table_name='park_buffer',**args.db.db_info)  
```

    __________________________________________________
    The GeoDataFrame has been written to the PostgreSQL database.The table name is adjacent_stations.
    __________________________________________________
    The GeoDataFrame has been written to the PostgreSQL database.The table name is park_buffer.
    

* 人口分布数据读写

可以将人口数据按各个站点位置，指定缓冲区，将其内的总人口数据传入网络，以高斯函数等作为权重，根据实际路线衰减人口数至公园邻近站点，从而计算各个公园的人口服务压力。读取人口分布数据，该数据为给定经纬度地理点位的人口数统计。统一将数据写入至数据库，表名为`population`。


```python
population=shp2gdf(args.data.population,epsg=args.gi.nanjing_epsg)
population.head(3)
```

    original data info:(6673, 4)
    dropna-how=all,result:(6673, 4)
    dropna-several rows,result:(6673, 4)
    EPSG:32650
    




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Lat</th>
      <th>Lng</th>
      <th>Population</th>
      <th>geometry</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>31.9497433580896</td>
      <td>118.378427463393</td>
      <td>129</td>
      <td>POINT (630276.381 3535694.515)</td>
    </tr>
    <tr>
      <th>1</th>
      <td>31.9497433580896</td>
      <td>118.400885345496</td>
      <td>129</td>
      <td>POINT (632399.081 3535721.765)</td>
    </tr>
    <tr>
      <th>2</th>
      <td>31.9230613713896</td>
      <td>118.405376921916</td>
      <td>386</td>
      <td>POINT (632862.009 3532769.406)</td>
    </tr>
  </tbody>
</table>
</div>




```python
fig, ax=plt.subplots(figsize=(10,10))
population.plot(ax=ax,column='Population',markersize=2,cmap='RdGy')
plt.show()
```


<img src="./imgs/2_8_3/output_43_0.png" height='auto' width='auto' title="caDesign">    

    



```python
gpd2postSQL(population,table_name='population',**args.db.db_info) 
```

    __________________________________________________
    The GeoDataFrame has been written to the PostgreSQL database.The table name is population.
    

* 行政区划读写

可以按行政区划分析公共交通复合网络对综合公园的影响，例如公园的供给服务和居民对公园服务的需求，及公园分布的均衡性或不均衡性等。读取的行政区划，每一区划为多个Polygon对象，需要按照区划字段`countyname`分组将同一组（相同值）空间相邻的几何对象聚合成一个，使用`GeoDataFrame.dissolve`(by=None, aggfunc='first', as_index=True, level=None, sort=True, observed=False, dropna=True)方法完成。在同组聚合时，要配合`aggfunc`参数，确定同组多个行对象所含属性字段计算的方式，例如对`area`和`人口密[度]`字段执行求和`sum`，对其它字段均选择第一行值`first`作为聚合后对应的字段值。最终聚合后，由117行聚合为13行，对应13个行政区划。


```python
administrative_districts=shp2gdf(args.data.administrative_districts,epsg=args.gi.nanjing_epsg,encoding='GBK')
print(administrative_districts.shape)
administrative_districts.head(3)
```

    original data info:(117, 15)
    dropna-how=all,result:(117, 14)
    dropna-several rows,result:(117, 14)
    EPSG:32650
    (117, 14)
    




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>gml_id</th>
      <th>id</th>
      <th>fldm</th>
      <th>xzdm</th>
      <th>Name</th>
      <th>area</th>
      <th>cityname</th>
      <th>citycode</th>
      <th>countyname</th>
      <th>countycode</th>
      <th>province</th>
      <th>prvcode</th>
      <th>人口密</th>
      <th>geometry</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>layer_township_pg.32902</td>
      <td>35004</td>
      <td>1004</td>
      <td>320102010</td>
      <td>红山街道</td>
      <td>7.158708</td>
      <td>南京市</td>
      <td>320100000</td>
      <td>玄武区</td>
      <td>320102000</td>
      <td>江苏省</td>
      <td>320000000</td>
      <td>12323.034145</td>
      <td>POLYGON ((668836.064 3551847.179, 668869.968 3...</td>
    </tr>
    <tr>
      <th>1</th>
      <td>layer_township_pg.32903</td>
      <td>35005</td>
      <td>1004</td>
      <td>320102008</td>
      <td>孝陵卫街道</td>
      <td>29.465389</td>
      <td>南京市</td>
      <td>320100000</td>
      <td>玄武区</td>
      <td>320102000</td>
      <td>江苏省</td>
      <td>320000000</td>
      <td>3823.265387</td>
      <td>POLYGON ((670653.916 3548460.478, 671258.502 3...</td>
    </tr>
    <tr>
      <th>2</th>
      <td>layer_township_pg.32904</td>
      <td>35006</td>
      <td>1004</td>
      <td>320102005</td>
      <td>后宰门街道</td>
      <td>3.574642</td>
      <td>南京市</td>
      <td>320100000</td>
      <td>玄武区</td>
      <td>320102000</td>
      <td>江苏省</td>
      <td>320000000</td>
      <td>17341.598641</td>
      <td>POLYGON ((672016.060 3546395.591, 671962.790 3...</td>
    </tr>
  </tbody>
</table>
</div>




```python
plt.rcParams['font.sans-serif']=['SimHei']
fig, ax=plt.subplots(figsize=(10,10))
administrative_districts.plot(ax=ax,color='none', edgecolor='k')
administrative_districts.apply(lambda x: ax.annotate(text=x['countyname'], xy=x.geometry.centroid.coords[0], ha='center'), axis=1);
plt.show()
```


<img src="./imgs/2_8_3/output_47_0.png" height='auto' width='auto' title="caDesign">    

    


按分组执行空间几何对象的聚合。也增加了`countyname_EN`字段存储行政区划翻译的英文名称（为可选，根据后续需要确定）。


```python
administrative_districts_name_mapping={
                                        '玄武区':'Xuanwu District', 
                                        '白下区':'Baixia District', 
                                        '建邺区':'Jianye District', 
                                        '下关区':'Xiaguan District', 
                                        '栖霞区':'Qixia District', 
                                        '六合区':'Liuhe District', 
                                        '鼓楼区':'Gulou District', 
                                        '秦淮区':'Qianhuai District', 
                                        '浦口区':'Pukou District',
                                        '雨花台区':'Yuhuatai District', 
                                        '江宁区':'Jiangning District', 
                                        '溧水县':'Lishui Country', 
                                        '高淳县':'Gaochun Country',        
                                       }

administrative_districts.countyname=administrative_districts.countyname.apply(lambda row:row.strip())
administrative_districts['countyname_EN']=administrative_districts['countyname'].map(administrative_districts_name_mapping)
administrative_districts.drop(['gml_id', 'id', 'xzdm', 'Name',],inplace=True,axis=1)
aggregation_functions={'fldm':'first',  'area':'sum', 'cityname':'first', 'citycode':'first','countyname':'first', 'countycode':'first', 'province':'first', 'prvcode':'first', '人口密':'sum', 'countyname_EN':'first'}
administrative_districts_dissolved=administrative_districts.dissolve(by='countyname_EN',aggfunc=aggregation_functions)
```


```python
print(administrative_districts_dissolved.shape)
administrative_districts_dissolved.head(3)
```

    (13, 11)
    




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>geometry</th>
      <th>fldm</th>
      <th>area</th>
      <th>cityname</th>
      <th>citycode</th>
      <th>countyname</th>
      <th>countycode</th>
      <th>province</th>
      <th>prvcode</th>
      <th>人口密</th>
      <th>countyname_EN</th>
    </tr>
    <tr>
      <th>countyname_EN</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Baixia District</th>
      <td>POLYGON ((673587.345 3544770.147, 673589.306 3...</td>
      <td>1004</td>
      <td>25.823915</td>
      <td>南京市</td>
      <td>320100000</td>
      <td>白下区</td>
      <td>320103000</td>
      <td>江苏省</td>
      <td>320000000</td>
      <td>469795.950111</td>
      <td>Baixia District</td>
    </tr>
    <tr>
      <th>Gaochun Country</th>
      <td>POLYGON ((680940.507 3458039.467, 680897.309 3...</td>
      <td>1004</td>
      <td>792.063405</td>
      <td>南京市</td>
      <td>320100000</td>
      <td>高淳县</td>
      <td>320125000</td>
      <td>江苏省</td>
      <td>320000000</td>
      <td>4365.512334</td>
      <td>Gaochun Country</td>
    </tr>
    <tr>
      <th>Gulou District</th>
      <td>POLYGON ((665909.067 3546529.362, 665845.406 3...</td>
      <td>1004</td>
      <td>24.819821</td>
      <td>南京市</td>
      <td>320100000</td>
      <td>鼓楼区</td>
      <td>320106000</td>
      <td>江苏省</td>
      <td>320000000</td>
      <td>310646.327962</td>
      <td>Gulou District</td>
    </tr>
  </tbody>
</table>
</div>




```python
plt.rcParams['font.sans-serif']=['SimHei']

fig, ax=plt.subplots(figsize=(10,10))
administrative_districts_dissolved.plot(ax=ax,color='none', edgecolor='k')
administrative_districts_dissolved.apply(lambda x: ax.annotate(text=x['countyname'], xy=x.geometry.centroid.coords[0], ha='center'), axis=1);
plt.show()
```


<img src="./imgs/2_8_3/output_51_0.png" height='auto' width='auto' title="caDesign">    



将行政区划聚合后的对象写入至数据库，表名为`admin_distr`。


```python
gpd2postSQL(administrative_districts_dissolved,table_name='admin_distr',**args.db.db_info) 
```

    __________________________________________________
    The GeoDataFrame has been written to the PostgreSQL database.The table name is admin_distr.
    

#### 3）GeoLife数据与时速统计

公共交通复合网络的空间距离权重，在考虑实际路线长度的同时，需要考虑交通工具的速度，计算为时间成本距离。通过[GeoLife数据集](https://www.microsoft.com/en-us/research/publication/geolife-gps-trajectory-dataset-user-guide/)<sup>②</sup>计算公交速度、地铁速度及二者各自内部换乘和之间换乘的步行速度。因为该数据集中南京区域的数据极少，主要以北京为主，因此以北京区域的计算结果为参考。提取北京区域30万条数据，每条数据包括经纬度、时间等信息，GPS轨迹的精度为每2~5 s记录一次。通过记录有通行模式、起始和结束时间戳的数据，确定每一条数据的通行方式。最终获取880条连续路径，其中公交103条，地铁（含城铁）52条，步行368条。以各自速度中位数（公交均速13.54 km/h、地铁均速18.77 km/h、步行均速4.39 km/h）配置公共交通复合网络的3个子网络，包括公交系统子网络、地铁系统子网络和换乘子网络。

> GPS轨迹数据是由微软亚洲研究院（Microsoft Research Asia）主导的GeoLife项目由178 个用户在四年多的时间里（从2007年4月到2011年10月）收集的。该数据集的GPS轨迹由一系列带有时间戳的点表示，每个点都包含纬度、经度和高度信息。 该数据集包含17,621条轨迹，总距离为1,251,654公里，总时长为48,203小时。 这些轨迹由不同的GPS记录器和GPS手机记录，并具有多种采样率。 91%的轨迹以密集表示形式记录，例如每 1\~5 秒或每 5\~10 米一点。该数据集记录了用户广泛的户外运动，不仅包括回家和上班等常规生活活动，还包括一些娱乐和体育活动，如购物、观光、餐饮、徒步旅行和骑自行车。该轨迹数据集可用于许多研究领域，例如移动模式挖掘、用户活动识别、基于位置的社交网络、位置隐私和位置推荐等。


下载的GPS轨迹数据（GeoLife数据集）包括181个子文件，从“000”编号至“181”，每个文件夹下含“Trajectory”子文件夹和一个`labels.txt`标签文件，“Trajectory”子文件夹下即包含后缀名为`.plt`的多个GPS轨迹数据，每行数据对应标签为纬度、经度、海拔、时间、格式化日期和格式化时间，单个文件抬头和部分数据如下：

`.plt`文件数据示例：

```txt
Geolife trajectory
WGS 84
Altitude is in Feet
Reserved 3
0,2,255,My Track,0,0,2,8421376
0
39.984702,116.318417,0,492,39744.1201851852,2008-10-23,02:53:04
39.984683,116.31845,0,492,39744.1202546296,2008-10-23,02:53:10
39.984686,116.318417,0,492,39744.1203125,2008-10-23,02:53:15
39.984688,116.318385,0,492,39744.1203703704,2008-10-23,02:53:20
39.984655,116.318263,0,492,39744.1204282407,2008-10-23,02:53:25
39.984611,116.318026,0,493,39744.1204861111,2008-10-23,02:53:30
```

`labels.txt`标签文件用于标识起始`Start Time`和终止`End Time`时间段内乘坐的交通方式`Transportation Mode`。

`labels.txt`文件数据示例：

```text
Start Time	End Time	Transportation Mode
2007/05/09 14:48:28	2007/05/09 15:00:03	taxi
2007/05/13 02:27:42	2007/05/13 03:33:15	car
2007/05/13 03:47:05	2007/05/13 04:24:42	car
2007/05/13 23:26:53	2007/05/14 00:03:05	car
2007/05/15 00:46:24	2007/05/15 00:56:51	walk
2007/05/15 13:41:41	2007/05/15 14:01:51	taxi
2007/05/16 01:31:27	2007/05/16 01:33:05	walk
2007/05/19 08:58:18	2007/05/19 09:01:36	walk
2007/05/19 09:02:10	2007/05/19 09:49:54	bus
```


* 合并GeoLife数据集

定义`geolife_dataset_preprocessing()`函数，将单独标识有`.plt`后缀的文件合并为一个GeoDataFrame对象（如果文件较大，可以根据以时间命名的文件名拆分为按时间周期切分的多个文件）；同时合并每一子文件下的`labels.txt`标签数据，分别返回`.plt`和`labels.txt`合并后的数据。数据量比较大，为了减少数据量或者仅GPS轨迹数据（GeoLife数据集）GPS轨迹数据（GeoLife数据集）提取给定区域内的数据，提供`boundary`参数，根据左下角和右上角坐标范围提取数据。


```python
def geolife_dataset_preprocessing(geolife_fp,fileType,epsg=None,boundary=None):
    '''
    将分散的GPS轨迹数据（GeoLife数据集）合并为一个单独的GeoDataFrame格式数据对象

    Parameters
    ----------
    geolife_fp : string
        GeoLife数据集根目录.
    fileType : list[str]
        文件类型，为.plt轨迹数据和.txt的标签数据.
    epsg :  pyproj.crs.crs.CRS[int], optional
        投影epsg编号. The default is None.
    boundary : list[float], optional
        [右上角坐标(Lat,Lng), 左下角坐标(Lat,Lng)]，例如[41.095365,117.756161,39.399080,115.095937]. The default is None.

    Returns
    -------
    plts_gdf : GeoDataFrame
        合并的GPS轨迹数据.
    labels_df : DataFrame
        合并的标签数据.

    '''    
    
    import util_misc
    import os
    import pandas as pd
    from tqdm import tqdm
    from shapely.geometry import Point
    import geopandas as gpd
    
    plt_columns=['Latitude','Longitude','code','altitude','date','date_str','time_str']
    plt_fns=util_misc.filePath_extraction(geolife_fp,fileType[0])
    plts_df=pd.DataFrame(columns=plt_columns)
    for root, fns in tqdm(plt_fns.items()):
        for fn in fns:
            fp=os.path.join(root,fn)
            plt_df=(pd.read_csv(fp, names=plt_columns, skiprows=6, sep=','))
            plts_df=pd.concat([plts_df, plt_df])

    if boundary:
        plts_df['within']=plts_df.apply(lambda row:1 if boundary[2]<row.Latitude<boundary[0] and boundary[3]<row.Longitude<boundary[1] else 0,axis=1)
        plts_df=plts_df[plts_df['within']==1]

    plts_df['geometry']=plts_df.apply(lambda row:Point(row.Longitude,row.Latitude),axis=1)
    wgs_epsg=4326
    plts_gdf=gpd.GeoDataFrame(plts_df,crs=wgs_epsg)
    if epsg is not None:
        plts_gdf=plts_gdf.to_crs(epsg=epsg) 
     
    labels_fns=util_misc.filePath_extraction(geolife_fp,fileType[1])
    label_columns=['start_time','end_time','transportation_mode']
    labels_df=pd.DataFrame(columns=label_columns)
    for root, fns in tqdm(labels_fns.items()):
        for fn in fns:
            fp=os.path.join(root,fn)
            label_df=(pd.read_csv(fp, names=label_columns, skiprows=1, sep='\t'))
            labels_df=pd.concat([labels_df,label_df],ignore_index=True)

    print("transportation_mode:{}".format(labels_df.transportation_mode.unique()))    
    
    return plts_gdf,labels_df
```


```python
boundary=[41.095365,117.756161,39.399080,115.095937] # right_coordinate(Lat,Lng) left coordinate(Lat,Lng)  ；Beijing region
geolife_gdf,geolife_labels_df=geolife_dataset_preprocessing(args.data.geolife,['plt','txt'],args.gi.beijing_epsg,boundary)
```

    100%|██████████| 182/182 [2:46:20<00:00, 54.84s/it]   
    C:\Users\richi\anaconda3\envs\usda\lib\site-packages\pandas\core\dtypes\cast.py:127: ShapelyDeprecationWarning: The array interface is deprecated and will no longer work in Shapely 2.0. Convert the '.coords' to a numpy array instead.
      arr = construct_1d_object_array_from_listlike(values)
    100%|██████████| 69/69 [00:00<00:00, 200.33it/s]
    

    transportation_mode:['bus' 'train' 'taxi' 'walk' 'subway' 'airplane' 'car' 'bike' 'boat' 'run'
     'motorcycle']
    


```python
geolife_gdf.head(3)
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Latitude</th>
      <th>Longitude</th>
      <th>code</th>
      <th>altitude</th>
      <th>date</th>
      <th>date_str</th>
      <th>time_str</th>
      <th>within</th>
      <th>geometry</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>39.984702</td>
      <td>116.318417</td>
      <td>0</td>
      <td>492</td>
      <td>39744.120185</td>
      <td>2008-10-23</td>
      <td>02:53:04</td>
      <td>1</td>
      <td>POINT (441807.057 14426281.714)</td>
    </tr>
    <tr>
      <th>1</th>
      <td>39.984683</td>
      <td>116.318450</td>
      <td>0</td>
      <td>492</td>
      <td>39744.120255</td>
      <td>2008-10-23</td>
      <td>02:53:10</td>
      <td>1</td>
      <td>POINT (441809.858 14426279.584)</td>
    </tr>
    <tr>
      <th>2</th>
      <td>39.984686</td>
      <td>116.318417</td>
      <td>0</td>
      <td>492</td>
      <td>39744.120313</td>
      <td>2008-10-23</td>
      <td>02:53:15</td>
      <td>1</td>
      <td>POINT (441807.043 14426279.938)</td>
    </tr>
  </tbody>
</table>
</div>



因为GPS轨迹数据合并后的数据量较大，并未将其存入本地数据库，而是存储到本地磁盘中（或外置磁盘中）。


```python
geolife_gdf.to_file(args.data.geolife_gdf)
```

    C:\Users\richi\anaconda3\envs\usda\lib\site-packages\geopandas\io\file.py:299: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
      pd.Int64Index,
    


```python
geolife_labels_df.head(3)
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>start_time</th>
      <th>end_time</th>
      <th>transportation_mode</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2007/06/26 11:32:29</td>
      <td>2007/06/26 11:40:29</td>
      <td>bus</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2008/03/28 14:52:54</td>
      <td>2008/03/28 15:59:59</td>
      <td>train</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2008/03/28 16:00:00</td>
      <td>2008/03/28 22:02:00</td>
      <td>train</td>
    </tr>
  </tbody>
</table>
</div>



geolife标签数据直接写入到数据库，表名为`geolife_labels`。


```python
df2postSQL(geolife_labels_df,'geolife_labels',**args.db.db_info)  
```

    __________________________________________________
    The GeoDataFrame has been written to the PostgreSQL database.The table name is geolife_labels.
    

* 合并GPS轨迹和标签

`.plt`GPS轨迹数据和`labels.txt`标签数据是分离的，需要将其按照标签数据提供的始末时间对应的交通工具，对位到GPS轨迹数据上，才可以统计不同交通方式下的时速。因为数据量庞大，且仅仅统计交通工具的均速，因此并未使用全部数据统计，而是提取了300,000条数据进行计算。为了提高计算效率，使用并行计算的方式，对于并行计算需要在`Spyder`中完成，分别建立`geolife_data_processing_pool`和`geolife_data_processing`模块。并将运行结果写入至数据库，表名为`geolife_tm_beijing`。

`geolife_data_processing_pool.py`


```python
import pandas as pd
from tqdm import tqdm
from multiprocessing import Pool
import numpy as np
from database import df2postSQL,postSQL2df
from util_misc import AttrDict
__C=AttrDict() 
args=__C

__C.db=AttrDict() 
__C.db.UN='postgres'
__C.db.PW='123456'
__C.db.DB='public_transportation'
__C.db.GC='geometry' 
__C.db.db_info=dict(geom_col=args.db.GC,myusername=args.db.UN,mypassword=args.db.PW,mydatabase=args.db.DB)

geolife_labels=postSQL2df('geolife_labels',**args.db.db_info)
geolife_labels['st_dt']=pd.to_datetime(geolife_labels['start_time'])
geolife_labels['et_dt']=pd.to_datetime(geolife_labels['end_time'])
geolife_labels.sort_values(by='st_dt',inplace=True)
geolife_labels['label_idx']=range(1, len(geolife_labels)+1)

def trans_mode(row):
    """根据轨迹点时间和标签时间段，确定轨迹点的交通模式"""
    dt=row.datetime
    t_mode=None
    
    for idx_label,row_label in geolife_labels.iterrows():
        transportation_mode=row_label.transportation_mode
        st_dt=row_label.st_dt
        et_dt=row_label.et_dt
        label_idx=row_label.label_idx
        if (dt>=st_dt) & (dt<=et_dt):
            t_mode=transportation_mode
            return pd.Series({"trans_mode":t_mode,"label_idx":label_idx})
        
    return pd.Series({"trans_mode":t_mode,"label_idx":None})

def process(df):
    results=df.apply(trans_mode, axis=1)
    return results
```

`geolife_data_processing.py`


```python
import geopandas as gpd
from database import postSQL2gpd,gpd2postSQL,df2postSQL,postSQL2df
from util_misc import AttrDict
__C=AttrDict() 
args=__C

__C.db=AttrDict() 
__C.db.UN='postgres'
__C.db.PW='123456'
__C.db.DB='public_transportation'
__C.db.GC='geometry' 
__C.db.db_info=dict(geom_col=args.db.GC,myusername=args.db.UN,mypassword=args.db.PW,mydatabase=args.db.DB)

__C.gi=AttrDict()
__C.gi.nanjing_epsg=32650
__C.gi.beijing_epsg=32750
__C.gi.epsg_wgs84=4326

__C.data=AttrDict()
__C.data.geolife_gdf='E:\data\geolife.gpkg'

def geolife_transportation_mode(geolife_gdf,geolife_labels,epsg=None):
    '''
    合并GeoLife数据的GPS轨迹和交通工具时间段标签，可用于计算不同通行工具的均速

    Parameters
    ----------
    geolife_gdf : GeoDataFrame
        合并的GPS轨迹数据.
    geolife_labels : DataFrame
        合并后的标签数据.
    epsg :pyproj.crs.crs.CRS[int], optional
        投影epsg编号. The default is None.

    Returns
    -------
    geolife_tm_gdf : GeoDataFrame
        合并GPS轨迹和标签后（交通方式）的数据.
    geolife_labels : DataFrame
        标签数据，将时间字符串转换为了时间格式数据.

    '''    
    import pandas as pd
    from tqdm import tqdm
    from multiprocessing import Pool
    import numpy as np
    from geolife_data_processing_pool import process
    tqdm.pandas()
   
    geolife_gdf=geolife_gdf.to_crs(epsg=epsg) 
    geolife_gdf['datetime']=pd.to_datetime(geolife_gdf['date_str']+' '+geolife_gdf['time_str'])
    geolife_gdf.sort_values(by='datetime',inplace=True)
    
    geolife_labels['st_dt']=pd.to_datetime(geolife_labels['start_time'])
    geolife_labels['et_dt']=pd.to_datetime(geolife_labels['end_time'])
    geolife_labels.sort_values(by='st_dt',inplace=True)
     
    workers=8
    with Pool(workers) as p:
        pool_results=p.map(process, tqdm(np.array_split(geolife_gdf,workers)))
    t_mode_df=pd.concat(pool_results, axis=0)
    geolife_tm_gdf=pd.concat([geolife_gdf, t_mode_df], axis=1)
    
    return geolife_tm_gdf,geolife_labels


if __name__=="__main__":
    geolife_beijing_gdf=gpd.read_file(args.data.geolife_gdf)
    geolife_beijing_gdf_part=geolife_beijing_gdf[:50000*6]
    print('-'*50)
    geolife_labels_df=postSQL2df('geolife_labels',**args.db.db_info)
    geolife_tm_beijing_gdf,geolife_labels=geolife_transportation_mode(geolife_beijing_gdf_part,geolife_labels_df,args.gi.beijing_epsg) 
    gpd2postSQL(geolife_tm_beijing_gdf,table_name='geolife_tm_beijing',myusername='postgres',mypassword='123456',mydatabase='public_transport_accessibility')
```

* 交通工具时速统计

统计不同交通方式下的通行时速，首先定义`geolife_traffic_mode_trajectory_pts2linestring()`函数，将GPS轨迹点按照所属，交通模式和时间顺序连为线段，计算线段（路径）的长度、持续时间，对应交通模式就可以计算交通工具的时速。


```python
geolife_tm_beijing_gdf=postSQL2gpd(table_name='geolife_tm_beijing',myusername='postgres',mypassword='123456',mydatabase='public_transport_accessibility') 
```

    __________________________________________________
    The data has been read from PostgreSQL database. The table name is geolife_tm_beijing.
    


```python
geolife_tm_beijing_gdf
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Latitude</th>
      <th>Longitude</th>
      <th>code</th>
      <th>altitude</th>
      <th>date</th>
      <th>date_str</th>
      <th>time_str</th>
      <th>geometry</th>
      <th>within</th>
      <th>datetime</th>
      <th>trans_mode</th>
      <th>label_idx</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>39.988992</td>
      <td>116.327023</td>
      <td>0</td>
      <td>128.937004593176</td>
      <td>36526.966887</td>
      <td>2000-01-01</td>
      <td>23:12:19</td>
      <td>POINT (442545.429 14426752.285)</td>
      <td>1</td>
      <td>2000-01-01 23:12:19</td>
      <td>None</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>1</th>
      <td>39.990964</td>
      <td>116.327041</td>
      <td>0</td>
      <td>221.128615485564</td>
      <td>36526.967604</td>
      <td>2000-01-01</td>
      <td>23:13:21</td>
      <td>POINT (442548.618 14426971.149)</td>
      <td>1</td>
      <td>2000-01-01 23:13:21</td>
      <td>None</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>2</th>
      <td>39.993207</td>
      <td>116.326827</td>
      <td>0</td>
      <td>217.191591207349</td>
      <td>36526.969016</td>
      <td>2000-01-01</td>
      <td>23:15:23</td>
      <td>POINT (442532.229 14427220.241)</td>
      <td>1</td>
      <td>2000-01-01 23:15:23</td>
      <td>None</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>3</th>
      <td>39.974233</td>
      <td>116.330383</td>
      <td>0</td>
      <td>823.490813648294</td>
      <td>39184.396898</td>
      <td>2007-04-12</td>
      <td>09:31:32</td>
      <td>POINT (442820.014 14425112.043)</td>
      <td>1</td>
      <td>2007-04-12 09:31:32</td>
      <td>None</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>4</th>
      <td>39.974317</td>
      <td>116.330450</td>
      <td>0</td>
      <td>823.490813648294</td>
      <td>39184.402512</td>
      <td>2007-04-12</td>
      <td>09:39:37</td>
      <td>POINT (442825.777 14425121.250)</td>
      <td>1</td>
      <td>2007-04-12 09:39:37</td>
      <td>None</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>299995</th>
      <td>40.885653</td>
      <td>117.069078</td>
      <td>0</td>
      <td>1360</td>
      <td>39569.179329</td>
      <td>2008-05-01</td>
      <td>04:18:14</td>
      <td>POINT (505819.594 14526065.883)</td>
      <td>1</td>
      <td>2008-05-01 04:18:14</td>
      <td>car</td>
      <td>2643.0</td>
    </tr>
    <tr>
      <th>299996</th>
      <td>39.893903</td>
      <td>116.315097</td>
      <td>0</td>
      <td>216.5</td>
      <td>39569.179329</td>
      <td>2008-05-01</td>
      <td>04:18:14</td>
      <td>POINT (441446.220 14416206.097)</td>
      <td>1</td>
      <td>2008-05-01 04:18:14</td>
      <td>car</td>
      <td>2643.0</td>
    </tr>
    <tr>
      <th>299997</th>
      <td>40.006852</td>
      <td>115.977567</td>
      <td>0</td>
      <td>1023.6</td>
      <td>39569.179329</td>
      <td>2008-05-01</td>
      <td>04:18:14</td>
      <td>POINT (412733.302 14429018.274)</td>
      <td>1</td>
      <td>2008-05-01 04:18:14</td>
      <td>car</td>
      <td>2643.0</td>
    </tr>
    <tr>
      <th>299998</th>
      <td>40.006852</td>
      <td>115.977567</td>
      <td>0</td>
      <td>1023.6</td>
      <td>39569.179329</td>
      <td>2008-05-01</td>
      <td>04:18:14</td>
      <td>POINT (412733.302 14429018.274)</td>
      <td>1</td>
      <td>2008-05-01 04:18:14</td>
      <td>car</td>
      <td>2643.0</td>
    </tr>
    <tr>
      <th>299999</th>
      <td>39.893903</td>
      <td>116.315097</td>
      <td>0</td>
      <td>216.5</td>
      <td>39569.179329</td>
      <td>2008-05-01</td>
      <td>04:18:14</td>
      <td>POINT (441446.220 14416206.097)</td>
      <td>1</td>
      <td>2008-05-01 04:18:14</td>
      <td>car</td>
      <td>2643.0</td>
    </tr>
  </tbody>
</table>
<p>300000 rows × 12 columns</p>
</div>




```python
def geolife_traffic_mode_trajectory_pts2linestring(geolife_tm_gdf,epsg=None):
    '''
    将GeoLife轨迹和标签合并后数据中的轨迹点按照轨迹所属，交通模式和时间顺序连为线段
    Parameters
    ----------
    geolife_tm_gdf : GeoDataFrame
        GeoLife轨迹和标签合并后数据.
    epsg : pyproj.crs.crs.CRS[int], optional
        投影epsg编号. The default is None.

    Returns
    -------
    duration_gdf : GeoDataFrame
        合并GPS轨迹点为折线段的地理空间数据，包含路径长度、持续时间、交通模式等字段.

    '''    
    import copy
    from shapely.geometry import LineString
    from shapely.geometry import Point
    import geopandas as gpd
    from tqdm import tqdm
    
    geolife_tm_gdf_=copy.deepcopy(geolife_tm_gdf)
    trans_mode_list=list(geolife_tm_gdf_.trans_mode.unique())
    
    geolife_tm_gdf_.dropna(inplace=True)
    geolife_tm_gdf_.set_index(['label_idx','trans_mode'],inplace=True)   
    columns=['line_length','duration','trans_mode','geometry','label_idx']
    duration_df=pd.DataFrame(columns=columns)
    i=0
    for label_idx,df_ in tqdm(geolife_tm_gdf_.groupby(level=0)):
        df=df_[::]
        df.sort_values(by=['datetime'],inplace=True)
        if len(list(df.geometry))>1:
            line=LineString(list(df.geometry))
            line_len=line.length
        else:    
            line_len=None
            
        dt_list=df.datetime.to_list()
        duration=pd.Timedelta(dt_list[-1]-dt_list[0]).seconds/60.0 # min/60 hour/3600
        t_mode=list(df.index.get_level_values(1).unique())           
        duration_df=duration_df.append(pd.DataFrame(data={'line_length':line_len,
                                                          'duration':duration,
                                                          'trans_mode':t_mode,
                                                          'geometry':line,
                                                          'label_idx':label_idx}),ignore_index=True)

    duration_gdf=gpd.GeoDataFrame(duration_df,crs=epsg)
    
    duration_gdf['speed_kmh']=duration_gdf.apply(lambda row:(row.line_length*0.001)/(row.duration/60) if row.duration else None,axis=1)
    duration_gdf.dropna(inplace=True)
    
    return duration_gdf
```


```python
duration_beijing_gdf=geolife_traffic_mode_trajectory_pts2linestring(geolife_tm_beijing_gdf,args.gi.beijing_epsg)
```

    100%|██████████| 906/906 [00:08<00:00, 106.66it/s]
    

30万条GPS轨迹点数据，含905条轨迹路径，涉及到8种交通模式，有自行车（bike）、 汽车（car）、火车（train）、 出租（taxi）、 步行（walk）、公交（ bus）、地铁（ subway）和飞机（airplane）等。


```python
print(duration_beijing_gdf.trans_mode.unique())
duration_beijing_gdf
```

    ['bike' 'car' 'train' 'taxi' 'walk' 'bus' 'subway' 'airplane']
    




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>line_length</th>
      <th>duration</th>
      <th>trans_mode</th>
      <th>geometry</th>
      <th>label_idx</th>
      <th>speed_kmh</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>23743.02579</td>
      <td>275.666667</td>
      <td>bike</td>
      <td>LINESTRING (442794.835 14425360.126, 442801.89...</td>
      <td>8.0</td>
      <td>5.167769</td>
    </tr>
    <tr>
      <th>1</th>
      <td>21388.89143</td>
      <td>385.433333</td>
      <td>car</td>
      <td>LINESTRING (444065.109 14424298.068, 444086.81...</td>
      <td>15.0</td>
      <td>3.329586</td>
    </tr>
    <tr>
      <th>2</th>
      <td>16124.881974</td>
      <td>51.533333</td>
      <td>train</td>
      <td>LINESTRING (442739.726 14425223.644, 442712.72...</td>
      <td>27.0</td>
      <td>18.774119</td>
    </tr>
    <tr>
      <th>3</th>
      <td>7772.472847</td>
      <td>10.533333</td>
      <td>taxi</td>
      <td>LINESTRING (446221.177 14424236.293, 446315.10...</td>
      <td>31.0</td>
      <td>44.273580</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1173.303359</td>
      <td>10.666667</td>
      <td>walk</td>
      <td>LINESTRING (442685.941 14436392.333, 442666.03...</td>
      <td>32.0</td>
      <td>6.599831</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>901</th>
      <td>9810.752545</td>
      <td>17.050000</td>
      <td>bike</td>
      <td>LINESTRING (442144.251 14428472.684, 442139.67...</td>
      <td>2637.0</td>
      <td>34.524642</td>
    </tr>
    <tr>
      <th>902</th>
      <td>12850.485243</td>
      <td>1.750000</td>
      <td>walk</td>
      <td>LINESTRING (442602.698 14425990.854, 442606.47...</td>
      <td>2639.0</td>
      <td>440.588065</td>
    </tr>
    <tr>
      <th>903</th>
      <td>1728503.461217</td>
      <td>14.016667</td>
      <td>train</td>
      <td>LINESTRING (442936.982 14426445.207, 442940.23...</td>
      <td>2640.0</td>
      <td>7399.063568</td>
    </tr>
    <tr>
      <th>904</th>
      <td>38347504.774009</td>
      <td>38.483333</td>
      <td>bus</td>
      <td>LINESTRING (468033.804 14418405.973, 444357.27...</td>
      <td>2642.0</td>
      <td>59788.227452</td>
    </tr>
    <tr>
      <th>905</th>
      <td>1050753295.343658</td>
      <td>186.300000</td>
      <td>car</td>
      <td>LINESTRING (440082.702 14434359.278, 484599.52...</td>
      <td>2643.0</td>
      <td>338406.858404</td>
    </tr>
  </tbody>
</table>
<p>880 rows × 6 columns</p>
</div>



按照交通模式字段`trans_mode`分组计算时速均值。


```python
trans_mode_speed_mean=duration_beijing_gdf.groupby('trans_mode').median()
trans_mode_speed_mean
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>line_length</th>
      <th>duration</th>
      <th>label_idx</th>
      <th>speed_kmh</th>
    </tr>
    <tr>
      <th>trans_mode</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>airplane</th>
      <td>3223.830547</td>
      <td>11.000000</td>
      <td>953.0</td>
      <td>17.584530</td>
    </tr>
    <tr>
      <th>bike</th>
      <td>2740.061339</td>
      <td>15.466667</td>
      <td>1018.0</td>
      <td>11.284929</td>
    </tr>
    <tr>
      <th>bus</th>
      <td>3694.354100</td>
      <td>13.850000</td>
      <td>1436.0</td>
      <td>15.570483</td>
    </tr>
    <tr>
      <th>car</th>
      <td>36721.506557</td>
      <td>73.516667</td>
      <td>416.0</td>
      <td>33.920102</td>
    </tr>
    <tr>
      <th>subway</th>
      <td>5887.140773</td>
      <td>15.725000</td>
      <td>790.5</td>
      <td>20.383329</td>
    </tr>
    <tr>
      <th>taxi</th>
      <td>7636.819993</td>
      <td>14.666667</td>
      <td>1174.5</td>
      <td>22.150590</td>
    </tr>
    <tr>
      <th>walk</th>
      <td>1028.530414</td>
      <td>11.316667</td>
      <td>1263.5</td>
      <td>5.009218</td>
    </tr>
  </tbody>
</table>
</div>



上述获取的时速中位数并未剔除异常值，因此定义`geolife_trans_modes_speed()`函数，剔除异常值后，打印不同交通工具各个GPS轨迹时速中位数的箱型图，观察数据分布情况，并以字典形式按照交通模式返回所有数值。统计的不同交通模式的时速是实际生活上人们使用交通工具，受各种因素（例如天气、启动和停止时间、交通状况、行使状态等）影响下具有的速度，这个速度一般小于交通工具自身可以达到的速度。


```python
def geolife_trans_modes_speed(duration_gdf,trans_modes=None,figsize=(5,5)):
    '''
    配合geolife_traffic_mode_trajectory_pts2linestring()函数计算结果，移除异常值，获取不同交通模式时速的中位数，并打印箱型图观察数值分布

    Parameters
    ----------
    duration_gdf : GeoDataFrame
        预处理后GeoLife数据集GPS轨迹路径数据.
    trans_modes : list[string], optional
        选择用于打印箱型图的交通模式. The default is ["bus","subway","walk"].
    figsize : tuple(int,int), optional
        图表大小. The default is (5,5).

    Returns
    -------
    t_mode_speed : dict[str:array]
        不同交通模式各个轨迹对应的时速中位数.

    '''    
    import matplotlib.pyplot as plt
    import matplotlib
    import numpy as np
    import util_misc
       
    duration_gdf.replace({"train":"subway"},inplace=True)
    t_mode=duration_gdf.trans_mode.unique()          
    trans_mode_group=duration_gdf.groupby(by=['trans_mode'])
     
    t_mode_speed={}
    for m in t_mode:
        group_m=trans_mode_group.get_group(name=m) 
        is_outlier_bool,data_clean=util_misc.is_outlier(np.array(group_m.speed_kmh),threshold=3.5)
        t_mode_speed[m]=np.array(data_clean)
       
    speed_median={}
    for k,v in t_mode_speed.items():
        speed_median[k]=np.median(v)
    print(speed_median)
    
    matplotlib.rcParams['font.family'] = ['SimHei']
    fig,ax=plt.subplots(figsize=figsize)   
    
    EN_CH_mapping={'bike': "自行车", 'car': "汽车", 'subway': "地铁", 'taxi': "出租车", 'walk':"步行", 'bus': "公交", 'airplane': "飞机"}
    dict_filter=lambda x, y: dict([(i,x[i]) for i in x if i in set(y)])
    if trans_modes:        
        t_mode_speed_filter=dict_filter(t_mode_speed,trans_modes)    
        k,v=list(t_mode_speed_filter.keys()),list(t_mode_speed_filter.values())
    else:
        t_mode_speed_filter=dict_filter(t_mode_speed,EN_CH_mapping.keys())
        k,v=list(t_mode_speed_filter.keys()),list(t_mode_speed_filter.values())
    k_CH=[EN_CH_mapping[i] for i in k]

    ax.boxplot(v)
    ax.yaxis.grid(True)
    ax.set_xticklabels(k_CH,fontsize=17)
    ax.set_xlabel('交通方式',fontsize=20)
    ax.set_ylabel('平均速度 km/h',fontsize=20)
    plt.yticks(fontsize=17)
    plt.show()
    
    return t_mode_speed
```


```python
t_mode_speed=geolife_trans_modes_speed(duration_beijing_gdf,figsize=(10,5))
```

    {'bike': 9.993853342819856, 'car': 28.43731442778485, 'subway': 18.7683686611522, 'taxi': 19.838916253915173, 'walk': 4.386498871077352, 'bus': 13.544846491362806, 'airplane': 17.58453025807208}
    


<img src="./imgs/2_8_3/output_79_1.png" height='auto' width='auto' title="caDesign">    



### 2.8.3.2  构建公共交通复合网络

#### 1) 构建公交系统子网络

根据获取的公交站点和公交线路SHP格式数据，预处理为GeoDataFrame数据格式，用于构建公交系统子网络。复杂网络构建需要确定两两顶点之间的关系，对于公交系统子网络则需要确定同一公交线路下两两相邻站点的关系，对应构建边及增加顶点（站点）和边（线路）的有关属性。因为获取的公交线路为LINESTRING对象的空间几何对象，获取的公交站点数据站点位置不一定正好位于公交下线路上，因此根据`LineUid`列合并站点和线路数据后，需要找到站点到线路上的最近点，使用`Shapely`库的`nearest_points`方法。每一条线路有多个站点，一个站点和下一个站点需要构建网络的边，抽象的边为两点间的直线，对应着实际上“曲折”的公交线路，因此需要增加`forward_length`属性存储边的实际线路长度，并增加时间距离成本属性值`time_cost`存储线路长度和时速的比值。定义`subG_bus()`函数用于构建公交系统子网络。该函数如果用于类似城市的公交（地铁）系统网络的构建，需要将站点和线路数据处理为本次实验对应GeoDataFrame地理空间数据，且对应定义相同的列名。


```python
bus_stations=postSQL2gpd(table_name='bus_stations',**args.db.db_info)
bus_routes=postSQL2gpd(table_name='bus_routes',**args.db.db_info)
```

    __________________________________________________
    The data has been read from PostgreSQL database. The table name is bus_stations.
    __________________________________________________
    The data has been read from PostgreSQL database. The table name is bus_routes.
    


```python
def subG_trans(bus_stations_,bus_routes_,speed): 
    '''
    根据公共（地铁）站和公交（地铁）线路，及时速构建公交（地铁）系统自网络

    Parameters
    ----------
    bus_stations_ : GeoDataFrame
        公交站点地理空间数据
    bus_routes_ : GeoDataFrame
        公交线路地理空间数据
    speed : float
        时速 km/h.

    Returns
    -------
    G : networkx.classes.graph.Graph
        公交系统子网络.
    s_e_nodes : list[(str,str)]
        所有公交线路的起始点.
    lines_df4G : GeoDataFrame
        用于生成公交子网络的GeoDataFrame对象.

    '''    
    import copy
    import pandas as pd
    import networkx as nx
    from shapely.ops import nearest_points
    from shapely.ops import substring
    from tqdm import tqdm
    
    # compute the distance between the site centroid and each bus station and get the nearest ones by given threshold
    bus_stations=copy.deepcopy(bus_stations_)
    
    # build bus stations network
    bus_staions_routes=pd.merge(bus_stations,bus_routes_,on='LineUid')
    bus_staions_routes_idx_LineUid=bus_staions_routes.set_index('LineUid',append=True,drop=False)    
    
    lines_group_list=[]
    s_e_nodes=[]
    for LineUid,sub_df in tqdm(bus_staions_routes_idx_LineUid.groupby(level=1)):
        sub_df['nearestPts']=sub_df.apply(lambda row:nearest_points(row.geometry_y,row.geometry_x)[0],axis=1)
        sub_df['project_norm']=sub_df.apply(lambda row:row.geometry_y.project(row.nearestPts,normalized=True),axis=1)
        sub_df.sort_values(by='project_norm',inplace=True)
        sub_df['order_idx']=range(1,len(sub_df)+1)
        project=sub_df.project_norm.to_list()
        sub_df['second_project']=project[1:]+project[:1]        
        PointName=sub_df.PointName.to_list()
        sub_df['second_PointName']=PointName[1:]+PointName[:1]
        PointUid=sub_df.PointUid.to_list()
        sub_df['second_PointUid']= PointUid[1:]+ PointUid[:1]
        sub_df['substring']=sub_df.apply(lambda row:substring(row.geometry_y,row.project_norm,row.second_project,normalized=True),axis=1)
        sub_df['forward_length']=sub_df.apply(lambda row:row.substring.length,axis=1)
        sub_df['time_cost']=sub_df.apply(lambda row:row.forward_length/(speed*1000)*60,axis=1)       
        sub_df['edges']=sub_df.apply(lambda row:[(row.PointUid,row.second_PointUid),(row.second_PointUid,row.PointUid)],axis=1)     
        lines_group_list.append(sub_df)
        
        if sub_df.shape[0]>2:
            s_e_nodes.append(sub_df.edges.to_list()[-1][0])

    lines_df4G=pd.concat(lines_group_list)

    G=nx.from_pandas_edgelist(df=lines_df4G,source='PointUid',target='second_PointUid',edge_attr=['PointName','second_PointName','forward_length','geometry_x','time_cost'])
    G.remove_edges_from(s_e_nodes)
    
    for idx,row in lines_df4G.iterrows():
        G.nodes[row['PointUid']]['position']=(row.geometry_x.x,row.geometry_x.y)
        G.nodes[row['PointUid']]['station_name']=row.PointName     
    
    return G,s_e_nodes,lines_df4G
```


```python
G_bus_stations,s_e_nodes,bus_lines_df4G=subG_trans(bus_stations,bus_routes,speed=13.54)
```

    100%|██████████| 1283/1283 [00:37<00:00, 34.42it/s]
    

查看用于构建复杂网络处理后的GeoDataFrame地理空间数据。


```python
bus_lines_df4G.head(3)
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th></th>
      <th>PointName</th>
      <th>PointUid</th>
      <th>Lng</th>
      <th>Lat</th>
      <th>LineName_x</th>
      <th>LineUid</th>
      <th>geometry_x</th>
      <th>mask_x</th>
      <th>LineName_y</th>
      <th>StartTime</th>
      <th>...</th>
      <th>nearestPts</th>
      <th>project_norm</th>
      <th>order_idx</th>
      <th>second_project</th>
      <th>second_PointName</th>
      <th>second_PointUid</th>
      <th>substring</th>
      <th>forward_length</th>
      <th>time_cost</th>
      <th>edges</th>
    </tr>
    <tr>
      <th></th>
      <th>LineUid</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2261</th>
      <th>000ec915034f2e3f58bbbc5c</th>
      <td>尧佳路东</td>
      <td>098d2a5e146f358c250bd02d</td>
      <td>118.892640622249</td>
      <td>32.1301950057802</td>
      <td>140路(尧佳路东-白马公园)</td>
      <td>000ec915034f2e3f58bbbc5c</td>
      <td>POINT (678531.157 3556435.574)</td>
      <td>True</td>
      <td>140路(尧佳路东-白马公园)</td>
      <td>05:40</td>
      <td>...</td>
      <td>POINT (678531.157 3556435.574)</td>
      <td>0.000000</td>
      <td>1</td>
      <td>0.059152</td>
      <td>新城金郡</td>
      <td>85aca85907cc7b0c210262fb</td>
      <td>LINESTRING (678531.157 3556435.574, 678531.402...</td>
      <td>863.631863</td>
      <td>3.827025</td>
      <td>[(098d2a5e146f358c250bd02d, 85aca85907cc7b0c21...</td>
    </tr>
    <tr>
      <th>2262</th>
      <th>000ec915034f2e3f58bbbc5c</th>
      <td>新城金郡</td>
      <td>85aca85907cc7b0c210262fb</td>
      <td>118.887909509396</td>
      <td>32.1318136548581</td>
      <td>140路(尧佳路东-白马公园)</td>
      <td>000ec915034f2e3f58bbbc5c</td>
      <td>POINT (678081.658 3556607.200)</td>
      <td>True</td>
      <td>140路(尧佳路东-白马公园)</td>
      <td>05:40</td>
      <td>...</td>
      <td>POINT (678081.658 3556607.200)</td>
      <td>0.059152</td>
      <td>2</td>
      <td>0.118442</td>
      <td>前新塘</td>
      <td>4b350e936a57861914c8f63b</td>
      <td>LINESTRING (678081.658 3556607.200, 678020.195...</td>
      <td>865.657054</td>
      <td>3.835999</td>
      <td>[(85aca85907cc7b0c210262fb, 4b350e936a57861914...</td>
    </tr>
    <tr>
      <th>2263</th>
      <th>000ec915034f2e3f58bbbc5c</th>
      <td>前新塘</td>
      <td>4b350e936a57861914c8f63b</td>
      <td>118.884917011823</td>
      <td>32.125994898654</td>
      <td>140路(尧佳路东-白马公园)</td>
      <td>000ec915034f2e3f58bbbc5c</td>
      <td>POINT (677810.631 3555957.124)</td>
      <td>True</td>
      <td>140路(尧佳路东-白马公园)</td>
      <td>05:40</td>
      <td>...</td>
      <td>POINT (677810.631 3555957.124)</td>
      <td>0.118442</td>
      <td>3</td>
      <td>0.154839</td>
      <td>太龙路东</td>
      <td>2881003e7516d4f130169bc7</td>
      <td>LINESTRING (677810.631 3555957.124, 677808.033...</td>
      <td>531.406948</td>
      <td>2.354831</td>
      <td>[(4b350e936a57861914c8f63b, 2881003e7516d4f130...</td>
    </tr>
  </tbody>
</table>
<p>3 rows × 26 columns</p>
</div>



查看公交系统子网络顶点和边的属性内容。


```python
print(G_bus_stations.nodes['098d2a5e146f358c250bd02d'])
print(G_bus_stations.edges['098d2a5e146f358c250bd02d', '85aca85907cc7b0c210262fb'])
```

    {'position': (678531.1572245015, 3556435.5737954923), 'station_name': '尧佳路东'}
    {'PointName': '尧佳路东', 'second_PointName': '新城金郡', 'forward_length': 863.6318633109651, 'geometry_x': <POINT (678531.157 3556435.574)>, 'time_cost': 3.8270245050707468}
    

打印公交系统子网络。


```python
import matplotlib.pyplot as plt
plt.rcParams['font.sans-serif']=['DengXian'] # 指定默认字体 'KaiTi','SimHei'
plt.rcParams['axes.unicode_minus']=False # 解决保存图像是负号'-'显示为方块的问题

fig, ax=plt.subplots(figsize=(30*2*2, 30*4*2))
nx.draw(G_bus_stations,pos=nx.get_node_attributes(G_bus_stations,'position'),edge_color='black',labels=nx.get_node_attributes(G_bus_stations,'station_name'),font_size=20,node_size=50,ax=ax)   
```


<img src="./imgs/2_8_3/output_89_0.png" height='auto' width='auto' title="caDesign">    



为方便后续应用公交系统子网络进行相关分析，将其存储到本地磁盘中。


```python
import pickle
__C.data.G_bus_stations="./data/network/G_bus_stations.gpickle"
with open(args.data.G_bus_stations,'wb') as f:
    pickle.dump(G_bus_stations, f)
```

#### 2) 构建公交系统的换乘子网络

一个地点附近可能会有多个线路交会，存在不同线路的站点，因此如果存在换乘，则需要考虑站点之间的距离，因此增加公交系统的换乘子网络，定义`transfer_stations_network()`函数实现。换乘距离`transfer_distance`参数，表述了换乘所能承受的最大距离，如果超过该距离，则不计入公交系统的换乘子网络。

> 实际上人们换乘所消耗的时间，不仅是路程距离的时间，还包括等待的时间；且这个距离可能并不是直线距离，因此公共交通复合网络的构建是一般情况的表述，为一个参照基础。


```python
def transfer_stations_network(station_geometries_df,transfer_distance,speed): 
    '''
    构建公交系统的换乘子网络

    Parameters
    ----------
    station_geometries_df : GeoDataFrame
        subG_trans函数（用于构建公共交通（公交或地铁）子网络）返回的结果.
    transfer_distance : float
        换乘所能承受的最大距离.
    speed : float
        步行时速.

    Returns
    -------
    G : networkx.classes.graph.Graph
        公交系统的换乘子网络.
    transfer_df_concat : DataFrame
        用于生成公交换乘子网络的DataFrame对象.

    '''    
    import copy
    from tqdm import tqdm
    import pandas as pd
    import networkx as nx
    
    station_geometries_dict=station_geometries_df.to_dict('record')
    transfer_df_list=[]
    for pt in tqdm(station_geometries_dict):
        station_geometries_df_=copy.deepcopy(station_geometries_df)
        station_geometries_df_['dist']=station_geometries_df_.geometry_x.apply(lambda row:row.distance(pt['geometry_x']))

        transfer_df=station_geometries_df_[station_geometries_df_.dist<=transfer_distance]
        transfer_df=transfer_df[transfer_df.dist!=0]
        transfer_df.drop_duplicates(subset='PointUid',keep='first',inplace=True)        
        transfer_df['source_station']=pt['PointUid']
        transfer_df['forward_length']=transfer_df.dist      
        transfer_df=transfer_df[transfer_df.LineUid!=pt['LineUid']]  
        transfer_df_list.append(transfer_df)
        
    transfer_df_concat=pd.concat(transfer_df_list)                           
    transfer_df_concat['time_cost']=transfer_df_concat.apply(lambda row:row.forward_length/(speed*1000)*60,axis=1)                
    
    G=nx.from_pandas_edgelist(df=transfer_df_concat,source='source_station',target='PointUid',edge_attr=['forward_length','time_cost'])
    
    for idx,row in transfer_df_concat.iterrows():
        G.nodes[row['PointUid']]['position']=(row.geometry_x.x,row.geometry_x.y)

    return  G,transfer_df_concat
```


```python
station_geometries_df=lines_df4G[['PointUid','geometry_x','LineUid']] 
G_bus_transfer,transfer_df_concat=transfer_stations_network(station_geometries_df,transfer_distance=400,speed=4.39) 
```

    100%|██████████| 31977/31977 [3:19:17<00:00,  2.67it/s]  
    

打印公交系统的换乘子网络。


```python
fig, ax=plt.subplots(figsize=(30*2*2, 30*4*2))
nx.draw(G_bus_transfer,pos=nx.get_node_attributes(G_bus_transfer,'position'),edge_color='black',node_size=50,ax=ax) 
```


<img src="./imgs/2_8_3/output_96_0.png" height='auto' width='auto' title="caDesign">    



将公交系统的换乘子网络存入本地磁盘。


```python
__C.data.G_bus_ransfer="./data/network/G_bus_transfer.gpickle"
with open(args.data.G_bus_ransfer,'wb') as f:
    pickle.dump(G_bus_transfer, f)
```

#### 3) 构建地铁系统子网络

同公交系统子网络的构建，直接调用已经定义的`subG_trans()`函数，生成地铁系统子网络，并存储到本地磁盘。


```python
subway_stations=postSQL2gpd(table_name='subway_stations',**args.db.db_info)
subway_routes=postSQL2gpd(table_name='subway_lines',**args.db.db_info)
```

    __________________________________________________
    The data has been read from PostgreSQL database. The table name is subway_stations.
    __________________________________________________
    The data has been read from PostgreSQL database. The table name is subway_lines.
    

地铁站点的`PointUid`字段ID标识和公交站点的`PointUid`字段ID标识可能存在相同的ID号（可能位于同一位置），为了区分地铁和公交的ID标识，将地铁的`PointUid`字段ID标识前增加字符`s_`作为区分。


```python
subway_stations['PointUid']=subway_stations.PointUid.apply(lambda row:'s_'+row)
```


```python
G_subway_stations,subway_s_e_nodes,subway_lines_df4G=subG_trans(subway_stations,subway_routes,speed=18.77) 
```

    100%|██████████| 20/20 [00:00<00:00, 43.89it/s]
    


```python
subway_lines_df4G.head(3)
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th></th>
      <th>PointName</th>
      <th>PointUid</th>
      <th>Lng</th>
      <th>Lat</th>
      <th>IsPractica</th>
      <th>LineName_x</th>
      <th>LineUid</th>
      <th>geometry_x</th>
      <th>mask_x</th>
      <th>LineName_y</th>
      <th>...</th>
      <th>nearestPts</th>
      <th>project_norm</th>
      <th>order_idx</th>
      <th>second_project</th>
      <th>second_PointName</th>
      <th>second_PointUid</th>
      <th>substring</th>
      <th>forward_length</th>
      <th>time_cost</th>
      <th>edges</th>
    </tr>
    <tr>
      <th></th>
      <th>LineUid</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>315</th>
      <th>031d4680f2fa3654e60738d4</th>
      <td>安德门</td>
      <td>s_26f430f612ec6cd121f01731</td>
      <td>118.75688738084</td>
      <td>31.992830651745</td>
      <td>1</td>
      <td>地铁10号线(安德门-雨山路)</td>
      <td>031d4680f2fa3654e60738d4</td>
      <td>POINT (665971.810 3540989.467)</td>
      <td>True</td>
      <td>地铁10号线(安德门-雨山路)</td>
      <td>...</td>
      <td>POINT (665971.810 3540989.467)</td>
      <td>0.000000</td>
      <td>1</td>
      <td>0.095246</td>
      <td>小行</td>
      <td>s_153f5f1301157bda4c3a595b</td>
      <td>LINESTRING (665971.810 3540989.467, 664311.516...</td>
      <td>1917.170671</td>
      <td>6.128409</td>
      <td>[(s_26f430f612ec6cd121f01731, s_153f5f1301157b...</td>
    </tr>
    <tr>
      <th>316</th>
      <th>031d4680f2fa3654e60738d4</th>
      <td>小行</td>
      <td>s_153f5f1301157bda4c3a595b</td>
      <td>118.739156216275</td>
      <td>31.9844281695514</td>
      <td>0</td>
      <td>地铁10号线(安德门-雨山路)</td>
      <td>031d4680f2fa3654e60738d4</td>
      <td>POINT (664311.516 3540030.840)</td>
      <td>True</td>
      <td>地铁10号线(安德门-雨山路)</td>
      <td>...</td>
      <td>POINT (664311.516 3540030.840)</td>
      <td>0.095246</td>
      <td>2</td>
      <td>0.155467</td>
      <td>中胜</td>
      <td>s_c67ae2d9d96e3b29df1e52e2</td>
      <td>LINESTRING (664311.516 3540030.840, 663273.829...</td>
      <td>1212.160321</td>
      <td>3.874780</td>
      <td>[(s_153f5f1301157bda4c3a595b, s_c67ae2d9d96e3b...</td>
    </tr>
    <tr>
      <th>317</th>
      <th>031d4680f2fa3654e60738d4</th>
      <td>中胜</td>
      <td>s_c67ae2d9d96e3b29df1e52e2</td>
      <td>118.728283054112</td>
      <td>31.9902280445245</td>
      <td>0</td>
      <td>地铁10号线(安德门-雨山路)</td>
      <td>031d4680f2fa3654e60738d4</td>
      <td>POINT (663273.829 3540657.368)</td>
      <td>True</td>
      <td>地铁10号线(安德门-雨山路)</td>
      <td>...</td>
      <td>POINT (663273.829 3540657.368)</td>
      <td>0.155467</td>
      <td>3</td>
      <td>0.225662</td>
      <td>元通</td>
      <td>s_918fd0373e1f728cf33cbad7</td>
      <td>LINESTRING (663273.829 3540657.368, 662128.887...</td>
      <td>1412.925204</td>
      <td>4.516543</td>
      <td>[(s_c67ae2d9d96e3b29df1e52e2, s_918fd0373e1f72...</td>
    </tr>
  </tbody>
</table>
<p>3 rows × 22 columns</p>
</div>



打印地铁系统子网络。


```python
fig, ax=plt.subplots(figsize=(30*2*2, 30*4*2))
nx.draw(G_subway_stations,pos=nx.get_node_attributes(G_subway_stations,'position'),edge_color='black',labels=nx.get_node_attributes(G_subway_stations,'station_name'),font_size=60,node_size=50,ax=ax) 
```


<img src="./imgs/2_8_3/output_106_0.png" height='auto' width='auto' title="caDesign">    




```python
__C.data.G_subway_stations="./data/network/G_subway_stations.gpickle"
with open(args.data.G_subway_stations,'wb') as f:
    pickle.dump(G_subway_stations, f)
```

#### 4) 构建公交-地铁系统换乘子网络

除了构建公交系统内部的换乘子网络，公交系统和地铁系统之间同样存在换乘，因此构建公交-地铁系统换乘子网络，定义`transfer_stations_network4subway_bus()`函数实现，该函数与定义的`transfer_stations_network()`函数基本类似。同样将计算获取的公交-地铁系统换乘子网络存至本地磁盘。


```python
def transfer_stations_network4subway_bus(bus_df,subway_df,transfer_distance,speed): 
    '''
    构建公交-地铁系统换乘子网络

    Parameters
    ----------
    bus_df : GeoDataFrame
        subG_trans函数（用于构建公共交通（公交或地铁）子网络）返回的结果——为公交系统返回结果.
    subway_df : GeoDataFrame
        subG_trans函数（用于构建公共交通（公交或地铁）子网络）返回的结果——为地铁系统返回结果.
    transfer_distance : float
        换乘所能承受的最大距离.
    speed : float
        步行时速.

    Returns
    -------
    G : networkx.classes.graph.Graph
        公交-地铁系统换乘子网络.
    transfer_df_concat : DataFrame
        用于生成公交-地铁系统换乘子网络的DataFrame对象.

    '''    
    import copy
    from tqdm import tqdm
    import pandas as pd
    import networkx as nx
    
    transfer_df_list=[]
    bus_stations_=bus_df[['PointUid','geometry_x','LineUid']]
    subway_station_=subway_df[['PointUid','geometry_x','LineUid']]
    subway_station=subway_station_.to_dict('record')
    for pt in tqdm(subway_station):
        bus_stations=copy.deepcopy(bus_stations_)
        bus_stations['dist']=bus_stations.geometry_x.apply(lambda row:row.distance(pt['geometry_x']))
        transfer_df=bus_stations[bus_stations.dist<=transfer_distance]
        transfer_df=transfer_df[transfer_df.dist!=0]
        transfer_df.drop_duplicates(subset='PointUid',keep='first',inplace=True)           
        transfer_df['source_station']=pt['PointUid']
        transfer_df['forward_length']=transfer_df.dist
        transfer_df_list.append(transfer_df)

    transfer_df_concat=pd.concat(transfer_df_list)
    transfer_df_concat['time_cost']=transfer_df_concat.apply(lambda row:row.forward_length/(speed*1000)*60,axis=1)
    G=nx.from_pandas_edgelist(df=transfer_df_concat,source='source_station',target='PointUid',edge_attr=['forward_length','time_cost'])
    
    for node in tqdm(G.nodes):      
        if node in bus_stations_.PointUid.to_list():
            pt=bus_stations_.loc[bus_stations_['PointUid']==node,'geometry_x'].item()
            G.nodes[node]['position']=(pt.x,pt.y)
            
        elif node in subway_station_.PointUid.to_list():
            pt=subway_station_.loc[subway_station_['PointUid']==node,'geometry_x'].item()
            G.nodes[node]['position']=(pt.x,pt.y)                        
    
    return G,transfer_df_concat
```


```python
G_subway_bus_transfer,subway_bus_transfer_df_concat=transfer_stations_network4subway_bus(bus_df=bus_lines_df4G,subway_df=subway_lines_df4G,transfer_distance=400,speed=4.39)   
```

    100%|██████████| 348/348 [02:42<00:00,  2.15it/s]
    100%|██████████| 4444/4444 [00:19<00:00, 222.55it/s]
    


```python
subway_bus_transfer_df_concat.head(3)
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th></th>
      <th>PointUid</th>
      <th>geometry_x</th>
      <th>LineUid</th>
      <th>dist</th>
      <th>source_station</th>
      <th>forward_length</th>
      <th>time_cost</th>
    </tr>
    <tr>
      <th></th>
      <th>LineUid</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>22404</th>
      <th>01000db975471b8cb64f54a7</th>
      <td>d3b6395653cc1c80601c67de</td>
      <td>POINT (666026.030 3541291.205)</td>
      <td>01000db975471b8cb64f54a7</td>
      <td>306.570722</td>
      <td>s_26f430f612ec6cd121f01731</td>
      <td>306.570722</td>
      <td>4.190033</td>
    </tr>
    <tr>
      <th>6506</th>
      <th>01a59c056cf31073266e9810</th>
      <td>e9de6509923177582bb97c50</td>
      <td>POINT (665686.091 3540973.057)</td>
      <td>01a59c056cf31073266e9810</td>
      <td>286.190597</td>
      <td>s_26f430f612ec6cd121f01731</td>
      <td>286.190597</td>
      <td>3.911489</td>
    </tr>
    <tr>
      <th>13809</th>
      <th>01c0f536aa9099c130621272</th>
      <td>6c9c9588865d300f9d82eac9</td>
      <td>POINT (666031.407 3541299.839)</td>
      <td>01c0f536aa9099c130621272</td>
      <td>316.041467</td>
      <td>s_26f430f612ec6cd121f01731</td>
      <td>316.041467</td>
      <td>4.319473</td>
    </tr>
  </tbody>
</table>
</div>



打印公交-地铁系统换乘子网络。


```python
fig, ax=plt.subplots(figsize=(30*2, 30*4))
nx.draw(G_subway_bus_transfer,pos=nx.get_node_attributes(G_subway_bus_transfer,'position'),edge_color='black',node_size=50,ax=ax) 
```


<img src="./imgs/2_8_3/output_113_0.png" height='auto' width='auto' title="caDesign">    




```python
__C.data.G_subway_bus_transfer="./data/network/G_subway_bus_transfer.gpickle"
with open(args.data.G_subway_bus_transfer,'wb') as f:
    pickle.dump(G_subway_bus_transfer, f)
```

#### 5) 合并子网络，构建公共交通复合网络

通过前文已经构建了公交系统子网络，公交系统的换乘子网络，地铁系统子网络和公交-地铁系统换乘子网络，可以将各个子网络合并为一个公共交通复合网络。`NetWorkX`库提供的`compose(G, H)`方法每次只能合并两个子网络，因此先分别合并为`G_bus`和`G_subway`，再合并为最终的复合网络。将合并后的公共交通复合网络同样存储至本地磁盘，用于后续调用分析。


```python
G_bus=nx.compose(G_bus_stations,G_bus_transfer)  
G_subway=nx.compose(G_subway_stations,G_subway_bus_transfer)
G_SB=nx.compose(G_subway,G_bus)
```


```python
__C.data.G_SB="./data/network/G_SB.gpickle"
with open(args.data.G_SB,'wb') as f:
    pickle.dump(G_SB, f)
```

* 打印公共交通复合网络

总共建立了4个子网络，和一个合并4个子网络后的公共交通复合网络，均已存储至本地磁盘，因此可以读取。为了方便查看网络不同内容的分布情况，可以叠加打印不同部分，例如下述打印了复合网络后，又叠加打印了`G_bus_transfer`公交换乘子网络的边（红色），`G_subway_stations`地铁子网络的边，和公园邻近的站点`G_start_stops`。


```python
G_fns={'G_SB':args.data.G_SB,
      'G_bus_stations':args.data.G_bus_stations,
      'G_bus_transfer':args.data.G_bus_ransfer,
      'G_subway_stations':args.data.G_subway_stations,
      'G_subway_bus_transfe':args.data.G_subway_bus_transfer}

Gs={}
for k,v in G_fns.items():
    with open(v,'rb') as f:
        Gs[k]=pickle.load(f)
```


```python
flatten_lst=lambda lst: [m for n_lst in lst for m in flatten_lst(n_lst)] if type(lst) is list else [lst]    

comprehensivePark_adjacentStations=postSQL2gpd(table_name='adjacent_stations',**args.db.db_info)
start_stops_PointUid=flatten_lst([eval(lst) for lst in comprehensivePark_adjacentStations.adjacent_PointUid])
G_bus_stations=Gs['G_bus_stations']
G_start_stops=G_bus_stations.subgraph(start_stops_PointUid)
```

    __________________________________________________
    The data has been read from PostgreSQL database. The table name is adjacent_stations.
    


```python
fig, ax=plt.subplots(figsize=(30*2*2, 30*4*2))
G_name='G_SB'
nx.draw(Gs['%s'%G_name],
        pos=nx.get_node_attributes(Gs['%s'%G_name],'position'),
        edge_color='black',
        font_size=20,
        node_size=50,
        ax=ax) 
nx.draw_networkx_edges(Gs['G_bus_transfer'],
                       pos=nx.get_node_attributes(Gs['G_bus_transfer'],'position'),
                       edgelist=Gs['G_bus_transfer'].edges,
                       edge_color='red',
                       width=5,
                       ax=ax) 
nx.draw_networkx_edges(Gs['G_subway_stations'],
                       pos=nx.get_node_attributes(Gs['G_subway_stations'],'position'),
                       edgelist=Gs['G_subway_stations'].edges,
                       edge_color='orange',
                       width=10,
                       ax=ax)
nx.draw_networkx_nodes(G_start_stops,
                       pos=nx.get_node_attributes(G_start_stops,'position'),
                       node_size=160,
                       ax=ax,
                       node_color='green')
plt.show()
```


<img src="./imgs/2_8_3/output_121_0.png" height='auto' width='auto' title="caDesign">    



### 2.8.3.3 最短路径及长度

#### 1) [NetWorkX库的最短路径算法](https://networkx.org/documentation/stable/reference/algorithms/shortest_paths.html)<sup>③</sup>

* Shortest Paths（最短路径）

计算图中顶点之间的最短路径和路径长度（该部分算法适用于无向图和有向图）。

`shortest_path`(G, source=None, target=None, weight=None, method='dijkstra')：计算图中顶点间的最短路径。


```python
import networkx as nx
import util_misc

G = nx.path_graph(5)
util_misc.G_drawing(G)
print(nx.shortest_path(G, source=0, target=4))

print(nx.shortest_path(G, source=0))  # target not specified
print(nx.shortest_path(G, target=4))  # source not specified
print(nx.shortest_path(G))  # source, target not specified
```


<img src="./imgs/2_8_3/output_123_0.png" height='auto' width='auto' title="caDesign">

    


    [0, 1, 2, 3, 4]
    {0: [0], 1: [0, 1], 2: [0, 1, 2], 3: [0, 1, 2, 3], 4: [0, 1, 2, 3, 4]}
    {4: [4], 3: [3, 4], 2: [2, 3, 4], 1: [1, 2, 3, 4], 0: [0, 1, 2, 3, 4]}
    {0: {0: [0], 1: [0, 1], 2: [0, 1, 2], 3: [0, 1, 2, 3], 4: [0, 1, 2, 3, 4]}, 1: {1: [1], 0: [1, 0], 2: [1, 2], 3: [1, 2, 3], 4: [1, 2, 3, 4]}, 2: {2: [2], 1: [2, 1], 3: [2, 3], 0: [2, 1, 0], 4: [2, 3, 4]}, 3: {3: [3], 2: [3, 2], 4: [3, 4], 1: [3, 2, 1], 0: [3, 2, 1, 0]}, 4: {4: [4], 3: [4, 3], 2: [4, 3, 2], 1: [4, 3, 2, 1], 0: [4, 3, 2, 1, 0]}}
    

`shortest_path_length`(G, source=None, target=None, weight=None, method='dijkstra')：计算图中顶点间的最短路径长度。其中`method`参数支持算法`dijkstra`和`bellman-ford`。


```python
print(nx.shortest_path_length(G, source=0, target=4))

print(nx.shortest_path_length(G, source=0))  # target not specified
print(nx.shortest_path_length(G, target=4))  # source not specified
print(dict(nx.shortest_path_length(G)))  # source,target not specified
```

    4
    {0: 0, 1: 1, 2: 2, 3: 3, 4: 4}
    {4: 0, 3: 1, 2: 2, 1: 3, 0: 4}
    {0: {0: 0, 1: 1, 2: 2, 3: 3, 4: 4}, 1: {1: 0, 0: 1, 2: 1, 3: 2, 4: 3}, 2: {2: 0, 1: 1, 3: 1, 0: 2, 4: 2}, 3: {3: 0, 2: 1, 4: 1, 1: 2, 0: 3}, 4: {4: 0, 3: 1, 2: 2, 1: 3, 0: 4}}
    

`average_shortest_path_length`(G, weight=None, method=None:返回所有两点间最短路径的平均长度，计算公式为$\begin{split}a =\sum_{\substack{s,t \in V \\ s\neq t}} \frac{d(s, t)}{n(n-1)}\end{split}$，式中，$v$是图$G$的顶点集；$d(s, t)$是顶点$s$到$t$的最短路径；$n$是图$G$的阶（顶点数量）。


```python
nx.average_shortest_path_length(G)
```




    2.0



`all_shortest_paths`(G, source, target, weight=None, method='dijkstra')：计算图中给定两个顶点间所有最短路径。


```python
G = nx.Graph()
nx.add_path(G, [0, 1, 2])
nx.add_path(G, [0, 10, 2])
nx.add_path(G, [0, 10, 3,2])
util_misc.G_drawing(G)
print([p for p in nx.all_shortest_paths(G, source=0, target=2)])
```


<img src="./imgs/2_8_3/output_129_0.png" height='auto' width='auto' title="caDesign">    

    


    [[0, 1, 2], [0, 10, 2]]
    

* Advanced Interface（高级交互）

**无权重最短路径算法**

`single_source_shortest_path`(G, source, cutoff=None)：计算从给定顶点到其它所有可达顶点之间的最短路径。


```python
G=nx.path_graph(5)
G.add_edges_from([(5,6),(5,7),(6,7)])
util_misc.G_drawing(G)
print(nx.single_source_shortest_path(G, 0))
```


<img src="./imgs/2_8_3/output_131_0.png" height='auto' width='auto' title="caDesign">    



    {0: [0], 1: [0, 1], 2: [0, 1, 2], 3: [0, 1, 2, 3], 4: [0, 1, 2, 3, 4]}
    

`single_source_shortest_path_length`(G, source, cutoff=None)：计算从给定顶点到其它所有可达顶点之间的最短路径长度。


```python
print(nx.single_source_shortest_path_length(G, 0))
```

    {0: 0, 1: 1, 2: 2, 3: 3, 4: 4}
    

`single_target_shortest_path`(G, target, cutoff=None)：计算可到给定顶点所有其它顶点之间的最短路径。


```python
print(nx.single_target_shortest_path(G, 4))
```

    {4: [4], 3: [3, 4], 2: [2, 3, 4], 1: [1, 2, 3, 4], 0: [0, 1, 2, 3, 4]}
    

`single_target_shortest_path_length`(G, target, cutoff=None)：计算可到给定顶点所有其它顶点之间的最短路径长度。


```python
print(dict(nx.single_target_shortest_path_length(G, 4)))
```

    {4: 0, 3: 1, 2: 2, 1: 3, 0: 4}
    

`all_pairs_shortest_path`(G, cutoff=None)：计算所有顶点间最短路径。


```python
print(dict(nx.all_pairs_shortest_path(G)))
```

    {0: {0: [0], 1: [0, 1], 2: [0, 1, 2], 3: [0, 1, 2, 3], 4: [0, 1, 2, 3, 4]}, 1: {1: [1], 0: [1, 0], 2: [1, 2], 3: [1, 2, 3], 4: [1, 2, 3, 4]}, 2: {2: [2], 1: [2, 1], 3: [2, 3], 0: [2, 1, 0], 4: [2, 3, 4]}, 3: {3: [3], 2: [3, 2], 4: [3, 4], 1: [3, 2, 1], 0: [3, 2, 1, 0]}, 4: {4: [4], 3: [4, 3], 2: [4, 3, 2], 1: [4, 3, 2, 1], 0: [4, 3, 2, 1, 0]}, 5: {5: [5], 6: [5, 6], 7: [5, 7]}, 6: {6: [6], 5: [6, 5], 7: [6, 7]}, 7: {7: [7], 5: [7, 5], 6: [7, 6]}}
    

`all_pairs_shortest_path_length`(G, cutoff=None)：计算所有顶点间最短路径长度。


```python
print(dict(nx.all_pairs_shortest_path_length(G)))
```

    {0: {0: 0, 1: 1, 2: 2, 3: 3, 4: 4}, 1: {1: 0, 0: 1, 2: 1, 3: 2, 4: 3}, 2: {2: 0, 1: 1, 3: 1, 0: 2, 4: 2}, 3: {3: 0, 2: 1, 4: 1, 1: 2, 0: 3}, 4: {4: 0, 3: 1, 2: 2, 1: 3, 0: 4}, 5: {5: 0, 6: 1, 7: 1}, 6: {6: 0, 5: 1, 7: 1}, 7: {7: 0, 5: 1, 6: 1}}
    

`predecessor`(G, source, target=None, cutoff=None, return_seen=None)：返回给定顶点到所有顶点最短路径的前一顶点。如果指定参数`return_seen=True`，同时返回以可达顶点为键，以到达该顶点的级（level）/跳（hops）数为值。


```python
print(nx.predecessor(G, 0))
print(nx.predecessor(G, 0, return_seen=True))
```

    {0: [], 1: [0], 2: [1], 3: [2], 4: [3]}
    ({0: [], 1: [0], 2: [1], 3: [2], 4: [3]}, {0: 0, 1: 1, 2: 2, 3: 3, 4: 4})
    

**有权重最短路径算法**

`dijkstra_predecessor_and_distance`(G, source, cutoff=None, weight='weight')：计算加权最短路径长度，并返回前一顶点。


```python
G = nx.path_graph(5, create_using=nx.DiGraph())
G.add_edge(1,3)
nx.set_edge_attributes(G,
                       {
                        (0,1): {"weight": 5.0},
                        (1,2): {"weight": 2.0},
                        (2,3): {"weight": 3.0},
                        (3,4): {"weight": 1.0},
                        (1,3): {"weight": 1.0},
                       })
util_misc.G_drawing(G,edge_labels='weight')
pred, dist = nx.dijkstra_predecessor_and_distance(G, 0) 
print(sorted(pred.items()))
print(sorted(dist.items()))
```


<img src="./imgs/2_8_3/output_145_0.png" height='auto' width='auto' title="caDesign">    

    


    [(0, []), (1, [0]), (2, [1]), (3, [1]), (4, [3])]
    [(0, 0), (1, 5.0), (2, 7.0), (3, 6.0), (4, 7.0)]
    

`dijkstra_path`(G, source, target, weight='weight')：返回图G两点间最短加权路径。


```python
print(nx.dijkstra_path(G, 0, 4))
```

    [0, 1, 3, 4]
    

`dijkstra_path_length`(G, source, target, weight='weight')：返回图G两点间最短加权路径长度。


```python
print(nx.dijkstra_path_length(G, 0, 4))
```

    7.0
    

`single_source_dijkstra`(G, source, target=None, cutoff=None, weight='weight'：计算从给定顶点到其它所有可达顶点之间的最短加权路径和长度。

如果要单独返回最短加权路径和长度，则可以调用`single_source_dijkstra_path`(G, source, cutoff=None, weight='weight')和`single_source_dijkstra_path_length`(G, source, cutoff=None, weight='weight')。如果要同时计算给定多个顶点（仅返回最短路径的顶点对应的路径和长度），则可以调用`multi_source_dijkstra`(G, sources, target=None, cutoff=None, weight='weight')、`multi_source_dijkstra_path`(G, sources, cutoff=None, weight='weight')和`multi_source_dijkstra_path_length`(G, sources, cutoff=None, weight='weight')方法。


```python
print(nx.single_source_dijkstra(G, 0))
```

    ({0: 0, 1: 5.0, 3: 6.0, 2: 7.0, 4: 7.0}, {0: [0], 1: [0, 1], 2: [0, 1, 2], 3: [0, 1, 3], 4: [0, 1, 3, 4]})
    

`all_pairs_dijkstra`(G, cutoff=None, weight='weight')：返回所有顶点间最短加权路径和长度。

如果只返回最短加权路径或长度，则可以调用`all_pairs_dijkstra_path`(G, cutoff=None, weight='weight')或`all_pairs_dijkstra_path_length`(G, cutoff=None, weight='weight')。


```python
sorted(nx.all_pairs_dijkstra(G))
```




    [(0,
      ({0: 0, 1: 5.0, 3: 6.0, 2: 7.0, 4: 7.0},
       {0: [0], 1: [0, 1], 2: [0, 1, 2], 3: [0, 1, 3], 4: [0, 1, 3, 4]})),
     (1,
      ({1: 0, 3: 1.0, 2: 2.0, 4: 2.0},
       {1: [1], 2: [1, 2], 3: [1, 3], 4: [1, 3, 4]})),
     (2, ({2: 0, 3: 3.0, 4: 4.0}, {2: [2], 3: [2, 3], 4: [2, 3, 4]})),
     (3, ({3: 0, 4: 1.0}, {3: [3], 4: [3, 4]})),
     (4, ({4: 0}, {4: [4]}))]



`NetWorkX`库也提供了`bellman_ford`、`Johnson`、`Floyd`和` A* (“A-star”)`等最短（加权）路径算法的各类计算形式，可从官网查看。

#### 2) 公共交通复合网络最短路径和长度计算

分析站点和公园（邻近站点）之间的关系，如果以公园为对象，则计算每个公园邻近站点到所有站点的最短距离（时间成本距离），反映的是公园服务于整个分析区域的位置优势，具有相对平均更短的时间成本距离，会更容易吸引分析区域内的居民到达（就近原则）；如果以站点为对象，则计算每个站点到所有公园的最短时间成本距离和均值，反映的是站点位置到达各个公园的优先选择，更多的居民会优先选择距离站点近的公园，而总体的均值则揭示了各个站点可达公园的水平，均值低的站点有更多选择不同公园的机会，而均值高的站点更容易选择距离近的公园。因此对公共交通复合网络最短路径（为顶点，即站点列表）和长度（为时间成本距离值）的计算，需要从公园服务和站点可达性两个方向（对象）进行分析，表述了服务和供给的关系。

应用`NetWorkX`库提供的`single_source_dijkstra`和`multi_source_dijkstra`方法计算。

* 公园服务——计算每个公园各个邻近站点到所有站点的加权最短时间成本距离


```python
import pickle
comprehensivePark_adjacentStations=postSQL2gpd(table_name='adjacent_stations',**args.db.db_info)
with open(args.data.G_SB,'rb') as f:
    G_SB=pickle.load(f)
```

    __________________________________________________
    The data has been read from PostgreSQL database. The table name is adjacent_stations.
    

查看公共交通复合网络顶点数有3万点之多，而每个公园各个邻近站点总共有3266个，如果计算每个邻近站点到所有站点的最短路径，将有$32325 \times 3266$条，如果同时存储路径和时间成本距离，文件的大小可能比较大，因此采取每个公园所有的最短路径存储为单独一个文件，总共为53个文件。每个文件的大小从几百MB到约2.5GB不等，总共约20.6GB。

计算时，也同时计算了每个公园各个邻近站点到所有站点的最短路径均值`park2station_mean_time_cost_all`，存储到单独的文件中。


```python
print(len(G_SB.nodes))
```

    32325
    


```python
import numpy as np
comprehensivePark_adjacentStations_unique_list=np.unique(flatten_lst([eval(i) for i in comprehensivePark_adjacentStations.adjacent_PointUid.to_list()]))
print(len(comprehensivePark_adjacentStations_unique_list))
```

    3266
    


```python
from tqdm import tqdm
import pickle
import os
from statistics import mean
__C.data.park2staton_sp_root=r"E:\data\public_trans_network\park2station_sp"
__C.data.park2station_mean_time_cost_all_fn=r'E:\data\public_trans_network\park2station_mean_time_cost_all.pickle'

park2station_mean_time_cost_all={}
for idx,row in tqdm(comprehensivePark_adjacentStations.iterrows(),total=comprehensivePark_adjacentStations.shape[0]):
    park2station_sp_all={}    
    park2station_mean_time_cost_all[row.Name_EN]={}
    save_fn=os.path.join(args.data.park2staton_sp_root,f'{idx}_{row.Name_EN}.pickle')
    for station in eval(row.adjacent_PointUid):
        park2station_sp=nx.single_source_dijkstra(G_SB, station,weight='time_cost')
        p2s_mean_time_cost=mean(park2station_sp[0].values())
        park2station_sp_all[station]=park2station_sp    
        park2station_mean_time_cost_all[row.Name_EN][station]=p2s_mean_time_cost

    with open(save_fn,'wb') as f:
         pickle.dump(park2station_sp_all,f)   

with open(args.data.park2station_mean_time_cost_all_fn,'wb') as f:
     pickle.dump(park2station_mean_time_cost_all,f)              
```

    100%|██████████| 53/53 [44:45<00:00, 50.67s/it] 
    

读取存储的公园邻近站点最短路径均值，并按公园打印为箱型图并叠加散点图，观察各个公园到分析区域所有站点最短路径时间成本距离的分布情况。较低值域分布通常位于分析区域中心，并有较多的站点可达；而较高值域分布通常位于分析区域偏离中心的位置，较为偏远。


```python
with open(args.data.park2station_mean_time_cost_all_fn,'rb') as f:
     park2station_mean_time_cost_all=pickle.load(f) 
```


```python
import seaborn as sns
import matplotlib.pyplot as plt
sns.set_style("ticks",{"font.sans-serif":['simhei', 'Arial']}) 

f, ax=plt.subplots(figsize=(20, 11))
mean_time_cost_park=[list(i.values()) for i in park2station_mean_time_cost_all.values()]
sns.boxplot(data=mean_time_cost_park,palette="vlag",orient='h',)
sns.stripplot(mean_time_cost_park,size=4, color=".3", linewidth=0,orient='h')

comprehensive_park_name_mapping_EN2CH={v:k for k,v in comprehensive_park_name_mapping.items()}
park_names=[comprehensive_park_name_mapping_EN2CH[i] for i in park2station_mean_time_cost_all.keys()]
ax.set_yticklabels(park_names)
ax.xaxis.grid(True)
sns.despine(trim=True, left=True)
```


<img src="./imgs/2_8_3/output_163_0.png" height='auto' width='auto' title="caDesign">    

    


* 站点可达性——计算每个站点到每个公园各个邻近站点的加权最短时间成本距离

已经获取每个公园各个邻近站点到分析区域内所有站点的最短距离，那么分析区域内各个站点到一个公园（包含多个邻近站点）的最短路径，应该是到该公园邻近站点中最短距离的那个邻近站点（即仅筛选出一条路径，对应一个邻近站点），因此定义`station2park_shortestPaths()`函数，批量计算分析区域内所有站点到各个公园的最短路径。同样将计算结果存至本地磁盘。


```python
def station2park_shortestPaths(G_SB,park2staton_sp_fns,epsg,save_path):
    '''
    计算各个站点到一个公园（包含多个邻近站点）的最短路径，可以批量计算多个公园

    Parameters
    ----------
    G_SB : networkx.classes.graph.Graph
        公共交通复合网络.
    park2staton_sp_fns : list[string]
        每个公园各个邻近站点到所有站点的加权最短时间成本距离文件路径.
    epsg : pyproj.crs.crs.CRS[int]
        投影epsg编号.
    save_path : string
        计算结果文件保存路径.

    Returns
    -------
    None.

    '''    
    import networkx as nx
    from tqdm import tqdm
    import pickle
    import pandas as pd
    import numpy as np
    from shapely.geometry import LineString
    import geopandas as gpd
    from pathlib import Path
    
    station_position=nx.get_node_attributes(G_SB,'position')
    park_shortest_path={}
    for fn in tqdm(park2staton_sp_fns):
        with open(fn,'rb') as f:
            park2staton_sp=pickle.load(f)
        all_shortest_length_df=pd.DataFrame.from_dict({k:v[0] for k,v in park2staton_sp.items()},orient='index')
        all_shortest_length_df.replace({0:np.NaN},inplace=True)
        min_length=all_shortest_length_df.min()
        min_idx=all_shortest_length_df.idxmin()
        min_concat=pd.concat([min_idx,min_length],axis=1).reset_index().rename(columns={0:'idx_adjacent',1:"time_cost",'index':'stations'})  
        all_shortest_path_dict={k:v[1] for k,v in park2staton_sp.items()}
        min_concat['path']=min_concat.apply(lambda row:all_shortest_path_dict[row.idx_adjacent][row.stations],axis=1)
        min_concat['geometry']=min_concat.path.apply(lambda row:LineString([station_position[PointUid] for PointUid in row]))
        min_concat_gdf=gpd.GeoDataFrame(min_concat,geometry='geometry',crs=epsg)
        park_shortest_path[Path(fn).stem]=min_concat_gdf

    with open(save_path,'wb') as f:
        pickle.dump(park_shortest_path,f)  
    
import os    
park2staton_sp_fns=[os.path.join(args.data.park2staton_sp_root,i) for i in  os.listdir(args.data.park2staton_sp_root)]    
__C.data.park_shortest_path_fn=r"E:\data\public_trans_network\park_shortest_path.pkl"
station2park_shortestPaths(G_SB,park2staton_sp_fns,args.gi.nanjing_epsg,args.data.park_shortest_path_fn)    
```

    100%|██████████| 53/53 [25:19<00:00, 28.68s/it]
    

读取并查看计算后存至本地磁盘的文件。每个公园对应一个GeoDataFrame格式数据，其中`stations`列为分析区域内所有站点，`idx_adjacent`列为站点对应的邻近站点，是该站点到达公园的最短路径（为到公园诸多邻近站点路径最短的，`time_cost`列为时间成本距离，`path`列为最短路径（路），`geometry`为最短路径空间几何对象。


```python
with open(args.data.park_shortest_path_fn,'rb') as f:
    park_shortest_path=pickle.load(f)
```


```python
print(park_shortest_path.keys())
park_shortest_path['0_Bazi Mountain']
```

    dict_keys(['0_Bazi Mountain', '10_Wulong Pool', '11_Xiuqing Park', '12_Hexi Central Park', '13_Green EXPO Garden', '14_Riverside Park', '15_Mochou Lake', '16_South Lake', '17_Baijia Lake', '18_Phoenix Park', '19_Jiulong Park', '1_Beigu Mountain', '20_Zhushan Park', '21_Jiulong Park', '22_Liuhe Phoenix Mountain', '23_Dragon Pool', '24_Pingding Mountain', '25_Prince Mountain', '26_Pagoda Hill', '27_North Fort', '28_Phoenix Mountain', '29_Pukou Park', '2_Bridge park', '30_Two Bridges Park', '31_Nanlian Park', '32_Three Leaf Lake', '33_Taiping Hill', '34_Wulong Mountain', '35_Swallow Rock', '36_Egret Island', '37_Qiqiaoweng Park', '38_Wuchaomen Park', '39_Crescent Lake', '3_Ancient Forest', '40_Zhenghe Park', '41_White House Park', '42_Arctic Pavilion', '43_Jiuhua Mountain', '44_Treasure Hill', '45_Plum Blossom Valley', '46_Couples Garden', '47_South Park of Sports Institute', '48_Xuanwu Lake', '49_Flora Lake', '4_Drum Tower', '50_Chrysanthemums Terrace', '51_Lotus Lake', '52_Plum Blossom Hill', '5_Tiger Mountain', '6_Mufu Mountain', '7_Qingliang Mountain', '8_Lion Rock Mountain', '9_Stone City Park'])
    




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>stations</th>
      <th>idx_adjacent</th>
      <th>time_cost</th>
      <th>path</th>
      <th>geometry</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>3176ab8f267a522adc1e5249</td>
      <td>fe1f80a7631696d4ab175aed</td>
      <td>0.019408</td>
      <td>[fe1f80a7631696d4ab175aed, 3176ab8f267a522adc1...</td>
      <td>LINESTRING (664855.936 3551546.438, 664855.439...</td>
    </tr>
    <tr>
      <th>1</th>
      <td>fe1f80a7631696d4ab175aed</td>
      <td>3176ab8f267a522adc1e5249</td>
      <td>0.019408</td>
      <td>[3176ab8f267a522adc1e5249, fe1f80a7631696d4ab1...</td>
      <td>LINESTRING (664855.439 3551547.768, 664855.936...</td>
    </tr>
    <tr>
      <th>2</th>
      <td>bdc72d7d81c5e9674d554732</td>
      <td>f9c911cc8443a54a58f6be3a</td>
      <td>0.009315</td>
      <td>[f9c911cc8443a54a58f6be3a, bdc72d7d81c5e9674d5...</td>
      <td>LINESTRING (664849.553 3551548.860, 664850.145...</td>
    </tr>
    <tr>
      <th>3</th>
      <td>9ae6f103dc1fa50f0aa8d4e7</td>
      <td>f9c911cc8443a54a58f6be3a</td>
      <td>0.033094</td>
      <td>[f9c911cc8443a54a58f6be3a, 9ae6f103dc1fa50f0aa...</td>
      <td>LINESTRING (664849.553 3551548.860, 664850.745...</td>
    </tr>
    <tr>
      <th>4</th>
      <td>f9c911cc8443a54a58f6be3a</td>
      <td>bdc72d7d81c5e9674d554732</td>
      <td>0.009315</td>
      <td>[bdc72d7d81c5e9674d554732, f9c911cc8443a54a58f...</td>
      <td>LINESTRING (664850.145 3551548.523, 664849.553...</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>32192</th>
      <td>33192a863cc21818d8d891a8</td>
      <td>2077fa870b9bbdb57adbd2c1</td>
      <td>487.746560</td>
      <td>[2077fa870b9bbdb57adbd2c1, 141ded09336bdae46e2...</td>
      <td>LINESTRING (665061.514 3551596.830, 665394.665...</td>
    </tr>
    <tr>
      <th>32193</th>
      <td>df1760ab01d707e48b2fb5c3</td>
      <td>2077fa870b9bbdb57adbd2c1</td>
      <td>488.808496</td>
      <td>[2077fa870b9bbdb57adbd2c1, 141ded09336bdae46e2...</td>
      <td>LINESTRING (665061.514 3551596.830, 665394.665...</td>
    </tr>
    <tr>
      <th>32194</th>
      <td>c9d47676a7369a2f95f08c9e</td>
      <td>2077fa870b9bbdb57adbd2c1</td>
      <td>488.949535</td>
      <td>[2077fa870b9bbdb57adbd2c1, 141ded09336bdae46e2...</td>
      <td>LINESTRING (665061.514 3551596.830, 665394.665...</td>
    </tr>
    <tr>
      <th>32195</th>
      <td>d3648dce49b200d02efaa7a5</td>
      <td>2077fa870b9bbdb57adbd2c1</td>
      <td>491.759761</td>
      <td>[2077fa870b9bbdb57adbd2c1, 141ded09336bdae46e2...</td>
      <td>LINESTRING (665061.514 3551596.830, 665394.665...</td>
    </tr>
    <tr>
      <th>32196</th>
      <td>f60b7ce35261670badb22aaf</td>
      <td>2077fa870b9bbdb57adbd2c1</td>
      <td>491.854833</td>
      <td>[2077fa870b9bbdb57adbd2c1, 141ded09336bdae46e2...</td>
      <td>LINESTRING (665061.514 3551596.830, 665394.665...</td>
    </tr>
  </tbody>
</table>
<p>32197 rows × 5 columns</p>
</div>



按照`stations`列合并包含各个站点到公园最短路径的`park_shortest_path`数据，合并时仅保留最短路径的时间成本列`time_cost`和`stations`。`Pandas`库提供的`merge`方法一次只能合并两个DataFrame格式数据，配合`functools`库提供的`reduce`批量计算。为了达到合并的目的，使用`reduce`时调用自定义函数`pd_merge()`实现重命名列名，避免合并后的列名重复；并移除`park`列，由重命名的列名表明`time_cost`值对应的公园名。


```python
from functools import reduce
import pandas as pd

park_shortest_path_list=[]
for park_name,df in park_shortest_path.items():
    df_=df[['stations','time_cost']]
    df_['park']=park_name
    park_shortest_path_list.append(df_)    
    
def pd_merge(x,y):
    y.rename(columns={i:"{}-{}".format(i,y.park[0]) for i in y.columns if i!='stations'},inplace=True)    
    y.drop(columns=[i for i in y.columns if 'park' in i],inplace=True)
    return pd.merge(x, y, on='stations')
  
station2parks_tc=reduce(pd_merge,park_shortest_path_list)   
station2parks_tc.rename(columns={'time_cost':"{}-{}".format('time_cost',station2parks_tc.park[0]),'park':"{}-{}".format('park',station2parks_tc.park[0])},inplace=True)
station2parks_tc.drop(columns=[i for i in station2parks_tc.columns if 'park' in i],inplace=True)
```

计算各个站点到达所有公园的最短路径时间成本距离均值，存储至列`time_cost_average`下。


```python
time_cost_columns=[i for i in station2parks_tc.columns if 'time_cost' in i]
station2parks_tc['time_cost_average']=station2parks_tc.apply(lambda row:row[time_cost_columns].mean(),axis=1) 
```


```python
station2parks_tc
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>stations</th>
      <th>time_cost-0_Bazi Mountain</th>
      <th>time_cost-10_Wulong Pool</th>
      <th>time_cost-11_Xiuqing Park</th>
      <th>time_cost-12_Hexi Central Park</th>
      <th>time_cost-13_Green EXPO Garden</th>
      <th>time_cost-14_Riverside Park</th>
      <th>time_cost-15_Mochou Lake</th>
      <th>time_cost-16_South Lake</th>
      <th>time_cost-17_Baijia Lake</th>
      <th>...</th>
      <th>time_cost-4_Drum Tower</th>
      <th>time_cost-50_Chrysanthemums Terrace</th>
      <th>time_cost-51_Lotus Lake</th>
      <th>time_cost-52_Plum Blossom Hill</th>
      <th>time_cost-5_Tiger Mountain</th>
      <th>time_cost-6_Mufu Mountain</th>
      <th>time_cost-7_Qingliang Mountain</th>
      <th>time_cost-8_Lion Rock Mountain</th>
      <th>time_cost-9_Stone City Park</th>
      <th>time_cost_average</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>3176ab8f267a522adc1e5249</td>
      <td>0.019408</td>
      <td>22.950006</td>
      <td>0.643352</td>
      <td>46.856041</td>
      <td>48.748149</td>
      <td>50.986255</td>
      <td>24.715803</td>
      <td>32.920009</td>
      <td>67.185653</td>
      <td>...</td>
      <td>17.198855</td>
      <td>46.180673</td>
      <td>100.309090</td>
      <td>110.793531</td>
      <td>93.538042</td>
      <td>18.425975</td>
      <td>17.457294</td>
      <td>4.405315</td>
      <td>17.457294</td>
      <td>50.073777</td>
    </tr>
    <tr>
      <th>1</th>
      <td>fe1f80a7631696d4ab175aed</td>
      <td>0.019408</td>
      <td>22.945966</td>
      <td>0.650552</td>
      <td>46.875450</td>
      <td>48.767558</td>
      <td>51.005663</td>
      <td>24.711762</td>
      <td>32.915968</td>
      <td>67.205062</td>
      <td>...</td>
      <td>17.218264</td>
      <td>46.200081</td>
      <td>100.328499</td>
      <td>110.812940</td>
      <td>93.557450</td>
      <td>18.406567</td>
      <td>17.453253</td>
      <td>4.385907</td>
      <td>17.453253</td>
      <td>50.081661</td>
    </tr>
    <tr>
      <th>2</th>
      <td>bdc72d7d81c5e9674d554732</td>
      <td>0.009315</td>
      <td>23.022326</td>
      <td>0.570990</td>
      <td>46.873608</td>
      <td>48.772338</td>
      <td>51.012818</td>
      <td>24.788123</td>
      <td>32.992329</td>
      <td>67.235164</td>
      <td>...</td>
      <td>17.225726</td>
      <td>46.208000</td>
      <td>100.326657</td>
      <td>110.811098</td>
      <td>93.534306</td>
      <td>18.378164</td>
      <td>17.529614</td>
      <td>4.416776</td>
      <td>17.529614</td>
      <td>50.096912</td>
    </tr>
    <tr>
      <th>3</th>
      <td>9ae6f103dc1fa50f0aa8d4e7</td>
      <td>0.033094</td>
      <td>23.016033</td>
      <td>0.580431</td>
      <td>46.883053</td>
      <td>48.781784</td>
      <td>51.022263</td>
      <td>24.784406</td>
      <td>32.988612</td>
      <td>67.211597</td>
      <td>...</td>
      <td>17.204724</td>
      <td>46.198019</td>
      <td>100.336102</td>
      <td>110.820543</td>
      <td>93.543751</td>
      <td>18.412571</td>
      <td>17.525897</td>
      <td>4.451183</td>
      <td>17.525897</td>
      <td>50.096371</td>
    </tr>
    <tr>
      <th>4</th>
      <td>f9c911cc8443a54a58f6be3a</td>
      <td>0.009315</td>
      <td>23.028336</td>
      <td>0.562955</td>
      <td>46.864804</td>
      <td>48.763534</td>
      <td>51.004014</td>
      <td>24.796411</td>
      <td>33.000616</td>
      <td>67.225849</td>
      <td>...</td>
      <td>17.216410</td>
      <td>46.198685</td>
      <td>100.317853</td>
      <td>110.802294</td>
      <td>93.525502</td>
      <td>18.387479</td>
      <td>17.537902</td>
      <td>4.426091</td>
      <td>17.537902</td>
      <td>50.093797</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>32192</th>
      <td>33192a863cc21818d8d891a8</td>
      <td>487.746560</td>
      <td>466.602987</td>
      <td>488.359041</td>
      <td>457.709650</td>
      <td>468.442227</td>
      <td>467.502121</td>
      <td>465.143139</td>
      <td>463.143003</td>
      <td>418.375926</td>
      <td>...</td>
      <td>467.682283</td>
      <td>438.379531</td>
      <td>472.670183</td>
      <td>492.522058</td>
      <td>519.658745</td>
      <td>486.296449</td>
      <td>471.567834</td>
      <td>490.716023</td>
      <td>471.567834</td>
      <td>485.338623</td>
    </tr>
    <tr>
      <th>32193</th>
      <td>df1760ab01d707e48b2fb5c3</td>
      <td>488.808496</td>
      <td>467.664923</td>
      <td>489.420978</td>
      <td>458.771587</td>
      <td>469.504164</td>
      <td>468.564057</td>
      <td>466.205075</td>
      <td>464.204940</td>
      <td>419.437862</td>
      <td>...</td>
      <td>468.744219</td>
      <td>439.441467</td>
      <td>473.732119</td>
      <td>493.583994</td>
      <td>520.720681</td>
      <td>487.358385</td>
      <td>472.629771</td>
      <td>491.777959</td>
      <td>472.629771</td>
      <td>486.400560</td>
    </tr>
    <tr>
      <th>32194</th>
      <td>c9d47676a7369a2f95f08c9e</td>
      <td>488.949535</td>
      <td>467.805961</td>
      <td>489.562016</td>
      <td>458.912625</td>
      <td>469.645202</td>
      <td>468.705096</td>
      <td>466.346114</td>
      <td>464.345978</td>
      <td>419.578901</td>
      <td>...</td>
      <td>468.885258</td>
      <td>439.582506</td>
      <td>473.873158</td>
      <td>493.725033</td>
      <td>520.861720</td>
      <td>487.499424</td>
      <td>472.770809</td>
      <td>491.918998</td>
      <td>472.770809</td>
      <td>486.541598</td>
    </tr>
    <tr>
      <th>32195</th>
      <td>d3648dce49b200d02efaa7a5</td>
      <td>491.759761</td>
      <td>470.616188</td>
      <td>492.372242</td>
      <td>461.722852</td>
      <td>472.455429</td>
      <td>471.515322</td>
      <td>469.156340</td>
      <td>467.156205</td>
      <td>422.389127</td>
      <td>...</td>
      <td>471.695484</td>
      <td>442.392732</td>
      <td>476.683384</td>
      <td>496.535259</td>
      <td>523.671946</td>
      <td>490.309650</td>
      <td>475.581035</td>
      <td>494.729224</td>
      <td>475.581035</td>
      <td>489.351825</td>
    </tr>
    <tr>
      <th>32196</th>
      <td>f60b7ce35261670badb22aaf</td>
      <td>491.854833</td>
      <td>470.711260</td>
      <td>492.467314</td>
      <td>461.817923</td>
      <td>472.550501</td>
      <td>471.610394</td>
      <td>469.251412</td>
      <td>467.251277</td>
      <td>422.484199</td>
      <td>...</td>
      <td>471.790556</td>
      <td>442.487804</td>
      <td>476.778456</td>
      <td>496.630331</td>
      <td>523.767018</td>
      <td>490.404722</td>
      <td>475.676107</td>
      <td>494.824296</td>
      <td>475.676107</td>
      <td>489.446897</td>
    </tr>
  </tbody>
</table>
<p>32197 rows × 54 columns</p>
</div>



将站点到达所有公园的最短路径时间成本距离均值加入到图顶点属性下，属性名为`station2parks_tc`，因为并不是所有站点都有到达公园的时间成本距离值，因此将空值部分替换为值0，避免图打印顶点颜色时出现错误。


```python
for idx,row in tqdm(station2parks_tc.iterrows(),total=station2parks_tc.shape[0]):
    G_SB.nodes[row.stations]['station2parks_tc']=row.time_cost_average
```

    100%|██████████| 32197/32197 [00:02<00:00, 11943.34it/s]
    


```python
for node in tqdm(G_SB.nodes):
    node_dict=G_SB.nodes[node]
    if node_dict.get('station2parks_tc') is None:
        node_dict['station2parks_tc']=0
```

    100%|██████████| 32325/32325 [00:00<00:00, 1198854.71it/s]
    

从打印结果来看，具有明显中心性特征的城市，站点越趋近于城市中心，该站点到达各个公园的最短路径时间成本距离均值越小；如果远离城市中心，则均值越大。


```python
fig, ax=plt.subplots(figsize=(30*2*2, 30*4*2))
node_color=[round(255*i) for i in nx.get_node_attributes(G_SB,'station2parks_tc').values()]
nx.draw(G_SB,
        pos=nx.get_node_attributes(G_SB,'position'),
        edge_color='black',
        font_size=20,
        node_size=800,
        ax=ax,
        node_color=node_color,
        cmap=plt.cm.twilight_shifted
       ) 
```

<img src="./imgs/2_8_3/output_178_0.png" height='auto' width='auto' title="caDesign">
    

    


* 最短距离圈（服务范围等级）

以一个公园为对象，在公共交通复合网络下，该公园根据时间成本距离可以划分出多个距离圈，即服务范围等级（跳），这有助于研究公园服务的范围变化和城市生活圈相关的研究内容。

为了清晰的查看各个公园在不同时间成本距离下覆盖的范围，定义`service_area_levels()`和`G_draw_paths_composite()`函数，可以打印各个公园不同距离（服务等级、圈）的子网络，并颜色标识区分满足不同距离的边。在函数定义时，将打印的子网络图存储至本地磁盘中。


```python
def G_draw_paths_composite(G,range_paths,adjacent_PointUid,title_name,savefig_root,figsize=(30, 30),level=3):
    '''
    计算单个公园的服务距离“圈”

    Parameters
    ----------
    G : networkx.classes.graph.Graph
        公共交通复合网络.
    range_paths : GeoDataFrame
        公园邻近站点满足最短距离圈的划分级别.
    adjacent_PointUid : list
        公园的邻里站点.
    title_name : string
        图表名.
    figsize : tuple(float,float), optional
        图表大小. The default is (30, 30).
    level : int, optional
        最短距离圈（服务范围等级）. The default is 3.

    Returns
    -------
    edges_dict : dict
        公园服务范围等级包含的所有边.
    G_p_range : networkx.classes.graph.Graph
        公园最短距离圈子网络.

    '''    
    import networkx as nx
    import matplotlib.pyplot as plt
    import random
    from collections import defaultdict
    import matplotlib
    import numpy as np
    import matplotlib.colors as mcolors
    import os    
    flatten_lst=lambda lst: [m for n_lst in lst for m in flatten_lst(n_lst)] if type(lst) is list else [lst]    
    
    fig, ax=plt.subplots(figsize=figsize)
    ax.set_title(title_name,fontsize=300)
    
    range_paths.dropna(inplace=True)
    ranges=range_paths.range.unique()[:level]
    # print('\nranges:',ranges)
    path_edges_dict={}
    for i in ranges:
        range_paths_range=range_paths[range_paths.range==i]
        path_edges=range_paths_range.path.to_list()    
        path_edges_dict[i]=path_edges
    
    G_p=G.copy()
    G_p.remove_edges_from(list(G_p.edges()))
    G_p_range=nx.Graph(G_p.subgraph(flatten_lst(list(path_edges_dict.values()))))
    
    edges_dict=defaultdict(list)
    for k in path_edges_dict.keys():
        for r in path_edges_dict[k]:
            path_edges=[(r[n],r[n+1]) for n in range(len(r)-1)]
            G_p_range.add_edges_from(path_edges)
            edges_dict[k].append(path_edges)
    # print("Graph has %d nodes with %d paths(edges)" %(G_p_range.number_of_nodes(), G_p_range.number_of_edges()))  

    pos=nx.get_node_attributes(G_p_range,'position')
    nx.draw(G_p_range,pos=pos,node_size=100,ax=ax)

    G_start_stops=G_p_range.subgraph(adjacent_PointUid)
    pos_adjacent=nx.get_node_attributes(G_start_stops,'position')
    nx.draw_networkx_nodes(G_start_stops,pos=pos_adjacent,node_size=1000*2,ax=ax,node_color='red')
    linewidths=[5+i*5 for i in range(len(ranges))] # [5,10,15,20,25]
    linewidths.reverse()
    cmap=matplotlib.cm.get_cmap('tab20b') # 'tab20b'
    colors=[cmap(i) for i in np.linspace(0,1,len(ranges))]
    for j,k in enumerate(reversed(list(edges_dict.keys()))):
        for i, edgelist in enumerate(edges_dict[k]):            
            nx.draw_networkx_edges(G_p_range,pos=pos,edgelist=edgelist,edge_color=mcolors.to_hex(colors[j]),width=linewidths[j],ax=ax)
    plt.savefig(os.path.join(savefig_root,'{}.png'.format(title_name)))    
    
    return edges_dict,G_p_range

def service_area_levels(G_SB,park_shortest_path,comprehensivePark_adjacentStations,name_mapping,savefig_root,SES=[0,25,5],figsize=(30, 30),level=3):
    '''
    计算公园服务距离“圈”，调用单个计算函数G_draw_paths_composite

    Parameters
    ----------
    G_SB : networkx.classes.graph.Graph
        公共交通复合网络.
    park_shortest_path : list[GeoDataFrame]
        各个站点到一个公园（包含多个邻近站点）的最短路径.
    comprehensivePark_adjacentStations : GeoDataFrame
        各个公园的邻近站点.
    SES : list, optional
        时间成本距离区间，为[start,stop,step]. The default is [0,25,5].
    figsize : tuple, optional
        图表大小. The default is (30, 30).
    level : int, optional
        最短距离圈（服务范围等级）. The default is 3.

    Returns
    -------
    park_serviceArea_level: dict[string:GeoDataFrame]
        各个公园邻近站点满足最短距离圈的划分级别.
    park_serviceArea_level_fre_df: DataFrame
        各个公园服务范围等级存有路径的频数.
    G_p_range_dict： dict[string,networkx.classes.graph.Graph]
        各个公园最短距离圈子网络.
    edges_range_dict: dict
        各个公园服务范围等级包含的所有边.
        
    '''    
    import pandas as pd
    import numpy as np
    from shapely.geometry import LineString
    import geopandas as gpd
    from pathlib import Path
    from tqdm import tqdm
    from IPython.display import clear_output

    start,end,step=SES  
    def partition(value,start,end,step):
        import numpy as np
        ranges_list=list(range(start,end+step,step))
        ranges=[(ranges_list[i],ranges_list[i+1]) for i in  range(len(ranges_list)-1)]
        for r in ranges:
            if r[0]<=value<r[1] :    
                return r[1]           
        
    park_serviceArea_level={}
    park_serviceArea_level_fre={}
    G_p_range_dict={}
    edges_range_dict={}
    for park,shortest_path in tqdm(park_shortest_path.items()):
        clear_output(wait=True)
        shortest_path['range']=shortest_path.time_cost.apply(partition,args=(start,end,step))
        ranges_frequency=shortest_path['range'].value_counts()
        park_serviceArea_level_fre[park]=ranges_frequency.to_dict()        
        park_serviceArea_level[park]=shortest_path
        park_serviceArea_level_fre_df=pd.DataFrame.from_dict(park_serviceArea_level_fre,orient='index')        
        park_name=park.split('_')[-1]      
        adjacent_PointUid=eval(comprehensivePark_adjacentStations[comprehensivePark_adjacentStations.Name_EN==park_name].adjacent_PointUid.to_list()[0])
        
        name_mapping_=dict([(value, key) for key, value in name_mapping.items()])
        park_name_=name_mapping_[park_name]
        edges_dict_,G_p_range=G_draw_paths_composite(G_SB,shortest_path,adjacent_PointUid,savefig_root=savefig_root,figsize=figsize,level=level,title_name=park_name_) 
        G_p_range_dict[park]=G_p_range
        edges_range_dict[park]=edges_dict_

    park_serviceArea_level_fre_df=pd.DataFrame.from_dict(park_serviceArea_level_fre,orient='index')
    
    return park_serviceArea_level,park_serviceArea_level_fre_df,G_p_range_dict,edges_range_dict
```


```python
__C.data.service_area_levels_root=r"E:\data\public_trans_network\service_area_levels"
park_serviceArea_level,park_serviceArea_level_fre,G_p_range_dict,edges_range_dict=service_area_levels(
    G_SB,
    park_shortest_path,
    comprehensivePark_adjacentStations,
    name_mapping=comprehensive_park_name_mapping,
    savefig_root=args.data.service_area_levels_root,
    SES=[0,90,5],
    figsize=(30*2, 30*2),
    level=3) 
```

100%|██████████| 53/53 [23:24<00:00, 26.51s/it]

将`G_p_range_dict`和`edges_range_dict`两个返回值存至本地磁盘，方便调用查看数据，而不必重新运行程序。


```python
__C.data.G_p_range_dict_fn=r"E:\data\public_trans_network\G_p_range_dict.pkl"
__C.data.edges_range_dict_fn=r"E:\data\public_trans_network\edges_range_dict.pkl"
with open(args.data.G_p_range_dict_fn,'wb') as f:
    pickle.dump(G_p_range_dict,f) 
with open(args.data.edges_range_dict_fn,'wb') as f:
    pickle.dump(edges_range_dict,f)  
```

在“调研图像与聚类城市色彩”一章定义有`imgs_layoutShow_FPList()`函数，将其置于`util_misc`模块，直接调用显示给定文件夹下所有公园不同距离圈子网络的图片。


```python
from util_misc import imgs_layoutShow_FPList
import glob
import os

imgs_park_serviceArea_level_fns=glob.glob(os.path.join(args.data.service_area_levels_root,'*.png'))
columns=6;scale=1
imgs_layoutShow_FPList(imgs_park_serviceArea_level_fns[:6*4],columns,scale,figsize=(15,10))
```


<img src="./imgs/2_8_3/output_186_0.png" height='auto' width='auto' title="caDesign">    

    


### 2.8.3.5 公园潜在服务人口压力

居民对公园绿地的需求会随距离的增加而下降，以高斯函数为阻抗函数反应距离衰减的影响，沿公共交通复合网络计算各个公园到所有站点的最短路径，将每一人口采样点的人口数延最近的站点传输到各个公园邻近站点，计算该公园潜在的人口服务压力。定义`population_flowOverNetwork()`函数用于计算人口统计数据中，每个统计点到达各个公园潜在的人口流入量；定义`populationWeighted_adjacentStations()`函数计算每个公园邻近站点传输至的潜在人口数（高斯权重加权后），及均值，表述分析区域各个公园潜在的人口压力。


```python
population=postSQL2gpd(table_name='population',**args.db.db_info)
comprehensive_park=postSQL2gpd(table_name='comprehensive_park',**args.db.db_info)
```

    __________________________________________________
    The data has been read from PostgreSQL database. The table name is population.
    __________________________________________________
    The data has been read from PostgreSQL database. The table name is comprehensive_park.
    

为了方便理解高斯（累积分布函数（Cumulative distribution function，CDF））权重对数值的变化影响，将`population_flowOverNetwork()`函数中计算高斯权重的部分代码迁移出来，通过图表打印的方式，观察到累积分布函数曲线（CDF）和1-CDF曲线的变化。1-CDF曲线是随着值（时间成本距离）的增加而逐步降低，达到300左右几乎降至为0，并趋于平缓，因此时间成本距离越高，值越小，传入的人口数乘以权重值后越小；反之，时间成本距离越低，值越大，传入的人口数乘以权重值后越大，可以表述为距离公园越近区域的市民到公园的几率就大，越远则到公园的几率越小，当足够远时，去公园的意愿基本为0。


```python
import statistics
from scipy.stats import norm
flatten_lst=lambda lst: [m for n_lst in lst for m in flatten_lst(n_lst)] if type(lst) is list else [lst]

time_cost=flatten_lst([v.time_cost.to_list() for v in park_shortest_path.values()])
tc_max=max(time_cost)
tc_min=min(time_cost)
tc_mean=statistics.mean(time_cost)
tc_std=statistics.stdev(time_cost) 

time_cost.sort()
cdf_tc=norm.cdf(time_cost,loc=tc_mean,scale=tc_std)

plt.plot(time_cost, cdf_tc, label='cdf')
plt.plot(time_cost, 1-cdf_tc, label='1-cdf')
plt.legend();
```


<img src="./imgs/2_8_3/output_190_0.png" height='auto' width='auto' title="caDesign">    

    



```python
def population_flowOverNetwork(G_SB,population,park_shortest_path,save_path):
    '''
    对于一个公园，获取人口分布统计点的最近站点，由该最近站点到这个公园的最短路径时间成本距离，计算高斯权重，乘以人口分布统计点的人口数作为可能到达公园的人口数。同样的方式批量计算所有公园的潜在人口流入量

    Parameters
    ----------
    G_SB : networkx.classes.graph.Graph
        公共交通复合网络.
    population : GeoDataFrame
        人口分布数据.
    park_shortest_path : list[GeoDataFrame]
        各个站点到一个公园（包含多个邻近站点）的最短路径.
    save_path : string
        计算结果文件保存路径.

    Returns
    -------
    dict[GeoDataFrame]
        各个人口统计点位到公园的潜在人口流入量.

    '''    
    from shapely.ops import nearest_points
    import pandas as pd
    from shapely.geometry import MultiPoint,Point
    from tqdm import tqdm
    import pickle
    import copy
    import statistics
    from scipy.stats import norm
    flatten_lst=lambda lst: [m for n_lst in lst for m in flatten_lst(n_lst)] if type(lst) is list else [lst]   

    stations_pts={k:Point(v) for k,v in nx.get_node_attributes(G_SB,"position").items()}
    stations_mpts=MultiPoint(list(stations_pts.values()))
       
    time_cost=flatten_lst([v.time_cost.to_list() for v in park_shortest_path.values()])
    tc_max=max(time_cost)
    tc_min=min(time_cost)
    tc_mean=statistics.mean(time_cost)
    tc_std=statistics.stdev(time_cost)    
    
    population_flow_dict={}
    def row_func(row):
        nearest_pt=nearest_points(row,stations_mpts)[1]
        nearest_pt_row=shortest_path_df[shortest_path_df["station_geometry"]==str(nearest_pt)]
 
        return [nearest_pt,nearest_pt_row.idx_adjacent.values[0],nearest_pt_row.time_cost.values[0],nearest_pt_row.stations.values[0]]
    
    for park,shortest_path_df in tqdm(park_shortest_path.items()):
        population_flow=copy.deepcopy(population)
        shortest_path_df['station_geometry']=shortest_path_df.stations.apply(lambda row:str(stations_pts[row]))   
        nearest_info=population_flow.geometry.apply(row_func)
        col_n=['nearest_pt','idx_adjacent','time_cost','stations']
        nearest_info_T=[list(i) for i in zip(*nearest_info.to_list())]        
        for n,info in zip(col_n,nearest_info_T):
            population_flow[n]=info
        
        population_flow['tc_weight']=population_flow.time_cost.apply(lambda row:1-(row-tc_min)/(tc_max-tc_min))
        population_flow['Gaussian_weight']=population_flow.time_cost.apply(lambda row:1-norm.cdf(row,loc=tc_mean,scale=tc_std)) 
        population_flow['population_Gweighted']=population_flow.apply(lambda row:int(row.Population)*row.Gaussian_weight,axis=1)
        population_flow_dict[park]=population_flow
        
    with open(save_path,'wb') as f:
        pickle.dump(population_flow_dict,f)        
    return population_flow_dict
```


```python
__C.data.G_p_range_dict_fn=r"E:\data\public_trans_network\population_flow_dict.pkl"
population_flow_dict=population_flowOverNetwork(G_SB,population,park_shortest_path,args.data.G_p_range_dict_fn)
```

    100%|██████████| 53/53 [46:33<00:00, 52.71s/it]
    


```python
population_flow_dict['0_Bazi Mountain']
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Lat</th>
      <th>Lng</th>
      <th>Population</th>
      <th>geometry</th>
      <th>nearest_pt</th>
      <th>idx_adjacent</th>
      <th>time_cost</th>
      <th>stations</th>
      <th>tc_weight</th>
      <th>Gaussian_weight</th>
      <th>population_Gweighted</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>31.9497433580896</td>
      <td>118.378427463393</td>
      <td>129</td>
      <td>POINT (630276.381 3535694.515)</td>
      <td>POINT (630806.0127756759 3534389.4983157325)</td>
      <td>d9f65176dce0a6b6abf7292d</td>
      <td>198.790329</td>
      <td>552fc62d8f0bc3133686f44f</td>
      <td>0.667461</td>
      <td>0.169984</td>
      <td>21.927988</td>
    </tr>
    <tr>
      <th>1</th>
      <td>31.9497433580896</td>
      <td>118.400885345496</td>
      <td>129</td>
      <td>POINT (632399.081 3535721.765)</td>
      <td>POINT (633041.3670544036 3535551.691866558)</td>
      <td>d9f65176dce0a6b6abf7292d</td>
      <td>185.991482</td>
      <td>9142035b5e14c615c909f0c0</td>
      <td>0.688871</td>
      <td>0.210451</td>
      <td>27.148125</td>
    </tr>
    <tr>
      <th>2</th>
      <td>31.9230613713896</td>
      <td>118.405376921916</td>
      <td>386</td>
      <td>POINT (632862.009 3532769.406)</td>
      <td>POINT (633186.7269609962 3532671.776092457)</td>
      <td>d9f65176dce0a6b6abf7292d</td>
      <td>197.886086</td>
      <td>307d64433aec7b65e215f9c8</td>
      <td>0.668974</td>
      <td>0.172668</td>
      <td>66.649900</td>
    </tr>
    <tr>
      <th>3</th>
      <td>31.9383091693281</td>
      <td>118.369444310552</td>
      <td>129</td>
      <td>POINT (629443.336 3534416.196)</td>
      <td>POINT (629592.4638845846 3534237.0085329)</td>
      <td>d9f65176dce0a6b6abf7292d</td>
      <td>204.295228</td>
      <td>4677409768844f44a21de954</td>
      <td>0.658252</td>
      <td>0.154227</td>
      <td>19.895280</td>
    </tr>
    <tr>
      <th>4</th>
      <td>31.976417597875</td>
      <td>118.391902192655</td>
      <td>386</td>
      <td>POINT (631511.965 3538667.820)</td>
      <td>POINT (633159.4666844679 3538380.031112542)</td>
      <td>d9f65176dce0a6b6abf7292d</td>
      <td>198.487712</td>
      <td>ac9653e99a0490c6b42655d4</td>
      <td>0.667967</td>
      <td>0.170880</td>
      <td>65.959508</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>6668</th>
      <td>32.2123364183777</td>
      <td>119.209369101203</td>
      <td>129</td>
      <td>POINT (708226.801 3566112.695)</td>
      <td>POINT (707718.9550723871 3566095.829331054)</td>
      <td>2077fa870b9bbdb57adbd2c1</td>
      <td>260.296110</td>
      <td>7b882850378ca225c1f1cfd6</td>
      <td>0.564573</td>
      <td>0.047260</td>
      <td>6.096488</td>
    </tr>
    <tr>
      <th>6669</th>
      <td>32.2199365524469</td>
      <td>119.204877524783</td>
      <td>386</td>
      <td>POINT (707786.094 3566946.714)</td>
      <td>POINT (707718.9550723871 3566095.829331054)</td>
      <td>2077fa870b9bbdb57adbd2c1</td>
      <td>260.296110</td>
      <td>7b882850378ca225c1f1cfd6</td>
      <td>0.564573</td>
      <td>0.047260</td>
      <td>18.242204</td>
    </tr>
    <tr>
      <th>6670</th>
      <td>32.2123364183777</td>
      <td>119.213860677624</td>
      <td>129</td>
      <td>POINT (708650.211 3566121.412)</td>
      <td>POINT (707718.9550723871 3566095.829331054)</td>
      <td>2077fa870b9bbdb57adbd2c1</td>
      <td>260.296110</td>
      <td>7b882850378ca225c1f1cfd6</td>
      <td>0.564573</td>
      <td>0.047260</td>
      <td>6.096488</td>
    </tr>
    <tr>
      <th>6671</th>
      <td>32.200935026272</td>
      <td>119.204877524783</td>
      <td>129</td>
      <td>POINT (707829.333 3564839.790)</td>
      <td>POINT (706822.3294598485 3565145.8209223025)</td>
      <td>2077fa870b9bbdb57adbd2c1</td>
      <td>254.448669</td>
      <td>5cf67b908cd4a332157643b2</td>
      <td>0.574355</td>
      <td>0.054381</td>
      <td>7.015130</td>
    </tr>
    <tr>
      <th>6672</th>
      <td>32.2199365524469</td>
      <td>119.204877524783</td>
      <td>386</td>
      <td>POINT (707786.094 3566946.714)</td>
      <td>POINT (707718.9550723871 3566095.829331054)</td>
      <td>2077fa870b9bbdb57adbd2c1</td>
      <td>260.296110</td>
      <td>7b882850378ca225c1f1cfd6</td>
      <td>0.564573</td>
      <td>0.047260</td>
      <td>18.242204</td>
    </tr>
  </tbody>
</table>
<p>6673 rows × 11 columns</p>
</div>




```python
def populationWeighted_adjacentStations(population_flow_dict,G_SB,epsg,comprehensive_park):
    '''
    计算各个公园邻近站点传入的潜在人口数，及均值，表述公园潜在人口压力

    Parameters
    ----------
    population_flow_dict : dict[GeoDataFrame]
        人口统计数据中，每个统计点到达各个公园潜在的人口流入量.
    G_SB : networkx.classes.graph.Graph
        公共交通复合网络.
    epsg : pyproj.crs.crs.CRS[int]
        投影epsg编号.
    comprehensive_park : GeoDataFrame
        公园地理空间数据.

    Returns
    -------
    populationWeighted_adjacentStations_dict : dict(GeoDataFrame)
        字典形式返回各个公园的潜在人口服务压力.
    populationWeighted_adjacentStations_stack_gdf : GeoDataFrame
        合并各个公园的潜在人口服务压力为单独一个GeoDataFrame格式数据，以公园名为行索引.
    comprehensive_park : GeoDataFrame
        各个公园的潜在人口服务压力均值.

    '''    
    from tqdm import tqdm
    import pandas as pd
    import geopandas as gpd
    from shapely.geometry import Point
    
    stations_pts={k:Point(v) for k,v in nx.get_node_attributes(G_SB,"position").items()}
    populationWeighted_adjacentStations_dict={}
    for park,population_flow in tqdm(population_flow_dict.items()):
        populationGWeighted_group_sum=population_flow[['idx_adjacent','population_Gweighted']].groupby(by=['idx_adjacent']).sum()
        populationGWeighted_group_sum.reset_index(inplace=True)
        populationGWeighted_group_sum.rename(columns={'index':'idx_adjacent'})
        populationGWeighted_group_sum['geometry']=populationGWeighted_group_sum.idx_adjacent.apply(lambda row:stations_pts[row])
        populationWeighted_adjacentStations_dict[park]=populationGWeighted_group_sum        
        
    populationWeighted_adjacentStations_stack=pd.concat(populationWeighted_adjacentStations_dict.values(),keys=populationWeighted_adjacentStations_dict.keys())
    populationWeighted_adjacentStations_stack['populationWeighted_10thous']=populationWeighted_adjacentStations_stack.population_Gweighted.apply(lambda row:row/10000)
    populationWeighted_adjacentStations_stack_gdf=gpd.GeoDataFrame(populationWeighted_adjacentStations_stack,crs="EPSG:{}".format(epsg))
    populationWeighted_parks={k.split("_")[-1]:v.population_Gweighted.sum() for k,v in populationWeighted_adjacentStations_dict.items()}    
    
    comprehensive_park['populationWeighted']=comprehensive_park['Name_EN'].map(populationWeighted_parks)  
    comprehensive_park['populationWeighted_10thous']=comprehensive_park.populationWeighted.apply(lambda row:row/10000)
    
    return populationWeighted_adjacentStations_dict,populationWeighted_adjacentStations_stack_gdf,comprehensive_park
```


```python
populationWeighted_adjacentStations_dict,populationWeighted_adjacentStations_stack_gdf,comprehensive_park=populationWeighted_adjacentStations(population_flow_dict,G_SB,args.gi.nanjing_epsg,comprehensive_park) 
```

    100%|██████████| 53/53 [00:00<00:00, 231.02it/s]
    


```python
populationWeighted_adjacentStations_stack_gdf.head(3)
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th></th>
      <th>idx_adjacent</th>
      <th>population_Gweighted</th>
      <th>geometry</th>
      <th>populationWeighted_10thous</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th rowspan="3" valign="top">0_Bazi Mountain</th>
      <th>0</th>
      <td>1585d76c5555a636f32d839c</td>
      <td>1.168231e+03</td>
      <td>POINT (664131.588 3551415.123)</td>
      <td>0.116823</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2077fa870b9bbdb57adbd2c1</td>
      <td>3.889698e+06</td>
      <td>POINT (665061.514 3551596.830)</td>
      <td>388.969841</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3176ab8f267a522adc1e5249</td>
      <td>1.494966e+04</td>
      <td>POINT (664855.439 3551547.768)</td>
      <td>1.494966</td>
    </tr>
  </tbody>
</table>
</div>




```python
comprehensive_park.head(3)
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Name</th>
      <th>Description</th>
      <th>geometry</th>
      <th>group</th>
      <th>Name_EN</th>
      <th>populationWeighted</th>
      <th>populationWeighted_10thous</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>八字山公园</td>
      <td>None</td>
      <td>POLYGON Z ((664351.229 3551540.582 0.000, 6643...</td>
      <td>NanjingParks</td>
      <td>Bazi Mountain</td>
      <td>5.662951e+06</td>
      <td>566.295130</td>
    </tr>
    <tr>
      <th>1</th>
      <td>北崮山公园</td>
      <td>None</td>
      <td>POLYGON Z ((667855.803 3553692.487 0.000, 6678...</td>
      <td>NanjingParks</td>
      <td>Beigu Mountain</td>
      <td>5.624582e+06</td>
      <td>562.458167</td>
    </tr>
    <tr>
      <th>2</th>
      <td>大桥公园</td>
      <td>None</td>
      <td>POLYGON Z ((664898.358 3554394.776 0.000, 6648...</td>
      <td>NanjingParks</td>
      <td>Bridge park</td>
      <td>5.411941e+06</td>
      <td>541.194094</td>
    </tr>
  </tbody>
</table>
</div>



公园潜在的人口服务压力是公园可达性的一种表现，较大的值表明具有较好的可达性，反之可达性较弱。配置参数`scheme='quantiles'`，并配置`k=3`，将人口压力分成3个层级：第1个层级，具有较高的人口压力，位于公共交通复合网络的核心区域，即城市的核心区域；进而向四周扩散，形成第2个层级；第3个层级，较小的人口压力，位于网络的边缘，也是城市的边缘区域。


```python
fig, ax=plt.subplots(figsize=(10,10))
comprehensive_park.plot(column='populationWeighted_10thous',ax=ax,legend=True,cmap='plasma', scheme='quantiles',k=3)
```




    <AxesSubplot: >




<img src="./imgs/2_8_3/output_199_1.png" height='auto' width='auto' title="caDesign">    
    


---

注释（Notes）：

① CSDN（Chinese Software Developer Network，（<https://www.csdn.net/>）。

② GeoLife数据集，（<https://www.microsoft.com/en-us/research/publication/geolife-gps-trajectory-dataset-user-guide/>）。

③ NetWorkX库的最短路径算法，（<https://networkx.org/documentation/stable/reference/algorithms/shortest_paths.html>）。
