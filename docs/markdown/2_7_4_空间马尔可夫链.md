> Created on Thu Dec  1 15:26:14 2022  @author: Richie Bao-caDesign设计(cadesign.cn)

## 2.7.4 空间动力学——空间马尔可夫链


### 2.7.4.1 数据预处理 

#### 1）[MCD12Q1_v006](https://lpdaac.usgs.gov/products/mcd12q1v006/) 土地覆盖类型数据集<sup>[1]</sup>

由Terra 和 Aqua卫星搭载的中分辨率成像光谱仪（Moderate Resolution Imaging Spectroradiometer，MODIS），每隔1到2天观察整个地球表面，获取36个光谱带或一组波长的数据，这些数据可用于对发生在陆地、海洋和低层大气中的全球动态和过程的理解，MODIS在开发经过验证的全球交互式地球系统模型方面发挥着重要作用，这些模型能够准确地预测全球变化，足以帮助决策者做出有关保护地球环境的合理决定。基于MODIS的第6版土地覆盖类型（MCD12Q1）数据产品提供了按年度划分的全球土地覆盖类型（2001年至2020年）数据。该数据通过对MODIS Terra和Aqua反射率数据进行监督分类得出，经过额外的后处理，结合先前的知识和辅助信息，进一步完善了特定的类别。

MCD12Q1_v006存储格式为HDF4，每一年的HDF4数据包括土地覆盖类型1-5、土地覆盖属性1-3、土地覆盖属性评估1-3、土地覆盖质量控制（QC）和土地水掩码的层，各层数据具体解释摘录如下：

| SDS Name            | Description                                                                                 | Units        | Data Type              | Fill Value | No Data Value | Valid Range | Scale Factor |
|---------------------|---------------------------------------------------------------------------------------------|--------------|------------------------|------------|---------------|-------------|--------------|
| LC_Type1            | Land Cover Type 1: Annual International Geosphere-Biosphere Programme (IGBP) classification</br>土地覆盖类型1：国际地圈-生物圈计划（IGBP）年度分类 | Class        | 8-bit unsigned integer | 255        | N/A           | 1 to 17     | N/A          |
| LC_Type2            | Land Cover Type 2: Annual University of Maryland (UMD) classification </br>土地覆盖类型2：马里兰大学（UMD）的年度分类                      | Class        | 8-bit unsigned integer | 255        | N/A           | 0 to 15     | N/A          |
| LC_Type3            | Land Cover Type 3: Annual Leaf Area Index (LAI) classification </br>土地覆盖类型3：年度叶面积指数（LAI）分类                            | Class        | 8-bit unsigned integer | 255        | N/A           | 0 to 10     | N/A          |
| LC_Type4            | Land Cover Type 4: Annual BIOME-Biogeochemical Cycles (BGC) classification </br>土地覆盖类型4：年度生物群落-生物地球化学循环（BGC）分类                 | Class        | 8-bit unsigned integer | 255        | N/A           | 0 to 8      | N/A          |
| LC_Type5            | Land Cover Type 5: Annual Plant Functional Types（PFT） classification </br>土地覆盖类型5：一年生植物功能类型分类                            | Class        | 8-bit unsigned integer | 255        | N/A           | 0 to 11     | N/A          |
| LC_Prop1            | FAO-Land Cover Classification System 1 (LCCS1) land cover layer </br>粮农组织-土地覆盖分类系统1（LCCS1）土地覆盖层                            | Class        | 8-bit unsigned integer | 255        | N/A           | 1 to 43     | N/A          |
| LC_Prop2            | FAO-LCCS2 land use layer </br>粮农组织-LCCS2土地利用层                                                                   | Class        | 8-bit unsigned integer | 255        | N/A           | 1 to 40     | N/A          |
| LC_Prop3            | FAO-LCCS3 surface hydrology layer </br>粮农组织-LCCS3地表水文层                                                          | Class        | 8-bit unsigned integer | 255        | N/A           | 1 to 51     | N/A          |
| LC_Prop1_Assessment | LCCS1 land cover layer confidence </br>LCCS1土地覆盖层置信度                                                            | Percent      | 8-bit unsigned integer | 255        | N/A           | 0 to 100    | N/A          |
| LC_Prop2_Assessment | LCCS2 land use layer confidence </br>LCCS2土地利用层的置信度                                                            | Percent      | 8-bit unsigned integer | 255        | N/A           | 0 to 100    | N/A          |
| LC_Prop3_Assessment | LCCS3 surface hydrology layer confidence </br>LCCS3地表水文层的置信度                                                   | Percent      | 8-bit unsigned integer | 255        | N/A           | 0 to 100    | N/A          |
| QC                  | Product quality flags</br>产品质量标志                                                                       | Quality Flag | 8-bit unsigned integer | 255        | N/A           | 0 to 10     | N/A          |
| LW                  | Binary land (class 2) / water (class 1) mask derived from MOD44W </br>来自MOD44W的二进制土地（类2）/水（类1）掩码                          | Class        | 8-bit unsigned integer | 255        | N/A           | 1 to 2      | N/A          |


不同分类内容和值及描述摘录如下：

* IGBP分类（LC_Type1）

| Name                                 | Value | Description                                                                                                 |
|--------------------------------------|-------|-------------------------------------------------------------------------------------------------------------|
| Evergreen Needleleaf Forests（常绿针叶林）         | 1     | Dominated  by  evergreen  conifer  trees  (canopy >2m). Tree cover >60%.                                    |
| Evergreen Broadleaf Forests（常绿阔叶林）          | 2     | Dominated by evergreen broadleaf and palmate trees (canopy >2m). Tree cover >60%.                           |
| Deciduous Needleleaf Forests（落叶针叶林）         | 3     | Dominated by deciduous needleleaf (larch) trees (canopy >2m). Tree cover >60%.                              |
| Deciduous Broadleaf Forests（落叶阔叶林）          | 4     | Dominated by deciduous broadleaf trees (canopy >2m). Tree cover >60%.                                       |
| Mixed Forests（混合林）                        | 5     | Dominated by neither deciduous nor evergreen (40-60% of each) tree type (canopy >2m).  Tree cover >60%.     |
| Closed Shrublands（封闭性灌木林地）                    | 6     | Dominated by woody perennials (1-2m height) >60% cover.                                                     |
| Open Shrublands（开放性灌木林地）                      | 7     | Dominated by woody perennials (1-2m height) 10-60% cover.                                                   |
| Woody Savannas（木质稀树草原）                       | 8     | Tree cover 30-60% (canopy >2m).                                                                             |
| Savannas（稀树草原）                             | 9     | Tree cover 10-30% (canopy >2m).                                                                             |
| Grasslands （草地）                          | 10    | Dominated by herbaceous annuals (<2m).                                                                      |
| Permanent Wetlands（永久湿地）                   | 11    | Permanently inundated lands with 30-60% water cover and >10% vegetated cover.                               |
| Croplands（耕地）                            | 12    | At least 60% of area is cultivated cropland.                                                                |
| Urban and Built-up Lands（城市和建成区土地）             | 13    | At least 30% impervious surface area including building materials, asphalt, and vehicles.                   |
| Cropland/Natural  Vegetation Mosaics（耕地/自然植被镶嵌物） | 14    | Mosaics of small-scale cultivation 40-60% with natural tree, shrub, or herbaceous vegetation.               |
| Permanent Snow and Ice（永久性冰雪）               | 15    | At least 60% of area is covered by snow and ice for at least 10 months of the year.                         |
| Barren（荒地）                               | 16    | At  least  60%  of  area  is  non-vegetated  barren (sand, rock, soil) areas with less than 10% vegetation. |
| Water Bodies（水体）                         | 17    | At least 60% of area is covered by permanent water bodies.                                                  |
| Unclassiﬁed（未分类的）                          | 255   | Has not received a map label because of missing inputs.                                                     |

* UMD分类（LC Type2）

| Name                                  | Value  |  Description                                                                                                               |
|---------------------------------------|--------|----------------------------------------------------------------------------------------------------------------------------|
| Water bodies（水体）                          | 0      | At least 60% of area is covered by permanent water bodies.                                                                 |
| Evergreen Needleleaf Forests（常绿针叶林）          | 1      | Dominated  by  evergreen  conifer  trees  (canopy >2m). Tree cover >60%.                                                   |
| Evergreen Broadleaf Forests（常绿阔叶林）           | 2      | Dominated by evergreen broadleaf and palmate trees (canopy >2m). Tree cover >60%.                                          |
| Deciduous Needleleaf Forests（落叶针叶林）          | 3      | Dominated by deciduous needleleaf (larch) trees (canopy >2m). Tree cover >60%.                                             |
| Deciduous Broadleaf Forests（落叶阔叶林）           | 4      | Dominated by deciduous broadleaf trees (canopy >2m). Tree cover >60%.                                                      |
| Mixed Forests（混合林）                         | 5      | Dominated by neither deciduous nor evergreen (40-60% of each) tree type (canopy >2m).  Tree cover >60%.                    |
| Closed Shrublands（封闭性灌木林地）                     | 6      | Dominated by woody perennials (1-2m height) >60% cover.                                                                    |
| Open Shrublands（开放性灌木林地）                       | 7      | Dominated by woody perennials (1-2m height) 10-60% cover.                                                                  |
| Woody Savannas（木质稀树草原）                        | 8      | Tree cover 30-60% (canopy >2m).                                                                                            |
| Savannas（稀树草原）                              | 9      | Tree cover 10-30% (canopy >2m).                                                                                            |
| Grasslands（草地）                            | 10     | Dominated by herbaceous annuals (<2m).                                                                                     |
| Permanent Wetlands（永久湿地）                    | 11     | Permanently inundated lands with 30-60% water cover and >10% vegetated cover.                                              |
| Croplands（耕地）                             | 12     | At least 60% of area is cultivated cropland.                                                                               |
| Urban and Built-up Lands（城市和建成区土地）              | 13     | At least 30% impervious surface area including building materials, asphalt, and vehicles.                                  |
| Cropland/Natural  Vegetation  Mosaics（耕地/自然植被镶嵌物） | 14     | Mosaics of small-scale cultivation 40-60% with natural tree, shrub, or herbaceous vegetation.                              |
| Non-Vegetated Lands（非植被地）                   | 15     | At  least  60%  of  area  is  non-vegetated  barren (sand, rock, soil)orpermanentsnowandice with less than 10% vegetation. |
| Unclassiﬁed（未分类的）                           | 255    | Has not received a map label because of missing inputs.                                                                    |

* LAI分类（LC Type3）

| Name                         | Value | Description                                                                                                                    |
|------------------------------|-------|--------------------------------------------------------------------------------------------------------------------------------|
| Water Bodies（水体）                 | 0     | At least 60% of area is covered by permanent water bodies.                                                                     |
| Grasslands（草地）                   | 1     | Dominated by herbaceous annuals (<2m) including cereal croplands.                                                              |
| Shrublands（灌木丛地）                   | 2     | Shrub (1-2m) cover >10%.                                                                                                       |
| Broadleaf Croplands（阔叶农田）          | 3     | Dominated by herbaceous annuals (<2m) that are cultivated with broadleaf crops.                                                |
| Savannas（稀树草原）                     | 4     | Between 10-60% tree cover (>2m).                                                                                               |
| Evergreen Broadleaf Forests（常绿阔叶林）  | 5     | Dominated by evergreen broadleaf and palmate trees (>2m). Tree cover >60%.                                                     |
| Deciduous Broadleaf Forests（落叶阔叶林）  | 6     | Dominated by deciduous broadleaf trees (>2m). Tree cover >60%.                                                                 |
| Evergreen Needleleaf Forests（常绿针叶林） | 7     | Dominated  by  evergreen  conifer  trees  (>2m). Tree cover >60%.                                                              |
| Deciduous Needleleaf Forests（落叶针叶林） | 8     | Dominated by deciduous needleleaf (larch) trees (>2m). Tree cover >60%.                                                        |
| Non-Vegetated Lands（非植被性土地）          | 9     | At  least  60%  of  area  is  non-vegetated  barren (sand, rock, soil)or permanent snow and ice with less than 10% vegetation. |
| Urban and Built-up Lands（城市和建成区土地）     | 10    | At least 30% impervious surface area including building materials, asphalt, and vehicles.                                      |
| Unclassiﬁed（未分类的）                  | 255   | Has not received a map label because of missing inputs.                                                                        |

* BGC分类（LC Type4）

| Name                            | Value | Description                                                                                                          |
|---------------------------------|-------|----------------------------------------------------------------------------------------------------------------------|
| Water Bodies（水体）                    | 0     | At least 60% of area is covered by permanent water bodies.                                                           |
| Evergreen Needleleaf Vegetation（常绿针叶植被） | 1     | Dominated by evergreen conifer trees and shrubs (>1m). Woody vegetation cover >10%.                                  |
| Evergreen Broadleaf Vegetation（常绿阔叶植被）  | 2     | Dominated by evergreen broadleaf and palmate treesandshrubs(>1m). Woodyvegetationcover >10%.                         |
| Deciduous Needleleaf Vegetation（落叶针叶植被） | 3     | Dominated by deciduous needleleaf (larch) trees and  shrubs  (>1m).    Woody  vegetation  cover >10%.                |
| Deciduous Broadleaf Vegetation（落叶阔叶植被）  | 4     | Dominated  by  deciduous  broadleaf  trees  and shrubs (>1m). Woody vegetation cover >10%.                           |
| Annual Broadleaf Vegetation（一年生阔叶植被）     | 5     | Dominated by herbaceous annuals (<2m).   At least 60% cultivated broadleaf crops.                                    |
| Annual Grass Vegetation（一年生草类植被）         | 6     | Dominated by herbaceous annuals (<2m) including cereal croplands.                                                    |
| Non-Vegetated Lands（非植被地）             | 7     | At  least  60%  of  area  is  non-vegetated  barren (sand,rock,soil)orpermanentsnow/icewithless than 10% vegetation. |
| Urban and Built-up Lands（城市和建成区土地）        | 8     | At least 30% impervious surface area including building materials, asphalt, and vehicles.                            |
| Unclassiﬁed（未分类的）                     | 255   | Has not received a map label because of missing inputs.                                                              |

* PFT分类（LC Type5）

| Name                       | Value | Description                                                                                           |
|----------------------------|-------|-------------------------------------------------------------------------------------------------------|
| Water Bodies（水体）               | 0     | At least 60% of area is covered by permanent water bodies.                                            |
| Evergreen Needleleaf Trees（常绿针叶树） | 1     | Dominated  by  evergreen  conifer  trees  (>2m). Tree cover >10%.                                     |
| Evergreen Broadleaf Trees（常绿阔叶树）  | 2     | Dominated by evergreen broadleaf and palmate trees (>2m). Tree cover >10%.                            |
| Deciduous Needleleaf Trees（落叶针叶树） | 3     | Dominated by deciduous needleleaf (larch) trees (>2m). Tree cover >10%.                               |
| Deciduous Broadleaf Trees（落叶阔叶树）  | 4     | Dominated by deciduous broadleaf trees (>2m). Tree cover >10%.                                        |
| Shrub（灌木）                      | 5     | Shrub (1-2m) cover >10%.                                                                              |
| Grass（草地）                      | 6     | Dominated by herbaceous annuals (<2m) that are not cultivated.                                        |
| Cereal Croplands（谷类耕地）           | 7     | Dominated by herbaceous annuals (<2m).   At least 60% cultivated cereal crops.                        |
| Broadleaf Croplands（阔叶农田）        | 8     | Dominated by herbaceous annuals (<2m).   At least 60% cultivated broadleaf crops.                     |
| Urban and Built-up Lands（城市和建成区土地）   | 9     | At least 30% impervious surface area including building materials, asphalt, and vehicles.             |
| Permanent Snow and Ice（永久性的雪和冰）     | 10    | At least 60% of area is covered by snow and ice for at least 10 months of the year.                   |
| Barren（荒地）                     | 11    | At  least  60%  of  area  is  non-vegetated  barren (sand, rock, soil) with less than 10% vegetation. |
| Unclassiﬁed（未分类的）                | 255   | Has not received a map label because of missing inputs.                                               |

* LCCS1分类（LC_Prop1）

| Name                                        | Value | Description                                                                                                          |  
|---------------------------------------------|-------|----------------------------------------------------------------------------------------------------------------------|
| Barren（贫瘠）                                      | 1     | At  least  of  area  60%  is  non-vegetated  barren (sand,rock,soil)orpermanentsnow/icewithless than 10% vegetation. |  
| Permanent Snow and Ice（永久的雪和冰）                      | 2     | At least of area 60% is covered by snow and ice for at least 10 months of the year.                                  | 
| Water Bodies（水体）                                | 3     | At least 60% of area is covered by permanent water bodies.                                                           | 
| Evergreen Needleleaf Forests（常绿针叶林）                | 11    | Dominated  by  evergreen  conifer  trees  (>2m). Tree cover >60%.                                                    | 
| Evergreen Broadleaf Forests（常绿阔叶林）                 | 12    | Dominated by evergreen broadleaf and palmate trees (>2m). Tree cover >60%.                                           |  
| Deciduous Needleleaf Forests（落叶针叶林）                | 13    | Dominated by deciduous needleleaf (larch) trees (>2m). Tree cover >60%.                                              |  
| Deciduous Broadleaf Forests（落叶阔叶林）                 | 14    | Dominated by deciduous broadleaf trees (>2m). Tree cover >60%.                                                       |  
| Mixed Broadleaf/Needleleaf Forests（阔叶/针叶混交林）          | 15    | Co-dominated (40-60%) by broadleaf deciduous and evergreen needleleaf tree (>2m) types. Tree cover >60%.             |  
| Mixed Broadleaf Evergreen/Deciduous Forests（常绿/落叶混合阔叶林） | 16    | Co-dominated (40-60%) by broadleaf evergreen and  deciduous  tree  (>2m)  types.   Tree  cover >60%.                 |  
| Open Forests（疏林）                                | 21    | Tree cover 30-60% (canopy >2m).                                                                                      | 
| Sparse Forests（稀疏的森林）                              | 22    | Tree cover 10-30% (canopy >2m).                                                                                      |  
| Dense Herbaceous（浓密的草本植物）                            | 31    | Dominated by herbaceous annuals(<2m) at least 60% cover.                                                             | 
| Sparse Herbaceous（稀疏的草本植物）                           | 32    | Dominated by herbaceous annuals(<2m)10-60% cover.                                                                    |  
| Dense Shrublands（茂密的灌木林地）                            | 41    | Dominated by woody perennials (1-2m) >60% cover.                                                                     | 
| Shrubland/Grassland Mosaics（灌木丛/草原镶嵌物）                 | 42    | Dominated by woody perennials (1-2m) 10-60% cover with dense herbaceous annual understory.                           |  
| Sparse Shrublands（稀疏的灌木丛）                           | 43    | Dominated by woody perennials (1-2m) 10-60% cover with minimal herbaceous understory.                                |  
| Unclassiﬁed（未分类的）                                 | 255   | Has not received a map label because of missing inputs.                                                              | 

* LCCS2分类（LC_Prop2）

| Name                                 | Value | Description                                                                                                          |
|--------------------------------------|-------|----------------------------------------------------------------------------------------------------------------------|
| Barren（贫瘠）                               | 1     | At  least  60%  of  area  is  non-vegetated  barren (sand,rock,soil)orpermanentsnow/icewithless than 10% vegetation. |
| Permanent Snow and Ice（永久性的雪和冰）               | 2     | At least 60% of area is covered by snow and ice for at least 10 months of the year.                                  |
| Water Bodies（水体）                         | 3     | At least 60% of area is covered by permanent water bodies.                                                           |
| Urban and Built-up Lands（城市和建筑用地）             | 9     | At least 30% of area is made up of impervious surfaces including building materials, asphalt, and vehicles.          |
| Dense Forests（茂密的森林）                        | 10    | Tree cover >60% (canopy >2m).                                                                                        |
| Open Forests（开放的森林）                         | 20    | Tree cover 10-60% (canopy >2m).                                                                                      |
| Forest/Cropland Mosaics（森林/耕地镶嵌物）              | 25    | Mosaics of small-scale cultivation 40-60% with >10% natural tree cover.                                              |
| Natural Herbaceous（天然草本植物）                   | 30    | Dominated by herbaceous annuals (<2m).   At least 10% cover.                                                         |
| Natural Herbaceous/Croplands Mosaics（天然草木/耕地镶嵌物） | 35    | Mosaics of small-scale cultivation 40-60% with natural shrub or herbaceous vegetation.                               |
| Herbaceous Croplands（草本农田）                 | 36    | Dominated by herbaceous annuals (<2m).   At least 60% cover. Cultivated fraction >60%.                               |
| Shrublands（灌木地）                           | 40    | Shrub cover >60% (1-2m).                                                                                             |
| Unclassiﬁed（未分类的）                          | 255   | Has not received a map label because of missing inputs.                                                              |

* LCCS3（LC_Prop3）

| Name                   | Value | Description                                                                                                              |
|------------------------|-------|--------------------------------------------------------------------------------------------------------------------------|
| Barren（贫瘠）                 | 1     | At  least  60%  of  area  is  non-vegetated  barren (sand,rock,soil) or permanent snow/ice withless than 10% vegetation. |
| Permanent Snow and Ice（永久的雪和冰） | 2     | At least 60% of area is covered by snow and ice for at least 10 months of the year.                                      |
| Water Bodies （水体）          | 3     | At least 60% of area is covered by permanent water bodies.                                                               |
| Dense Forests（茂密的森林）          | 10    | Tree cover >60% (canopy >2m).                                                                                            |
| Open Forests（疏林）           | 20    | Tree cover 10-60% (canopy >2m).                                                                                          |
| Woody Wetlands（木质湿地）         | 27    | Shrub and tree cover >10% (>1m). Permanently or seasonally inundated                                                     |
| Grasslands（草地）             | 30    | Dominated by herbaceous annuals (<2m) >10% cover.                                                                        |
| Shrublands （灌木丛地）             | 40    | Shrub cover >60% (1-2m).                                                                                                 |
| Herbaceous Wetlands（草本湿地）    | 50    | Dominated by herbaceous annuals (<2m) >10% cover. Permanently or seasonally inundated.                                   |
| Tundra （苔原）                 | 51    | Tree cover <10%.   Snow-covered for at least 8 months of the year.                                                       |
| Unclassiﬁed（未分类的）            | 255   | Has not received a map label because of missing inputs.                                                                  |



**[MODIS网格（ MODIS Grids）](https://modis-land.gsfc.nasa.gov/MODLAND_grid.html)<sup>①</sup>**

MODIS陆地产品以4种分辨率（250m、500m、1km和0.05degree）和3种投影（Sinusoidal, Lambert Azimuthal Equal-Area, and Geographic）制作。简单的地理纬度投影只用于最粗分辨率的网格，产生于0.05km（~5.5km）分辨率的网格被称为气候模型网格（Climate Modeling Grid，CMG）。为了使其它更高分辨率的MODIS陆地数据产品保持合理的文件大小，每个投影都被划分为一个平铺的网格。因此，土地产品被制作并分布在相邻不重叠的瓦片（tiles）中，这些瓦片大约为10度见方（在赤道）。大多数较高分辨率的MODIS陆地产品都是在正弦形瓦片网格中制作的，只有海冰产品是在极地Lambert Azimuthal Equal-Area瓦片网格中制作。

* Sinusoidal Tile Grid

有460个非填充瓦片，瓦片在赤道上是10度乘10度。瓦片坐标系从左上角的（0,0）（水平瓦片编号，垂直瓦片编号）开始，向右（水平）和向下（垂直）前进。右下角的瓦片是（35,17）。

<img src="./imgs/2_7_4/2_7_4_01.jpg" height="auto" width="auto"  title="digit-x" />  

* Lambert Azimuthal Equal-Area Tile Grids (Polar)

网格中共有626块10度乘10度的非填充瓦片。一半的瓦片（313）在北极网格，另一半在南极网格。北极网格瓦片坐标系统从左上角的（0，0）（水平瓦片号，垂直瓦片号）开始，向右（水平）和向下（垂直）前进。右下角的瓦片是（18，18）。南极网格瓦片坐标系统从北极网格的终点开始，在（0，20），右下角的瓦片是（18，38）。极地网格是基于以每个极点为中心的Lambert Azimuthal Equal Area地图投影。这些网格与NSIDC EASI网格兼容。

<img src="./imgs/2_7_4/2_7_4_02.jpg" height="auto" width="auto"  title="digit-x" />  <img src="./imgs/2_7_4/2_7_4_03.jpg" height="auto" width="auto"  title="digit-x" />  

**地理投影（Geographical Projections）**

* Climate Modeling Grid (CMG)

气候模型网格（CMG）数据集以地理纬度投影提供全球覆盖，分辨率为0.05度。MODIS CMG图像的左上角像素的地理坐标为-180.00度经度，90.00度纬度。右下角像素的地理坐标是经度180.00度，纬度-90.00度。

<img src="./imgs/2_7_4/2_7_4_04.png" height="auto" width="auto"  title="digit-x" />  

* Linear Latitude/Longitude Grid

MODIS洪水图（MCDWD）产品使用地理线性经纬度投影。这种地理投影由460个不重叠的土地瓦片组成，尺寸约为10°X10°。瓦片坐标系统从左上角的（00,00）（水平瓦片编号，垂直瓦片编号）开始，向右（水平）和向下（垂直）前进。这种投影也被VIIRS DNB (VNP46)网格化产品所使用。

<img src="./imgs/2_7_4/2_7_4_05.png" height="auto" width="auto"  title="digit-x" />  

美国国家航空和航天局（National Aeronautics and Space Administration，NASA）的[MODIS Land](https://modis-land.gsfc.nasa.gov/MODLAND_grid.html)<sup>①</sup>网页提供了相应可下载的文本文件或在线说明，包括Sinusoidal Tile Grid的[Table of Tile Bounding Coordinates (10 deg tiles)](https://modis-land.gsfc.nasa.gov/pdf/sn_bound_10deg.txt)<sup>②</sup>，[Table of Tile G-ring Coordinates (10 deg tiles)](https://modis-land.gsfc.nasa.gov/pdf/sn_gring_10deg.txt)<sup>③</sup>和[General Cartographic Transformation Package (GCTP) projection parameters and other tile infomation](https://modis-land.gsfc.nasa.gov/GCTP.html)<sup>④</sup>；Lambert Azimuthal Equal-Area Tile Grids (Polar)的[Table of Tile Bounding Coordinates](https://modis-land.gsfc.nasa.gov/pdf/MODISPolarGridTiles.pdf)<sup>⑤</sup>;及Linear Latitude/Longitude Grid的[lat/long bounding (G-ring) coordinates](https://modis-land.gsfc.nasa.gov/lat_long_tiles.txt)<sup>⑥</sup>。

此次实验数据为[MCD12Q1_v006](https://e4ftl01.cr.usgs.gov/MOTA/MCD12Q1.006/)<sup>⑦</sup>，包括2001年至2020年的数据，每年的数据按照Sinusoidal Tile Grid方式切分为单独的HDF文件，例如2020年数据文件夹下的“MCD12Q1.A2020001.h21v03.006.2021360001124.hdf”数据文件为`h21v03`位置瓦片数据，即水平瓦片号为21，垂直瓦片号为03。Sinusoidal Tile Grid划分方式包括460个瓦片，分析区域仅为中国区域的数据，因此无需下载全部数据，但是需要根据下载的Table of Tile Bounding Coordinates (10 deg tiles)文件（默认下载文件名为“sn_bound_10deg.txt”），提取分析区域瓦片的水平瓦片号（ih）和垂直瓦片号（iv），定义函数`modland_grids()`实现自动化批量提取工作。

参数定义和参数值的存储仍使用自定义的AttrDict类方法，方便常用参数值的管理和扩充，初步定义有存储投影信息的`gi`子属性，和存储有数据文件路径的`data`子属性。


```python
from database import postSQL2gpd,gpd2postSQL
from util_misc import AttrDict
__C=AttrDict() 
args=__C

__C.gi=AttrDict()
__C.gi.Chicago_epsg=32616
__C.gi.epsg_wgs84=4326

__C.data=AttrDict()
__C.data.sn_bound_10deg='./data/MCD12Q1v006/sn_bound_10deg.txt' # Table of Tile Bounding Coordinates (10 deg tiles)文件
__C.data.MCD12Q1v006_fns=r'G:\data\MCD12Q1v006\data\all' # MCD12Q1v006数据文件所在文件夹
__C.data.CH_provincial_borders_fn='./data/CN-sheng-A/CN-sheng-A.shp' # 2015年中国省级行政边界数据
__C.data.MCD12Q1v006_preprocessed=r'G:/data/MCD12Q1v006/MCD12Q1v006_CH.nc'  # 放置MCD12Q1v006处理后数据
__C.data.MCD12Q1v006_dt_vals=r'G:/data/MCD12Q1v006/MCD12Q1v006_dt_vals.pickle' # 放置对位坐标的历年分类值
__C.data.MCD12Q1v006_tif=r'D:\data\MCD12Q1v006\tif' # 放置MCD12Q1v006转换为栅格.tif格式文件
__C.data.MCD12Q1v006_years_vals_array=r'D:\data\MCD12Q1v006\MCD12Q1v006_years_vals_array.pickle' # 合并MCD12Q1v006粮农组织-土地覆盖分类系统1（LCCS1）土地覆盖层历年数据为一个数组
```


```python
import pandas as pd
pd.options.mode.chained_assignment=None  # default='warn'

def modland_grids(fp,start_idx=0,boundary_coordi=None): 
    '''
    给定经纬度范围，提取Sinusoidal Tile Grid方式下，提取MCD12Q1_v006数据集对应官方文件Table of Tile Bounding Coordinates (10 deg tiles)满足要求的行信息，包括水平瓦片号（ih）和垂直瓦片号（iv）

    Parameters
    ----------
    fp : string
        Table of Tile Bounding Coordinates (10 deg tiles)文件，默认名为sn_bound_10deg.txt.
    start_idx : int, optional
        开始行，忽略抬头信息. The default is 0.
    boundary_coordi : list(float), optional
        提取边界经纬度信息，格式为 [lon_min,lon_max,lat_min,lat_max]. The default is None.

    Returns
    -------
    DataFrame
        位于给定范围内的数据行信息，包括水平瓦片号（ih）和垂直瓦片号（iv.
        
    '''        
    import pandas as pd
    
    with open (fp,'r') as f:
        lines=f.readlines()[start_idx:-2]
    lines_df=pd.DataFrame(columns=lines[0].split(),data=[row.split() for row in lines[1:]])
    lines_df=lines_df.apply(pd.to_numeric,errors='ignore')
    
    def within_func(row):
        lon_sum=(row.lon_min>=lon_min and row.lon_min<=lon_max)+(row.lon_max>=lon_min and row.lon_max<=lon_max)    
        lat_sum=(row.lat_min>=lat_min and row.lat_min<=lat_max)+(row.lat_max>=lat_min and row.lat_max<=lat_max)
        if lon_sum>0 and lat_sum>0:
            return 1
        else: 
            return 0        
        
    if boundary_coordi:
        lon_min,lon_max,lat_min,lat_max=boundary_coordi
        lines_df['mask']=lines_df.apply(within_func,axis=1) 
        extracted_rows=lines_df[lines_df['mask']==1]
        extracted_rows['identifier']=extracted_rows.apply(lambda row:f"h{int(row.ih)}v{int(row.iv):02}",axis=1)
        return extracted_rows
    else:
        return lines_df    
    
modland_ivih_masked=modland_grids(args.data.sn_bound_10deg,start_idx=6,boundary_coordi=[68,139,15,57])    
print(modland_ivih_masked.shape)
modland_ivih_masked.sort_values(by=['ih','iv'])
```

    (38, 8)
    




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>iv</th>
      <th>ih</th>
      <th>lon_min</th>
      <th>lon_max</th>
      <th>lat_min</th>
      <th>lat_max</th>
      <th>mask</th>
      <th>identifier</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>129</th>
      <td>3</td>
      <td>21</td>
      <td>46.6717</td>
      <td>80.0167</td>
      <td>50.0</td>
      <td>60.0</td>
      <td>1</td>
      <td>h21v03</td>
    </tr>
    <tr>
      <th>130</th>
      <td>3</td>
      <td>22</td>
      <td>62.2290</td>
      <td>100.0167</td>
      <td>50.0</td>
      <td>60.0</td>
      <td>1</td>
      <td>h22v03</td>
    </tr>
    <tr>
      <th>166</th>
      <td>4</td>
      <td>22</td>
      <td>52.2163</td>
      <td>77.7992</td>
      <td>40.0</td>
      <td>50.0</td>
      <td>1</td>
      <td>h22v04</td>
    </tr>
    <tr>
      <th>131</th>
      <td>3</td>
      <td>23</td>
      <td>77.7862</td>
      <td>120.0167</td>
      <td>50.0</td>
      <td>60.0</td>
      <td>1</td>
      <td>h23v03</td>
    </tr>
    <tr>
      <th>167</th>
      <td>4</td>
      <td>23</td>
      <td>65.2704</td>
      <td>93.3564</td>
      <td>40.0</td>
      <td>50.0</td>
      <td>1</td>
      <td>h23v04</td>
    </tr>
    <tr>
      <th>203</th>
      <td>5</td>
      <td>23</td>
      <td>57.7350</td>
      <td>78.3353</td>
      <td>30.0</td>
      <td>40.0</td>
      <td>1</td>
      <td>h23v05</td>
    </tr>
    <tr>
      <th>239</th>
      <td>6</td>
      <td>23</td>
      <td>53.2089</td>
      <td>69.2917</td>
      <td>20.0</td>
      <td>30.0</td>
      <td>1</td>
      <td>h23v06</td>
    </tr>
    <tr>
      <th>132</th>
      <td>3</td>
      <td>24</td>
      <td>93.3434</td>
      <td>140.0167</td>
      <td>50.0</td>
      <td>60.0</td>
      <td>1</td>
      <td>h24v03</td>
    </tr>
    <tr>
      <th>168</th>
      <td>4</td>
      <td>24</td>
      <td>78.3244</td>
      <td>108.9136</td>
      <td>40.0</td>
      <td>50.0</td>
      <td>1</td>
      <td>h24v04</td>
    </tr>
    <tr>
      <th>204</th>
      <td>5</td>
      <td>24</td>
      <td>69.2820</td>
      <td>91.3894</td>
      <td>30.0</td>
      <td>40.0</td>
      <td>1</td>
      <td>h24v05</td>
    </tr>
    <tr>
      <th>240</th>
      <td>6</td>
      <td>24</td>
      <td>63.8507</td>
      <td>80.8387</td>
      <td>20.0</td>
      <td>30.0</td>
      <td>1</td>
      <td>h24v06</td>
    </tr>
    <tr>
      <th>276</th>
      <td>7</td>
      <td>24</td>
      <td>60.9256</td>
      <td>74.5013</td>
      <td>10.0</td>
      <td>20.0</td>
      <td>1</td>
      <td>h24v07</td>
    </tr>
    <tr>
      <th>133</th>
      <td>3</td>
      <td>25</td>
      <td>108.9007</td>
      <td>160.0167</td>
      <td>50.0</td>
      <td>60.0</td>
      <td>1</td>
      <td>h25v03</td>
    </tr>
    <tr>
      <th>169</th>
      <td>4</td>
      <td>25</td>
      <td>91.3785</td>
      <td>124.4709</td>
      <td>40.0</td>
      <td>50.0</td>
      <td>1</td>
      <td>h25v04</td>
    </tr>
    <tr>
      <th>205</th>
      <td>5</td>
      <td>25</td>
      <td>80.8290</td>
      <td>104.4435</td>
      <td>30.0</td>
      <td>40.0</td>
      <td>1</td>
      <td>h25v05</td>
    </tr>
    <tr>
      <th>241</th>
      <td>6</td>
      <td>25</td>
      <td>74.4924</td>
      <td>92.3857</td>
      <td>20.0</td>
      <td>30.0</td>
      <td>1</td>
      <td>h25v06</td>
    </tr>
    <tr>
      <th>277</th>
      <td>7</td>
      <td>25</td>
      <td>71.0799</td>
      <td>85.1431</td>
      <td>10.0</td>
      <td>20.0</td>
      <td>1</td>
      <td>h25v07</td>
    </tr>
    <tr>
      <th>134</th>
      <td>3</td>
      <td>26</td>
      <td>124.4579</td>
      <td>180.0000</td>
      <td>50.0</td>
      <td>60.0</td>
      <td>1</td>
      <td>h26v03</td>
    </tr>
    <tr>
      <th>170</th>
      <td>4</td>
      <td>26</td>
      <td>104.4326</td>
      <td>140.0281</td>
      <td>40.0</td>
      <td>50.0</td>
      <td>1</td>
      <td>h26v04</td>
    </tr>
    <tr>
      <th>206</th>
      <td>5</td>
      <td>26</td>
      <td>92.3760</td>
      <td>117.4975</td>
      <td>30.0</td>
      <td>40.0</td>
      <td>1</td>
      <td>h26v05</td>
    </tr>
    <tr>
      <th>242</th>
      <td>6</td>
      <td>26</td>
      <td>85.1342</td>
      <td>103.9327</td>
      <td>20.0</td>
      <td>30.0</td>
      <td>1</td>
      <td>h26v06</td>
    </tr>
    <tr>
      <th>278</th>
      <td>7</td>
      <td>26</td>
      <td>81.2341</td>
      <td>95.7849</td>
      <td>10.0</td>
      <td>20.0</td>
      <td>1</td>
      <td>h26v07</td>
    </tr>
    <tr>
      <th>171</th>
      <td>4</td>
      <td>27</td>
      <td>117.4867</td>
      <td>155.5853</td>
      <td>40.0</td>
      <td>50.0</td>
      <td>1</td>
      <td>h27v04</td>
    </tr>
    <tr>
      <th>207</th>
      <td>5</td>
      <td>27</td>
      <td>103.9230</td>
      <td>130.5516</td>
      <td>30.0</td>
      <td>40.0</td>
      <td>1</td>
      <td>h27v05</td>
    </tr>
    <tr>
      <th>243</th>
      <td>6</td>
      <td>27</td>
      <td>95.7760</td>
      <td>115.4797</td>
      <td>20.0</td>
      <td>30.0</td>
      <td>1</td>
      <td>h27v06</td>
    </tr>
    <tr>
      <th>279</th>
      <td>7</td>
      <td>27</td>
      <td>91.3884</td>
      <td>106.4266</td>
      <td>10.0</td>
      <td>20.0</td>
      <td>1</td>
      <td>h27v07</td>
    </tr>
    <tr>
      <th>172</th>
      <td>4</td>
      <td>28</td>
      <td>130.5407</td>
      <td>171.1426</td>
      <td>40.0</td>
      <td>50.0</td>
      <td>1</td>
      <td>h28v04</td>
    </tr>
    <tr>
      <th>208</th>
      <td>5</td>
      <td>28</td>
      <td>115.4701</td>
      <td>143.6057</td>
      <td>30.0</td>
      <td>40.0</td>
      <td>1</td>
      <td>h28v05</td>
    </tr>
    <tr>
      <th>244</th>
      <td>6</td>
      <td>28</td>
      <td>106.4178</td>
      <td>127.0267</td>
      <td>20.0</td>
      <td>30.0</td>
      <td>1</td>
      <td>h28v06</td>
    </tr>
    <tr>
      <th>280</th>
      <td>7</td>
      <td>28</td>
      <td>101.5427</td>
      <td>117.0684</td>
      <td>10.0</td>
      <td>20.0</td>
      <td>1</td>
      <td>h28v07</td>
    </tr>
    <tr>
      <th>209</th>
      <td>5</td>
      <td>29</td>
      <td>127.0171</td>
      <td>156.6598</td>
      <td>30.0</td>
      <td>40.0</td>
      <td>1</td>
      <td>h29v05</td>
    </tr>
    <tr>
      <th>245</th>
      <td>6</td>
      <td>29</td>
      <td>117.0596</td>
      <td>138.5737</td>
      <td>20.0</td>
      <td>30.0</td>
      <td>1</td>
      <td>h29v06</td>
    </tr>
    <tr>
      <th>281</th>
      <td>7</td>
      <td>29</td>
      <td>111.6969</td>
      <td>127.7102</td>
      <td>10.0</td>
      <td>20.0</td>
      <td>1</td>
      <td>h29v07</td>
    </tr>
    <tr>
      <th>210</th>
      <td>5</td>
      <td>30</td>
      <td>138.5641</td>
      <td>169.7138</td>
      <td>30.0</td>
      <td>40.0</td>
      <td>1</td>
      <td>h30v05</td>
    </tr>
    <tr>
      <th>246</th>
      <td>6</td>
      <td>30</td>
      <td>127.7013</td>
      <td>150.1207</td>
      <td>20.0</td>
      <td>30.0</td>
      <td>1</td>
      <td>h30v06</td>
    </tr>
    <tr>
      <th>282</th>
      <td>7</td>
      <td>30</td>
      <td>121.8512</td>
      <td>138.3520</td>
      <td>10.0</td>
      <td>20.0</td>
      <td>1</td>
      <td>h30v07</td>
    </tr>
    <tr>
      <th>247</th>
      <td>6</td>
      <td>31</td>
      <td>138.3431</td>
      <td>161.6677</td>
      <td>20.0</td>
      <td>30.0</td>
      <td>1</td>
      <td>h31v06</td>
    </tr>
    <tr>
      <th>283</th>
      <td>7</td>
      <td>31</td>
      <td>132.0055</td>
      <td>148.9938</td>
      <td>10.0</td>
      <td>20.0</td>
      <td>1</td>
      <td>h31v07</td>
    </tr>
  </tbody>
</table>
</div>



`modland_grids()`函数计算返回的DataFrame增加了一个新列`identifier`，该列对应下载文件名例如“MCD12Q1.A2020001.h21v03.006.2021360001124.hdf”中的`h21v03`，指明下载瓦片区域的水平瓦片号（ih）和垂直瓦片号（iv），用于网页数据批量检索提取的标注信息。


```python
identifier=modland_ivih_masked.identifier.to_list()
print(identifier)
```

    ['h21v03', 'h22v03', 'h23v03', 'h24v03', 'h25v03', 'h26v03', 'h22v04', 'h23v04', 'h24v04', 'h25v04', 'h26v04', 'h27v04', 'h28v04', 'h23v05', 'h24v05', 'h25v05', 'h26v05', 'h27v05', 'h28v05', 'h29v05', 'h30v05', 'h23v06', 'h24v06', 'h25v06', 'h26v06', 'h27v06', 'h28v06', 'h29v06', 'h30v06', 'h31v06', 'h24v07', 'h25v07', 'h26v07', 'h27v07', 'h28v07', 'h29v07', 'h30v07', 'h31v07']
    

**网络抓取（Web crawling）**

下述代码迁移于[Web crawling with Python](https://www.scrapingbee.com/blog/crawling-python/)<sup>⑧</sup>中简单的网络抓取代码部分，并做了简单的调整，增加了是否搜索子页的`iter`初始化参数，如果为`False`则仅抓取指定页面可下载文件的链接。同时增加了`visited_urls_dict`变量，以字典形式存储页面和对应页面可下载文件链接。要在Python中建立一个简单的网络爬虫，至少需要一个库来从URL中下载HTML，及一个HTML解析库来提取链接。Python提供了用于发出HTTP请求的标准库`urllib`和用于解析HTML的`html.parser`。用于请求和HTML解析的标准Python库对开发者不是很友好，可使用其它其他流行的库，例如`request`和`Beautiful Soup`等，提供更好的开发体验。下述定义的`Crawler`类，其中的辅助方法是包含使用`requests`库的`get().text`方法定义的`download_url()`函数，包含使用`BeautifulSoup`库定义的`get_linked_url()`和`add_url_to_visit()`函数过滤RUL。要访问的URL和已访问的URL被存储在两个独立的列表中，`visited_urls`和`visited_urls`。


```python
import logging
from urllib.parse import urljoin
import requests
from bs4 import BeautifulSoup

logging.basicConfig(
    format='%(asctime)s %(levelname)s:%(message)s',
    level=logging.INFO)

class Crawler:
    '''
    简单的网络抓取工具，调整迁移于：Web crawling with Python，https://www.scrapingbee.com/blog/crawling-python/
    指定网页，抓取可以下载的文件链接。
    '''
    def __init__(self, urls=[],iter=True):
        self.visited_urls = []
        self.urls_to_visit = urls
        self.iter=iter
        self.visited_urls_dict={}

    def download_url(self, url):
        return requests.get(url).text

    def get_linked_urls(self, url, html):
        soup = BeautifulSoup(html, 'html.parser')
        for link in soup.find_all('a'):
            path = link.get('href')
            if path and path.startswith('/'):
                path = urljoin(url, path)
            yield path

    def add_url_to_visit(self, url):
        if url not in self.visited_urls and url not in self.urls_to_visit:
            self.urls_to_visit.append(url)

    def crawl(self, url_):
        self.visited_urls_dict[url_]=[]
        html = self.download_url(url_)
        for url in self.get_linked_urls(url_, html):
            if self.iter:
                self.add_url_to_visit(url)
            else:
                self.visited_urls_dict[url_].append(url)

    def run(self):
        while self.urls_to_visit:
            url = self.urls_to_visit.pop(0)
            logging.info(f'Crawling: {url}')            
            try:
                self.crawl(url)
            except Exception:
                logging.exception(f'Failed to crawl: {url}')
            finally:
                self.visited_urls.append(url)      
                
if __name__=="__main__":
    url_root_lst=[f'https://e4ftl01.cr.usgs.gov/MOTA/MCD12Q1.006/{i}.01.01/' for i in range(2001,2021,1)]       
    wc=Crawler(urls=url_root_lst,iter=False)
    wc.run() 
```

抓取可获取的网页文件链接，存储在了`visited_urls_dict`字典中，为避免重复抓取，将该数据存储到本地空间，方便调用。


```python
import pickle
MCD12Q1_crawl_url_fp="./data/MCD12Q1_crawl_urls.pickle"
with open(MCD12Q1_crawl_url_fp,'wb') as f:
    pickle.dump(wc.visited_urls_dict,f)
```


```python
with open(MCD12Q1_crawl_url_fp,'rb') as f:
    MCD12Q1_crawl_urls=pickle.load(f)
```


```python
print(f"keys: {MCD12Q1_crawl_urls.keys()}")
print("-"*50)
print(f"values: {MCD12Q1_crawl_urls['https://e4ftl01.cr.usgs.gov/MOTA/MCD12Q1.006/2001.01.01/'][:10]}")
```

    keys: dict_keys(['https://e4ftl01.cr.usgs.gov/MOTA/MCD12Q1.006/2001.01.01/', 'https://e4ftl01.cr.usgs.gov/MOTA/MCD12Q1.006/2002.01.01/', 'https://e4ftl01.cr.usgs.gov/MOTA/MCD12Q1.006/2003.01.01/', 'https://e4ftl01.cr.usgs.gov/MOTA/MCD12Q1.006/2004.01.01/', 'https://e4ftl01.cr.usgs.gov/MOTA/MCD12Q1.006/2005.01.01/', 'https://e4ftl01.cr.usgs.gov/MOTA/MCD12Q1.006/2006.01.01/', 'https://e4ftl01.cr.usgs.gov/MOTA/MCD12Q1.006/2007.01.01/', 'https://e4ftl01.cr.usgs.gov/MOTA/MCD12Q1.006/2008.01.01/', 'https://e4ftl01.cr.usgs.gov/MOTA/MCD12Q1.006/2009.01.01/', 'https://e4ftl01.cr.usgs.gov/MOTA/MCD12Q1.006/2010.01.01/', 'https://e4ftl01.cr.usgs.gov/MOTA/MCD12Q1.006/2011.01.01/', 'https://e4ftl01.cr.usgs.gov/MOTA/MCD12Q1.006/2012.01.01/', 'https://e4ftl01.cr.usgs.gov/MOTA/MCD12Q1.006/2013.01.01/', 'https://e4ftl01.cr.usgs.gov/MOTA/MCD12Q1.006/2014.01.01/', 'https://e4ftl01.cr.usgs.gov/MOTA/MCD12Q1.006/2015.01.01/', 'https://e4ftl01.cr.usgs.gov/MOTA/MCD12Q1.006/2016.01.01/', 'https://e4ftl01.cr.usgs.gov/MOTA/MCD12Q1.006/2017.01.01/', 'https://e4ftl01.cr.usgs.gov/MOTA/MCD12Q1.006/2018.01.01/', 'https://e4ftl01.cr.usgs.gov/MOTA/MCD12Q1.006/2019.01.01/', 'https://e4ftl01.cr.usgs.gov/MOTA/MCD12Q1.006/2020.01.01/'])
    --------------------------------------------------
    values: ['https://urs.earthdata.nasa.gov/users/new', 'https://lpdaac.usgs.gov/', '?C=N;O=D', '?C=M;O=A', '?C=S;O=A', '?C=D;O=A', 'https://e4ftl01.cr.usgs.gov/MOTA/MCD12Q1.006/', 'MCD12Q1.A2001001.h00v08.006.2018142182903.hdf', 'MCD12Q1.A2001001.h00v08.006.2018142182903.hdf.xml', 'MCD12Q1.A2001001.h00v09.006.2018142182901.hdf']
    

通过`modland_grids()`函数获取了分析区域的瓦片编号，通过`Crawler`类抓取了数据文件下载链接，定义`urls_extraction()`函数，根据瓦片编号提取对应数据文件下载链接，并用`NumPy`库的`savetxt()`方法存储提取后的列表数据，方便直接用于浏览器扩展（Extensions）应用，例如Chrome浏览器的`Simple mass downloader`工具读取数据链接文件批量下载等。


```python
import numpy as np

def urls_extraction(urls_dict,conditional_chars):
    '''
    根据modland_grids()函数获取的瓦片编号，提取对应的Crawler类抓取的数据文件下载链接

    Parameters
    ----------
    urls_dict : list(string)
        Crawler类抓取的数据文件下载链接.
    conditional_chars : list(string)
        'hXvX'格式标识，例如'h21v03'，为水平瓦片号（ih）和垂直瓦片号（iv）.

    Returns
    -------
    urls_extraction_dict : dict(string:string)
        满足要求的数据文件下载链接，键为下载的文件夹，值为该文件夹下满足要求的数据文件下载链接.
    urls_extraction_lst : list(string)
        所有满足要求的数据文件下载链接列表.

    '''    
    from urllib.parse import urljoin
    
    urls_extraction_dict={}
    urls_extraction_lst=[]
    for k,v in urls_dict.items():
        urls_extraction_dict[k]=[]
        for url in v:
            for i in identifier:
                if i in url:
                    urls_extraction_dict[k].append(urljoin(k,url))
                    urls_extraction_lst.append(urljoin(k,url))
    return urls_extraction_dict,urls_extraction_lst    
    
urls_extraction_dict,urls_extraction_lst=urls_extraction(MCD12Q1_crawl_urls,identifier)    
np.savetxt('./data/urls_extraction_lst.txt', urls_extraction_lst, delimiter="\n", fmt="%s")
print(urls_extraction_lst[::200])
print("-"*50)
print(f"符合要求的数据文件总数量: {len(urls_extraction_lst)}")
```

    ['https://e4ftl01.cr.usgs.gov/MOTA/MCD12Q1.006/2001.01.01/MCD12Q1.A2001001.h21v03.006.2018142213330.hdf', 'https://e4ftl01.cr.usgs.gov/MOTA/MCD12Q1.006/2003.01.01/MCD12Q1.A2003001.h27v06.006.2018144212435.hdf', 'https://e4ftl01.cr.usgs.gov/MOTA/MCD12Q1.006/2006.01.01/MCD12Q1.A2006001.h24v06.006.2018145212751.hdf', 'https://e4ftl01.cr.usgs.gov/MOTA/MCD12Q1.006/2008.01.01/BROWSE.MCD12Q1.A2008001.h29v05.006.2018054191051.1.jpg', 'https://e4ftl01.cr.usgs.gov/MOTA/MCD12Q1.006/2010.01.01/BROWSE.MCD12Q1.A2010001.h22v04.006.2018054201414.1.jpg', 'https://e4ftl01.cr.usgs.gov/MOTA/MCD12Q1.006/2011.01.01/MCD12Q1.A2011001.h27v07.006.2018146004501.hdf', 'https://e4ftl01.cr.usgs.gov/MOTA/MCD12Q1.006/2013.01.01/MCD12Q1.A2013001.h24v07.006.2018146014649.hdf', 'https://e4ftl01.cr.usgs.gov/MOTA/MCD12Q1.006/2015.01.01/BROWSE.MCD12Q1.A2015001.h29v07.006.2018055065547.1.jpg', 'https://e4ftl01.cr.usgs.gov/MOTA/MCD12Q1.006/2017.01.01/BROWSE.MCD12Q1.A2017001.h23v04.006.2019196135638.1.jpg', 'https://e4ftl01.cr.usgs.gov/MOTA/MCD12Q1.006/2018.01.01/MCD12Q1.A2018001.h28v04.006.2019200010243.hdf', 'https://e4ftl01.cr.usgs.gov/MOTA/MCD12Q1.006/2020.01.01/MCD12Q1.A2020001.h25v03.006.2021360020156.hdf']
    --------------------------------------------------
    符合要求的数据文件总数量: 2052
    

获取分析区域MCD12Q1_v006土地覆盖类型数据集数据文件下载链接后，可以用python继续编写下载程序，也可以直接使用浏览器扩展工具中的下载程序，这里使用了Chrome浏览器的`Simple mass downloader`工具加载保存的`urls_extraction_lst.txt`文件实现批量下载，下载的数据均置于了同一文件夹下。


```python
import glob
import os
MCD12Q1v006_2020_fps=glob.glob(os.path.join(args.data.MCD12Q1v006_fns,"*.hdf"))
MCD12Q1v006_2020_fps[:5]
```




    ['G:\\data\\MCD12Q1v006\\data\\all\\MCD12Q1.A2003001.h29v05.006.2018144213302.hdf',
     'G:\\data\\MCD12Q1v006\\data\\all\\MCD12Q1.A2003001.h29v06.006.2018144213347.hdf',
     'G:\\data\\MCD12Q1v006\\data\\all\\MCD12Q1.A2003001.h29v07.006.2018144213421.hdf',
     'G:\\data\\MCD12Q1v006\\data\\all\\MCD12Q1.A2003001.h30v05.006.2018145033504.hdf',
     'G:\\data\\MCD12Q1v006\\data\\all\\MCD12Q1.A2003001.h30v07.006.2018144214353.hdf']



下载的数据文件均位于同一文件夹下，需要按照年份分组提取。根据文件路径名可以观察到`A2003001`部分标识有数据年份，因此定义`data_grouping_basedon_formatting_pattern()`函数按给定的正则表达式提取标识字符，并以标识字符为键，以对应的路径名为值，以字典形式存储分组后数据。


```python
def data_grouping_basedon_formatting_pattern(str_data_list,pattern):
    '''
    按给定的正则表达式分组数据列表

    Parameters
    ----------
    str_data_list : list(string)
        字符串列表.
    pattern : string
        正则表达式.

    Returns
    -------
    data_grouping : dict(string:string)
        分组后字典.

    '''    
    import re
    data_grouping={}
    tabu=[]
    for text in str_data_list:
        string_match=re.findall(pattern,text)[0]
        if string_match not in tabu:
            tabu.append(string_match)
            data_grouping[string_match]=[text]
        else:
            data_grouping[string_match].append(text)
    return data_grouping

pattern="(?x)MCD12Q1\.(.*?)\."    
MCD12Q1v006_group=data_grouping_basedon_formatting_pattern(MCD12Q1v006_2020_fps,pattern)
print(MCD12Q1v006_group.keys())
```

    dict_keys(['A2003001', 'A2004001', 'A2005001', 'A2006001', 'A2001001', 'A2007001', 'A2002001', 'A2008001', 'A2011001', 'A2009001', 'A2012001', 'A2013001', 'A2010001', 'A2014001', 'A2017001', 'A2015001', 'A2018001', 'A2019001', 'A2016001', 'A2020001'])
    

**颜色值**

打印分类地图时，需要配置类别色彩，`matplotlib`库提供了[plot_colortable()](https://matplotlib.org/3.1.1/gallery/color/named_colors.html)函数<sup>⑨</sup>，可以直接迁移运行查看该库支持的不同色系颜色名称。


```python
from matplotlib.patches import Rectangle
import matplotlib.pyplot as plt
import matplotlib.colors as mcolors

def plot_colortable(colors, sort_colors=True, emptycols=0):
    '''
    绘制一个matplotlib支持命名颜色的列表，迁移于matplotlib库“List of named colors”，https://matplotlib.org/3.1.1/gallery/color/named_colors.html

    Parameters
    ----------
    colors : dict
        由mcolors模块提取，例如mcolors.BASE_COLORS，mcolors.TABLEAU_COLORS，mcolors.CSS4_COLORS等.
    sort_colors : bool, optional
        是否排序颜色. The default is True.
    emptycols : int, optional
        调整列数量，避免列中出现空值. The default is 0.

    Returns
    -------
    fig : matplotlib.figure.Figure
        返回图表.

    '''      
    cell_width = 212
    cell_height = 22
    swatch_width = 48
    margin = 12

    # Sort colors by hue, saturation, value and name.
    if sort_colors is True:
        by_hsv = sorted((tuple(mcolors.rgb_to_hsv(mcolors.to_rgb(color))),
                         name)
                        for name, color in colors.items())
        names = [name for hsv, name in by_hsv]
    else:
        names = list(colors)

    n = len(names)
    ncols = 4 - emptycols
    nrows = n // ncols + int(n % ncols > 0)

    width = cell_width * 4 + 2 * margin
    height = cell_height * nrows + 2 * margin
    dpi = 72

    fig, ax = plt.subplots(figsize=(width / dpi, height / dpi), dpi=dpi)
    fig.subplots_adjust(margin/width, margin/height,
                        (width-margin)/width, (height-margin)/height)
    ax.set_xlim(0, cell_width * 4)
    ax.set_ylim(cell_height * (nrows-0.5), -cell_height/2.)
    ax.yaxis.set_visible(False)
    ax.xaxis.set_visible(False)
    ax.set_axis_off()

    for i, name in enumerate(names):
        row = i % nrows
        col = i // nrows
        y = row * cell_height

        swatch_start_x = cell_width * col
        text_pos_x = cell_width * col + swatch_width + 7

        ax.text(text_pos_x, y, name, fontsize=14,
                horizontalalignment='left',
                verticalalignment='center')

        ax.add_patch(
            Rectangle(xy=(swatch_start_x, y-9), width=swatch_width,
                      height=18, facecolor=colors[name], edgecolor='0.7')
        )

    return fig
```


```python
plot_colortable(mcolors.BASE_COLORS, sort_colors=False, emptycols=1)
plot_colortable(mcolors.TABLEAU_COLORS, sort_colors=True, emptycols=2)
plot_colortable(mcolors.CSS4_COLORS)
plt.show()
```


<img src="./imgs/2_7_4/output_21_0.png" height='auto' width='auto' title="caDesign">   


<img src="./imgs/2_7_4/output_21_1.png" height='auto' width='auto' title="caDesign">    

<img src="./imgs/2_7_4/output_21_2.png" height='auto' width='auto' title="caDesign">


MCD12Q1_v006 土地覆盖类型数据集下载完成后，需要通过打印地图的方式查看下载的数据瓦片是否完全并落于分析区域内。定义`cmap_patch_build()`函数为分类地图打印配置分类颜色和图例参数。在组织分类信息输入条件时，以字典形式给出如`labels_cmap_dict`，以分类值为键，以分类名和颜色值列表为值。定义`MCD12Q1v006_merge_plot()`函数打印地图，栅格数据处理主要使用的库为[rioxarray](https://github.com/corteva/rioxarray)<sup>⑩</sup>，MCD12Q1_v006的HDF格式数据包含有多个层，打印时仅打印一层数据信息，因此需要指定层名称参数`layer`，下述打印的层名为`LC_Prop1`，即粮农组织-土地覆盖分类系统1（LCCS1）土地覆盖层。


```python
def cmap_patch_build(labels_cmap_dict):
    '''
    生成matplotlib.colors.ListedColormap，matplotlib.colors.BoundaryNorm和matplotlib.patches.Patch，用于分类数据地图打印并显示图例

    Parameters
    ----------
    labels_cmap_dict : dict
        字典格式为{分类值:[分类名，颜色则]}，例如{1:["Barren",'gray'],2:["Permanent_Snow_and_Ice",'ghostwhite']}.

    Returns
    -------
    cmap : matplotlib.colors.ListedColormap
        Colormap object generated from a list of colors. it can also be used to generate special colormaps for ordinary mapping.
    norm : matplotlib.colors.BoundaryNorm
        Generate a colormap index based on discrete intervals.
    patches : matplotlib.patches.Patch
        A patch is a 2D artist with a face color and an edge color.

    '''    
    from matplotlib.colors import from_levels_and_colors
    from matplotlib import colors
    import matplotlib.patches as mpatches
    
    labels={k:v[0] for k,v in labels_cmap_dict.items()}
    cmap_lst=list(map(list,zip(*[[k,v[1]] for k,v in labels_cmap_dict.items()])))

    cmap_dict={k[0]:colors.to_rgb(k[1]) for k in zip(*cmap_lst)}
    cmap, norm=from_levels_and_colors(cmap_lst[0],cmap_lst[1][:-1])    
    patches=[mpatches.Patch(color=cmap_dict[i],label=labels[i]) for i in cmap_dict]
    
    return cmap,norm,patches

labels_cmap_dict={1:["Barren",'gray'],
                  2:["Permanent_Snow_and_Ice",'ghostwhite'],
                  3:["Water_Bodies",'deepskyblue'],
                  11:["Evergreen_Needleleaf_Forests",'teal'],
                  13:["Deciduous_Needleleaf_Forests",'mediumturquoise'],
                  14:["Deciduous_Broadleaf_Forests",'green'],
                  15:["Mixed_Broadleaf_Needleleaf_Forests",'darkgreen'],
                  16:["Mixed_Broadleaf_Forests",'yellowgreen'],
                  21:["Open_Forests",'khaki'],
                  22:["Sparse_Forests",'palegreen'],
                  31:["Dense_Herbaceous",'goldenrod'],
                  32:["Sparse_Herbaceous",'beige'],
                  42:["Shrubland_Grassland_Mosaics",'peru'],
                  43:["Sparse_Shrublands",'linen'],
                  255:["Unclassified",'black']}
cmap,norm,patches=cmap_patch_build(labels_cmap_dict)
cmap
```

<img src="./imgs/2_7_4/output_23_0.png" height='auto' width='auto' title="caDesign">



```python
def MCD12Q1v006_merge_plot(fns,layer,cmap,norm,patches,**args):
    '''
    指定数据文件夹和层名称，打印MCD12Q1v006分类数据地图

    Parameters
    ----------
    fns : list(string)
        数据文件路径列表.
    layer : string
        MCD12Q1v006分类层.
    cmap : matplotlib.colors.ListedColormap
         Colormap object generated from a list of colors. it can also be used to generate special colormaps for ordinary mapping.
    norm : matplotlib.colors.BoundaryNorm
        Generate a colormap index based on discrete intervals.
    patches : matplotlib.patches.Patch
        A patch is a 2D artist with a face color and an edge color.
    **args : 关键字参数
        包括：  params=dict(box_to_anchor=(1.9, 1.02),
               ncol=1,
               fancybox=True).

    Returns
    -------
    merged : xarray.core.dataarray.DataArray
        合并后的MCD12Q1v006分类数据.

    '''    
    from rioxarray.merge import merge_arrays
    import rioxarray as rxr
    import matplotlib.pyplot as plt
    
    params=dict(box_to_anchor=(1.9, 1.02),
               ncol=1,
               fancybox=True)
    params.update(args)
    
    arrays=[rxr.open_rasterio(i,masked=True)[layer] for i in fns]
    merged=merge_arrays(arrays)
    plt.imshow(merged[0], cmap=cmap, norm=norm)
    plt.legend(handles=patches, bbox_to_anchor=params['box_to_anchor'],ncol=params['ncol'], fancybox=params['fancybox'],)
    
    return merged
    
LCCS1_merged=MCD12Q1v006_merge_plot(MCD12Q1v006_group['A2002001'],'LC_Prop1',cmap,norm,patches,box_to_anchor=(1.65, 1.03))    
```

<img src="./imgs/2_7_4/output_24_0.png" height='auto' width='auto' title="caDesign">



**HDF 层次化的数据格式（Hierarchical Data Format）**

层次数据格式（Hierarchical Data Format，HDF）是旨在存储和组织大量的数据一组文件格式（HDF4，HDF5），最初由美国国家超级计算应用中心（U.S. National Center for Supercomputing Applications）开发，由HDF集团支持，该集团是一个非营利性公司，其使命是确保HDF5技术的持续发展和以HDF存储数据的持续可及性。HDF数据格式是用于存储MODIS遥感数据的常用格式，可以使用`rioxarray`库读取。因为HDF文件的层次化，且元数据包含在数据中，因此需要循环读取主数据集和嵌套在主数据集中的子数据集来访问各层数据，例如MCD12Q1v006的不同分类层等。

下述代码读取了MCD12Q1v006原始数据集一个瓦片的数据，并打印读取结果，从`Dimensions`字段可以查看到波段的大小，为2400×2400；从`Coordinates`字段可以查看波段的数值类型为`int32`，x和y坐标值数据类型为`
float64`，空间投影`spatial_ref`则可以通过`tile_single.rio.crs`方式打印查看；`Data variables`字段则给出了所有层名称，对应到MCD12Q1_v006各层分类数据和相关数据层，通过层名可以分别提取各个分类数据；`Attributes`字段提供了数据集的相关信息。


```python
import rioxarray as rxr

tile_single=rxr.open_rasterio(MCD12Q1v006_group['A2002001'][0], masked=True)
tile_single
```



    xarray.Dataset
    Dimensions:              (band: 1, x: 2400, y: 2400)
    Coordinates:
    * band                 (band) int32 1
    * x                    (x) float64 4.448e+06 4.448e+06 ... 5.559e+06 5.56e+06
    * y                    (y) float64 6.671e+06 6.671e+06 ... 5.56e+06 5.56e+06
        spatial_ref          int32 0
    Data variables: (12/13)
        LC_Type1             (band, y, x) float32 ...
        LC_Prop2             (band, y, x) float32 ...
        LC_Prop3             (band, y, x) float32 ...
        QC                   (band, y, x) float32 ...
        LW                   (band, y, x) float32 ...
        LC_Type2             (band, y, x) float32 ...
        ...                   ...
        LC_Type4             (band, y, x) float32 ...
        LC_Type5             (band, y, x) float32 ...
        LC_Prop1_Assessment  (band, y, x) float32 ...
        LC_Prop2_Assessment  (band, y, x) float32 ...
        LC_Prop3_Assessment  (band, y, x) float32 ...
        LC_Prop1             (band, y, x) float32 ...
    Attributes: (12/64)
        ALGORITHMPACKAGEACCEPTANCEDATE:     1998-01-01
        ALGORITHMPACKAGEMATURITYCODE:       LAUNCH
        ALGORITHMPACKAGENAME:               MOD12Q1
        ALGORITHMPACKAGEVERSION:            V2.0
        ASSOCIATEDINSTRUMENTSHORTNAME.1:    MODIS
        ASSOCIATEDINSTRUMENTSHORTNAME.2:    MODIS
        ...                                 ...
        SOUTHBOUNDINGCOORDINATE:            50.0
        SPSOPARAMETERS:                     2669
        TileID:                             51022003
        VERSIONID:                          6
        VERTICALTILENUMBER:                 3
        WESTBOUNDINGCOORDINATE:             62.228953


查看数据的投影信息，可以使用`tile_single.rio.crs`，或者`tile_single.spatial_ref`方式，前者仅返回CRS信息，后者则可以返回更多投影相关信息。


```python
tile_single.rio.crs
```


    CRS.from_wkt('PROJCS["unnamed",GEOGCS["Unknown datum based upon the custom spheroid",DATUM["Not specified (based on custom spheroid)",SPHEROID["Custom spheroid",6371007.181,0]],PRIMEM["Greenwich",0],UNIT["degree",0.0174532925199433,AUTHORITY["EPSG","9122"]]],PROJECTION["Sinusoidal"],PARAMETER["longitude_of_center",0],PARAMETER["false_easting",0],PARAMETER["false_northing",0],UNIT["Meter",1],AXIS["Easting",EAST],AXIS["Northing",NORTH]]')




```python
tile_single.spatial_ref
```



    xarray.DataArrays 'spatial_ref'
    array(0)
    Coordinates:
        spatial_ref  int32 0
    Attributes: (12/16)
        crs_wkt:                         PROJCS[&quot;unnamed&quot;,GEOGCS[&quot;Unknown datum b...
        semi_major_axis:                 6371007.181
        semi_minor_axis:                 6371007.181
        inverse_flattening:              0.0
        reference_ellipsoid_name:        Custom spheroid
        longitude_of_prime_meridian:     0.0
        ...                              ...
        grid_mapping_name:               sinusoidal
        longitude_of_projection_origin:  0.0
        false_easting:                   0.0
        false_northing:                  0.0
        spatial_ref:                     PROJCS[&quot;unnamed&quot;,GEOGCS[&quot;Unknown datum b...
        GeoTransform:                    4447802.078667 463.31271652750013 0.0 66...



读取分类数据层，可以用`tile_single.LC_Prop1 `或者`tile_single['LC_Prop1']`方式。分类数据层仅显示该层相关信息，从`Attributes`字段可以查看到分类的名称和对应的栅格值。如果只查看`Attributes`字段信息，可以执行`tile_single.LC_Prop1.attrs`代码。


```python
tile_single.LC_Prop1 
```



 
    xarray.DataArray LC_Prop1 (band: 1, y: 2400, x: 2400)
    [5760000 values with dtype=float32]
    Coordinates:
    * band         (band) int32 1
    * x            (x) float64 4.448e+06 4.448e+06 ... 5.559e+06 5.56e+06
    * y            (y) float64 6.671e+06 6.671e+06 6.671e+06 ... 5.56e+06 5.56e+06
        spatial_ref  int32 0
    Attributes: (12/21)
        Barren:                              1
        Deciduous Broadleaf Forests:         14
        Deciduous Needleleaf Forests:        13
        Dense Herbaceous:                    31
        Dense Shrublands:                    41
        Evergreen Broadleaf Forests:         12
        ...                                  ...
        Sparse Shrublands:                   43
        Unclassified:                        255
        valid_range:                         1, 43
        Water Bodies:                        3
        scale_factor:                        1.0
        add_offset:                          0.0


`tile_single.LC_Prop1.values`方式可以提取波段数值。


```python
tile_single.LC_Prop1.values
```




    array([[[31., 31., 22., ..., 21., 21., 21.],
            [31., 31., 31., ..., 21., 21., 21.],
            [22., 22., 31., ..., 21., 21., 21.],
            ...,
            [31., 32., 32., ..., 32., 32., 32.],
            [31., 31., 31., ..., 32., 32., 32.],
            [31., 31., 31., ..., 32., 32., 32.]]], dtype=float32)



下述则打印了MCD12Q1v006合并的数据，因为仅合并了`LC_Prop1`层，为LCCS1分类数据。从打印信息可以得知波段大小为`y: 12000 x: 26401`，`Attributes`信息同上述单个瓦片的`LC_Prop1`层信息。


```python
LCCS1_merged
```


    xarray.DataArray LC_Prop1 (band: 1, y: 12000, x: 26401)
    array([[[15., 15., 15., ..., nan, nan, nan],
            [15., 15., 15., ..., nan, nan, nan],
            [15., 15., 15., ..., nan, nan, nan],
            ...,
            [nan, nan, nan, ...,  3.,  3., nan],
            [nan, nan, nan, ...,  3.,  3., nan],
            [nan, nan, nan, ...,  3.,  3., nan]]], dtype=float32)
    Coordinates:
    * x            (x) float64 3.336e+06 3.337e+06 ... 1.557e+07 1.557e+07
    * y            (y) float64 6.671e+06 6.671e+06 ... 1.113e+06 1.112e+06
    * band         (band) int32 1
        spatial_ref  int32 0
    Attributes: (12/22)
        Barren:                              1
        Deciduous Broadleaf Forests:         14
        Deciduous Needleleaf Forests:        13
        Dense Herbaceous:                    31
        Dense Shrublands:                    41
        Evergreen Broadleaf Forests:         12
        ...                                  ...
        Unclassified:                        255
        valid_range:                         1, 43
        Water Bodies:                        3
        scale_factor:                        1.0
        add_offset:                          0.0
        _FillValue:                          nan


合并的原始MCD12Q1v006数据，通常需要重新配置投影并裁切到更明确的分析区域。

1. 通过定义`gdf_box_construction()`函数，构建具有地理空间坐标和投影，用于裁切的矩形对象；
2. 为了方便地图观察，裁切前先对分类数据通过`xarray.rio.reproject`方法重投影，投影来自于中国科学院资源环境科学与数据中心的[2015年中国省级行政边界数据](https://www.resdc.cn/data.aspx?DATAID=200)<sup>⑪</sup>。为了方便投影信息调用，将其存储于AttrDict类方法实例化对象属性字典下；
3. 裁切的方法使用`rioxarray`库提供的`xarray.rio.clip`方法，裁切边界外的单元将被`nan`替换；
4. 因为被裁切的区域填充为`nan`，为了聚焦分析区域并减小数据量，需要移除全部为空的行或列，定义`array2d_drop_allNanRowCol()`函数实现。


```python
import geopandas as gpd
ch_provincial_borders=gpd.read_file(args.data.CH_provincial_borders_fn)
proj_Krasovsky_1940_Albers=ch_provincial_borders.crs
__C.gi.Krasovsky_1940_Albers=proj_Krasovsky_1940_Albers

print(args.gi.Krasovsky_1940_Albers)
ch_provincial_borders.plot();
```

    PROJCS["Krasovsky_1940_Albers",GEOGCS["Unknown datum based upon the Krassowsky 1940 ellipsoid",DATUM["Not_specified_based_on_Krassowsky_1940_ellipsoid",SPHEROID["Krassowsky 1940",6378245,298.3,AUTHORITY["EPSG","7024"]],AUTHORITY["EPSG","6024"]],PRIMEM["Greenwich",0],UNIT["Degree",0.0174532925199433]],PROJECTION["Albers_Conic_Equal_Area"],PARAMETER["latitude_of_center",0],PARAMETER["longitude_of_center",105],PARAMETER["standard_parallel_1",25],PARAMETER["standard_parallel_2",47],PARAMETER["false_easting",0],PARAMETER["false_northing",0],UNIT["metre",1,AUTHORITY["EPSG","9001"]],AXIS["Easting",EAST],AXIS["Northing",NORTH]]
    


<img src="./imgs/2_7_4/output_37_1.png" height='auto' width='auto' title="caDesign">    




```python
def gdf_box_construction(bounding,crs=4326):
    '''
    根据指定的经纬度范围建立具有空间坐标和投影的矩形（盒体）GeoDataFrame格式数据对象，通常用于地理数据的裁切提取操作

    Parameters
    ----------
    bounding : list(float)
        边界经纬度坐标，顺序为[minx, miny, maxx, maxy].
    crs : CRS, optional
        指定转换的投影坐标，crs形式. The default is 4326.

    Returns
    -------
    geodf : GeoDataFrame
        具有空间坐标和投影的矩形区域.

    '''    
    import geopandas as gpd
    from shapely.geometry import box

    geodf=gpd.GeoDataFrame(
        geometry=[
            box(*bounding)
        ],
        crs=4326
    )
    geodf.to_crs(crs,inplace=True)
    geodf.plot()    
    
    return geodf
    
bounding_gdf=gdf_box_construction(bounding=[73.14, 11.56, 137.00, 57.55],crs=args.gi.Krasovsky_1940_Albers)  
```


<img src="./imgs/2_7_4/output_38_0.png" height='auto' width='auto' title="caDesign">    



```python
LCCS1_merged_KA=LCCS1_merged.rio.reproject(args.gi.Krasovsky_1940_Albers) 
LCCS1_merged_KA_clipped=LCCS1_merged_KA.rio.clip(bounding_gdf.geometry.values, bounding_gdf.crs, drop=False)merged_reproject_clipped
```


```python
def array2d_drop_allNanRowCol(array,drop_rows=True,drop_cols=True):
    '''
    移除2D数组全空行或列 

    Parameters
    ----------
    array : array
        2D数组.
    drop_rows : bool, optional
        如果为True，则移除全空行. The default is True.
    drop_cols : bool, optional
        如果为True，则移除全空列. The default is True.

    Returns
    -------
    array
        移除全空行或列的数组.

    '''    
    import numpy as np
    
    if drop_rows and drop_cols:
        return array[~np.all(np.isnan(array),axis=1),~np.all(np.isnan(array),axis=0)]
    elif drop_rows and not drop_cols:
        return array[~np.all(np.isnan(array),axis=1),:]
    elif drop_cols and not drop_rows:
        return array[:,~np.all(np.isnan(array),axis=0)]

LCCS1_merged_KA_clipped_notna=array2d_drop_allNanRowCol(LCCS1_merged_KA_clipped[0])   
```


```python
import matplotlib.pyplot as plt
plt.imshow(LCCS1_merged_KA_clipped_notna, cmap=cmap, norm=norm)
plt.legend(handles=patches, bbox_to_anchor=(1.65, 1.03),ncol=1, fancybox=True,);
```


<img src="./imgs/2_7_4/output_41_0.png" height='auto' width='auto' title="caDesign">    



上述使用了自定义矩形裁切边界裁切数据，如果仅保留中国国界内的数据，则可以使用`ch_provincial_borders`数据进行裁切，并且使用自定义函数`array2d_drop_allNanRowCol()`再次移除全空行或列。


```python
LCCS1_merged_KA_clipped_CH=LCCS1_merged_KA_clipped_notna.rio.clip(ch_provincial_borders.geometry.values, ch_provincial_borders.crs, drop=False)
LCCS1_merged_KA_clipped_notna_CH=array2d_drop_allNanRowCol(LCCS1_merged_KA_clipped_CH)  
```


```python
plt.imshow(LCCS1_merged_KA_clipped_notna_CH, cmap=cmap, norm=norm)
plt.legend(handles=patches, bbox_to_anchor=(1.75, 1.03),ncol=1, fancybox=True,);
```


<img src="./imgs/2_7_4/output_44_0.png" height='auto' width='auto' title="caDesign">   


**xarray.DataArray 数据保存**

`rioxarray`库是`rasterio`库对[Xarray](https://docs.xarray.dev/en/stable/index.html)<sup>⑫</sup>的扩展。`Xarray`是一个用于处理标记多维（N-dimensional, ND）数组的Python库，且包括高级分析和可视化等功能。`Pandas`库的数据结构包括`Series`和`DataFramd`两种，为1维度和2维度；`NumPy`库不限维度，处理多维数组，但是每一数组只能有一种数据类型，因此`Xarray`库试图解决多维数据且具有不同数据类型的问题：

1. `Xarray`库使用命名的维度来代替轴标签，使得数据选择和维度操作更容易；
2. `Xarray`库支持多种类型数据，可以在一个ND数组中保存异质数据；
3. `obj.attrs`方法可以追踪对象任意元数据。

`Xarray`有两类数据结构，为`DataArray`和`DataSet`。`DataArray`用于单个数据变量，`DataSet`为多个`DataArray`数据变量的容器。

上述合并、裁切后的`LCCS1_merged_KA_clipped_notna_CH`数据，为`DataArray`格式数据，`Xarray`库提供了多种保存的方法，下述代码采用了两种方式，一种是`ojb.rio.to_raster`方法，将`DataArray`对象存储为`TIFF`格式数据；另一种是`obj.to_netcdf`方法，将`DataArray`对象存储为[netCDF（Network Common Data Form）](https://en.wikipedia.org/wiki/NetCDF)<sup>⑬</sup>格式文件。`netCDF`是一种用于创建、存储、访问和共享面向多维科学数据的文件格式，具有自我描述性（self-describing）。`TIFF`格式数据仅为栅格数据，并不包括属性等说明，而`netCDF`的自我描述性使得数据存储的信息更加全面。保存为`netCDF`数据文件，仍可以使用`rioxarray`库的`open_rasterio`方法读取。

在执行`obj.to_netcdf`时，如果属性值等命名不符合要求，则会提示错误，例如元数据中的属性值，即分类字典中包含有`/` 等非法字符，例如'Mixed Broadleaf/Needleleaf Forests'，因此需要替换该字符。为了避免直接修改原数据，可以使用`obj.copy()`复制为一个副本。


```python
save_temp_tif_fn=r"G:\data\MCD12Q1v006\temp\LCCS1_merged_KA_clipped_notna_CH.tif"
LCCS1_merged_KA_clipped_notna_CH.rio.to_raster(save_temp_tif_fn)
```


```python
LCCS1_merged_KA_clipped_notna_CH_copy=LCCS1_merged_KA_clipped_notna_CH.copy()
LCCS1_merged_KA_clipped_notna_CH_copy_attrs=LCCS1_merged_KA_clipped_notna_CH_copy.attrs
LCCS1_merged_KA_clipped_notna_CH_copy_attrs_update={k.replace("/","_"):v for k,v in LCCS1_merged_KA_clipped_notna_CH_copy_attrs.items()}
LCCS1_merged_KA_clipped_notna_CH_copy.attrs=LCCS1_merged_KA_clipped_notna_CH_copy_attrs_update
LCCS1_merged_KA_clipped_notna_CH_copy
```




    xarray.DataArray LC_Prop1 (y: 13477, x: 16046)
    array([[nan, nan, nan, ..., nan, nan, nan],
        [nan, nan, nan, ..., nan, nan, nan],
        [nan, nan, nan, ..., nan, nan, nan],
        ...,
        [nan, nan, nan, ..., nan, nan, nan],
        [nan, nan, nan, ..., nan, nan, nan],
        [nan, nan, nan, ..., nan, nan, nan]], dtype=float32)
    Coordinates:
    * x            (x) float64 -2.626e+06 -2.626e+06 ... 2.207e+06 2.207e+06
    * y            (y) float64 5.922e+06 5.921e+06 ... 1.753e+06 1.753e+06
        band         int32 1
        spatial_ref  int32 0
    Attributes: (12/22)
        Barren:                              1
        Deciduous Broadleaf Forests:         14
        Deciduous Needleleaf Forests:        13
        Dense Herbaceous:                    31
        Dense Shrublands:                    41
        Evergreen Broadleaf Forests:         12
        ...                                  ...
        Unclassified:                        255
        valid_range:                         1, 43
        Water Bodies:                        3
        scale_factor:                        1.0
        add_offset:                          0.0
        _FillValue:                          nan


```python
save_temp_hdf_fn=r"G:\data\MCD12Q1v006\temp\LCCS1_merged_KA_clipped_notna_CH.nc"
LCCS1_merged_KA_clipped_notna_CH_copy.to_netcdf(save_temp_hdf_fn)
```

**批量处理和保存MCD12Q1_v006 各年数据**

批量处理MCD12Q1_v006各年数据，将上述合并、重投影、裁切和保存的过程置于一个函数`MCD12Q1v006_batch_processing()`之内，简化操作流程。保存的数据类型为netCDF格式文件，通过配置`group`参数可以将各年的数据存储于同一文件下，避免不方便管理的零散数据文件。合并存储后的数据文件（中国区域）约17G大小，如果单个存储文件过大，可以存储时分批存储于不同的文件下，减少单个文件的大小。


```python
def MCD12Q1v006_batch_processing(fns_group,clip_border,layer,save_fn):
    '''
    批量处理MCD12Q1v006各年数据，包括合并、重投影、裁切，保存等过程。投影将转换为裁切对象投影。保存数据文件类型为netcdf，并配置`group`参数，将合并后的各年数据存于同一个文件下

    Parameters
    ----------
    fns_group : dict(string:string)
        由data_grouping_basedon_formatting_pattern()函数计算获取，为按年份分组后的数据集.
    clip_border : GeoDataFrame
        用于裁切的Polygon对象.
    layer : string
        MCD12Q1v006分类层.
    save_fn : string
        保存文件路径，后缀名通常为'.nc'.

    Returns
    -------
    None.

    '''    
    from rioxarray.merge import merge_arrays
    import rioxarray as rxr
    import numpy as np
    from tqdm import tqdm

    for g in tqdm(fns_group):
        arrays=[rxr.open_rasterio(i,masked=True)[layer] for i in fns_group[g]]
        merged=merge_arrays(arrays)
        merged_reproject=merged.rio.reproject(clip_border.crs)         
        merged_reproject_clipped=merged_reproject.rio.clip(clip_border.geometry.values, clip_border.crs, drop=False)
        array=merged_reproject_clipped[0]
        merged_reproject_clipped_notna=array[~np.all(np.isnan(array),axis=1),~np.all(np.isnan(array),axis=0)]
        attrs=merged_reproject_clipped_notna.attrs
        attrs_update={k.replace("/","_"):v for k,v in attrs.items()}
        merged_reproject_clipped_notna.attrs=attrs_update
        
        merged_reproject_clipped_notna.to_netcdf(save_fn,"a",group=g,engine="netcdf4") # engine="netcdf4"        

MCD12Q1v006_batch_processing(MCD12Q1v006_group,ch_provincial_borders,'LC_Prop1',save_fn=args.data.MCD12Q1v006_preprocessed)
```

    100%|██████████| 20/20 [32:28<00:00, 97.45s/it] 
    

读取给定`group`参数保存的netcdf数据格式文件，在读取时使用`rioxarray.open_rasterio`方法或`xarray`库的`xarray.open_dataset`方法，但是需要给出组名参数`group`，例如`rxr.open_rasterio(args.data.MCD12Q1v006_preprocessed, group='A2001001')`。为了按年顺序读取文件，提取组名中时间信息转换为`datetime`对象并按其排序构建列表。


```python
from datetime import datetime

g_names=MCD12Q1v006_group.keys()
g_names_dt=[(g,datetime.strptime(g[1:5],'%Y')) for g in g_names]
g_names_dt.sort(key=lambda x:x[1])
g_names_dt
```




    [('A2001001', datetime.datetime(2001, 1, 1, 0, 0)),
     ('A2002001', datetime.datetime(2002, 1, 1, 0, 0)),
     ('A2003001', datetime.datetime(2003, 1, 1, 0, 0)),
     ('A2004001', datetime.datetime(2004, 1, 1, 0, 0)),
     ('A2005001', datetime.datetime(2005, 1, 1, 0, 0)),
     ('A2006001', datetime.datetime(2006, 1, 1, 0, 0)),
     ('A2007001', datetime.datetime(2007, 1, 1, 0, 0)),
     ('A2008001', datetime.datetime(2008, 1, 1, 0, 0)),
     ('A2009001', datetime.datetime(2009, 1, 1, 0, 0)),
     ('A2010001', datetime.datetime(2010, 1, 1, 0, 0)),
     ('A2011001', datetime.datetime(2011, 1, 1, 0, 0)),
     ('A2012001', datetime.datetime(2012, 1, 1, 0, 0)),
     ('A2013001', datetime.datetime(2013, 1, 1, 0, 0)),
     ('A2014001', datetime.datetime(2014, 1, 1, 0, 0)),
     ('A2015001', datetime.datetime(2015, 1, 1, 0, 0)),
     ('A2016001', datetime.datetime(2016, 1, 1, 0, 0)),
     ('A2017001', datetime.datetime(2017, 1, 1, 0, 0)),
     ('A2018001', datetime.datetime(2018, 1, 1, 0, 0)),
     ('A2019001', datetime.datetime(2019, 1, 1, 0, 0)),
     ('A2020001', datetime.datetime(2020, 1, 1, 0, 0))]



在存储为netcdf数据格式文件时，保留了原始MCD12Q1_v006数据的信息，如果直接打印`MCD12Q1v006_2001`时，会提示有`Data variables`变量层为`LC_Prop1`，因此如果只读取变量，执行`MCD12Q1v006_2001.LC_Prop1`即可。


```python
import rioxarray as rxr
MCD12Q1v006_2001=rxr.open_rasterio(args.data.MCD12Q1v006_preprocessed, group='A2001001')
MCD12Q1v006_2001.LC_Prop1
```




    xarray.DataArray LC_Prop1 (band: 1, y: 14313, x: 16045)
    [229652085 values with dtype=float32]
    Coordinates:
    * band         (band) int32 1
    * x            (x) float64 -2.626e+06 -2.626e+06 ... 2.206e+06 2.207e+06
    * y            (y) float64 5.922e+06 5.921e+06 ... 1.049e+06 1.048e+06
        spatial_ref  int32 0
    Attributes: (12/75)
        /A2001001/LC_Prop1#add_offset:                          0
        /A2001001/LC_Prop1#Barren:                              1
        /A2001001/LC_Prop1#coordinates:                         band
        /A2001001/LC_Prop1#Deciduous Broadleaf Forests:         14
        /A2001001/LC_Prop1#Deciduous Needleleaf Forests:        13
        /A2001001/LC_Prop1#Dense Herbaceous:                    31
        ...                                                     ...
        Sparse Herbaceous:                                      32
        Sparse Shrublands:                                      43
        Unclassified:                                           255
        valid_range:                                            1, 43
        Water Bodies:                                           3
        _FillValue:                                             nan

除了保存为netcdf等格式文件外，可以直接指定DataArray数据变量层转换为.tif格式的栅格数据，并保存到指定文件夹下。


```python
def MCD12Q1v006_gnc2tif(g_names_dt,nc_fn,layer,save_path):
    '''
    按组提取netcdf格式数据，并转换为.tif格式的栅格数据

    Parameters
    ----------
    g_names_dt : dict(string:datetime)
        包含组名和对应时间信息的列表，例如：
        [('A2001001', datetime.datetime(2001, 1, 1, 0, 0)),
         ('A2002001', datetime.datetime(2002, 1, 1, 0, 0))].
    nc_fn : string
        含组的netcdf格式文件路径名.
    layer : string
        转换为栅格的变量名（Data variables）.
    save_path : string
        保存路径根目录.

    Returns
    -------
    fns : list(string)
        保存的栅格文件路径.

    '''    
    from tqdm import tqdm
    
    fns=[]
    for g_n,dt in tqdm(g_names_dt):
        g=rxr.open_rasterio(nc_fn, group=g_n) 
        print(f"{dt.year}.tif")
        fn=os.path.join(save_path,f"{dt.year}.tif")
        fns.append(fn)
        g_layer=g[layer]
        g_layer.rio.to_raster(fn)      
        
    return fns
        
MCD12Q1v006_tif_fns=MCD12Q1v006_gnc2tif(g_names_dt,args.data.MCD12Q1v006_preprocessed,'LC_Prop1',args.data.MCD12Q1v006_tif)    
```

    100%|██████████| 20/20 [00:00<?, ?it/s]
    

**按采样点提取数据**

原始历年MCD12Q1_v006数据各层读取为DataArray格式，虽然具有统一的大地坐标和投影，但是坐标值`Coordinates`不同年份可能会存在差异，因此通过`xarray.DataArray.sel`方法按照统一坐标列表提取历年各层值（即栅格值）会存在偏差，造成数据错误；同时，中国区数据量为(y: 13477 x: 16046）即$16046 \times 13477=216,251,942$多个栅格单元或坐标，且后续进行经典离散时间马尔可夫链分析时，只需要足够多的单元样本就可进行，因此采用生成采样点，由采样点提取历年栅格单元值的方法。

定义`random_pts_in_bounds()`和`random_pts_in_geoBounds()`函数，实现给定边界生成对应投影坐标GeoDataFrame格式的采样点。给定的边界为GeoDataFrame格式的Polygon对象，如果使用中国区2015年中国省级行政边界数据，则需要用`gdf.dissolve`方法合并各行数据为一个Polygon对象。对于不规则图形边界，生成的采样点是边界外接矩形指定数量的采样点，当仅保留边界内的点时，采样点数据会变少。


```python
ch_provincial_borders_dissolved=ch_provincial_borders.dissolve()
ch_provincial_borders_dissolved
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>geometry</th>
      <th>AREA</th>
      <th>PERIMETER</th>
      <th>SHENG_</th>
      <th>SHENG_ID</th>
      <th>SHENG</th>
      <th>name</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>MULTIPOLYGON (((494657.361 1879931.569, 494643...</td>
      <td>4.525440e+11</td>
      <td>6666710.0</td>
      <td>2</td>
      <td>23</td>
      <td>23</td>
      <td>黑龙江</td>
    </tr>
  </tbody>
</table>
</div>




```python
ch_provincial_borders_dissolved.plot()
```



<img src="./imgs/2_7_4/output_59_1.png" height='auto' width='auto' title="caDesign">
    


```python
def random_pts_in_bounds(polygon_gdf, number):  
    '''
    根据给定的Polygon格式边界，生成指定数量的随机点坐标值

    Parameters
    ----------
    polygon_gdf : GeoDataFrame
        Polygon边界.
    number : int
        生成随机点坐标值数量.

    Returns
    -------
    x : array(float)
        X坐标值.
    y :  array(float)
        Y坐标值.

    '''    
    import numpy as np
    from shapely.geometry import Polygon
    
    minx, miny, maxx, maxy=polygon_gdf.bounds.values[0]
    x=np.random.uniform( minx, maxx, number )
    y=np.random.uniform( miny, maxy, number )
    return x, y

def random_pts_in_geoBounds(polygon_gdf,number,plot=False):
    '''
    根据给定的Polygon格式边界，生成指定数量对应到Polygon对象投影的GeoDataFrame格式随机点，配合random_pts_in_bounds()函数

    Parameters
    ----------
    polygon_gdf : GeoDataFrame
        Polygon边界.
    number : int
        生成随机点的数量.
    plot : bool, optional
        是否打印边界和随机点地图查看. The default is False.

    Returns
    -------
    pts_in_polygon_gdf : TYPE
        DESCRIPTION.

    '''    
    from shapely.geometry import Point
    import geopandas as gpd
    import matplotlib.pyplot as plt
    
    x,y=random_pts_in_bounds(polygon_gdf, number)
    pts_df=pd.DataFrame()
    pts_df['points']=list(zip(x,y))    
    pts_df['points']=pts_df['points'].apply(Point)
    points_gdf=gpd.GeoDataFrame(pts_df, geometry='points')
    points_gdf.set_crs(polygon_gdf.crs,inplace=True)

    Sjoin=gpd.tools.sjoin(points_gdf,polygon_gdf,predicate="within", how='left')
    idx_name=polygon_gdf.index.values[0]
    pts_in_polygon_gdf=points_gdf[Sjoin.index_right==idx_name]
    
    if plot:
        ax=polygon_gdf.boundary.plot(linewidth=1, edgecolor="black")
        pts_in_polygon_gdf.plot(ax=ax, linewidth=1, color="red", markersize=8)
        plt.show()
    
    return pts_in_polygon_gdf 

pts_num=10_000    
pts_in_polygon_gdf=random_pts_in_geoBounds(ch_provincial_borders_dissolved, pts_num,plot=True)    
```


<img src="./imgs/2_7_4/output_60_0.png" height='auto' width='auto' title="caDesign">   


定义`extract_raster_vals_at_pts()`和`extract_raster_vals_at_pts_batch()`函数根据采样点坐标值列表提取对应栅格单元值。提取单元值的主要方法是使用`rasterio`库的`sample`方法。


```python
sample_pt_coords=[(p.x,p.y) for p in pts_in_polygon_gdf.points.values]
```


```python
def extract_raster_vals_at_pts(pt_coords,raster_fn):
    '''
    对一个栅格数据执行给定采样点提取栅格值

    Parameters
    ----------
    pt_coords : list(float)
        采样点坐标值列表，格式为[(x1,y1),(x2,y2)].
    raster_fn : string
        栅格文件路径名.

    Returns
    -------
    sample_vals : array
        采样点位置栅格值.

    '''    
    import rasterio as rio
    import numpy as np
    
    raster=rio.open(raster_fn)
    sample_vals=np.stack(list(raster.sample(pt_coords)))
    
    return sample_vals

def extract_raster_vals_at_pts_batch(pt_coords,raster_fns_lst):
    '''
    对多个栅格数据执行给定采样点提取栅格值

    Parameters
    ----------
    pt_coords : list(float)
        采样点坐标值列表，格式为[(x1,y1),(x2,y2)].
    raster_fns_lst : list(string)
        多个栅格文件路径名列表.

    Returns
    -------
    sample_vals_array : array
        多个栅格采样点值数组.
    idx_lst : list(int)
        栅格数索引值列表.

    '''    
    from tqdm.notebook import tqdm
    
    idx_lst=[]
    sample_vals_lst=[]
    pbar=tqdm(total=len(raster_fns_lst))
    for i,fn in tqdm(enumerate(raster_fns_lst)):
        sample_vals=extract_raster_vals_at_pts(pt_coords,fn)
        idx_lst.append(i)
        sample_vals_lst.append(sample_vals)
        pbar.update(1)
        
    pbar.close()    
    sample_vals_array=np.concatenate(sample_vals_lst, axis=1)
    return sample_vals_array,idx_lst   
            
sample_vals_array,idx_lst=extract_raster_vals_at_pts_batch(sample_pt_coords,MCD12Q1v006_tif_fns)
```


      0%|          | 0/20 [00:00<?, ?it/s]



    0it [00:00, ?it/s]


保存按采样点提取的栅格值数组，方便后续实验读取。数组的第1维度对应采样点，第2维度对应历年栅格。


```python
import pickle
with open(args.data.MCD12Q1v006_years_vals_array,'wb') as f:
    pickle.dump(sample_vals_array,f)
```


```python
sample_vals_array
```




    array([[31., 31., 31., ..., 31., 31., 31.],
           [ 1.,  1.,  1., ...,  1.,  1.,  1.],
           [ 1.,  1.,  1., ...,  1.,  1.,  1.],
           ...,
           [31., 31., 31., ..., 31., 31., 31.],
           [ 1.,  1.,  1., ...,  1.,  1.,  1.],
           [22., 22., 22., ..., 22., 22., 22.]], dtype=float32)



#### 2）芝加哥市发生报告的犯罪事件数据集

从[Chicago Data Portal](https://data.cityofchicago.org/)获取[Crimes - 2001 to present](https://data.cityofchicago.org/Public-Safety/Crimes-2001-to-present-Dashboard/5cd6-ry5g)<sup>⑭</sup>数据集，该数据集提取自芝加哥警察局的CLEAR（Citizen Law Enforcement Analysis and Reporting，公民执法分析和报告）系统，反映了2001年至今在芝加哥市发生报告的犯罪事件。时空类数据除了空间分布的位置信息外，包括时间轴向上的属性变化数据，符合在时间序列上取多个截面，在这些截面上同时选取样本观测值构成的面板数据（Panel data）。该数据包括犯罪地点（经纬度值），也包括该地点所属社区区域编号，最终要分析的内容是按给定时间区间段重采样各个社区范围内累计报告犯罪数量在时间上和在时空上的动态变化，因此数据预处理的内容包括：

1. 将没有空间几何字段报告的犯罪记录数据按社区编号字段`Community Area `合并入同样下载于`Chicago Data Portal`的“Boundaries - Community Areas (current)”数据（含有社区区域地理空间信息的社区范围），对应`Community Area `的字段为`area_numbe`；
2. 因为时空面板数据表述为GeoDataFrame格式的二维度数据，在列中既包括样本所属空间几何对象（即按社区分组），也包括时间轴向上的日期数据及对应日期的各属性数据，需按组（社区范围）统计给定时间长度报告犯罪数累积量，即按组按给定时间长度重采样;
3. 为方便时间序列数据的处理，将含有时间的字符串转换为统一格式化的Datatime格式数据。





```python
from database import postSQL2gpd,gpd2postSQL

__C.data.crimes='G:/data/Crimes_-_2001_to_Present.csv' # 芝加哥城犯罪记录数据
__C.data.community_areas="./data/ChicagoCommunityAreas/ChicagoCommunityAreas.shp" # 芝加哥城社区边界数据
__C.data.crimes_resample='G:/data/crimes_resample.gpkg' # 用于存储时间采样后的数据
```

使用`pandas`库的`read_csv`方法直接读取CSV格式报告的犯罪记录数据集，打印一行数据查看含有的字段名和对应的值，确定样本所属社区编号列为`Community Area `，发生时间列为`Date`。


```python
import pandas as pd
crimes_df=pd.read_csv(args.data.crimes)
```


```python
print(crimes_df.loc[0])
crimes_df.head()
```

    ID                                                 10224738
    Case Number                                        HY411648
    Date                                 09/05/2015 01:30:00 PM
    Block                                       043XX S WOOD ST
    IUCR                                                   0486
    Primary Type                                        BATTERY
    Description                         DOMESTIC BATTERY SIMPLE
    Location Description                              RESIDENCE
    Arrest                                                False
    Domestic                                               True
    Beat                                                    924
    District                                                9.0
    Ward                                                   12.0
    Community Area                                         61.0
    FBI Code                                                08B
    X Coordinate                                      1165074.0
    Y Coordinate                                      1875917.0
    Year                                                   2015
    Updated On                           02/10/2018 03:50:01 PM
    Latitude                                          41.815117
    Longitude                                            -87.67
    Location                      (41.815117282, -87.669999562)
    Historical Wards 2003-2015                             29.0
    Zip Codes                                           14924.0
    Community Areas                                        59.0
    Census Tracts                                         706.0
    Wards                                                   3.0
    Boundaries - ZIP Codes                                 37.0
    Police Districts                                       23.0
    Police Beats                                          108.0
    Name: 0, dtype: object
    




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>ID</th>
      <th>Case Number</th>
      <th>Date</th>
      <th>Block</th>
      <th>IUCR</th>
      <th>Primary Type</th>
      <th>Description</th>
      <th>Location Description</th>
      <th>Arrest</th>
      <th>Domestic</th>
      <th>...</th>
      <th>Longitude</th>
      <th>Location</th>
      <th>Historical Wards 2003-2015</th>
      <th>Zip Codes</th>
      <th>Community Areas</th>
      <th>Census Tracts</th>
      <th>Wards</th>
      <th>Boundaries - ZIP Codes</th>
      <th>Police Districts</th>
      <th>Police Beats</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>10224738</td>
      <td>HY411648</td>
      <td>09/05/2015 01:30:00 PM</td>
      <td>043XX S WOOD ST</td>
      <td>0486</td>
      <td>BATTERY</td>
      <td>DOMESTIC BATTERY SIMPLE</td>
      <td>RESIDENCE</td>
      <td>False</td>
      <td>True</td>
      <td>...</td>
      <td>-87.670000</td>
      <td>(41.815117282, -87.669999562)</td>
      <td>29.0</td>
      <td>14924.0</td>
      <td>59.0</td>
      <td>706.0</td>
      <td>3.0</td>
      <td>37.0</td>
      <td>23.0</td>
      <td>108.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>10224739</td>
      <td>HY411615</td>
      <td>09/04/2015 11:30:00 AM</td>
      <td>008XX N CENTRAL AVE</td>
      <td>0870</td>
      <td>THEFT</td>
      <td>POCKET-PICKING</td>
      <td>CTA BUS</td>
      <td>False</td>
      <td>False</td>
      <td>...</td>
      <td>-87.765400</td>
      <td>(41.895080471, -87.765400451)</td>
      <td>4.0</td>
      <td>4299.0</td>
      <td>26.0</td>
      <td>562.0</td>
      <td>45.0</td>
      <td>5.0</td>
      <td>25.0</td>
      <td>67.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>11646166</td>
      <td>JC213529</td>
      <td>09/01/2018 12:01:00 AM</td>
      <td>082XX S INGLESIDE AVE</td>
      <td>0810</td>
      <td>THEFT</td>
      <td>OVER $500</td>
      <td>RESIDENCE</td>
      <td>False</td>
      <td>True</td>
      <td>...</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>3</th>
      <td>10224740</td>
      <td>HY411595</td>
      <td>09/05/2015 12:45:00 PM</td>
      <td>035XX W BARRY AVE</td>
      <td>2023</td>
      <td>NARCOTICS</td>
      <td>POSS: HEROIN(BRN/TAN)</td>
      <td>SIDEWALK</td>
      <td>True</td>
      <td>False</td>
      <td>...</td>
      <td>-87.716650</td>
      <td>(41.937405765, -87.716649687)</td>
      <td>15.0</td>
      <td>21538.0</td>
      <td>22.0</td>
      <td>216.0</td>
      <td>12.0</td>
      <td>39.0</td>
      <td>7.0</td>
      <td>168.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>10224741</td>
      <td>HY411610</td>
      <td>09/05/2015 01:00:00 PM</td>
      <td>0000X N LARAMIE AVE</td>
      <td>0560</td>
      <td>ASSAULT</td>
      <td>SIMPLE</td>
      <td>APARTMENT</td>
      <td>False</td>
      <td>True</td>
      <td>...</td>
      <td>-87.755121</td>
      <td>(41.881903443, -87.755121152)</td>
      <td>11.0</td>
      <td>22216.0</td>
      <td>26.0</td>
      <td>696.0</td>
      <td>23.0</td>
      <td>32.0</td>
      <td>25.0</td>
      <td>81.0</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 30 columns</p>
</div>



使用`GeoPandas`库的`read_file`方法直接读取SHP格式的社区范围数据，打印查看包含列，确定社区编号字段为`area_numbe`，几何列为`geometry`(Polygon几何类型)。


```python
import geopandas as gpd
community_area_gdf=gpd.read_file(args.data.community_areas)
community_area_gdf.area_numbe=community_area_gdf.area_numbe.astype("int64")
community_area_gdf.sort_values(by=["area_numbe"],inplace=True)
community_area_gdf.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>area</th>
      <th>area_num_1</th>
      <th>area_numbe</th>
      <th>comarea</th>
      <th>comarea_id</th>
      <th>community</th>
      <th>perimeter</th>
      <th>shape_area</th>
      <th>shape_len</th>
      <th>geometry</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>9</th>
      <td>0.0</td>
      <td>1</td>
      <td>1</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>ROGERS PARK</td>
      <td>0.0</td>
      <td>5.125990e+07</td>
      <td>34052.397576</td>
      <td>POLYGON ((-87.65456 41.99817, -87.65574 41.998...</td>
    </tr>
    <tr>
      <th>19</th>
      <td>0.0</td>
      <td>2</td>
      <td>2</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>WEST RIDGE</td>
      <td>0.0</td>
      <td>9.842909e+07</td>
      <td>43020.689458</td>
      <td>POLYGON ((-87.68465 42.01948, -87.68464 42.019...</td>
    </tr>
    <tr>
      <th>30</th>
      <td>0.0</td>
      <td>3</td>
      <td>3</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>UPTOWN</td>
      <td>0.0</td>
      <td>6.509564e+07</td>
      <td>46972.794555</td>
      <td>POLYGON ((-87.64102 41.95480, -87.64400 41.954...</td>
    </tr>
    <tr>
      <th>5</th>
      <td>0.0</td>
      <td>4</td>
      <td>4</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>LINCOLN SQUARE</td>
      <td>0.0</td>
      <td>7.135233e+07</td>
      <td>36624.603085</td>
      <td>POLYGON ((-87.67441 41.97610, -87.67440 41.976...</td>
    </tr>
    <tr>
      <th>47</th>
      <td>0.0</td>
      <td>5</td>
      <td>5</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>NORTH CENTER</td>
      <td>0.0</td>
      <td>5.705417e+07</td>
      <td>31391.669754</td>
      <td>POLYGON ((-87.67336 41.93234, -87.67342 41.932...</td>
    </tr>
  </tbody>
</table>
</div>



在“空间自相关分析”部分定义有`df_linking_geometry()`函数，用于包含有属性的DataFrame格式数据合并包含有地理空间信息的GeoDataFrame格式数据，将其置入`util_misc`模块调用合并报告的犯罪记录数据和社区范围数据。


```python
import util_misc
crimes_gdf=util_misc.df_linking_geometry(crimes_df,community_area_gdf,key_df="Community Area",key_gdf="area_numbe")    
```

使用`pandas`库提供的`to_datetime`方法将含有时间字符串`Date`列转换为`datatime`格式数据并置于新列`ts`下。


```python
import datetime
crimes_gdf['ts']=pd.to_datetime(crimes_gdf['Date'])
```

将时间列数据用于行索引值，为避免名称冲突，将时间行索引名重命名为`ts_idx`，避免后续相关执行代码可能发生的错误。


```python
crimes_gdf.set_index('ts',inplace=True,drop=False)
crimes_gdf.rename_axis(index={'ts':'ts_idx'},inplace=True)
```

通过直接打印GeoDataFrame格式数据，或者只打印前几行和后几行来初步判断时间周期，起始时间为“2001-01-01”，结束时间为“2022-11-22 23:58:00”。


```python
crimes_gdf.sort_index(inplace=True)
crimes_gdf.head(3)
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>area_numbe</th>
      <th>geometry</th>
      <th>ID</th>
      <th>Case Number</th>
      <th>Date</th>
      <th>Block</th>
      <th>IUCR</th>
      <th>Primary Type</th>
      <th>Description</th>
      <th>Location Description</th>
      <th>...</th>
      <th>Location</th>
      <th>Historical Wards 2003-2015</th>
      <th>Zip Codes</th>
      <th>Community Areas</th>
      <th>Census Tracts</th>
      <th>Wards</th>
      <th>Boundaries - ZIP Codes</th>
      <th>Police Districts</th>
      <th>Police Beats</th>
      <th>ts</th>
    </tr>
    <tr>
      <th>ts_idx</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2001-01-01</th>
      <td>68</td>
      <td>POLYGON ((-87.62826 41.78316, -87.62826 41.783...</td>
      <td>3723059</td>
      <td>HK830095</td>
      <td>01/01/2001 12:00:00 AM</td>
      <td>071XX S UNION AVE</td>
      <td>0840</td>
      <td>THEFT</td>
      <td>FINANCIAL ID THEFT: OVER $300</td>
      <td>APARTMENT</td>
      <td>...</td>
      <td>(41.765053677, -87.641686171)</td>
      <td>31.0</td>
      <td>21559.0</td>
      <td>66.0</td>
      <td>511.0</td>
      <td>32.0</td>
      <td>11.0</td>
      <td>17.0</td>
      <td>214.0</td>
      <td>2001-01-01</td>
    </tr>
    <tr>
      <th>2001-01-01</th>
      <td>17</td>
      <td>POLYGON ((-87.77621 41.93845, -87.77677 41.938...</td>
      <td>9959537</td>
      <td>HY141743</td>
      <td>01/01/2001 12:00:00 AM</td>
      <td>034XX N NOTTINGHAM AVE</td>
      <td>1752</td>
      <td>OFFENSE INVOLVING CHILDREN</td>
      <td>AGG CRIM SEX ABUSE FAM MEMBER</td>
      <td>RESIDENCE</td>
      <td>...</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>2001-01-01</td>
    </tr>
    <tr>
      <th>2001-01-01</th>
      <td>67</td>
      <td>POLYGON ((-87.65487 41.79417, -87.65487 41.794...</td>
      <td>5091512</td>
      <td>HM695128</td>
      <td>01/01/2001 12:00:00 AM</td>
      <td>057XX S JUSTINE ST</td>
      <td>0840</td>
      <td>THEFT</td>
      <td>FINANCIAL ID THEFT: OVER $300</td>
      <td>OTHER</td>
      <td>...</td>
      <td>(41.789165627, -87.663083724)</td>
      <td>19.0</td>
      <td>22257.0</td>
      <td>65.0</td>
      <td>384.0</td>
      <td>2.0</td>
      <td>23.0</td>
      <td>17.0</td>
      <td>266.0</td>
      <td>2001-01-01</td>
    </tr>
  </tbody>
</table>
<p>3 rows × 33 columns</p>
</div>




```python
crimes_gdf.tail(3)
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>area_numbe</th>
      <th>geometry</th>
      <th>ID</th>
      <th>Case Number</th>
      <th>Date</th>
      <th>Block</th>
      <th>IUCR</th>
      <th>Primary Type</th>
      <th>Description</th>
      <th>Location Description</th>
      <th>...</th>
      <th>Location</th>
      <th>Historical Wards 2003-2015</th>
      <th>Zip Codes</th>
      <th>Community Areas</th>
      <th>Census Tracts</th>
      <th>Wards</th>
      <th>Boundaries - ZIP Codes</th>
      <th>Police Districts</th>
      <th>Police Beats</th>
      <th>ts</th>
    </tr>
    <tr>
      <th>ts_idx</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2022-11-22 23:51:00</th>
      <td>20</td>
      <td>POLYGON ((-87.73146 41.93173, -87.73139 41.931...</td>
      <td>12900924</td>
      <td>JF484559</td>
      <td>11/22/2022 11:51:00 PM</td>
      <td>020XX N PULASKI RD</td>
      <td>0460</td>
      <td>BATTERY</td>
      <td>SIMPLE</td>
      <td>GAS STATION</td>
      <td>...</td>
      <td>(41.917425774, -87.726571455)</td>
      <td>27.0</td>
      <td>22535.0</td>
      <td>21.0</td>
      <td>76.0</td>
      <td>49.0</td>
      <td>2.0</td>
      <td>6.0</td>
      <td>187.0</td>
      <td>2022-11-22 23:51:00</td>
    </tr>
    <tr>
      <th>2022-11-22 23:53:00</th>
      <td>25</td>
      <td>POLYGON ((-87.78942 41.91751, -87.78927 41.917...</td>
      <td>12901051</td>
      <td>JF484599</td>
      <td>11/22/2022 11:53:00 PM</td>
      <td>049XX W CONGRESS PKWY</td>
      <td>0454</td>
      <td>BATTERY</td>
      <td>AGGRAVATED P.O. - HANDS, FISTS, FEET, NO / MIN...</td>
      <td>RESIDENCE - PORCH / HALLWAY</td>
      <td>...</td>
      <td>(41.874030213, -87.748083613)</td>
      <td>36.0</td>
      <td>22216.0</td>
      <td>26.0</td>
      <td>69.0</td>
      <td>7.0</td>
      <td>32.0</td>
      <td>25.0</td>
      <td>137.0</td>
      <td>2022-11-22 23:53:00</td>
    </tr>
    <tr>
      <th>2022-11-22 23:58:00</th>
      <td>23</td>
      <td>POLYGON ((-87.69157 41.88820, -87.69501 41.888...</td>
      <td>12900998</td>
      <td>JF484554</td>
      <td>11/22/2022 11:58:00 PM</td>
      <td>032XX W GRAND AVE</td>
      <td>0560</td>
      <td>ASSAULT</td>
      <td>SIMPLE</td>
      <td>STREET</td>
      <td>...</td>
      <td>(41.898771348, -87.707812918)</td>
      <td>41.0</td>
      <td>4299.0</td>
      <td>24.0</td>
      <td>150.0</td>
      <td>46.0</td>
      <td>5.0</td>
      <td>16.0</td>
      <td>65.0</td>
      <td>2022-11-22 23:58:00</td>
    </tr>
  </tbody>
</table>
<p>3 rows × 33 columns</p>
</div>



定义按时间长度分组重采样的`df_group_resample()`函数。重采样部分主要使用`pandas`提供的`resample`方法，其中`rule`参数为被赋予特定时间序列频率的字符串别名，别名含义可以从`pandas`手册[Time series / date functionality：Offset aliases](https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases)<sup>⑮</sup>处查看，摘录如下：

| Alias    | Description                                      |
|----------|--------------------------------------------------|
| B        | business day frequency                           |
| C        | custom business day frequency                    |
| D        | calendar day frequency                           |
| W        | weekly frequency                                 |
| M        | month end frequency                              |
| SM       | semi-month end frequency (15th and end of month) |
| BM       | business month end frequency                     |
| CBM      | custom business month end frequency              |
| MS       | month start frequency                            |
| SMS      | semi-month start frequency (1st and 15th)        |
| BMS      | business month start frequency                   |
| CBMS     | custom business month start frequency            |
| Q        | quarter end frequency                            |
| BQ       | business quarter end frequency                   |
| QS       | quarter start frequency                          |
| BQS      | business quarter start frequency                 |
| A, Y     | year end frequency                               |
| BA, BY   | business year end frequency                      |
| AS, YS   | year start frequency                             |
| BAS, BYS | business year start frequency                    |
| BH       | business hour frequency                          |
| H        | hourly frequency                                 |
| T, min   | minutely frequency                               |
| S        | secondly frequency                               |
| L, ms    | milliseconds                                     |
| U, us    | microseconds                                     |
| N        | nanoseconds                                      |


```python
def df_group_resample(df,val_column,time_column,rules,methods=["mean","min","max","sum"],group_column=None,geometry_column=None):
    '''
    时空数据（面板数据），按照给定的分组，时间长度，数值计算方法重采样数值列。

    Parameters
    ----------
    df : DataFrame
        时空数据.
    val_column : string
        用于重采样的数据值.
    time_column : string
        时间列.
    rules : string
        偏移量（时间长度），例'H'，'D'，`W`，`M`，`Y`，'30S'，`3T`，`Q`，`17min`等.
    methods : list(string), optional
        数值采样方法，包括均值、最小和最大值，及和. The default is ["mean","min","max","sum"].
    group_column : string, optional
        分组列名. The default is None.
    geometry_column : string, optional
        几何列. The default is None.

    Returns
    -------
    GeoDataFrame
        重采样后时空数据.

    '''    
    from pandas.api.types import is_datetime64_any_dtype as is_datetime
    import pandas as pd
    import geopandas as gpd
    from tqdm import tqdm
    from shapely import wkt
    
    df_notna=df[df[val_column].notna()]
    if is_datetime(df_notna[time_column]):
        df_notna.rename(columns={time_column:"ts"},inplace=True)
    else:
        df_notn['ts']=pd.to_datetime(df_notna[time_column])
    df_notna.sort_values(by=["ts"],inplace=True)
    df_notna[val_column]=df_notna[val_column].astype("float")
    if geometry_column:
        crs=df_notna.crs
        print(f"CRS={crs}")
    
    if group_column:
        df_group=df_notna.groupby(group_column)    
        nodeID_geometry_mapping={}
        g_v_resample_lst=[]
        for g_n,g_v in tqdm(df_group):
            g_v.set_index('ts',inplace=True)       
            if geometry_column:
                nodeID_geometry_mapping[g_n]=g_v.iloc[[0]].geometry.values[0].wkt
            g_v_resample_r_dict={}
            for r in rules:               
                g_v_resample=g_v[val_column].resample(r)
                g_v_resample_methods_dict={}
                for m in methods:
                    if m=="mean":
                        g_v_resample_mean=g_v_resample.mean()
                        g_v_resample_methods_dict["mean"]=g_v_resample_mean
                    elif m=="min":
                        g_v_resample_min=g_v_resample.min()
                        g_v_resample_methods_dict["min"]=g_v_resample_min=g_v_resample_min
                    elif m=="max":
                        g_v_resample_max=g_v_resample.max()
                        g_v_resample_methods_dict["max"]=g_v_resample_min=g_v_resample_max
                    elif m=="sum":
                        g_v_resample_max=g_v_resample.sum()
                        g_v_resample_methods_dict["sum"]=g_v_resample_min=g_v_resample_max                        
                    else:
                        pass
                g_v_resample_r_dict[r]=pd.concat(g_v_resample_methods_dict,axis=1)  
                
            g_v_resample_r_df=pd.concat(g_v_resample_r_dict,axis=1)     
            g_v_resample_r_df.columns=g_v_resample_r_df.columns.map("_".join).str.strip("_")
            g_v_resample_r_df[group_column]=g_n
            g_v_resample_lst.append(g_v_resample_r_df)
            
        g_v_resample_df=pd.concat(g_v_resample_lst)
        if geometry_column:
            g_v_resample_df[geometry_column]=g_v_resample_df[group_column].map(nodeID_geometry_mapping)
            g_v_resample_df[geometry_column]=g_v_resample_df[geometry_column].apply(wkt.loads)
            g_v_resample_df=gpd.GeoDataFrame(g_v_resample_df,geometry=geometry_column,crs=crs)  
            g_v_resample_df.reset_index(inplace=True)
        return g_v_resample_df
    
    else:
        df_notna.set_index('ts',inplace=True) 
        df_notna_resample_r_dict={}
        for r in rules:                  
            df_notna_resample=df_notna[val_column].resample(r)
            df_notna_resample_methods_dict={}
            for m in methods:
                if m=="mean":
                    df_notna_resample_mean=df_notna_resample.mean()
                    df_notna_resample_methods_dict["mean"]=df_notna_resample_mean
                elif m=="min":
                    df_notna_resample_min=df_notna_resample.min()
                    df_notna_resample_methods_dict["min"]=df_notna_resample_min
                elif m=="max":
                    df_notna_resample_max=df_notna_resample.max()
                    df_notna_resample_methods_dict["max"]=df_notna_resample_max
                elif m=="sum":
                    df_notna_resample_max=df_notna_resample.sum()
                    df_notna_resample_methods_dict["sum"]=df_notna_resample_max                
                else:
                        pass        
            df_notna_resample_r_dict[r]=pd.concat(df_notna_resample_methods_dict,axis=1)    
        df_notna_resample_r_df=pd.concat(df_notna_resample_r_dict,axis=1)   
        df_notna_resample_r_df.reset_index(inplace=True)
        return df_notna_resample_r_df
```

因为报告的犯罪记录为事件发生相关信息，每一条为一个事件，为按组按时间长度重采样计算各组给定时间长度下的事件数量，定义`num`列，并为各个样本赋值为1，表示每个样本为一件犯罪记录，用于`df_group_resample()`函数的`val_column`参数。首先配置`rules`参数值为`["M"]`，按组按月计算犯罪发生数量。


```python
crimes_gdf['num']=1
crimes_M_gdf=df_group_resample(crimes_gdf.copy(deep=True),"num","ts",["M"],["sum"],group_column="area_numbe",geometry_column="geometry")    
crimes_M_gdf
```

    CRS=GEOGCS["WGS84(DD)",DATUM["WGS84",SPHEROID["WGS84",6378137,298.257223563]],PRIMEM["Greenwich",0],UNIT["degree",0.0174532925199433],AXIS["Longitude",EAST],AXIS["Latitude",NORTH]]
    

    100%|██████████| 77/77 [00:10<00:00,  7.20it/s]
    




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>ts</th>
      <th>M_sum</th>
      <th>area_numbe</th>
      <th>geometry</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2001-01-31</td>
      <td>11.0</td>
      <td>1</td>
      <td>POLYGON ((-87.65456 41.99817, -87.65574 41.998...</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2001-02-28</td>
      <td>3.0</td>
      <td>1</td>
      <td>POLYGON ((-87.65456 41.99817, -87.65574 41.998...</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2001-03-31</td>
      <td>4.0</td>
      <td>1</td>
      <td>POLYGON ((-87.65456 41.99817, -87.65574 41.998...</td>
    </tr>
    <tr>
      <th>3</th>
      <td>2001-04-30</td>
      <td>5.0</td>
      <td>1</td>
      <td>POLYGON ((-87.65456 41.99817, -87.65574 41.998...</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2001-05-31</td>
      <td>3.0</td>
      <td>1</td>
      <td>POLYGON ((-87.65456 41.99817, -87.65574 41.998...</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>20231</th>
      <td>2022-07-31</td>
      <td>216.0</td>
      <td>77</td>
      <td>POLYGON ((-87.65456 41.99817, -87.65456 41.998...</td>
    </tr>
    <tr>
      <th>20232</th>
      <td>2022-08-31</td>
      <td>268.0</td>
      <td>77</td>
      <td>POLYGON ((-87.65456 41.99817, -87.65456 41.998...</td>
    </tr>
    <tr>
      <th>20233</th>
      <td>2022-09-30</td>
      <td>261.0</td>
      <td>77</td>
      <td>POLYGON ((-87.65456 41.99817, -87.65456 41.998...</td>
    </tr>
    <tr>
      <th>20234</th>
      <td>2022-10-31</td>
      <td>283.0</td>
      <td>77</td>
      <td>POLYGON ((-87.65456 41.99817, -87.65456 41.998...</td>
    </tr>
    <tr>
      <th>20235</th>
      <td>2022-11-30</td>
      <td>173.0</td>
      <td>77</td>
      <td>POLYGON ((-87.65456 41.99817, -87.65456 41.998...</td>
    </tr>
  </tbody>
</table>
<p>20236 rows × 4 columns</p>
</div>



数据量较大，重采样计算花费一定的时间，为避免重复计算，将计算结果存储为`GPKG`格式数据，并配置层为`M`，方便后续计算数据同样按层存储到该文件下。读取时按层读取，方便数据规整，避免冗余数据文件。


```python
crimes_M_gdf.to_file(args.data.crimes_resample,driver='GPKG',layer='M')
```


```python
crimes_Y_gdf=df_group_resample(crimes_gdf.copy(deep=True),"num","ts",["Y"],["sum"],group_column="area_numbe",geometry_column="geometry")   
crimes_Y_gdf.to_file(args.data.crimes_resample,driver='GPKG',layer='Y')
```

    CRS=GEOGCS["WGS84(DD)",DATUM["WGS84",SPHEROID["WGS84",6378137,298.257223563]],PRIMEM["Greenwich",0],UNIT["degree",0.0174532925199433],AXIS["Longitude",EAST],AXIS["Latitude",NORTH]]
    

    100%|██████████| 77/77 [00:10<00:00,  7.52it/s]
    

### 2.7.4.2 空间马尔可夫链（Spatially Markov chain）<sup>[2]</sup>

#### 1）经典离散（时间）马尔可夫链<sup></sup>

马尔可夫链（Markov chain）又称离散时间马尔科夫链（Discrete-time Markov chain，D(T)MC），因俄国数学家安德烈·安德烈耶维奇·马尔可夫（俄语：Андре́й Андре́евич Ма́рков，英语：Andrey Andreyevich Markov）得名，为状态空间（ state space ）中经过从一个状态到另一个状态转换的随机过程。该过程要求具备“无记忆”的性质，为下一状态的概率分布只能由当前状态决定，在时间序列中它前面的事件均与之无关，该种特定类型的“无记忆性”称作马尔可夫性质（ Markov property）。在马尔可夫链的每一步，系统根据概率分布可以从一个状态变成另一个状态，也可以保持当前状态，状态的改变叫做转移（ transitions），与不同的状态改变相关的概率叫做转移概率（ transition probabilities）。

[PySAL-giddy](https://pysal.org/notebooks/explore/giddy/intro.html)<sup>⑯</sup>在阐释经典离散马尔可夫链时，给出了如下的示例，定义数据`c`为一个状态分布矩阵，包含有3个状态，分别为a，b和c（可理解为土地利用类型，例如林地、草地和建设用地；或股市，例如牛市、熊市和横盘；或人活动，例如吃、玩和睡，及天气情况、收入阶层等）；有5个样本（行）和3个时刻的状态分布（列），例如第一行样本初始状态为b，第2时刻状态为a，第3时刻状态为c，且后一状态仅与邻接的前一状态有关，以此类推。通过`PySAL`库提供的`giddy.markov.Markov`方法，给定状态分布矩阵，计算马尔可夫链的状态转移矩阵（transitions）、状态转移概率矩阵（ transition probabilities）和平稳状态分布（steady_state distribution）等。马尔科夫链平稳状态为转移矩阵在转移概率矩阵作用下达到的平稳状态，以下述案例为例，如果在某一时刻，转移概率如何达到$\begin{bmatrix}0.30769231 &0.28846154 &0.40384615  \end{bmatrix} $时，之后的任何分布都是同一分布。


```python
import numpy as np
c=np.array([['b','a','c'],['c','c','a'],['c','b','c'],['a','a','b'],['a','b','c']])
c
```




    array([['b', 'a', 'c'],
           ['c', 'c', 'a'],
           ['c', 'b', 'c'],
           ['a', 'a', 'b'],
           ['a', 'b', 'c']], dtype='<U1')



通过样本的状态分布数据，计算的转移矩阵为$\begin{bmatrix}1 & 2&1 \\1 & 0&2\\1&1&1 \end{bmatrix} $，横纵坐标分别对应状态a、b和c，从中可以得知状态a到a的次数为1次，状态a到b的次数为2次，状态a到c的次数为1次，以状态a为开始状态的情景有4次；状态b到a、b、c的次数分别为1、0和2，以状态b为开始状态的情景有3次，依次类推，统计了状态分布数据中所有状态转移的数量。

而转移概率矩阵，计算结果为$\begin{bmatrix}0.25 &0.5& 0.25  \\0.33333333 & 0&0.66666667\\0.33333333&0.33333333&0.33333333 \end{bmatrix} $，所用公式为$ \widehat{p} _{i,j}= \frac{ n_{i,j} }{ \sum_{q=1}^k  n_{i,q}  }  $，式中$\widehat{p} _{i,j}$为每一转移状态的最大似然估计，$n_{i,j}$是每一转移状态（从$i$到$j$）的数量，$k$是状态的总数。例如$i$为a，$j$为b，则是计算$a \rightarrow b$转移状态的概率，其中以a为初始状态转移到b状态的各个样本总次数为2次，即$n_{a,b}=2$；而由a状态转移到a自身状态的次数为1，到b的为2，到c的为1，则$\sum_{q=1}^k  n_{i,q}= n_{a,a}+ n_{a,b}+ n_{a,c}=1+2+1=4 $，因此$\widehat{p} _{a,b}=2/4=0.5$，表明从状态a转移到状态b的概率为0.5，高于保持自身状态和转移至状态c的概率0.25。当样本处于a状态时，则下一状态更可能转移为状态b。
 
基于转移概率矩阵获得平稳状态分布，对应状态a、b和c概率为$\begin{bmatrix}0.30769231 &0.28846154 &0.40384615  \end{bmatrix} $。

用`giddy.ergodic.fmpt`方法可以估计从一个状态（类别）到另一个状态的平均通过时间（步骤数），例如从状态a到b越需要2.200步，而到c需要2.573步，返回到自身a则需要3.25步。


```python
import giddy
m=giddy.markov.Markov(c)

def markov_info_print(m,decimal=None):
    '''
    打印PySAL-giddy库giddy.markov.Markov方法计算离散时间马尔科夫链结果，包括分类名、转移矩阵、转移概率矩阵和平稳状态转移概率

    Parameters
    ----------
    m : giddy.markov.Markov
        giddy.markov.Markov方法计算离散时间马尔科夫链结果.
    decimal : int, optional
        转移概率矩阵和平稳状态概率小数位数. The default is None.

    Returns
    -------
    None.

    '''    
    import numpy as np
    import giddy
    import pandas as pd
    np.set_printoptions(suppress=True)
    
    print('-'*50)
    m_classes=m.classes    
    print(f"Unique classes: {m_classes}")
    df_from_nested_lst=lambda lst,cols,idxes:pd.DataFrame(lst,columns=cols,index=idxes)    
    print(f"Transition matrix:\n {df_from_nested_lst(m.transitions,m_classes,m_classes)}")
    if decimal:
        print(f"Transition probability matrix:\n {df_from_nested_lst(m.p.round(decimal),m_classes,m_classes)}")
        print(f"ergodic matrix:\n {df_from_nested_lst(giddy.ergodic.fmpt(m.p).round(decimal),m_classes,m_classes)}")
        print(f"Steady_state: {m.steady_state.round(decimal)}")
        
    else:
        print(f"Transition probability matrix:\n {df_from_nested_lst(m.p,m_classes,m_classes)}")
        print(f"ergodic matrix:\n {df_from_nested_lst(giddy.ergodic.fmpt(m.p),m_classes,m_classes)}")
        print(f"Steady_state: {m.steady_state}")        
    
markov_info_print(m,decimal=3)
```

    The Markov Chain is irreducible and is composed by:
    1 Recurrent class (indices):
    [0 1 2]
    0 Transient classes.
    The Markov Chain has 0 absorbing states.
    --------------------------------------------------
    Unique classes: ['a' 'b' 'c']
    Transition matrix:
          a    b    c
    a  1.0  2.0  1.0
    b  1.0  0.0  2.0
    c  1.0  1.0  1.0
    Transition probability matrix:
            a      b      c
    a  0.250  0.500  0.250
    b  0.333  0.000  0.667
    c  0.333  0.333  0.333
    ergodic matrix:
           a      b      c
    a  3.25  2.200  2.571
    b  3.00  3.467  1.857
    c  3.00  2.600  2.476
    Steady_state: [0.308 0.288 0.404]
    


```python
sum(m.steady_state)
```




    1.0



直接打印转移概率矩阵并不方便观察数据变化关系，因此定义`colorplot_2d_array_with_labels()`函数，标注轴向标签，并根据值大小显示颜色变化。从图表可以观察到$a   \rightarrow    b$和$b   \rightarrow    c$转移概率值较高，而$b   \rightarrow    b$自身则为0。


```python
def colorplot_2d_array_with_labels(array,labels,**args):
    '''
    图表打印二维数组方阵，并标识轴向标签（分类名）

    Parameters
    ----------
    array : array（2d）
        二维数组.
    labels : list
        标签.
    **args : TYPE
        配置图表打印样式参数，默认为：
        setting=dict(figsize=(15,15),
             cmap='YlGn',
             xlabel_rotation=0).

    Returns
    -------
    None.

    '''    
    import matplotlib.pyplot as plt
    import matplotlib.cm as cm
    import matplotlib.ticker as ticker
    
    setting=dict(figsize=(15,15),
                 cmap='YlGn',
                 xlabel_rotation=0)
    setting.update(args)
    
    nx, ny=array.shape
    indx, indy=np.arange(nx), np.arange(ny)
    x, y=np.meshgrid(indx, indy)    
    
    fig, ax=plt.subplots(figsize=setting['figsize'])
    ax.imshow(array, interpolation="nearest", cmap=setting['cmap']) 
    
    for xval, yval in zip(x.flatten(), y.flatten()):
        zval=array[yval, xval]
        t="%.3f"%(zval) 
        ax.text(xval, yval, t,va='center', ha='center')    
        
    ax.set_xticks(indx+0.5) # offset x/y ticks so gridlines run on border of boxes
    ax.set_yticks(indy+0.5)
    ax.grid(ls='-', lw=2)
    
    for a, ind, labels in zip((ax.xaxis, ax.yaxis), (indx, indy), (labels, labels)):
        a.set_major_formatter(ticker.NullFormatter())
        a.set_minor_locator(ticker.FixedLocator(ind))
        a.set_minor_formatter(ticker.FixedFormatter(labels))
       
    ax.xaxis.tick_top()
    ax.tick_params(axis="x", which="both", rotation=setting['xlabel_rotation'])
    plt.show()    

colorplot_2d_array_with_labels(m.p.round(3),m.classes,figsize=(3,3))    
```


<img src="./imgs/2_7_4/output_96_0.png" height='auto' width='auto' title="caDesign">    



**MCD12Q1_v006-LCCS1土地覆盖类型变化的离散时间马尔科夫链计算**

用前文提取的MCD12Q1_v006土地覆盖类型数据集中的粮农组织-土地覆盖分类系统1（LCCS1）土地覆盖层2001至2020历年变化采样点（去除空值，有效采样点为3233条）数据，计算离散时间马尔科夫链，获取转移概率矩阵。


```python
import pickle

with open(args.data.MCD12Q1v006_years_vals_array,'rb') as f:
    MCD12Q1v006_years_vals=pickle.load(f)
MCD12Q1v006_years_vals.shape    
```




    (3586, 20)



移除空值。


```python
MCD12Q1v006_years_vals_notna=MCD12Q1v006_years_vals[~np.isnan(MCD12Q1v006_years_vals).any(axis=1), :]
print(MCD12Q1v006_years_vals_notna.shape)
MCD12Q1v006_years_vals_notna
```

    (3233, 20)
    




    array([[31., 31., 31., ..., 31., 31., 31.],
           [ 1.,  1.,  1., ...,  1.,  1.,  1.],
           [ 1.,  1.,  1., ...,  1.,  1.,  1.],
           ...,
           [31., 31., 31., ..., 31., 31., 31.],
           [ 1.,  1.,  1., ...,  1.,  1.,  1.],
           [22., 22., 22., ..., 22., 22., 22.]], dtype=float32)



计算计算离散时间马尔科夫链，并打印结果。


```python
import giddy
MCD12Q1v006_years_vals_markov=giddy.markov.Markov(MCD12Q1v006_years_vals_notna)
markov_info_print(MCD12Q1v006_years_vals_markov,decimal=3)
```

    The Markov Chain is irreducible and is composed by:
    1 Recurrent class (indices):
    [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]
    0 Transient classes.
    The Markov Chain has 0 absorbing states.
    --------------------------------------------------
    Unique classes: [ 1.  2.  3. 11. 12. 13. 14. 15. 16. 21. 22. 31. 32. 41. 43.]
    Transition matrix:
              1.0    2.0    3.0    11.0   12.0   13.0    14.0    15.0  16.0  \
    1.0   16521.0   24.0   20.0    0.0    0.0    0.0     0.0     0.0   0.0   
    2.0      22.0  124.0    0.0    0.0    0.0    0.0     0.0     0.0   0.0   
    3.0      15.0    1.0  522.0    0.0    0.0    0.0     0.0     0.0   0.0   
    11.0      0.0    0.0    0.0  189.0    0.0    0.0     1.0    33.0   7.0   
    12.0      0.0    0.0    0.0    0.0  266.0    0.0     1.0    24.0   4.0   
    13.0      0.0    0.0    0.0    0.0    0.0  103.0     5.0     0.0   0.0   
    14.0      0.0    0.0    0.0    0.0    2.0    4.0  1971.0    52.0   4.0   
    15.0      0.0    0.0    0.0   38.0   22.0    2.0    61.0  1127.0   7.0   
    16.0      0.0    0.0    0.0    6.0    2.0    0.0     4.0    11.0  78.0   
    21.0      1.0    0.0    0.0   56.0   50.0   11.0   164.0   157.0  38.0   
    22.0      6.0    0.0    2.0    1.0    9.0    0.0    36.0     5.0   0.0   
    31.0     35.0    0.0    9.0    2.0    0.0    2.0    34.0     1.0   0.0   
    32.0    219.0    1.0    4.0    0.0    0.0    0.0     2.0     0.0   0.0   
    41.0      0.0    0.0    0.0    0.0    0.0    0.0     0.0     0.0   0.0   
    43.0      0.0    0.0    0.0    0.0    0.0    0.0     0.0     0.0   0.0   
    
            21.0    22.0     31.0    32.0  41.0  43.0  
    1.0      1.0     7.0     33.0   262.0   0.0   1.0  
    2.0      0.0     0.0      0.0     0.0   0.0   0.0  
    3.0      0.0     2.0      9.0     4.0   0.0   0.0  
    11.0    54.0     2.0      1.0     0.0   0.0   0.0  
    12.0    46.0     8.0      0.0     0.0   0.0   0.0  
    13.0    13.0     0.0      2.0     0.0   0.0   0.0  
    14.0   162.0    36.0     29.0     2.0   0.0   0.0  
    15.0   132.0     3.0      1.0     0.0   0.0   0.0  
    16.0    34.0     0.0      0.0     0.0   0.0   0.0  
    21.0  4952.0   272.0     96.0     0.0   0.0   0.0  
    22.0   289.0  4385.0    249.0    23.0   4.0   0.0  
    31.0   106.0   275.0  22020.0   342.0   1.0   0.0  
    32.0     0.0    24.0    376.0  5017.0   0.0   4.0  
    41.0     0.0     5.0      0.0     0.0   0.0   0.0  
    43.0     0.0     0.0      0.0     3.0   0.0  22.0  
    Transition probability matrix:
            1.0    2.0    3.0    11.0   12.0   13.0   14.0   15.0   16.0   21.0  \
    1.0   0.979  0.001  0.001  0.000  0.000  0.000  0.000  0.000  0.000  0.000   
    2.0   0.151  0.849  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   
    3.0   0.027  0.002  0.944  0.000  0.000  0.000  0.000  0.000  0.000  0.000   
    11.0  0.000  0.000  0.000  0.659  0.000  0.000  0.003  0.115  0.024  0.188   
    12.0  0.000  0.000  0.000  0.000  0.762  0.000  0.003  0.069  0.011  0.132   
    13.0  0.000  0.000  0.000  0.000  0.000  0.837  0.041  0.000  0.000  0.106   
    14.0  0.000  0.000  0.000  0.000  0.001  0.002  0.871  0.023  0.002  0.072   
    15.0  0.000  0.000  0.000  0.027  0.016  0.001  0.044  0.809  0.005  0.095   
    16.0  0.000  0.000  0.000  0.044  0.015  0.000  0.030  0.081  0.578  0.252   
    21.0  0.000  0.000  0.000  0.010  0.009  0.002  0.028  0.027  0.007  0.854   
    22.0  0.001  0.000  0.000  0.000  0.002  0.000  0.007  0.001  0.000  0.058   
    31.0  0.002  0.000  0.000  0.000  0.000  0.000  0.001  0.000  0.000  0.005   
    32.0  0.039  0.000  0.001  0.000  0.000  0.000  0.000  0.000  0.000  0.000   
    41.0  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   
    43.0  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   
    
           22.0   31.0   32.0   41.0   43.0  
    1.0   0.000  0.002  0.016  0.000  0.000  
    2.0   0.000  0.000  0.000  0.000  0.000  
    3.0   0.004  0.016  0.007  0.000  0.000  
    11.0  0.007  0.003  0.000  0.000  0.000  
    12.0  0.023  0.000  0.000  0.000  0.000  
    13.0  0.000  0.016  0.000  0.000  0.000  
    14.0  0.016  0.013  0.001  0.000  0.000  
    15.0  0.002  0.001  0.000  0.000  0.000  
    16.0  0.000  0.000  0.000  0.000  0.000  
    21.0  0.047  0.017  0.000  0.000  0.000  
    22.0  0.875  0.050  0.005  0.001  0.000  
    31.0  0.012  0.965  0.015  0.000  0.000  
    32.0  0.004  0.067  0.888  0.000  0.001  
    41.0  1.000  0.000  0.000  0.000  0.000  
    43.0  0.000  0.000  0.120  0.000  0.880  
    ergodic matrix:
              1.0       2.0       3.0      11.0     12.0      13.0     14.0  \
    1.0     4.347  2772.881  1857.875  743.033  834.375  2971.143  349.698   
    2.0     6.636   418.831  1864.511  749.669  841.011  2977.780  356.334   
    3.0   126.676  2802.282   107.608  720.948  812.100  2949.352  327.911   
    11.0  285.172  3042.128  1996.280  170.795  606.619  2765.936  144.770   
    12.0  285.304  3042.255  1996.243  510.216  146.017  2771.662  150.402   
    13.0  283.222  3040.183  1994.684  545.729  641.192   452.275  131.899   
    14.0  282.941  3039.899  1994.391  540.264  635.269  2754.104   22.278   
    15.0  287.085  3044.042  1998.240  455.117  574.645  2749.518  121.976   
    16.0  284.856  3041.813  1995.978  456.728  589.801  2764.786  137.414   
    21.0  280.307  3037.265  1991.393  520.904  617.110  2766.404  152.543   
    22.0  265.592  3022.481  1974.876  593.415  679.738  2830.340  205.037   
    31.0  241.369  2998.365  1955.309  659.257  751.027  2886.517  265.960   
    32.0  165.956  2923.570  1918.533  695.273  786.691  2923.167  301.683   
    41.0  266.592  3023.481  1975.876  594.415  680.738  2831.340  206.037   
    43.0  174.290  2931.904  1926.866  703.607  795.024  2931.500  310.017   
    
             15.0      16.0     21.0     22.0     31.0     32.0       41.0  \
    1.0   411.436  1100.023  230.701  189.598   94.184   72.049  11448.297   
    2.0   418.072  1106.660  237.337  196.234  100.820   78.685  11454.934   
    3.0   389.343  1077.913  208.565  165.861   74.896   93.408  11425.395   
    11.0  129.758   810.096   13.715   59.485   55.451  148.638  11335.326   
    12.0  145.028   837.128   18.428   55.617   55.933  148.825  11332.274   
    13.0  210.497   899.217   30.274   67.785   52.378  146.427  11341.493   
    14.0  187.880   890.824   37.664   62.815   53.216  146.065  11337.612   
    15.0   35.068   849.966   19.319   61.974   57.409  150.502  11337.715   
    16.0  148.640   365.417   10.830   59.115   55.195  148.326  11334.978   
    21.0  191.687   874.957    9.213   53.925   50.652  143.833  11329.909   
    22.0  261.041   949.321   79.480   11.092   38.948  129.468  11283.904   
    31.0  327.809  1016.391  147.076  108.798    2.635  102.697  11364.987   
    32.0  363.669  1052.287  183.001  142.325   44.326   11.320  11400.540   
    41.0  262.041   950.321   80.480    1.000   39.948  130.468  11284.904   
    43.0  372.003  1060.621  191.335  150.659   52.660    8.333  11408.873   
    
               43.0  
    1.0   13142.420  
    2.0   13149.056  
    3.0   13182.625  
    11.0  13256.336  
    12.0  13256.513  
    13.0  13254.172  
    14.0  13253.824  
    15.0  13258.209  
    16.0  13256.023  
    21.0  13251.520  
    22.0  13237.093  
    31.0  13210.778  
    32.0  13112.963  
    41.0  13238.093  
    43.0   1574.556  
    Steady_state: [0.23  0.002 0.009 0.006 0.007 0.002 0.045 0.029 0.003 0.109 0.09  0.379
     0.088 0.    0.001]
    

对于分类数量较多的二维转移概率矩阵，打印图表更易于观察不同分类间的转移程度。从下述图表可以观察到，这20年间，除了'Dense Shrublands'全部转移为'Sparse Forests'外，各类别通常保持不变，但是有多数不同类的`Forests`会小部分的转移为'Open Forests'类型，及更少更小转移概率的到'Mixed Broadleaf_Needleleaf Forests'类型；同时可以注意到，'Permanent Snow and Ice'有0.151的概率转换为'Barren'。


```python
LCCS1_mapping={1:'Barren',
               2:'Permanent Snow and Ice',
               3:'Water Bodies',
               11:'Evergreen Needleleaf Forests',
               12:'Evergreen Broadleaf Forests',
               13:'Deciduous Needleleaf Forests',
               14:'Deciduous Broadleaf Forests',
               15:'Mixed Broadleaf_Needleleaf Forests',
               16:'Mixed Broadleaf Evergreen_Deciduous Forests',
               21:'Open Forests',
               22:'Sparse Forests',
               31:'Dense Herbaceous',
               32:'Sparse Herbaceous',
               41:'Dense Shrublands',
               42:'Shrubland_Grassland Mosaics',
               43:'Sparse Shrublands',
               255:'Unclassiﬁed'
              }

LCCS1_labels=[LCCS1_mapping[i] for i in MCD12Q1v006_years_vals_markov.classes]
colorplot_2d_array_with_labels(MCD12Q1v006_years_vals_markov.p.round(3),LCCS1_labels,figsize=(10,10),xlabel_rotation=90,cmap='GnBu')   
```

<img src="./imgs/2_7_4/output_104_0.png" height='auto' width='auto' title="caDesign">

    


打印土地覆盖类型转化时长（单位年，1步为1年），所有类型要转化为'Dense Shrublands'或'Sparse Shrublands'类型均需要万年时间；但也存在十几年甚至几年就能发生转化的类型，例如$Permanent Snow and Ice \rightarrow Barren$为6.636年，$Sparse Shrublands \rightarrow Sparse Herbaceous$为8.333年等。


```python
MCD12Q1v006_years_vals_ergodic=giddy.ergodic.fmpt(MCD12Q1v006_years_vals_markov.p).round(3)
colorplot_2d_array_with_labels(MCD12Q1v006_years_vals_ergodic,LCCS1_labels,figsize=(15,15),xlabel_rotation=90,cmap='GnBu') 
```

<img src="./imgs/2_7_4/output_106_0.png" height='auto' width='auto' title="caDesign">
    


计算各类转化的平均时间，可以得知各土地覆盖类型转化为'Dense Herbaceous'的平均时长为55.2434年，其次为'Sparse Forests'等。


```python
MCD12Q1v006_years_vals_ergodic_mean=list(zip(MCD12Q1v006_years_vals_ergodic.mean(axis=0),LCCS1_labels))
MCD12Q1v006_years_vals_ergodic_mean.sort(key=lambda x:x[0])
MCD12Q1v006_years_vals_ergodic_mean
```




    [(55.2434, 'Dense Herbaceous'),
     (92.41886666666666, 'Sparse Forests'),
     (99.82786666666668, 'Open Forests'),
     (110.60293333333335, 'Sparse Herbaceous'),
     (212.26393333333328, 'Deciduous Broadleaf Forests'),
     (216.02300000000005, 'Barren'),
     (256.9314666666667, 'Mixed Broadleaf_Needleleaf Forests'),
     (577.2913333333332, 'Evergreen Needleleaf Forests'),
     (666.0904666666665, 'Evergreen Broadleaf Forests'),
     (922.7428, 'Mixed Broadleaf Evergreen_Deciduous Forests'),
     (1836.5775333333333, 'Water Bodies'),
     (2688.3882666666664, 'Deciduous Needleleaf Forests'),
     (2812.092, 'Permanent Snow and Ice'),
     (11361.4094, 'Dense Shrublands'),
     (12442.278733333334, 'Sparse Shrublands')]



#### 2）时空数据绝对和相对动态变化图表打印

通过图表打印各社区历年数值，有绝对和相对动态两种变化曲线方便观察数据变化，定义函数为`absoluteORrelative_dynamics_ts_plot()`。绝对曲线并不对数值做出任何改变，可以从图表中观察到各社区犯罪报告数量的绝对变化趋势；相对曲线则是各社区时间轴向上数值除以该社区所有数值的均值，方便观察时间轴向上各社区数值变化的相对趋势，是各社区数值趋于聚拢还是趋于扩散，如果都向均值聚拢，可以说明历年犯罪报告事件浮动较小；如何趋于扩散，则表明历年犯罪报告事件浮动较大。

下述代码打印了月和年采样的时间轴向数值绝对变化曲线。从月变化曲线可以得知每年各月份犯罪报告数以每年年中6、7、8月份居高，依次向两侧递减，至1、2月份降到最低；从年绝对变化曲线可以观察到各社区的犯罪报告数均趋于下降趋势，在2019年有一个明显的下滑，这与2019年末开始爆发的疫情可能有关。


```python
import geopandas as gpd
crimes_M_gdf=gpd.read_file(args.data.crimes_resample,layer='M')
```


```python
def absoluteORrelative_dynamics_ts_plot(df_,datetime_column,val_column,group_column,strftime_pattern='%Y-%m',freq='M',fill_val=-1,absoluteORrelative='absolute',**setting):
    '''
    时间轴向面板数据的绝对变化和相对变化曲线。绝对变化保持数值不变，相对变化为时间轴向上各行数值除以对应行所有数值的均值

    Parameters
    ----------
    df_ : DataFrame
        时间轴向面板数据.
    datetime_column : string
        时间列名.
    val_column : string
        值列名.
    group_column : string
        分组列名.
    strftime_pattern : string, optional
        时间格式化字符. The default is '%Y-%m'.
    freq : string, optional
        时间序列频率的别名. The default is 'M'.
    fill_val : numerical, optional
        数值，浮点型或整型. The default is -1.
    absoluteORrelative : string, optional
        绝对变化或相对变化曲线，为absolute和relative. The default is 'absolute'.
    **setting : TYPE
        图表打印样式，默认为：
        setting_dict=dict(figsize=(15,10),
                          rotation=90,
                          text_fontsize=9,
                         ).

    Returns
    -------
    val_array : array
        面板数组，如果为相对变化则为各行数值除以该行均值.
    ts_unique : Index
        时间轴向时间索引.
    group_unique : Index
        分组值.

    '''    
    import pandas as pd
    import numpy as np
    import matplotlib.pyplot as plt
    from pylab import rcParams
    
    setting_dict=dict(figsize=(15,10),
                      rotation=90,
                      text_fontsize=9,
                     )
    setting_dict.update(setting)
    
    df=df_.copy(deep=True)
    df['ts_sft']=df[datetime_column].apply(lambda x:x.strftime(strftime_pattern))
    df_hierarchicalIdx=df.set_index([group_column,'ts_sft']).sort_index()
    dt_complement=pd.date_range(df['ts_sft'].min(),df['ts_sft'].max(),freq=freq,inclusive="both").strftime(strftime_pattern)
    group_unique=df_hierarchicalIdx.index.get_level_values(group_column).unique() 
    idx_all=[(g,t) for g in group_unique for t in dt_complement]
    idx_missing=set(idx_all)-set(df_hierarchicalIdx.index)
    for idx in idx_missing:
        df_hierarchicalIdx.loc[idx,:]=None
    df_hierarchicalIdx.sort_index(inplace=True)
    df_hierarchicalIdx[val_column].fillna(value=fill_val,inplace=True)
    ts_unique=df_hierarchicalIdx.index.get_level_values('ts_sft').unique() 
    val_array_lst=df_hierarchicalIdx[val_column].groupby(level=group_column).apply(pd.Series.to_numpy).to_numpy()
    val_array=np.stack(val_array_lst).T
    
    if absoluteORrelative=='absolute':
        order_ts_0=np.argsort(val_array[0])    
        order_ts_tailender=np.argsort(val_array[-1])
        val_0=group_unique[order_ts_0[::-1]]
        val_tailender=group_unique[order_ts_tailender[::-1]]
        first_last=np.vstack((val_0,val_tailender))
    elif absoluteORrelative=='relative':
        val_array=(val_array.T / val_array.mean(axis=1)).T
        order_ts_0=np.argsort(val_array[0])    
        order_ts_tailender=np.argsort(val_array[-1])
        val_0=group_unique[order_ts_0[::-1]]
        val_tailender=group_unique[order_ts_tailender[::-1]]
        first_last=np.vstack((val_0,val_tailender))     
    
    plt.figure()
    rcParams['figure.figsize']=setting_dict['figsize']
    plt.plot(ts_unique,val_array)
    
    x_min=min(ts_unique)
    x_max=max(ts_unique)
    y_min=np.min(val_array)
    y_max=np.max(val_array)
    y_unit=(y_max-y_min)/len(group_unique)

    for i in range(len(group_unique)):
        plt.text(x_min,y_max-(i*y_unit), first_last[0][i],fontsize=setting_dict['text_fontsize'])
        plt.text(x_max,y_max-(i*y_unit), first_last[1][i],fontsize=setting_dict['text_fontsize'])
    
    plt.xlim((x_min, x_max))
    plt.ylim((y_min, y_max))
    plt.xticks(rotation=setting_dict['rotation'])
    plt.show()
        
    return val_array,ts_unique,group_unique
        
val_array_M,_,_=absoluteORrelative_dynamics_ts_plot(crimes_M_gdf,'ts','M_sum','area_numbe',absoluteORrelative='absolute',figsize=(15*2,10*2));    
```


<img src="./imgs/2_7_4/output_111_0.png" height='auto' width='auto' title="caDesign">    



```python
crimes_Y_gdf=gpd.read_file(args.data.crimes_resample,layer='Y')
crimes_Y_gdf
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>ts</th>
      <th>Y_sum</th>
      <th>area_numbe</th>
      <th>geometry</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2001-12-31</td>
      <td>58.0</td>
      <td>1</td>
      <td>POLYGON ((-87.65456 41.99817, -87.65574 41.998...</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2002-12-31</td>
      <td>6106.0</td>
      <td>1</td>
      <td>POLYGON ((-87.65456 41.99817, -87.65574 41.998...</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2003-12-31</td>
      <td>7685.0</td>
      <td>1</td>
      <td>POLYGON ((-87.65456 41.99817, -87.65574 41.998...</td>
    </tr>
    <tr>
      <th>3</th>
      <td>2004-12-31</td>
      <td>7610.0</td>
      <td>1</td>
      <td>POLYGON ((-87.65456 41.99817, -87.65574 41.998...</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2005-12-31</td>
      <td>7531.0</td>
      <td>1</td>
      <td>POLYGON ((-87.65456 41.99817, -87.65574 41.998...</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>1689</th>
      <td>2018-12-31</td>
      <td>2793.0</td>
      <td>77</td>
      <td>POLYGON ((-87.65456 41.99817, -87.65456 41.998...</td>
    </tr>
    <tr>
      <th>1690</th>
      <td>2019-12-31</td>
      <td>2510.0</td>
      <td>77</td>
      <td>POLYGON ((-87.65456 41.99817, -87.65456 41.998...</td>
    </tr>
    <tr>
      <th>1691</th>
      <td>2020-12-31</td>
      <td>2345.0</td>
      <td>77</td>
      <td>POLYGON ((-87.65456 41.99817, -87.65456 41.998...</td>
    </tr>
    <tr>
      <th>1692</th>
      <td>2021-12-31</td>
      <td>2465.0</td>
      <td>77</td>
      <td>POLYGON ((-87.65456 41.99817, -87.65456 41.998...</td>
    </tr>
    <tr>
      <th>1693</th>
      <td>2022-12-31</td>
      <td>2534.0</td>
      <td>77</td>
      <td>POLYGON ((-87.65456 41.99817, -87.65456 41.998...</td>
    </tr>
  </tbody>
</table>
<p>1694 rows × 4 columns</p>
</div>




```python
val_array_Y,ts_unique,group_unique=absoluteORrelative_dynamics_ts_plot(crimes_Y_gdf,'ts','Y_sum','area_numbe',strftime_pattern='%Y',freq='Y',absoluteORrelative='absolute',figsize=(15*2,10*2))
```

<img src="./imgs/2_7_4/output_113_0.png" height='auto' width='auto' title="caDesign">
    


从相对变化曲线可以初步判断历年各社区的犯罪报告数的分布除个别社区基本保持不变。


```python
absoluteORrelative_dynamics_ts_plot(crimes_Y_gdf,'ts','Y_sum','area_numbe',strftime_pattern='%Y',freq='Y',absoluteORrelative='relative',figsize=(15*2,10*2))   
```

<img src="./imgs/2_7_4/output_115_0.png" height='auto' width='auto' title="caDesign">
    





    (array([[ 0.71444569,  0.51735722,  0.89921613, ...,  0.30795073,
             24.9193729 ,  0.5912654 ],
            [ 1.32756746,  0.88033421,  1.31321773, ...,  0.60181899,
              0.48702115,  0.8198914 ],
            [ 1.24336551,  0.84713882,  1.21715533, ...,  0.5785654 ,
              0.35885292,  0.77465635],
            ...,
            [ 1.19711332,  1.12663078,  1.07431384, ...,  0.61508736,
              0.44106087,  0.85196684],
            [ 1.25068399,  1.10962105,  1.18737228, ...,  0.64681614,
              0.54796101,  0.91265128],
            [ 1.32311852,  1.2659422 ,  1.25897842, ...,  0.55673602,
              0.53877679,  0.92874857]]),
     Index(['2001', '2002', '2003', '2004', '2005', '2006', '2007', '2008', '2009',
            '2010', '2011', '2012', '2013', '2014', '2015', '2016', '2017', '2018',
            '2019', '2020', '2021', '2022'],
           dtype='object', name='ts_sft'),
     Int64Index([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
                 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34,
                 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51,
                 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68,
                 69, 70, 71, 72, 73, 74, 75, 76, 77],
                dtype='int64', name='area_numbe'))



#### 3）犯罪率年统计量的经典离散型马尔可夫链计算

使用`mapclassify`库提供的`Quantiles`方法，按分位数将数值按时间点将各社区犯罪报告数划分为5个区间（分类过程），然后计算各社区5分位数时间轴向的变化情况。使用`markov_info_print()`函数打印计算结果，包括分类名、转移矩阵、转移概率矩阵和平稳状态转移概率等。使用`colorplot_2d_array_with_labels()`打印转移概率矩阵，可以观察到各类（数值的5分位数）基本保持不变，但是存在向所在分位数邻接分位数转移概率，离所在分位数越远，转换概率越低。


```python
import mapclassify as mc
q5=np.array([mc.Quantiles(y,k=5).yb for y in val_array_Y]).transpose()
print(q5.shape)
q5
```

    (77, 22)
    




    array([[3, 3, 3, ..., 3, 3, 3],
           [2, 2, 2, ..., 3, 3, 3],
           [3, 3, 3, ..., 3, 3, 3],
           ...,
           [1, 2, 2, ..., 2, 2, 1],
           [4, 1, 1, ..., 1, 1, 1],
           [2, 2, 2, ..., 2, 2, 2]])




```python
m5=giddy.markov.Markov(q5)
markov_info_print(m5,decimal=3)
colorplot_2d_array_with_labels(m5.p.round(3),m5.classes,figsize=(3,3))    
```

    The Markov Chain is irreducible and is composed by:
    1 Recurrent class (indices):
    [0 1 2 3 4]
    0 Transient classes.
    The Markov Chain has 0 absorbing states.
    --------------------------------------------------
    Unique classes: [0 1 2 3 4]
    Transition matrix:
            0      1      2      3      4
    0  317.0   21.0    0.0    0.0    0.0
    1   21.0  273.0   20.0    0.0    0.0
    2    0.0   18.0  284.0   13.0    0.0
    3    0.0    0.0   12.0  287.0   15.0
    4    0.0    1.0    0.0   14.0  321.0
    Transition probability matrix:
            0      1      2      3      4
    0  0.938  0.062  0.000  0.000  0.000
    1  0.067  0.869  0.064  0.000  0.000
    2  0.000  0.057  0.902  0.041  0.000
    3  0.000  0.000  0.038  0.914  0.048
    4  0.000  0.003  0.000  0.042  0.955
    ergodic matrix:
              0        1       2        3        4
    0    4.934   16.095  48.695  118.064  194.493
    1   63.323    5.311  32.600  101.969  178.398
    2  114.113   50.789   5.030   69.369  145.798
    3  160.206   96.883  52.508    5.046   76.429
    4  176.147  112.824  73.581   29.198    4.715
    Steady_state: [0.203 0.188 0.199 0.198 0.212]
    

<img src="./imgs/2_7_4/output_118_1.png" height='auto' width='auto' title="caDesign">
    



#### 4）莫兰指数 （Moran's Is）

经典离散型马尔可夫链并未考虑空间邻里关系，即一个空间单元的状态转移受到该单元邻里单元的影响情况并未考虑。下述定义了`gdf_plot_annotate_subplots()`函数，可以打印多个时间节点观测数值，从图表结果来看不难发现，按分位数划分的区间分类，在各年均具有明显的集聚特征，表明空间邻里单元可能会影响到目标单元的状态转移概率。


```python
def gdf_plot_annotate_subplots(gdf_,value_column,annotate_column,ts_column,ts_lst,ncols=3,**setting):  
    '''
    打印多个时间点（分组）地图

    Parameters
    ----------
    gdf_ : GeoDataFrame
        地理时空数据.
    value_column : string
        观测值列名.
    annotate_column : string 
        标注列名.
    ts_column : string
        时间(分组)列名.
    ts_lst : list(string)
        时间点列表.
    ncols : int, optional
        图表子图列数. The default is 3.
    **setting : TYPE
        图表样式参数，默认为：
            setting_dict=dict(annotate_fontsize=8,
                      figsize=(10,10),    
                      legend_position="right",
                      legend_size="5%",
                      legend_pad=0.1,
                      legend_bbox_to_anchor=(1, 1),
                      cmap='OrRd',
                      labelsize=8,
                      scheme=None,
                      k=5,
                      categorical=False,
                     ).

    Returns
    -------
    None.

    '''    
    import matplotlib.pyplot as plt
    from mpl_toolkits.axes_grid1 import make_axes_locatable
    
    gdf=gdf_.copy(deep=True)
    setting_dict=dict(annotate_fontsize=8,
                      figsize=(10,10),    
                      legend_position="right",
                      legend_size="5%",
                      legend_pad=0.1,
                      legend_bbox_to_anchor=(1, 1),
                      cmap='OrRd',
                      labelsize=8,
                      scheme=None,
                      k=5,
                      categorical=False,
                     )
    setting_dict.update(setting)
    gdf["index"]=gdf.index
    
    nrows=len(ts_lst)//ncols
    fig, axes=plt.subplots(nrows=nrows, ncols=ncols,figsize=setting_dict["figsize"])
    
    ts_gdfs=[]
    for ts in ts_lst:
        ts_gdfs.append(gdf[gdf[ts_column]==ts])
    
    for i in range(nrows):
        for j in range(ncols):
            ax=axes[i,j]        
            idx=i*ncols+j
            if idx<len(ts_lst):
                ts_gdf=ts_gdfs[idx]    
                divider=make_axes_locatable(ax) 
                if setting_dict["scheme"]:
                    ts_gdf.plot(column=value_column,scheme=setting_dict["scheme"], k=setting_dict["k"],ax=ax,legend=True,cmap=setting_dict["cmap"],legend_kwds={'bbox_to_anchor':setting_dict["legend_bbox_to_anchor"]}) 
                elif setting_dict["categorical"]:
                    ts_gdf.plot(column=value_column,categorical=True,ax=ax,legend=True,cmap=setting_dict["cmap"],edgecolor='white',legend_kwds={'bbox_to_anchor':setting_dict["legend_bbox_to_anchor"]}) 
                else:   
                    cax=divider.append_axes(setting_dict["legend_position"], size=setting_dict["legend_size"], pad=setting_dict["legend_pad"]) # 配置图例参数
                    ts_gdf.plot(column=value_column,scheme=setting_dict["scheme"], k= setting_dict["k"],ax=ax,cax=cax,legend=True,cmap=setting_dict["cmap"]) 
                ts_gdf.apply(lambda x: ax.annotate(text=x[annotate_column], xy=x.geometry.centroid.coords[0], ha='center',fontsize=setting_dict["annotate_fontsize"]),axis=1) # 增加标注
                ax.tick_params(axis='both', labelsize=setting_dict["labelsize"])
                ax.set_title(ts_lst[idx])
                
    plt.tight_layout()
    plt.show()
    
crimes_Y_gdf['ts_sft']=crimes_Y_gdf['ts'].apply(lambda x:x.strftime('%Y'))
gdf_plot_annotate_subplots(crimes_Y_gdf,"Y_sum","area_numbe",ts_column="ts_sft",ts_lst=['2001','2005','2009','2014','2018','2022'],annotate_fontsize=10,scheme="Quantiles",k=5,figsize=(30,15),legend_bbox_to_anchor=(0.4, 0.2))
```

<img src="./imgs/2_7_4/output_120_0.png" height='auto' width='auto' title="caDesign">
    

    


为进一步量化证明空间单元邻里测量值的相关性，使用全局空间自相关衡量，定义`GIs4panel_data_plot()`函数打印各年Moran's I指数，可以发现，2002年至2022年，Moran's I值为正高于0.3，表明各个社区的犯罪报告数并不是相互独立的，单元邻里背景区域可能对该单元测量值的动态形成有重要影响。


```python
def GIs4panel_data_plot(gdf,value_column,group_column,ts_column,**setting):
    '''
    打印各个时间点上各分组测量值全局空间自相关指数

    Parameters
    ----------
    gdf : GeoDataFrame
        时空地理数据.
    value_column : string
        测量值（观测值）列名.
    group_column : string
        分组列名.
    ts_column : string
        时间列名.
    **setting : TYPE
        图表打印样式，默认值为：
            setting_dict=dict(figsize=(10,5),    
                      fontsize=15,
                      rotation=90,
                     ).

    Returns
    -------
    wr : libpysal.weights.contiguity.Rook
        空间权重.

    '''    
    import libpysal.weights as LW
    from esda.moran import Moran
    import numpy as np
    import matplotlib.pyplot as plt
    
    setting_dict=dict(figsize=(10,5),    
                      fontsize=15,
                      rotation=90,
                     )    
    setting_dict.update(setting)
    
    grouped_gdf=gdf.groupby(ts_column)
    mits=[]
    names=[]
    for name,group in grouped_gdf:
        wr=LW.contiguity.Rook.from_dataframe(group)
        wr.transform='R'
        mits.append(Moran(group[value_column],wr))
        names.append(name)
    
    print(names)
    res=np.array([(mi.I, mi.EI, mi.seI_norm, mi.sim[0]) for mi in mits])
    fig, ax=plt.subplots(nrows=1,ncols=1,figsize=setting_dict['figsize'])
    ax.plot(names, res[:,0], label='Moran\'s I')

    ax.plot(names, res[:,1]+1.96*res[:,2], label='Upper bound',linestyle='dashed')
    ax.plot(names, res[:,1]-1.96*res[:,2], label='Lower bound',linestyle='dashed')
    ax.set_title("Global spatial autocorrelation",fontdict={'fontsize':setting_dict['fontsize']})
    ax.set_xlim([names[0],names[-1]])
    ax.legend()
    plt.xticks(rotation=setting_dict['rotation'])
    
    return wr

wr=GIs4panel_data_plot(crimes_Y_gdf,"Y_sum","area_numbe",'ts_sft')
```

    ['2001', '2002', '2003', '2004', '2005', '2006', '2007', '2008', '2009', '2010', '2011', '2012', '2013', '2014', '2015', '2016', '2017', '2018', '2019', '2020', '2021', '2022']
    

<img src="./imgs/2_7_4/output_122_1.png" height='auto' width='auto' title="caDesign">
    



#### 5）空间马尔科夫 （Spatial Markov）

空间马尔科夫是经典马尔科夫的延申，是对时空地理数据状态转化在空间维度上更全面的分析<sup>[3]</sup>。空间马尔科夫的转移概率是否受到邻里单元的影响已有研究且量化。空间马尔科夫不是估计一个转移概率矩阵，而是需要估计$k$个转移概率矩阵，每个矩阵都是以前一时期邻里单元背景为条件。邻里单元背景条件通常由空间滞后邻里单元测量值加权平均值确定，公式为：$z_{r,t}= \sum_{s=1}^n   w_{r,s} y_{s,t} $，式中，$w_{r,s}$为空间权重矩阵，代表$r$的邻里空间单元$s$在时间段$t$时刻对空间单元$r$的贡献权重；$y_{s,t}$为单元$s$在$t$时刻的观测值。

`PySAL-giddy`库提供了`Spatial_Markov`空间马尔科夫计算方法，该计算方法整合和了`mapclassify`库提供的分类方法，因此可以直接输入原始连续观测值，而不用事先计算分类，例如前文用到的5分位数区间划分等。打印转移概率矩阵，其结果与经典马尔科夫计算结果存在差异，为考虑邻里单元空间权重影响后的结果。


```python
crimes_M_gdf
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>ts</th>
      <th>M_sum</th>
      <th>area_numbe</th>
      <th>geometry</th>
      <th>ts_sft</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2001-01-31</td>
      <td>11.0</td>
      <td>1</td>
      <td>POLYGON ((-87.65456 41.99817, -87.65574 41.998...</td>
      <td>200101</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2001-02-28</td>
      <td>3.0</td>
      <td>1</td>
      <td>POLYGON ((-87.65456 41.99817, -87.65574 41.998...</td>
      <td>200102</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2001-03-31</td>
      <td>4.0</td>
      <td>1</td>
      <td>POLYGON ((-87.65456 41.99817, -87.65574 41.998...</td>
      <td>200103</td>
    </tr>
    <tr>
      <th>3</th>
      <td>2001-04-30</td>
      <td>5.0</td>
      <td>1</td>
      <td>POLYGON ((-87.65456 41.99817, -87.65574 41.998...</td>
      <td>200104</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2001-05-31</td>
      <td>3.0</td>
      <td>1</td>
      <td>POLYGON ((-87.65456 41.99817, -87.65574 41.998...</td>
      <td>200105</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>20231</th>
      <td>2022-07-31</td>
      <td>216.0</td>
      <td>77</td>
      <td>POLYGON ((-87.65456 41.99817, -87.65456 41.998...</td>
      <td>202207</td>
    </tr>
    <tr>
      <th>20232</th>
      <td>2022-08-31</td>
      <td>268.0</td>
      <td>77</td>
      <td>POLYGON ((-87.65456 41.99817, -87.65456 41.998...</td>
      <td>202208</td>
    </tr>
    <tr>
      <th>20233</th>
      <td>2022-09-30</td>
      <td>261.0</td>
      <td>77</td>
      <td>POLYGON ((-87.65456 41.99817, -87.65456 41.998...</td>
      <td>202209</td>
    </tr>
    <tr>
      <th>20234</th>
      <td>2022-10-31</td>
      <td>283.0</td>
      <td>77</td>
      <td>POLYGON ((-87.65456 41.99817, -87.65456 41.998...</td>
      <td>202210</td>
    </tr>
    <tr>
      <th>20235</th>
      <td>2022-11-30</td>
      <td>173.0</td>
      <td>77</td>
      <td>POLYGON ((-87.65456 41.99817, -87.65456 41.998...</td>
      <td>202211</td>
    </tr>
  </tbody>
</table>
<p>20236 rows × 5 columns</p>
</div>




```python
crimes_M_gdf
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>ts</th>
      <th>M_sum</th>
      <th>area_numbe</th>
      <th>geometry</th>
      <th>ts_sft</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2001-01-31</td>
      <td>11.0</td>
      <td>1</td>
      <td>POLYGON ((-87.65456 41.99817, -87.65574 41.998...</td>
      <td>2001</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2001-02-28</td>
      <td>3.0</td>
      <td>1</td>
      <td>POLYGON ((-87.65456 41.99817, -87.65574 41.998...</td>
      <td>2001</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2001-03-31</td>
      <td>4.0</td>
      <td>1</td>
      <td>POLYGON ((-87.65456 41.99817, -87.65574 41.998...</td>
      <td>2001</td>
    </tr>
    <tr>
      <th>3</th>
      <td>2001-04-30</td>
      <td>5.0</td>
      <td>1</td>
      <td>POLYGON ((-87.65456 41.99817, -87.65574 41.998...</td>
      <td>2001</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2001-05-31</td>
      <td>3.0</td>
      <td>1</td>
      <td>POLYGON ((-87.65456 41.99817, -87.65574 41.998...</td>
      <td>2001</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>20231</th>
      <td>2022-07-31</td>
      <td>216.0</td>
      <td>77</td>
      <td>POLYGON ((-87.65456 41.99817, -87.65456 41.998...</td>
      <td>2022</td>
    </tr>
    <tr>
      <th>20232</th>
      <td>2022-08-31</td>
      <td>268.0</td>
      <td>77</td>
      <td>POLYGON ((-87.65456 41.99817, -87.65456 41.998...</td>
      <td>2022</td>
    </tr>
    <tr>
      <th>20233</th>
      <td>2022-09-30</td>
      <td>261.0</td>
      <td>77</td>
      <td>POLYGON ((-87.65456 41.99817, -87.65456 41.998...</td>
      <td>2022</td>
    </tr>
    <tr>
      <th>20234</th>
      <td>2022-10-31</td>
      <td>283.0</td>
      <td>77</td>
      <td>POLYGON ((-87.65456 41.99817, -87.65456 41.998...</td>
      <td>2022</td>
    </tr>
    <tr>
      <th>20235</th>
      <td>2022-11-30</td>
      <td>173.0</td>
      <td>77</td>
      <td>POLYGON ((-87.65456 41.99817, -87.65456 41.998...</td>
      <td>2022</td>
    </tr>
  </tbody>
</table>
<p>20236 rows × 5 columns</p>
</div>




```python
import giddy
import libpysal.weights as LW
import numpy as np

val_array=val_array_M
crimes_M_gdf['ts_sft']=crimes_M_gdf['ts'].apply(lambda x:x.strftime('%Y'))

#wr=LW.contiguity.Rook.from_dataframe(crimes_M_gdf.groupby('ts_sft').get_group('2001'))
wr=LW.contiguity.Rook.from_dataframe(community_area_gdf)
wr.transform='R'
r_val_array=(val_array.T / val_array.mean(axis=1))
sm=giddy.markov.Spatial_Markov(r_val_array,wr,fixed=True,k=5,m=5, fill_empty_classes=True ) # spatial_markov instance 
colorplot_2d_array_with_labels(sm.p.round(3),sm.classes,figsize=(3,3))    
```

<img src="./imgs/2_7_4/output_126_0.png" height='auto' width='auto' title="caDesign">
    



`PySAL-giddy`提供了`P`或者`summary`方法可以提取分析查看目标单元的邻里单元处于不同状态（不同分位数，由低值到高值标签0~4）下，目标单元的转移概率，例如图表中的“Spatial Lag 0”，为邻里单元状态为分位数标签0时不同状态转移概率矩阵，可以发现位于$0 \rightarrow 0$的状态转移概率为0.87，说明当邻里单元观测值为状态标签0，即较低值时，目标单元如果状态标签也为0，处于较低值时，目标单元保持自身较低值的状态转移概率很高。但也注意到，$4 \rightarrow 4$的状态转移概率为0.7，一定程度上显示当邻里单元观测值为状态标签0时，目标单元如果状态标签为4较高值时，目标单元保持自身状态的概率较之目标单元为0的状态时低，即有部分会向状态3、2等低值状态转化；同样，从图表中的“Spatial Lag 4”可以观察到如果邻里单元观测值为标签4，较高值时，目标单元也为标签4的较高值，则目标单元保持自身较高值的状态转移概率很高为0.97，但如果邻里单元观测值为标签3时，对应图“Spatial Lag 3”，则目标单元为标签4保持自身的概率降至0.9。同时，注意到，在“Spatial Lag 4”中，$0 \rightarrow 0$的转移概率为0.94，接近，$4 \rightarrow 4$的转移概率0.97，但$2 \rightarrow 2$仅为0.56，这一定程度上表明，当邻里单元状态为高值时，目标单元处于状态高低区域保持自身的状态的概率都很高，但处于中间区域，例如状态2，向1和3状态都有一定转移。


```python
sm.summary() # sm.P
```

    --------------------------------------------------------------
                         Spatial Markov Test                      
    --------------------------------------------------------------
    Number of classes: 5
    Number of transitions: 20174
    Number of regimes: 5
    Regime names: LAG0, LAG1, LAG2, LAG3, LAG4
    --------------------------------------------------------------
       Test                   LR                Chi-2
      Stat.             1073.791             2361.386
        DOF                   76                   76
    p-value                0.000                0.000
    --------------------------------------------------------------
    P(H0)           C0         C1         C2         C3         C4
         C0      0.853      0.134      0.011      0.002      0.000
         C1      0.131      0.768      0.097      0.003      0.000
         C2      0.009      0.096      0.816      0.075      0.004
         C3      0.003      0.002      0.074      0.861      0.060
         C4      0.000      0.001      0.002      0.060      0.936
    --------------------------------------------------------------
    P(LAG0)         C0         C1         C2         C3         C4
         C0      0.870      0.110      0.017      0.002      0.000
         C1      0.164      0.731      0.100      0.005      0.000
         C2      0.024      0.122      0.779      0.072      0.002
         C3      0.020      0.014      0.203      0.756      0.007
         C4      0.050      0.000      0.100      0.150      0.700
    --------------------------------------------------------------
    P(LAG1)         C0         C1         C2         C3         C4
         C0      0.791      0.199      0.007      0.003      0.000
         C1      0.138      0.752      0.109      0.001      0.001
         C2      0.004      0.146      0.730      0.116      0.004
         C3      0.008      0.004      0.210      0.767      0.011
         C4      0.000      0.250      0.083      0.333      0.333
    --------------------------------------------------------------
    P(LAG2)         C0         C1         C2         C3         C4
         C0      0.840      0.152      0.006      0.001      0.000
         C1      0.173      0.734      0.087      0.004      0.001
         C2      0.007      0.091      0.871      0.026      0.005
         C3      0.000      0.002      0.020      0.931      0.047
         C4      0.000      0.000      0.002      0.154      0.844
    --------------------------------------------------------------
    P(LAG3)         C0         C1         C2         C3         C4
         C0      0.938      0.058      0.004      0.000      0.000
         C1      0.029      0.867      0.096      0.008      0.000
         C2      0.002      0.035      0.889      0.073      0.002
         C3      0.001      0.000      0.085      0.814      0.100
         C4      0.000      0.000      0.004      0.094      0.902
    --------------------------------------------------------------
    P(LAG4)         C0         C1         C2         C3         C4
         C0      0.941      0.052      0.007      0.000      0.000
         C1      0.056      0.893      0.052      0.000      0.000
         C2      0.029      0.221      0.559      0.147      0.044
         C3      0.000      0.001      0.016      0.901      0.082
         C4      0.000      0.000      0.001      0.029      0.970
    --------------------------------------------------------------
    


```python
def spatial_markov_lag(sm,**args):
    '''
    打印空间马尔科夫状态滞后图表

    Parameters
    ----------
    sm : giddy.markov.Spatial_Markov
        空间马尔科夫链.
    **args : TYPE
        图表打印样式，默认值为：
            setting=dict(figsize=(10,7),
                 cmap="coolwarm",
                 subplots_adjust_right=0.92,
                 subplots_rows_cols=(2,3)
                ).

    Returns
    -------
    None.

    '''    
    import matplotlib.pyplot as plt
    
    setting=dict(figsize=(10,7),
                 cmap="coolwarm",
                 subplots_adjust_right=0.92,
                 subplots_rows_cols=(2,3)
                )
    
    fig, axes=plt.subplots(setting['subplots_rows_cols'][0],setting['subplots_rows_cols'][1],figsize=setting['figsize']) 
    for i in range(2):
        for j in range(3):
            ax=axes[i,j]
            if i==0 and j==0:
                p_temp=sm.p
                im=ax.imshow(p_temp,cmap=setting['cmap'],vmin=0, vmax=1)
                ax.set_title("Pooled",fontsize=18) 
            else:
                p_temp=sm.P[i*3+j-1]
                im=ax.imshow(p_temp,cmap=setting['cmap'],vmin=0, vmax=1)
                ax.set_title("Spatial Lag %d"%(i*3+j-1),fontsize=18) 
            for x in range(len(p_temp)):
                for y in range(len(p_temp)):
                    text=ax.text(y, x, round(p_temp[x, y], 2),
                                   ha="center", va="center", color="w")

    fig.subplots_adjust(right=setting['subplots_adjust_right'])
    cbar_ax=fig.add_axes([0.95, 0.228, 0.01, 0.5])
    fig.colorbar(im, cax=cbar_ax)
    plt.show()
    
spatial_markov_lag(sm)    
```

<img src="./imgs/2_7_4/output_129_0.png" height='auto' width='auto' title="caDesign">
    
    


`sm.S`方法可以估计不同状态空间滞后的平稳状态分布，从结果可以得知，各行为邻里单元所处状态（由低值到高值标签0-4的不同分位数），各列为目标单元所处状态（由低值到高值标签0-4的不同分位数），例如对于第1行第1个值，邻里单元状态为0（低值），目标单元处于状态0长期分布有0.407的比例，第1行第2个值，目标单元处于状态1长期分布有0.274的比例，依次类推，对于第1行最后一个值，目标单元处于状态4时长期分布有0.004的比例，每一行的比例之和为1；同样，对于第5行最后一个值，为邻里单元状态为4（高值）时，目标单元状态为4时，长期分布占0.588的比例等。可以发现，长期平稳状态下，邻里单元观测值为低值时，目标单元中观测值也处于低值的比例较高；同样，邻里单元观测值为高值时，目标单元中观测值也处于高值的比例较高。


```python
sm.S.round(3)
```




    array([[0.407, 0.276, 0.233, 0.081, 0.004],
           [0.243, 0.354, 0.259, 0.139, 0.004],
           [0.21 , 0.186, 0.187, 0.315, 0.102],
           [0.062, 0.107, 0.302, 0.259, 0.27 ],
           [0.096, 0.092, 0.021, 0.203, 0.588]])



`sm.F`用于计算邻里单元处于不同状态下状态转移平均所需时间，例如当邻里单元为状态0时（第1组），目标单元状态为0时，回到状态0即$0 \rightarrow 0$需要2.485年，而状态0到状态1即$0 \rightarrow 1$需要9.334年，如果要到达状态4即$0 \rightarrow 4$则需要961.611年；同样，当邻里单元为状态4时（最后一组），目标单元为状态0，对于$0 \rightarrow 4$的状态转化只需要113.74年，较之处于邻里单元状态为0的条件，$0 \rightarrow 4$的转换961.611年而言有较大的缩短；而，由$4 \rightarrow 4$也仅需要1.701年。


```python
print(sm.F.round(3))
```

    [[[  2.458   9.334  23.015  63.717 961.611]
      [ 10.251   3.624  17.879  58.997 956.69 ]
      [ 16.576  10.219   4.3    44.468 940.537]
      [ 18.99   13.813   7.309  12.335 921.161]
      [ 18.354  15.202  10.824  28.775 281.308]]
    
     [[  4.109   5.301  18.581  43.479 366.569]
      [ 14.389   2.822  14.403  39.711 362.524]
      [ 23.297   9.887   3.864  26.116 350.607]
      [ 26.688  13.867   5.613   7.182 338.518]
      [ 23.152   9.67    9.708  19.656 233.687]]
    
     [[  4.763   8.045  30.582 101.921 146.671]
      [ 21.808   5.371  25.058  97.031 141.689]
      [ 48.106  28.492   5.347  82.26  127.081]
      [104.002  84.241  59.329   3.176  55.402]
      [109.592  89.833  64.869   7.621   9.805]]
    
     [[ 16.184  21.342  30.532  47.755  73.954]
      [241.123   9.343  15.496  32.496  58.699]
      [297.048  72.787   3.308  20.118  46.264]
      [316.262  94.698  22.812   3.863  26.934]
      [325.743 104.071  32.149  11.055   3.703]]
    
     [[ 10.4    34.859  46.06  104.692 113.74 ]
      [142.448  10.885  33.134  91.767 100.815]
      [275.786 153.298  48.063  58.633  67.681]
      [460.227 336.555 194.31    4.921  22.271]
      [488.86  365.22  222.683  35.03    1.701]]]
    

对于条件型空间依赖性的检验包括似然比（Likelihood Ratio，LR）检验和$ \chi ^{2} $检验<sup>[4]</sup>，以及基于信息论的检验<sup>[5]</sup>，对于前两个检验，可以用`giddy`库提供的如下方法计算，获得统计数据、DOF和P值。

从计算结果来看，LR检验结果为111.320，p-value值为0；$ \chi ^{2} $检验结果为419.927，p-value值为0，因此拒绝条件空间独立性的无效假设。


```python
giddy.markov.Homogeneity_Results(sm.T).summary()
```

    --------------------------------------------------
                 Markov Homogeneity Test              
    --------------------------------------------------
    Number of classes: 5
    Number of transitions: 1617
    Number of regimes: 5
    Regime names: 0, 1, 2, 3, 4
    --------------------------------------------------
       Test                   LR                Chi-2
      Stat.              111.320              419.927
        DOF                   42                   42
    p-value                0.000                0.000
    --------------------------------------------------
    P(H0)        0        1        2        3        4
        0    0.887    0.110    0.003    0.000    0.000
        1    0.074    0.839    0.084    0.003    0.000
        2    0.000    0.053    0.875    0.072    0.000
        3    0.000    0.000    0.044    0.881    0.075
        4    0.000    0.003    0.000    0.046    0.951
    --------------------------------------------------
    P(0)         0        1        2        3        4
        0    0.880    0.113    0.007    0.000    0.000
        1    0.099    0.736    0.154    0.011    0.000
        2    0.000    0.100    0.786    0.114    0.000
        3    0.000    0.000    0.136    0.818    0.045
        4    0.000    1.000    0.000    0.000    0.000
    --------------------------------------------------
    P(1)         0        1        2        3        4
        0    0.831    0.169    0.000    0.000    0.000
        1    0.066    0.844    0.090    0.000    0.000
        2    0.000    0.095    0.784    0.122    0.000
        3    0.000    0.000    0.186    0.744    0.070
        4    0.000    0.000    0.000    0.000    0.000
    --------------------------------------------------
    P(2)         0        1        2        3        4
        0    0.937    0.063    0.000    0.000    0.000
        1    0.143    0.833    0.024    0.000    0.000
        2    0.000    0.030    0.955    0.015    0.000
        3    0.000    0.000    0.000    0.939    0.061
        4    0.000    0.000    0.000    0.081    0.919
    --------------------------------------------------
    P(3)         0        1        2        3        4
        0    0.941    0.059    0.000    0.000    0.000
        1    0.021    0.958    0.021    0.000    0.000
        2    0.000    0.009    0.943    0.047    0.000
        3    0.000    0.000    0.042    0.845    0.113
        4    0.000    0.000    0.000    0.090    0.910
    --------------------------------------------------
    P(4)         0        1        2        3        4
        0    0.955    0.045    0.000    0.000    0.000
        1    0.000    1.000    0.000    0.000    0.000
        2    0.000    0.000    1.000    0.000    0.000
        3    0.000    0.000    0.000    0.928    0.072
        4    0.000    0.000    0.000    0.024    0.976
    --------------------------------------------------
    

基于信息论的检验调用`kullback`方法计算，结果与LR和$ \chi ^{2} $检验结果同，观察到检验统计量为162.419，其p-value为1.484809997176484e-07，拒绝条件空间独立性的无效假设。


```python
print(giddy.markov.kullback(sm.T))
```

    {'Conditional homogeneity': 162.41979588493268, 'Conditional homogeneity dof': 80, 'Conditional homogeneity pvalue': 1.484809997176484e-07}
    

#### 6）局部空间自相关马尔科夫（LISA Markov）

`giddy`提供了`LISA_Markov`方法，将局部空间自相关，高-高（HH，0）、低-高（LH，1）、低-低（LL，2）和高-低（HL，3）作为4种状态，计算这4种状态之间的转移矩阵、转移概率矩阵和平稳状态转移概率等。从下述计算结果，观察转移概率矩阵的对角线估计值，可以发现HL（3）概率值为0.820，相对HH（0）、LH（1）和LL（2）值低，即具有相对较高的流动性，其它3种状态则具有相对较高的稳定性。

为了检验目标单元与其邻里单元间的动态关系，使用`lm.chi_2)`方法进行$ \chi ^{2} $的独立性检验，其p-value等于0，拒绝原条件空间独立性的无效假设，即目标单元和邻里单元对犯罪报告记录局部空间自相关4种状态的转变存在空间的影响。


```python
lm=giddy.markov.LISA_Markov(val_array.T, wr)
markov_info_print(lm,decimal=3)
```

    --------------------------------------------------
    Unique classes: [1 2 3 4]
    Transition matrix:
             1       2       3       4
    1  5228.0    80.0    15.0   138.0
    2    87.0  2764.0   139.0     9.0
    3    21.0   143.0  9232.0   227.0
    4   140.0    10.0   227.0  1714.0
    Transition probability matrix:
            1      2      3      4
    1  0.957  0.015  0.003  0.025
    2  0.029  0.922  0.046  0.003
    3  0.002  0.015  0.959  0.024
    4  0.067  0.005  0.109  0.820
    ergodic matrix:
             1       2       3       4
    1   3.497  73.854  48.897  46.777
    2  61.467   6.774  31.804  58.854
    3  78.806  73.367   2.158  48.648
    4  54.628  77.148  24.548   9.695
    Steady_state: [0.286 0.148 0.463 0.103]
    


```python
colorplot_2d_array_with_labels(lm.p.round(3),sm.classes,figsize=(3,3))  
```


<img src="./imgs/2_7_4/output_140_0.png" height='auto' width='auto' title="caDesign">    




```python
print(lm.chi_2)
```

    (18720.987813562097, 0.0, 9)
    

---

注释（Notes）：

① MODIS Grids，（<https://modis-land.gsfc.nasa.gov/MODLAND_grid.html>）。

② Table of Tile Bounding Coordinates (10 deg tiles)，（<https://modis-land.gsfc.nasa.gov/pdf/sn_bound_10deg.txt>）。

③ Table of Tile G-ring Coordinates (10 deg tiles)，（<https://modis-land.gsfc.nasa.gov/pdf/sn_gring_10deg.txt>）。

④ General Cartographic Transformation Package (GCTP) projection parameters and other tile infomation，（<https://modis-land.gsfc.nasa.gov/GCTP.html>）。

⑤ Table of Tile Bounding Coordinates，（<https://modis-land.gsfc.nasa.gov/pdf/MODISPolarGridTiles.pdf>）。

⑥ lat/long bounding (G-ring) coordinates，（<https://modis-land.gsfc.nasa.gov/lat_long_tiles.txt>）。

⑦ MCD12Q1_v006数据集下载地址，（<https://e4ftl01.cr.usgs.gov/MOTA/MCD12Q1.006/>）。

⑧ Web crawling with Python，（<https://www.scrapingbee.com/blog/crawling-python/>）。

⑨ plot_colortable()绘制一个matplotlib支持命名颜色的列表函数，（<https://matplotlib.org/3.1.1/gallery/color/named_colors.html>）。

⑩ rioxarray，rasterio xarray extension（<https://github.com/corteva/rioxarray>）。

⑪ 2015年中国省级行政边界数据，来自于中国科学院资源环境科学与数据中心（<https://www.resdc.cn/data.aspx?DATAID=200>）。

⑫ Xarray库，（<https://docs.xarray.dev/en/stable/index.html>）。

⑬ netCDF（Network Common Data Form），（<https://en.wikipedia.org/wiki/NetCDF>）。

⑭ Crimes - 2001 to present，该数据集反映了2001年至今发生在芝加哥市的报告犯罪事件（谋杀除外），减去最近的七天。（<https://data.cityofchicago.org/Public-Safety/Crimes-2001-to-present-Dashboard/5cd6-ry5g>）。

⑮ Time series / date functionality：Offset aliases，一些字符串别名被赋予有用的普通时间序列频率,称为偏移别名（<https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases>）。

⑯ PySAL-giddy，Giddy是一个开源的Python库，用于分析纵向空间数据的动态变化（<https://pysal.org/notebooks/explore/giddy/intro.html>）。

参考文献（References）:

[1] Damien Sulla-Menashe and Mark A Friedl. User Guide to Collection 6 MODIS Land Cover (MCD12Q1 and MCD12C1) Product.May 14, 2018. <https://lpdaac.usgs.gov/products/mcd12q1v006/>

[2] Spatially Explicit Markov Methods，<http://pysal.org/notebooks/explore/giddy/Markov_Based_Methods.html>.

[3] Rey, S. J. 2001. “Spatial Empirics for Economic Growth and Convergence.” Geographical Analysis 33 (3). Wiley Online Library: 195–214.

[4] Bickenbach, F., and E. Bode. 2003. “Evaluating the Markov Property in Studies of Economic Convergence.” International Regional Science Review 26 (3): 363–92.

[5] Kullback, S., M. Kupperman, and H. H. Ku. 1962. “Tests for Contingency Tables and Markov Chains.” Technometrics: A Journal of Statistics for the Physical, Chemical, and Engineering Sciences 4 (4). JSTOR: 573–608.
